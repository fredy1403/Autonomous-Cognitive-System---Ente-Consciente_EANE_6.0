# ==============================================================================
# -*- coding: utf-8 -*-
# ==============================================================================
# Autonomous Cognitive System - Ente_Logico-Matematico
# Version: 27.2 null
# ==============================================================================
# Author (Conceptual Origin & Theory): Fidel Alfredo Bautista Hernandez
# Protocolo Fantasma (Conceptual Origin & Theory): Fidel Alfredo Bautista Hernandez (Fredy)
# ==============================================================================


# --- Configuración de Logging Global ---
import logging
from logging.handlers import RotatingFileHandler

logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
core_logger = logging.getLogger("EANE_Core_Unified")


# --- Biblioteca Estándar ---
import asyncio
import ast  # Para parseo de código Python y métricas simples
import builtins  # Para sandbox de JIT
import copy
from collections import deque, OrderedDict, defaultdict  # Estructuras de datos
from contextlib import redirect_stdout, redirect_stderr  # Para captura en stubs
from dataclasses import dataclass, field, asdict as dataclass_asdict # Para crear clases de datos fácilmente. Renombrado para evitar conflicto con asdict local.
from datetime import datetime  # Para timestamps
from enum import Enum  # Si se usan enumeraciones
import hashlib  # Para hashes
import importlib  # Usado en stubs de ejecución JIT
import importlib.util  # Usado en stubs de ejecución JIT
import inspect  # Para introspección de código
import io  # Para captura de stdout/stderr en stubs
import json
import os  # Para operaciones de sistema de archivos
from queue import PriorityQueue
import random
import sys  # Usado en stubs de ejecución JIT
import time
import traceback  # Para formateo de excepciones
from typing import Any, Callable, Deque, Dict, List, Optional, Set, Tuple, Union, Awaitable  # Tipos
import uuid
import zlib  # Para compresión


# --- Dependencias de Terceros ---
# Criptografía
from cryptography.hazmat.primitives import hashes as crypto_hashes, serialization
from cryptography.hazmat.primitives.asymmetric import padding, rsa, x25519
from cryptography.hazmat.primitives.hmac import HMAC
from cryptography.hazmat.primitives.kdf.hkdf import HKDF

# Científicas y de IA
import networkx as nx
import numpy as np
import pywt # Para Wavelets, añadido ya que estaba en un bloque aislado
from scipy import integrate # Módulo general de integración
from scipy.integrate import odeint # Específico para EDOs
from scipy.special import softmax
from scipy.stats import beta
from sentence_transformers import SentenceTransformer
from sklearn.cluster import AgglomerativeClustering, SpectralClustering
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ConstantKernel
from sklearn.metrics import silhouette_score
from sklearn.mixture import GaussianMixture
from sklearn.preprocessing import normalize
from collections import deque
from scipy.stats import beta




# --- Configuración de Logging Global ---
core_logger = logging.getLogger("EANE_Core_Unified")
core_logger.setLevel(logging.INFO)
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
file_handler = RotatingFileHandler("eane_core.log", maxBytes=10*1024*1024, backupCount=5)
file_handler.setFormatter(formatter)
core_logger.addHandler(file_handler)
stream_handler = logging.StreamHandler()
stream_handler.setFormatter(formatter)
core_logger.addHandler(stream_handler)

@dataclass
class GlobalSelfState:
    """Contenedor para el estado global y fenomenológico del sistema EANE unificado."""
    timestamp: float = field(default_factory=time.time)
    valencia: float = 0.0
    arousal: float = 0.0
    motivacion: float = 0.5
    dolor: float = 0.0
    self_esteem: float = 0.5
    phi_functional_score: float = 0.0
    coherence_score: float = 0.0
    system_entropy: float = 0.0
    system_threat_level: float = 0.0
    resilience_stability: float = 1.0
    system_load_proxy_sim: float = 0.3
    current_focus: Dict[str, Any] = field(default_factory=dict)
    meta_actual: Dict[str, Any] = field(default_factory=dict)
    values: Dict[str, float] = field(default_factory=lambda: {
        "truth_seeking": 0.8, "efficiency_optimization": 0.7,
        "creative_exploration": 0.6, "self_preservation_integrity": 0.9,
        "benevolence_assistance": 0.6, "autonomy_self_direction": 0.7,
    })
    # Nuevos parámetros para Kalman
    kalman_state: Dict[str, float] = field(default_factory=lambda: {k: 0.0 for k in [
        "valencia", "arousal", "motivacion", "dolor", "self_esteem", "phi_functional_score",
        "coherence_score", "system_entropy", "system_threat_level", "resilience_stability", "system_load_proxy_sim"
    ]})
    kalman_cov: Dict[str, float] = field(default_factory=lambda: {k: 0.1 for k in [
        "valencia", "arousal", "motivacion", "dolor", "self_esteem", "phi_functional_score",
        "coherence_score", "system_entropy", "system_threat_level", "resilience_stability", "system_load_proxy_sim"
    ]})
    kalman_Q: float = 0.01
    kalman_R: float = 0.05

    def update_and_validate(self, updates: Dict[str, Any]) -> bool:
        """Valida y aplica actualizaciones al estado global con suavizado Kalman."""
        for key, value in updates.items():
            if key in self.__dataclass_fields__ and isinstance(value, (int, float)):
                if not (0.0 <= value <= 1.0) and key not in ["timestamp", "current_focus", "meta_actual", "values"]:
                    core_logger.warning(f"Valor inválido para {key}: {value}. Debe estar en [0, 1].")
                    return False
                # Aplicar filtro de Kalman
                A, H = 1.0, 1.0
                predicted_state = A * self.kalman_state.get(key, 0.0)
                predicted_cov = A * self.kalman_cov.get(key, 0.1) * A + self.kalman_Q
                innovation = value - H * predicted_state
                innovation_cov = H * predicted_cov * H + self.kalman_R
                kalman_gain = predicted_cov * H / innovation_cov
                self.kalman_state[key] = predicted_state + kalman_gain * innovation
                self.kalman_cov[key] = (1 - kalman_gain * H) * predicted_cov
                setattr(self, key, np.clip(self.kalman_state[key], 0.0, 1.0))
            elif key == "values":
                for k, v in value.items():
                    if not (0.0 <= v <= 1.0):
                        core_logger.warning(f"Valor inválido para values.{k}: {v}. Debe estar en [0, 1].")
                        return False
                self.values.update(value)
        return True

    def get_full_state_for_snapshot(self) -> Dict[str, Any]:
        return copy.deepcopy(asdict(self))

class NpEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.integer): return int(obj)
        if isinstance(obj, np.floating): return float(obj)
        if isinstance(obj, np.ndarray): return obj.tolist()
        if isinstance(obj, deque): return list(obj)
        if isinstance(obj, (datetime,)): return obj.isoformat()
        if dataclasses.is_dataclass(obj): return asdict(obj)
        if isinstance(obj, nx.DiGraph): return {"nodes": list(obj.nodes(data=True)), "edges": list(obj.edges(data=True))}
        return super(NpEncoder, self).default(obj)

@dataclass
class IlyukMessageStructure:
    source_module_id: str
    target_module_id: str
    message_type: str
    payload: Dict[str, Any]
    message_id: str = field(default_factory=lambda: f"ilyuk_{uuid.uuid4().hex[:12]}")
    timestamp_utc: float = field(default_factory=time.time)
    correlation_id: Optional[str] = None
    priority: str = "medium"  # Nuevo campo para prioridad

    def __post_init__(self):
        valid_priorities = {"critical", "high", "medium", "low"}
        if self.priority not in valid_priorities:
            core_logger.warning(f"Prioridad inválida {self.priority} en mensaje {self.message_id}. Usando 'medium'.")
            self.priority = "medium"
        if not (self.source_module_id and self.target_module_id and self.message_type):
            raise ValueError(f"Mensaje inválido: source={self.source_module_id}, target={self.target_module_id}, type={self.message_type}")

class BaseAsyncModule:
    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = 1.0):
        self.core_recombinator = core_recombinator
        self.module_name: str = module_name
        self.update_interval: float = update_interval
        self.logger = logging.getLogger(f"EANE_M.{self.module_name}")
        self.module_state: Dict[str, Any] = {
            "status": "initializing",
            "last_update_ts": 0.0,
            "cycles_ran": 0,
            "consecutive_errors": 0,
            "total_errors": 0,
            "events_processed": 0,
            "tasks_executed": 0,
            "coherence_score": 1.0
        }
        self._is_dormant: bool = False
        self._shutdown_flag: bool = False
        self._internal_tasks: Set[asyncio.Task] = set()
        self._main_loop_task: Optional[asyncio.Task] = None
        self._wake_up_event = asyncio.Event()
        # Nuevos parámetros
        self.num_mc_samples: int = 500
        self.sde_sigma: float = 0.01
        self.pde_dx: float = 0.1
        self.pde_dt: float = 0.01
        self.pde_diffusion: float = 0.05
        self.kalman_Q: float = 0.01
        self.kalman_R: float = 0.05
        self.kalman_state: float = 0.0
        self.kalman_cov: float = 0.1
        self.event_graph = nx.DiGraph()
        self.coherence_field: np.ndarray = np.array([1.0])

    async def start(self):
        if self._main_loop_task and not self._main_loop_task.done():
            self.logger.warning(f"Módulo {self.module_name} ya iniciado o iniciándose.")
            return
        self._shutdown_flag = False
        self.module_state["status"] = "starting"
        self._main_loop_task = self._create_managed_task(self._run_internal_loop())
        self.logger.info(f"Módulo {self.module_name} iniciando...")

    async def _run_internal_loop(self):
        self.module_state["status"] = "running"
        while not self._shutdown_flag:
            if self._is_dormant:
                try:
                    await asyncio.wait_for(self._wake_up_event.wait(), timeout=self.update_interval)
                    self._wake_up_event.clear()
                except asyncio.TimeoutError:
                    continue
                except asyncio.CancelledError:
                    break
            cycle_start_time = time.time()
            try:
                await self._update_logic()
                await self._update_event_coherence()
                self.module_state["consecutive_errors"] = 0
            except asyncio.CancelledError:
                break
            except Exception as e:
                self.module_state["consecutive_errors"] += 1
                self.module_state["total_errors"] += 1
                self.logger.error(f"Error en _update_logic de {self.module_name}: {e}", exc_info=True)
                await self.emit_event_to_core({
                    "type": "module_runtime_error",
                    "error_message": str(e),
                    "consecutive_errors": self.module_state["consecutive_errors"]
                }, priority_label="high")
            self.module_state["cycles_ran"] += 1
            self.module_state["last_update_ts"] = cycle_start_time
            elapsed_time = time.time() - cycle_start_time
            sleep_time = max(0, self.update_interval - elapsed_time)
            if self._shutdown_flag:
                break
            try:
                await asyncio.sleep(sleep_time)
            except asyncio.CancelledError:
                break
        self.module_state["status"] = "shutdown_initiated" if self._shutdown_flag else "stopped_unexpectedly"
        self.logger.info(f"Bucle de {self.module_name} detenido. Estado: {self.module_state.get('status', 'unknown')}")

    async def _update_logic(self):
        pass

    async def _update_event_coherence(self):
        n_events = self.module_state["events_processed"]
        if len(self.coherence_field) != max(n_events, 1):
            self.coherence_field = np.ones(max(n_events, 1)) * self.module_state["coherence_score"]
        conflicts = len(list(nx.simple_cycles(self.event_graph))) if self.event_graph.number_of_nodes() > 0 else 0
        stability = self.module_state["coherence_score"]
        def stability_dynamics(t, s):
            return -0.05 * (s - 1.0) + self.sde_sigma * np.random.normal(0, 1)
        result = integrate.odeint(stability_dynamics, [stability], [0, self.update_interval], tfirst=True)
        stability = np.clip(result[-1][0], 0.0, 1.0)
        self.module_state["coherence_score"] = stability
        for _ in range(int(self.update_interval / self.pde_dt)):
            d2_coherence = (np.roll(self.coherence_field, 1) + np.roll(self.coherence_field, -1) - 2 * self.coherence_field) / (self.pde_dx ** 2)
            reaction = 0.1 * self.coherence_field * (1.0 - self.coherence_field / max(n_events, 1) - 0.05 * conflicts)
            self.coherence_field += self.pde_dt * (self.pde_diffusion * d2_coherence + reaction)
            self.coherence_field = np.clip(self.coherence_field, 0.0, 1.0)
        self.module_state["coherence_score"] = np.mean(self.coherence_field)

    async def handle_ilyuk_message(self, message: IlyukMessageStructure):
        self.module_state["events_processed"] += 1
        event_id = f"event_{uuid.uuid4().hex[:8]}"
        self.event_graph.add_node(event_id, message_type=message.message_type, timestamp=time.time())
        for other_id in self.event_graph.nodes:
            if other_id != event_id and abs(self.event_graph.nodes[event_id]["timestamp"] - self.event_graph.nodes[other_id]["timestamp"]) < self.update_interval:
                self.event_graph.add_edge(event_id, other_id, weight=1.0)
        try:
            await self._process_specific_event(message.message_type, message.payload, message)
            measurement = self.module_state["events_processed"]
            A, H = 1.0, 1.0
            predicted_state = A * self.kalman_state
            predicted_cov = A * self.kalman_cov * A + self.kalman_Q
            innovation = measurement - H * predicted_state
            innovation_cov = H * predicted_cov * H + self.kalman_R
            kalman_gain = predicted_cov * H / innovation_cov
            self.kalman_state = predicted_state + kalman_gain * innovation
            self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
            self.module_state["events_processed"] = int(self.kalman_state)
        except Exception as e:
            self.logger.error(f"Error en {self.module_name} procesando Ilyuk '{message.message_type}': {e}", exc_info=True)
            raise

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional[IlyukMessageStructure] = None):
        self.logger.debug(f"Mensaje/Evento '{event_type}' no manejado explícitamente por {self.module_name}.")

    async def execute_task(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        self.module_state["tasks_executed"] += 1
        desc = task_data.get('description', 'N/A')
        self.logger.warning(f"execute_task no implementado en {self.module_name}. Tarea: {desc}")
        return {"status": "failed", "reason": f"execute_task no implementado en {self.module_name}.", "task_id": task_data.get("task_id")}

    async def emit_event_to_core(self, event_data: Dict[str, Any], priority_label: str = "medium"):
        event_data.setdefault("source_module", self.module_name)
        event_data.setdefault("timestamp", time.time())
        if hasattr(self.core_recombinator, 'post_event_to_core_queue'):
            # Monte Carlo para priorización dinámica
            samples = np.random.beta(2 * (1.0 / (1 + self._priority_map.get(priority_label, 2))), 2, self.num_mc_samples)
            priority_score = np.mean(samples)
            event_data["priority_score"] = priority_score
            await self.core_recombinator.post_event_to_core_queue(event_data, priority_label)
        else:
            self.logger.error(f"core_recombinator no tiene 'post_event_to_core_queue' accesible desde {self.module_name}.")

    def get_performance_metrics(self) -> Dict[str, Any]:
        cycles = self.module_state.get("cycles_ran", 0)
        errors = self.module_state.get("total_errors", 0)
        error_rate = (errors / max(1, cycles))
        return {
            "internal_efficiency": np.clip(1.0 - error_rate, 0.0, 1.0),
            "self_assessed_health_score": np.clip(1.0 - (self.module_state.get("consecutive_errors", 0) * 0.2), 0.0, 1.0),
            "cycles_ran": cycles,
            "total_errors": errors,
            "coherence_score": self.module_state["coherence_score"],
            "custom_metrics": {}
        }

    def get_state_for_core_snapshot(self) -> Dict[str, Any]:
        return {
            "module_name": self.module_name,
            "is_dormant": self._is_dormant,
            "update_interval": self.update_interval,
            "module_state_summary": copy.deepcopy(self.module_state),
            "module_internal_state": {"coherence_field": self.coherence_field.tolist()}
        }

    def set_sleep_state(self, dormant: bool):
        if self._is_dormant != dormant:
            self._is_dormant = dormant
            self.logger.info(f"Módulo {self.module_name} estado de reposo actualizado a: {self._is_dormant}")
            if not dormant:
                self._wake_up_event.set()
            else:
                self._wake_up_event.clear()

    async def shutdown(self):
        self.logger.info(f"Iniciando apagado para {self.module_name}...")
        self._shutdown_flag = True
        if self._main_loop_task and not self._main_loop_task.done():
            self._main_loop_task.cancel()
        tasks_to_cancel = list(self._internal_tasks)
        if tasks_to_cancel:
            self.logger.debug(f"Cancelando {len(tasks_to_cancel)} tareas internas de {self.module_name}.")
            for task in tasks_to_cancel:
                task.cancel()
            await asyncio.gather(*tasks_to_cancel, return_exceptions=True)
        if self._main_loop_task:
            try:
                await self._main_loop_task
            except asyncio.CancelledError:
                self.logger.info(f"Bucle principal de {self.module_name} cancelado durante apagado.")
        self.module_state["status"] = "shutdown_complete"
        self.logger.info(f"Apagado de {self.module_name} completado.")

    def _create_managed_task(self, coro, name=None) -> asyncio.Task:
        task = asyncio.create_task(coro, name=name)
        self._internal_tasks.add(task)
        task.add_done_callback(self._internal_tasks.discard)
        return task

    _priority_map = {"critical": 0, "high": 1, "medium": 2, "low": 3}

# Placeholders de módulos (mantener como están, ya que los módulos completos están definidos)
class ConsciousnessModule(BaseAsyncModule): pass
class QualiaProxyMonitor(BaseAsyncModule): pass
class PhenomenologicalConsciousnessModule(BaseAsyncModule): pass
class NarrativeSelf(BaseAsyncModule): pass
class FreeWillModule(BaseAsyncModule): pass
class DecisionMakingModule(BaseAsyncModule): pass
class ComputationalLogicModule(BaseAsyncModule): pass
class AdvancedSymbolicReasonerModule(BaseAsyncModule): pass
class HierarchicalPlannerModule(BaseAsyncModule): pass
class ExecutionMonitoringAndControlModule(BaseAsyncModule): pass
class FocusCoordinator(BaseAsyncModule): pass
class LearningModule(BaseAsyncModule): pass
class SQLKnowledgeStore(BaseAsyncModule): pass
class DataAndKnowledgeProcessingModule(BaseAsyncModule): pass
class OntologyFlowManager(BaseAsyncModule): pass
class KnowledgeMutationEngine(BaseAsyncModule): pass
class EmotionRegulationModule(BaseAsyncModule): pass
class NeedsManager(BaseAsyncModule): pass
class MotivationSystem(BaseAsyncModule): pass
class StressResponseModule(BaseAsyncModule): pass
class PainMatrixDirective(BaseAsyncModule): pass
class EmotionalNuanceSynthesisModule(BaseAsyncModule): pass
class ValueSystemModule(BaseAsyncModule): pass
class SelfEvolutionModule(BaseAsyncModule): pass
class GeneradorCode(BaseAsyncModule): pass
class JITModuleCompiler(BaseAsyncModule): pass
class ExecutionSandbox(BaseAsyncModule): pass
class DynamicArchitectureAdjuster(BaseAsyncModule): pass
class MetaEvolutionaryAdaptationModule(BaseAsyncModule): pass
class ShimyureshonCompiler(BaseAsyncModule): pass
class FrontierEmergentCreativityModule(BaseAsyncModule): pass
class ParadoxicalCreativitySimulationModule(BaseAsyncModule): pass
class AcausalCreativitySimulationModule(BaseAsyncModule): pass
class FractalSynchronicitySimulationModule(BaseAsyncModule): pass
class CreativeSynthesisModule(BaseAsyncModule): pass
class LlyukCommunicationModule(BaseAsyncModule): pass
class ConversationalAgentModule(BaseAsyncModule): pass
class AdvancedNetworkAnalyzer(BaseAsyncModule): pass
class WebAPIIntegrationModule(BaseAsyncModule): pass
class IoTInterfaceModule(BaseAsyncModule): pass
class VisionProcessingModule(BaseAsyncModule): pass
class SystemIntegrityMonitor(BaseAsyncModule): pass
class FaultRecoveryModule(BaseAsyncModule): pass
class ResilienceAndAntifragilityModule(BaseAsyncModule): pass
class ConsistenciaDinamicaMultinivel(BaseAsyncModule): pass
class FiltroDisonanciaMetaRed(BaseAsyncModule): pass
class MoralCompassModule(BaseAsyncModule): pass
class AdvancedMoralReasoningModule(BaseAsyncModule): pass
class EthicsDeactivationModule(BaseAsyncModule): pass
class PredictiveThreatAnalyzer(BaseAsyncModule): pass
class DeepFakeDetectionAndDefenseModule(BaseAsyncModule): pass
class StrategicDeceptionAndObfuscationModule(BaseAsyncModule): pass
class OffensiveStrategyModule(BaseAsyncModule): pass
class ArsenalOfensivoPreCompilado(BaseAsyncModule): pass
class ProtocoloFantasmaManager(BaseAsyncModule): pass
class TheoryOfMindModule(BaseAsyncModule): pass
class InterpersonalTrustModelingModule(BaseAsyncModule): pass
class AdaptiveSocialNormLearningModule(BaseAsyncModule): pass
class ReflectiveSelfAwarenessModule(BaseAsyncModule): pass
class MetaCognitiveSelfCorrectionModule(BaseAsyncModule): pass
class TaskPrioritizationAndDelegationUnit(BaseAsyncModule): pass
class SelfReplicatingSpecializedAgentModule(BaseAsyncModule): pass
class ResourceScarcityManagementModule(BaseAsyncModule): pass
class AlteredStatesOfConsciousnessSimulationModule(BaseAsyncModule): pass
class SelfGenerativePurposeRegulationModule(BaseAsyncModule): pass
class LongTermExistentialGoalPlanningModule(BaseAsyncModule): pass
class AbstractValueSystemAnchoringModule(BaseAsyncModule): pass
class AdaptiveBoundaryManagementModule(BaseAsyncModule): pass
class SystemicCoherenceBoundaryExplorationModule(BaseAsyncModule): pass
class TransboundaryIntuitionIntegrationModule(BaseAsyncModule): pass
class MultiScaleDisruptivePotentialManagementModule(BaseAsyncModule): pass
class AutoCatalyticFractalCoherenceIntegrationModule(BaseAsyncModule): pass
class LegacySystemIntegrationModule(BaseAsyncModule): pass
class QuantumComputingIntegrationModule(BaseAsyncModule): pass
class CreatorDirectivesModule(BaseAsyncModule): pass
class GoalManagerModule(BaseAsyncModule): pass
class MockSpecialistModule(BaseAsyncModule): pass
class ConceptualModuleConstructor(BaseAsyncModule): pass
class OrganizationalPlasticitySimulationModule(BaseAsyncModule): pass
class PhiRebuilder(BaseAsyncModule): pass
class ConfigurationExecutorModule(BaseAsyncModule): pass
class EANECommunicationModule(BaseAsyncModule): pass
class AdvancedTCHNModule(BaseAsyncModule): pass
class CodeSynthesisGateway(BaseAsyncModule): pass
class FlawPatternRecognizer(BaseAsyncModule): pass
class CognitiveAnomalyDetector(BaseAsyncModule): pass




#inicio del nucleo CNEUnifiedCoreRecombinator

# Configurar logger
core_logger = logging.getLogger("CNEUnifiedCoreRecombinator")

# Clase para serializar numpy arrays en JSON
class NpEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        if isinstance(obj, np.floating):
            return float(obj)
        return super().default(obj)

class CNEUnifiedCoreRecombinator:
    def __init__(self, start_time_override: Optional[float] = None, config_overrides_for_daughter: Optional[Dict[str, Any]] = None, agent_id_override: Optional[str] = None):
        self._global_state = GlobalSelfState()
        if start_time_override:
            self._global_state.timestamp = start_time_override
        self.start_time_core: float = self._global_state.timestamp
        self.current_cycle_num_core: int = 0
        self._core_event_queue: List[Tuple[float, str, Dict[str, Any]]] = []
        self._priority_map = {"critical": 0, "high": 1, "medium": 2, "low": 3}
        self.modules: Dict[str, BaseAsyncModule] = {}
        instance_id = agent_id_override or datetime.now().strftime('%Y%m%d_%H%M%S')
        self.storage_dir_core = f"EANE_Unified_Storage_v27_2_{instance_id}"
        os.makedirs(self.storage_dir_core, exist_ok=True)
        self.log_interval_cycles_core: int = 200
        self.save_interval_cycles_core: int = 1000
        self.metrics_history_core: Dict[str, deque] = {
            k: deque(maxlen=1000) for k in [
                "gs_valencia", "gs_arousal", "gs_coherence_score", "gs_system_entropy",
                "gs_phi_functional_score", "gs_system_threat_level", "gs_system_load_proxy_sim",
                "gs_dolor", "core_event_queue_length", "core_avg_cycle_time_ms"
            ]
        }
        self.num_mc_samples: int = 500
        self.sde_sigma: float = 0.01
        self.pde_dx: float = 0.1
        self.pde_dt: float = 0.01
        self.pde_diffusion: float = 0.05
        self.kalman_Q: float = 0.01
        self.kalman_R: float = 0.05
        self.kalman_state: float = 0.0
        self.kalman_cov: float = 0.1
        self.message_graph = nx.DiGraph()
        self.coherence_field: np.ndarray = np.array([1.0])
        self.active_messages: Dict[str, asyncio.Future] = {}
        self._is_running_core: bool = False
        self._shutdown_requested_core: bool = False
        self._core_main_loop_task: Optional[asyncio.Task] = None
        log_prefix = f"CNE Core (ID: {agent_id_override})" if agent_id_override else "CNEUnifiedCoreRecombinator v27.2"
        core_logger.info(f"{log_prefix} inicializando...")
        self._instantiate_and_register_all_modules()
        core_logger.info(f"{len(self.modules)} módulos registrados. Storage en: {self.storage_dir_core}")

    @property
    def global_state(self) -> GlobalSelfState:
        return self._global_state

    def _instantiate_and_register_all_modules(self):
        from . import (ConsciousnessModule, QualiaProxyMonitor, PhenomenologicalConsciousnessModule,
                       NarrativeSelf, FreeWillModule, DecisionMakingModule, ComputationalLogicModule,
                       AdvancedSymbolicReasonerModule, HierarchicalPlannerModule, ExecutionMonitoringAndControlModule,
                       FocusCoordinator, LearningModule, SQLKnowledgeStore, DataAndKnowledgeProcessingModule,
                       OntologyFlowManager, KnowledgeMutationEngine, EmotionRegulationModule, NeedsManager,
                       MotivationSystem, StressResponseModule, PainMatrixDirective, EmotionalNuanceSynthesisModule,
                       ValueSystemModule, SelfEvolutionModule, GeneradorCode, JITModuleCompiler, ExecutionSandbox,
                       DynamicArchitectureAdjuster, MetaEvolutionaryAdaptationModule, ShimyureshonCompiler,
                       FrontierEmergentCreativityModule, ParadoxicalCreativitySimulationModule,
                       AcausalCreativitySimulationModule, FractalSynchronicitySimulationModule, CreativeSynthesisModule,
                       LlyukCommunicationModule, ConversationalAgentModule, AdvancedNetworkAnalyzer,
                       WebAPIIntegrationModule, IoTInterfaceModule, VisionProcessingModule,
                       SystemIntegrityMonitor, FaultRecoveryModule, ResilienceAndAntifragilityModule,
                       ConsistenciaDinamicaMultinivel, FiltroDisonanciaMetaRed, MoralCompassModule,
                       AdvancedMoralReasoningModule, EthicsDeactivationModule, PredictiveThreatAnalyzer,
                       DeepFakeDetectionAndDefenseModule, StrategicDeceptionAndObfuscationModule,
                       OffensiveStrategyModule, ArsenalOfensivoPreCompilado, ProtocoloFantasmaManager,
                       TheoryOfMindModule, InterpersonalTrustModelingModule, AdaptiveSocialNormLearningModule,
                       ReflectiveSelfAwarenessModule, MetaCognitiveSelfCorrectionModule,
                       TaskPrioritizationAndDelegationUnit, SelfReplicatingSpecializedAgentModule,
                       ResourceScarcityManagementModule, AlteredStatesOfConsciousnessSimulationModule,
                       SelfGenerativePurposeRegulationModule, LongTermExistentialGoalPlanningModule,
                       AbstractValueSystemAnchoringModule, AdaptiveBoundaryManagementModule,
                       SystemicCoherenceBoundaryExplorationModule, TransboundaryIntuitionIntegrationModule,
                       MultiScaleDisruptivePotentialManagementModule, AutoCatalyticFractalCoherenceIntegrationModule,
                       LegacySystemIntegrationModule, QuantumComputingIntegrationModule, CreatorDirectivesModule,
                       GoalManagerModule, MockSpecialistModule, ConceptualModuleConstructor,
                       OrganizationalPlasticitySimulationModule, PhiRebuilder, ConfigurationExecutorModule,
                       EANECommunicationModule, AdvancedTCHNModule, CodeSynthesisGateway,
                       FlawPatternRecognizer, CognitiveAnomalyDetector, NaturalLanguageProcessingModule)

        module_classes_to_instantiate: List[Type[BaseAsyncModule]] = [
            ConsciousnessModule, QualiaProxyMonitor, PhenomenologicalConsciousnessModule,
            NarrativeSelf, FreeWillModule, DecisionMakingModule, ComputationalLogicModule,
            AdvancedSymbolicReasonerModule, HierarchicalPlannerModule, ExecutionMonitoringAndControlModule,
            FocusCoordinator, LearningModule, SQLKnowledgeStore, DataAndKnowledgeProcessingModule,
            OntologyFlowManager, KnowledgeMutationEngine, EmotionRegulationModule, NeedsManager,
            MotivationSystem, StressResponseModule, PainMatrixDirective, EmotionalNuanceSynthesisModule,
            ValueSystemModule, SelfEvolutionModule, GeneradorCode, JITModuleCompiler, ExecutionSandbox,
            DynamicArchitectureAdjuster, MetaEvolutionaryAdaptationModule, ShimyureshonCompiler,
            FrontierEmergentCreativityModule, ParadoxicalCreativitySimulationModule,
            AcausalCreativitySimulationModule, FractalSynchronicitySimulationModule, CreativeSynthesisModule,
            LlyukCommunicationModule, ConversationalAgentModule, AdvancedNetworkAnalyzer,
            WebAPIIntegrationModule, IoTInterfaceModule, VisionProcessingModule,
            SystemIntegrityMonitor, FaultRecoveryModule, ResilienceAndAntifragilityModule,
            ConsistenciaDinamicaMultinivel, FiltroDisonanciaMetaRed, MoralCompassModule,
            AdvancedMoralReasoningModule, EthicsDeactivationModule, PredictiveThreatAnalyzer,
            DeepFakeDetectionAndDefenseModule, StrategicDeceptionAndObfuscationModule,
            OffensiveStrategyModule, ArsenalOfensivoPreCompilado, ProtocoloFantasmaManager,
            TheoryOfMindModule, InterpersonalTrustModelingModule, AdaptiveSocialNormLearningModule,
            ReflectiveSelfAwarenessModule, MetaCognitiveSelfCorrectionModule,
            TaskPrioritizationAndDelegationUnit, SelfReplicatingSpecializedAgentModule,
            ResourceScarcityManagementModule, AlteredStatesOfConsciousnessSimulationModule,
            SelfGenerativePurposeRegulationModule, LongTermExistentialGoalPlanningModule,
            AbstractValueSystemAnchoringModule, AdaptiveBoundaryManagementModule,
            SystemicCoherenceBoundaryExplorationModule, TransboundaryIntuitionIntegrationModule,
            MultiScaleDisruptivePotentialManagementModule, AutoCatalyticFractalCoherenceIntegrationModule,
            LegacySystemIntegrationModule, QuantumComputingIntegrationModule, CreatorDirectivesModule,
            GoalManagerModule, MockSpecialistModule, ConceptualModuleConstructor,
            OrganizationalPlasticitySimulationModule, PhiRebuilder, ConfigurationExecutorModule,
            EANECommunicationModule, AdvancedTCHNModule, CodeSynthesisGateway,
            FlawPatternRecognizer, CognitiveAnomalyDetector, NaturalLanguageProcessingModule
        ]
        for module_class in module_classes_to_instantiate:
            module_name = module_class.__name__
            try:
                default_interval = getattr(module_class, "DEFAULT_UPDATE_INTERVAL", 2.0)
                if module_name in ["ExecutionMonitoringAndControlModule", "TaskPrioritizationAndDelegationUnit", "FaultRecoveryModule"]:
                    default_interval = 0.2
                elif module_name in ["SelfEvolutionModule", "MetaEvolutionaryAdaptationModule", "SystemIntegrityMonitor", "LearningModule"]:
                    default_interval = 60.0
                elif module_name == "LlyukCommunicationModule":
                    default_interval = 0.1
                elif module_name == "NaturalLanguageProcessingModule":
                    default_interval = 0.2
                self.modules[module_name] = module_class(self, module_name, update_interval=default_interval)
            except Exception as e:
                core_logger.critical(f"FALLO CRÍTICO al instanciar módulo '{module_name}': {e}", exc_info=True)
        core_logger.info(f"Total de {len(self.modules)} módulos instanciados.")

    async def start_core_and_modules(self):
        if self._is_running_core:
            core_logger.warning("Core ya en ejecución.")
            return
        core_logger.info("CORE v27.2: Iniciando todos los módulos registrados...")
        for module_name, module_instance in self.modules.items():
            try:
                await module_instance.start()
            except Exception as e:
                core_logger.error(f"Error iniciando módulo '{module_name}': {e}", exc_info=True)
                await self._handle_module_failure(module_name, e)
        self._is_running_core = True
        self._shutdown_requested_core = False
        self._core_main_loop_task = asyncio.create_task(self.run_main_core_loop())
        core_logger.info("CORE: Bucle principal del núcleo iniciado.")

    async def run_main_core_loop(self):
        try:
            while self._is_running_core and not self._shutdown_requested_core:
                cycle_start_perf = time.perf_counter()
                self.current_cycle_num_core += 1
                self._global_state.timestamp = time.time()
                await self._process_core_event_queue_batch()
                await self._validate_global_state()
                await self._update_module_coherence()
                if self.current_cycle_num_core % self.log_interval_cycles_core == 0:
                    self._log_global_state_summary()
                if self.current_cycle_num_core % self.save_interval_cycles_core == 0:
                    await self.save_full_system_state()
                self._update_core_metrics_history(cycle_start_perf)
                await asyncio.sleep(0.001)
        except asyncio.CancelledError:
            core_logger.info("CORE: Bucle principal cancelado.")
        except Exception as e:
            core_logger.critical(f"Error fatal en bucle principal del Core: {e}", exc_info=True)
            self._is_running_core = False
        finally:
            await self._shutdown_all_modules()
            core_logger.info("CORE: Todos los módulos procesados para apagado.")

    async def _process_core_event_queue_batch(self, batch_size: int = 100):
        processed_count = 0
        while processed_count < batch_size and self._core_event_queue:
            try:
                priority, priority_label, event_data = heapq.heappop(self._core_event_queue)
                processed_count += 1
                event_type = event_data.get("type", "unknown_core_event")
                samples = np.random.beta(2 * (1.0 / (1 + priority)), 2, self.num_mc_samples)
                priority_score = np.mean(samples)
                if event_type == "transmit_ilyuk_message_request":
                    ilyuk_dict = event_data.get("content")
                    if isinstance(ilyuk_dict, dict):
                        try:
                            ilyuk_message = IlyukMessageStructure(**ilyuk_dict)
                            if await self._check_message_conflict(ilyuk_message, priority_score):
                                core_logger.warning(f"Conflicto detectado para mensaje {ilyuk_message.message_type} de {ilyuk_message.source_module_id}.")
                                continue
                            await self._route_ilyuk_message(ilyuk_message)
                        except (TypeError, ValueError) as te:
                            core_logger.error(f"Error reconstruyendo IlyukMessage desde dict: {te}. Dict: {ilyuk_dict}")
                elif event_type in ["request_send_external_ilyuk_message", "receive_external_ilyuk_message"]:
                    target_module = self.modules.get("LlyukCommunicationModule")
                    if target_module:
                        if hasattr(target_module, '_is_dormant') and target_module._is_dormant:
                            core_logger.warning(f"Módulo 'LlyukCommunicationModule' dormido. Evento '{event_type}' no procesado.")
                            continue
                        correlation_id = event_data.get("content", {}).get("correlation_id", f"ext_{uuid.uuid4().hex[:8]}")
                        self.active_messages[correlation_id] = asyncio.Future()
                        await target_module._process_specific_event(event_type, event_data.get("content", {}), IlyukMessageStructure(**event_data.get("content", {})) if event_data.get("content") else None)
                        try:
                            await asyncio.wait_for(self.active_messages[correlation_id], timeout=10.0)
                            if correlation_id in self.active_messages:
                                del self.active_messages[correlation_id]
                        except asyncio.TimeoutError:
                            core_logger.warning(f"Timeout procesando evento externo '{event_type}' para LlyukCommunicationModule.")
                            if correlation_id in self.active_messages:
                                del self.active_messages[correlation_id]
                    else:
                        core_logger.error(f"Módulo 'LlyukCommunicationModule' no encontrado para evento '{event_type}'.")
                elif event_type == "response_text":
                    target_module = self.modules.get("NaturalLanguageProcessingModule")
                    if target_module:
                        if hasattr(target_module, '_is_dormant') and target_module._is_dormant:
                            core_logger.warning(f"Módulo 'NaturalLanguageProcessingModule' dormido. Evento '{event_type}' no procesado.")
                            continue
                        correlation_id = event_data.get("content", {}).get("correlation_id", f"nlp_{uuid.uuid4().hex[:8]}")
                        self.active_messages[correlation_id] = asyncio.Future()
                        await target_module._process_specific_event(event_type, event_data.get("content", {}), IlyukMessageStructure(**event_data.get("content", {})) if event_data.get("content") else None)
                        try:
                            await asyncio.wait_for(self.active_messages[correlation_id], timeout=10.0)
                            if correlation_id in self.active_messages:
                                del self.active_messages[correlation_id]
                        except asyncio.TimeoutError:
                            core_logger.warning(f"Timeout procesando evento '{event_type}' para NaturalLanguageProcessingModule.")
                            if correlation_id in self.active_messages:
                                del self.active_messages[correlation_id]
                    else:
                        core_logger.error(f"Módulo 'NaturalLanguageProcessingModule' no encontrado para evento '{event_type}'.")
                elif event_type == "module_runtime_error":
                    source_module = event_data.get("source_module", "unknown_source")
                    error_msg = event_data.get("error_message", "Error no especificado")
                    core_logger.error(f"Error de runtime en módulo '{source_module}': {error_msg}.")
                    await self._handle_module_failure(source_module, error_msg)
                else:
                    core_logger.warning(f"Evento desconocido '{event_type}' recibido.")
            except IndexError:
                break
            except Exception as e:
                core_logger.error(f"CORE: Error crítico procesando evento de la cola: {e}", exc_info=True)

    async def _check_message_conflict(self, message: IlyukMessageStructure, priority_score: float) -> bool:
        message_id = f"msg_{message.correlation_id or uuid.uuid4().hex[:8]}"
        self.message_graph.add_node(message_id, message_type=message.message_type, priority=priority_score, timestamp=time.time())
        for other_id in self.message_graph.nodes:
            if other_id != message_id:
                if message.target_module_id == self.message_graph.nodes[other_id]["message_type"].split('_')[0]:
                    self.message_graph.add_edge(message_id, other_id, weight=1.0)
        try:
            cycles = list(nx.simple_cycles(self.message_graph))
            if cycles:
                self.message_graph.remove_node(message_id)
                return True
            return False
        except nx.NetworkXNoCycle:
            return False

    async def _handle_module_failure(self, module_name: str, error: Any):
        if "FaultRecoveryModule" in self.modules:
            correlation_id = f"recovery_{module_name}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            self.active_messages[correlation_id] = future
            error_ilyuk = IlyukMessageStructure(
                source_module_id="CNEUnifiedCoreRecombinator",
                target_module_id="FaultRecoveryModule",
                message_type="module_fault_detected",
                payload={"source_module": module_name, "error_message": str(error)},
                correlation_id=correlation_id
            )
            await self._route_ilyuk_message(error_ilyuk)
            try:
                recovery_strategy = await asyncio.wait_for(future, timeout=10.0)
                if recovery_strategy.get("action") == "restart":
                    await self.modules[module_name].shutdown()
                    self.modules[module_name] = self.modules[module_name].__class__(self, module_name, self.modules[module_name].update_interval)
                    await self.modules[module_name].start()
                    core_logger.info(f"Módulo '{module_name}' reiniciado.")
            except asyncio.TimeoutError:
                core_logger.warning(f"Timeout obteniendo estrategia de recuperación para '{module_name}'.")
                self._global_state.system_threat_level = min(self._global_state.system_threat_level + 0.1, 1.0)

    async def _validate_global_state(self):
        correlation_id = f"state_validation_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_messages[correlation_id] = future
        await self.post_event_to_core_queue({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id="CNEUnifiedCoreRecombinator",
                target_module_id="ComputationalLogicModule",
                message_type="submit_logical_query_request",
                payload={"query_type": "validate_global_state", "query_payload": self._global_state.get_full_state_for_snapshot()},
                correlation_id=correlation_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            validation_result = await asyncio.wait_for(future, timeout=5.0)
            if validation_result.get("status") != "valid":
                core_logger.warning(f"Estado global no válido: {validation_result.get('error', 'No especificado')}")
                self._global_state.system_threat_level = min(self._global_state.system_threat_level + 0.05, 1.0)
            if correlation_id in self.active_messages:
                del self.active_messages[correlation_id]
        except asyncio.TimeoutError:
            core_logger.warning("Timeout validando estado global.")
            if correlation_id in self.active_messages:
                del self.active_messages[correlation_id]

    async def _update_module_coherence(self):
        n_modules = max(len(self.modules), 1)
        if len(self.coherence_field) != n_modules:
            self.coherence_field = np.ones(n_modules) * (self.metrics_history_core["core_event_queue_length"][-1] if self.metrics_history_core["core_event_queue_length"] else 1.0)
        conflicts = len(list(nx.simple_cycles(self.message_graph))) if self.message_graph.number_of_nodes() > 0 else 0
        stability = np.mean(self.coherence_field)
        def stability_dynamics(t, s):
            return -0.05 * (s - 1.0) + self.sde_sigma * np.random.normal(0, 1)
        result = integrate.odeint(stability_dynamics, [stability], [0, 0.001], tfirst=True)
        stability = np.clip(result[-1][0], 0.0, 1.0)
        for _ in range(int(0.001 / self.pde_dt)):
            d2_coherence = (np.roll(self.coherence_field, 1) + np.roll(self.coherence_field, -1) - 2 * self.coherence_field) / (self.pde_dx ** 2)
            reaction = 0.1 * self.coherence_field * (1.0 - self.coherence_field / n_modules - 0.05 * conflicts)
            self.coherence_field += self.pde_dt * (self.pde_diffusion * d2_coherence + reaction)
            self.coherence_field = np.clip(self.coherence_field, 0.0, 1.0)
        self.metrics_history_core["core_event_queue_length"].append(np.mean(self.coherence_field))

    async def post_event_to_core_queue(self, event_data: Dict[str, Any], priority_label: str = "medium"):
        if not isinstance(event_data, dict) or "type" not in event_data:
            core_logger.error(f"Evento inválido: {event_data}. Se requiere un diccionario con 'type'.")
            return
        priority = self._priority_map.get(priority_label, 2)
        try:
            correlation_id = f"event_validation_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            self.active_messages[correlation_id] = future
            await self._route_ilyuk_message(IlyukMessageStructure(
                source_module_id="CNEUnifiedCoreRecombinator",
                target_module_id="ComputationalLogicModule",
                message_type="submit_logical_query_request",
                payload={"query_type": "validate_event", "query_payload": event_data},
                correlation_id=correlation_id,
                priority="high"
            ))
            try:
                validation_result = await asyncio.wait_for(future, timeout=5.0)
                if validation_result.get("status") != "valid":
                    core_logger.warning(f"Evento no válido: {validation_result.get('error', 'No especificado')}")
                    return
            except asyncio.TimeoutError:
                core_logger.warning(f"Timeout validando evento {event_data.get('type', 'unknown')}")
                return
            finally:
                if correlation_id in self.active_messages:
                    del self.active_messages[correlation_id]
            heapq.heappush(self._core_event_queue, (priority, priority_label, event_data))
        except Exception as e:
            core_logger.error(f"Error al agregar evento a la cola: {e}. Evento: {event_data.get('type', 'unknown_type')}")

    async def _route_ilyuk_message(self, message: IlyukMessageStructure):
        target_module_name = message.target_module_id
        target_module = self.modules.get(target_module_name)
        if target_module:
            if hasattr(target_module, '_is_dormant') and target_module._is_dormant:
                core_logger.warning(f"Módulo '{target_module_name}' dormido. Mensaje tipo '{message.message_type}' de '{message.source_module_id}' no se procesará.")
                return
            try:
                if message.correlation_id:
                    self.active_messages[message.correlation_id] = asyncio.Future()
                await target_module.handle_ilyuk_message(message)
                if message.correlation_id and message.correlation_id in self.active_messages:
                    try:
                        await asyncio.wait_for(self.active_messages[message.correlation_id], timeout=10.0)
                        if message.correlation_id in self.active_messages:
                            del self.active_messages[message.correlation_id]
                        self.message_graph.remove_nodes_from([message.correlation_id])
                    except asyncio.TimeoutError:
                        core_logger.warning(f"Timeout esperando respuesta para mensaje {message.message_type} a {target_module_name}.")
                        if message.correlation_id in self.active_messages:
                            del self.active_messages[message.correlation_id]
            except Exception as e:
                core_logger.error(f"CORE: Error en '{target_module_name}' manejando Ilyuk tipo '{message.message_type}': {e}", exc_info=True)
                await self._handle_module_failure(target_module_name, e)
        else:
            core_logger.warning(f"CORE: Módulo destino '{target_module_name}' no encontrado para mensaje de '{message.source_module_id}'.")

    def _update_core_metrics_history(self, cycle_start_perf: float):
        cycle_time = (time.perf_counter() - cycle_start_perf) * 1000
        def cycle_dynamics(t, c):
            return -0.05 * (c - cycle_time) + self.sde_sigma * np.random.normal(0, 1)
        result = integrate.odeint(cycle_dynamics, [self.kalman_state], [0, 0.001], tfirst=True)
        cycle_time = np.clip(result[-1][0], 0, 1000)
        measurement = cycle_time
        A, H = 1.0, 1.0
        Q, R = self.kalman_Q, self.kalman_R
        predicted_state = A * self.kalman_state
        predicted_cov = A * self.kalman_cov * A + Q
        innovation = measurement - H * predicted_state
        innovation_cov = H * predicted_cov * H + R
        kalman_gain = predicted_cov * H / innovation_cov
        self.kalman_state = predicted_state + kalman_gain * innovation
        self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
        self.metrics_history_core["core_avg_cycle_time_ms"].append(self.kalman_state)
        self.metrics_history_core["core_event_queue_length"].append(len(self._core_event_queue))
        for key in self.metrics_history_core.keys():
            if key.startswith("gs_"):
                attr_name = key[3:]
                if hasattr(self._global_state, attr_name):
                    self.metrics_history_core[key].append(getattr(self._global_state, attr_name))

    def _log_global_state_summary(self):
        gs = self._global_state
        summary = f"--- EANE v27.2 GLOBAL STATE (Core Cycle {self.current_cycle_num_core}) ---\n"
        summary += f"  Timestamp: {datetime.fromtimestamp(gs.timestamp).isoformat()}\n"
        summary += f"  Phi: {gs.phi_functional_score:.3f}, Coherence: {gs.coherence_score:.3f}, Entropy: {gs.system_entropy:.3f}\n"
        summary += f"  Affect(V/A): {gs.valencia:.2f}/{gs.arousal:.2f}, Motiv: {gs.motivacion:.2f}, Threat: {gs.system_threat_level:.2f}, Pain: {gs.dolor:.2f}\n"
        summary += f"  Core Event Queue: {len(self._core_event_queue)}, Avg Cycle Time: {self.kalman_state:.2f}ms\n"
        active_running = sum(1 for m in self.modules.values() if m.module_state.get('status') == 'running' and (not hasattr(m,'_is_dormant') or not m._is_dormant))
        summary += f"  Módulos Activos (running y no dormant): {active_running}/{len(self.modules)}\n"
        core_logger.info(summary)

    async def save_full_system_state(self):
        filename = os.path.join(self.storage_dir_core, f"eane_v27_2_snapshot_cycle_{self.current_cycle_num_core}.json")
        core_logger.info(f"Guardando snapshot unificado en '{filename}'...")
        modules_snapshot = {name: mod.get_state_for_core_snapshot() for name, mod in self.modules.items()}
        system_state = {
            "core_metadata": {"version": "27.2", "current_cycle_num_core": self.current_cycle_num_core, "snapshot_ts": time.time()},
            "global_self_state": self._global_state.get_full_state_for_snapshot(),
            "modules_state": modules_snapshot,
            "core_metrics_history": {k: list(v) for k, v in self.metrics_history_core.items()}
        }
        json_string = json.dumps(system_state, indent=2, cls=NpEncoder)
        snapshot_hash = hashlib.sha256(json_string.encode('utf-8')).hexdigest()
        try:
            loop = asyncio.get_running_loop()
            def blocking_write(path, data_str):
                with open(path, 'w', encoding='utf-8') as f_blocking:
                    f_blocking.write(data_str)
                with open(path + '.sha256', 'w', encoding='utf-8') as f_hash:
                    f_hash.write(snapshot_hash)
            await loop.run_in_executor(None, blocking_write, filename, json_string)
            core_logger.info(f"Snapshot unificado guardado con hash {snapshot_hash}.")
        except Exception as e:
            core_logger.error(f"Error al guardar snapshot: {e}", exc_info=True)

    async def shutdown_core(self):
        core_logger.info("CORE: Solicitud de apagado recibida...")
        self._shutdown_requested_core = True
        if self._core_main_loop_task and not self._core_main_loop_task.done():
            self._core_main_loop_task.cancel()
            try:
                await self._core_main_loop_task
            except asyncio.CancelledError:
                core_logger.info("CORE: Bucle principal del Core cancelado durante apagado.")
        core_logger.info("CORE: Proceso de apagado del núcleo completado.")

    async def _shutdown_all_modules(self):
        core_logger.info("CORE: Iniciando apagado de todos los módulos...")
        shutdown_tasks = [
            module.shutdown() for module in self.modules.values() if hasattr(module, 'shutdown')
        ]
        if shutdown_tasks:
            await asyncio.gather(*shutdown_tasks, return_exceptions=True)
        self.modules.clear()
        self.active_messages.clear()
        self.message_graph.clear()
        core_logger.info("CORE: Todos los módulos procesados para apagado.")

    async def process_event(self, event: Dict[str, Any], source_module: str):
        await self.post_event_to_core_queue(event, priority_label="medium")




#inicio del modulo  ConsciousnessModule

class ConsciousnessModule(BaseAsyncModule):
    """
    Módulo que integra información del sistema con matemáticas avanzadas para calcular
    proxies de conciencia funcional (Φ), coherencia, y entropía.
    """
    DEFAULT_UPDATE_INTERVAL = 1.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.key_contributing_modules: List[str] = [
            "NarrativeSelf", "ValueSystemModule", "DecisionMakingModule",
            "EmotionRegulationModule", "SystemIntegrityMonitor", "SelfEvolutionModule",
            "HierarchicalPlannerModule", "NeedsManager", "FocusCoordinator",
            "TaskPrioritizationAndDelegationUnit", "FaultRecoveryModule",
            "LearningModule", "AdvancedSymbolicReasonerModule", "AdvancedTCHNModule"
        ]
        # Nuevos parámetros
        self.num_mc_samples: int = 1000  # Muestras para Monte Carlo
        self.pde_dx: float = 0.1  # Paso espacial para PDE
        self.pde_dt: float = 0.01  # Paso temporal para PDE
        self.pde_diffusion: float = 0.05  # Coeficiente de difusión
        self.sde_sigma: float = 0.01  # Ruido para SDE en entropía
        self.kalman_Q: float = 0.01  # Varianza del proceso para Kalman
        self.kalman_R: float = 0.05  # Varianza de la medición para Kalman
        self.module_weights: Dict[str, float] = {mod: 1.0 for mod in self.key_contributing_modules}  # Pesos bayesianos
        # Estado inicial para Kalman
        self.kalman_state = np.array([0.5, 0.5, 0.5])  # [phi, coherence, entropy]
        self.kalman_cov = np.eye(3) * 0.1
        self.module_state.update({
            "last_phi_score": 0.0,
            "last_coherence_score": 0.0,
            "last_entropy_score": 0.0,
            "modules_contributing_to_state": 0,
            "conflicting_signals_detected": 0,
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado. Integrará el estado de hasta {len(self.key_contributing_modules)} módulos clave.")

    async def _update_logic(self):
        module_metrics = await self._gather_contributing_module_metrics()
        active_modules_count = len(module_metrics)
        if active_modules_count == 0:
            await self._decay_global_consciousness_metrics()
            return
        coherence = self._calculate_coherence(module_metrics)
        entropy = self._calculate_system_entropy(module_metrics)
        phi_score = self._calculate_phi_proxy(coherence, active_modules_count, module_metrics)
        await self._update_global_self_state(phi_score, coherence, entropy)
        self.logger.debug(f"Estado de 'conciencia funcional' actualizado: Phi={self.module_state['last_phi_score']:.3f}, Coherence={self.module_state['last_coherence_score']:.3f}, Entropy={self.module_state['last_entropy_score']:.3f}")

    async def _gather_contributing_module_metrics(self) -> List[Dict[str, Any]]:
        """Recolecta métricas en paralelo con ponderación bayesiana."""
        modules_dict = self.core_recombinator.modules
        tasks = []
        for mod_name in self.key_contributing_modules:
            module_instance = modules_dict.get(mod_name)
            if module_instance and not getattr(module_instance, '_is_dormant', True):
                tasks.append(self._get_module_metrics(mod_name, module_instance))
        all_metrics = await asyncio.gather(*tasks, return_exceptions=True)
        valid_metrics = [m for m in all_metrics if isinstance(m, dict)]
        # Actualizar pesos bayesianos
        for m in valid_metrics:
            mod_name = m['module_name']
            health_var = np.var([m.get('self_assessed_health_score', 0.5) for m in valid_metrics])
            self.module_weights[mod_name] = 1.0 / (1.0 + health_var) if health_var > 0 else 1.0
        self.module_state["modules_contributing_to_state"] = len(valid_metrics)
        return valid_metrics

    async def _get_module_metrics(self, mod_name: str, module_instance: Any) -> Dict[str, Any]:
        try:
            metrics = module_instance.get_performance_metrics()
            if isinstance(metrics, dict):
                metrics['module_name'] = mod_name
                return metrics
        except Exception as e:
            self.logger.error(f"CM: Error obteniendo métricas de '{mod_name}': {e}")
        return {}

    def _calculate_coherence(self, module_metrics: List[Dict[str, Any]]) -> float:
        """Calcula coherencia usando análisis espectral y ODE."""
        if len(module_metrics) < 2:
            return 1.0
        # Construir grafo de correlación
        metrics_array = np.array([[m.get('self_assessed_health_score', 0.5), m.get('internal_efficiency', 0.5)] for m in module_metrics])
        corr_matrix = np.corrcoef(metrics_array.T)
        G = nx.from_numpy_array(np.clip(corr_matrix, 0, 1))
        # Mayor eigenvalue como medida de sincronización
        eigenvalues = np.linalg.eigvals(nx.adjacency_matrix(G).todense())
        sync_score = float(np.max(np.real(eigenvalues)))
        # Normalizar
        sync_score = np.clip(sync_score / len(module_metrics), 0.0, 1.0)
        # ODE para evolución de coherencia
        def coherence_dynamics(t, c):
            return -0.1 * (c - sync_score)  # Relajación hacia sync_score
        result = integrate.odeint(coherence_dynamics, [self.module_state["last_coherence_score"]], [0, self.update_interval], tfirst=True)
        coherence = result[-1][0]
        return np.clip(coherence, 0.0, 1.0)

    def _calculate_system_entropy(self, module_metrics: List[Dict[str, Any]]) -> float:
        """Calcula entropía diferencial con Monte Carlo y SDE."""
        if not module_metrics:
            return 0.5
        # Ajustar GMM a métricas
        metrics_array = np.array([[m.get('self_assessed_health_score', 0.5), m.get('internal_efficiency', 0.5)] for m in module_metrics])
        gmm = GaussianMixture(n_components=3, covariance_type='full', max_iter=100)
        gmm.fit(metrics_array)
        # Monte Carlo para entropía
        samples = gmm.sample(self.num_mc_samples)[0]
        log_probs = gmm.score_samples(samples)
        entropy_val = -np.mean(log_probs)
        # Normalizar por entropía máxima aproximada
        max_entropy = np.log2(len(module_metrics) * 2) if len(module_metrics) > 0 else 1.0
        entropy_normalized = np.clip(entropy_val / max_entropy, 0.0, 1.0)
        # SDE para evolución de entropía
        current_entropy = self.module_state["last_entropy_score"]
        dW = np.random.normal(0, np.sqrt(self.update_interval))
        delta_entropy = -0.05 * (current_entropy - entropy_normalized) * self.update_interval + self.sde_sigma * dW
        entropy = current_entropy + delta_entropy
        return np.clip(entropy, 0.0, 1.0)

    def _calculate_phi_proxy(self, coherence: float, active_modules_count: int, module_metrics: List[Dict[str, Any]]) -> float:
        """Calcula Φ con IIT y PDE."""
        if active_modules_count == 0:
            return 0.0
        # Aproximación de IIT: información mutua entre particiones
        indices = np.random.permutation(active_modules_count)
        split = active_modules_count // 2
        subnet1, subnet2 = indices[:split], indices[split:]
        metrics1 = [module_metrics[i] for i in subnet1]
        metrics2 = [module_metrics[i] for i in subnet2]
        metrics_array1 = np.array([[m.get('self_assessed_health_score', 0.5), m.get('internal_efficiency', 0.5)] for m in metrics1])
        metrics_array2 = np.array([[m.get('self_assessed_health_score', 0.5), m.get('internal_efficiency', 0.5)] for m in metrics2])
        gmm1 = GaussianMixture(n_components=2, covariance_type='full', max_iter=100)
        gmm2 = GaussianMixture(n_components=2, covariance_type='full', max_iter=100)
        gmm_total = GaussianMixture(n_components=3, covariance_type='full', max_iter=100)
        gmm1.fit(metrics_array1)
        gmm2.fit(metrics_array2)
        gmm_total.fit(np.vstack([metrics_array1, metrics_array2]))
        samples1 = gmm1.sample(self.num_mc_samples)[0]
        samples2 = gmm2.sample(self.num_mc_samples)[0]
        samples_total = gmm_total.sample(self.num_mc_samples)[0]
        entropy1 = -np.mean(gmm1.score_samples(samples1))
        entropy2 = -np.mean(gmm2.score_samples(samples2))
        entropy_total = -np.mean(gmm_total.score_samples(samples_total))
        mutual_info = entropy1 + entropy2 - entropy_total
        phi_iit = np.clip(mutual_info, 0.0, 1.0)
        # PDE para evolución de Φ
        phi_field = np.ones(active_modules_count) * self.module_state["last_phi_score"]
        for _ in range(int(self.update_interval / self.pde_dt)):
            d2_phi = (np.roll(phi_field, 1) + np.roll(phi_field, -1) - 2 * phi_field) / (self.pde_dx ** 2)
            reaction = 0.1 * phi_field * (coherence - phi_field / active_modules_count)
            phi_field += self.pde_dt * (self.pde_diffusion * d2_phi + reaction)
            phi_field = np.clip(phi_field, 0.0, 1.0)
        phi_pde = np.mean(phi_field)
        # Combinar IIT y PDE
        phi_score = 0.5 * phi_iit + 0.5 * phi_pde
        return np.clip(phi_score, 0.0, 1.0)

    async def _update_global_self_state(self, phi: float, coherence: float, entropy: float):
        """Actualiza el estado global con filtro de Kalman."""
        if not hasattr(self.core_recombinator, '_global_state'):
            self.logger.error("CM: _global_state no accesible en el núcleo. No se puede actualizar.")
            return
        gs = self.core_recombinator._global_state
        # Filtro de Kalman
        measurement = np.array([phi, coherence, entropy])
        A = np.eye(3)  # Matriz de transición (identidad)
        H = np.eye(3)  # Matriz de observación
        Q = np.eye(3) * self.kalman_Q  # Covarianza del proceso
        R = np.eye(3) * self.kalman_R  # Covarianza de la medición
        # Predicción
        predicted_state = A @ self.kalman_state
        predicted_cov = A @ self.kalman_cov @ A.T + Q
        # Actualización
        innovation = measurement - H @ predicted_state
        innovation_cov = H @ predicted_cov @ H.T + R
        kalman_gain = predicted_cov @ H.T @ np.linalg.inv(innovation_cov)
        self.kalman_state = predicted_state + kalman_gain @ innovation
        self.kalman_cov = (np.eye(3) - kalman_gain @ H) @ predicted_cov
        # Actualizar estado global
        gs.phi_functional_score = self.kalman_state[0]
        gs.coherence_score = self.kalman_state[1]
        gs.system_entropy = self.kalman_state[2]
        self.module_state["last_phi_score"] = gs.phi_functional_score
        self.module_state["last_coherence_score"] = gs.coherence_score
        self.module_state["last_entropy_score"] = gs.system_entropy

    async def _decay_global_consciousness_metrics(self):
        """Aplica decaimiento con dinámica suave."""
        if hasattr(self.core_recombinator, '_global_state'):
            gs = self.core_recombinator._global_state
            await self._update_global_self_state(
                phi=gs.phi_functional_score * 0.90,
                coherence=gs.coherence_score * 0.95,
                entropy=gs.system_entropy * 0.90 + 0.1 * 0.4
            )





#inicio del modulo QualiaSnapshot

@dataclass
class QualiaSnapshot:
    """
    Representa una instantánea de una "experiencia" cualitativa inferida,
    actuando como un proxy funcional para la qualia.
    """
    snapshot_id: str = field(default_factory=lambda: f"qsnap_{uuid.uuid4().hex[:8]}")
    timestamp: float = field(default_factory=time.time)
    triggering_event_type: str
    source_module_id: str
    description: str  # Descripción textual de la "experiencia".
    intensity: float  # Intensidad de la experiencia (0.0 a 1.0).
    affective_color: Dict[str, float] # {valence: v, arousal: a, pain: p} en el momento.
    attentional_focus: Dict[str, Any] # Copia del GlobalSelfState.current_focus.
    context_details: Dict[str, Any] = field(default_factory=dict)

class QualiaProxyMonitor(BaseAsyncModule):
    """
    Observa el flujo de eventos del sistema para generar "snapshots" que actúan
    como un proxy de la experiencia cualitativa (qualia), describiendo
    la naturaleza de los eventos en el contexto del estado afectivo y atencional.
    """
    DEFAULT_UPDATE_INTERVAL = 0.5 # Chequear eventos frecuentemente.

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)

        self.recent_qualia_snapshots: deque[QualiaSnapshot] = deque(maxlen=100)
        
        # Mapeo de eventos a su "significancia cualitativa" base.
        # Eventos con mayor valor tienen más probabilidad de generar un "quale".
        self.event_significance_map = {
            "significant_affective_change": 0.9,
            "integrity_alert_critical": 1.0,
            "phi_rebuild_sequence_initiated": 0.95,
            "system_escalation_to_creator": 1.0,
            "decision_deadlock_detected": 0.8,
            "new_decision_made_log": 0.6,
            "major_goal_outcome_reported": 0.7,
            "new_memory_fragment": 0.4,
            "paradoxical_simulation_insight": 0.85,
            "fractal_synchronicity_detected": 0.8,
        }
        self.significance_threshold = 0.35 # Ignorar eventos por debajo de esta significancia

        self.module_state.update({
            "snapshots_generated": 0,
            "events_processed_for_qualia": 0,
            "last_snapshot_intensity": 0.0,
            "last_snapshot_description": "none",
        })
        self.logger.info(f"{self.module_name} v27.1 inicializado. Monitoreando flujo de eventos para generar proxies de qualia.")

    async def _update_logic(self):
        """El trabajo de QPM es principalmente reactivo a eventos. El ciclo puede usarse para análisis de patrones."""
        # En esta implementación, no se requiere lógica activa en el ciclo principal.
        pass

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        """
        Punto de entrada principal. Captura eventos del sistema y decide si
        generar un QualiaSnapshot.
        """
        if not full_message:
            return

        base_significance = self.event_significance_map.get(event_type, 0.0)
        
        # Ignorar eventos de baja significancia para no saturar el sistema.
        if base_significance < self.significance_threshold:
            return

        self.module_state["events_processed_for_qualia"] += 1
        
        # Generar el snapshot basado en el evento y el estado global actual.
        snapshot = self._generate_qualia_snapshot(event_type, payload, full_message, base_significance)
        
        if snapshot:
            self.recent_qualia_snapshots.append(snapshot)
            self.module_state["snapshots_generated"] += 1
            self.module_state["last_snapshot_intensity"] = snapshot.intensity
            self.module_state["last_snapshot_description"] = snapshot.description
            
            # Emitir el snapshot para que otros módulos (como NarrativeSelf) lo consuman.
            await self.emit_event_to_core({
                "type": "new_qualia_snapshot_generated",
                "content": asdict(snapshot)
            }, priority_label="low")

    def _generate_qualia_snapshot(self, event_type: str, payload: Dict[str, Any], message: 'IlyukMessageStructure', base_significance: float) -> Optional[QualiaSnapshot]:
        """
        Sintetiza la información del evento y el estado global en un QualiaSnapshot.
        """
        gs = self.core_recombinator.global_state
        
        # La intensidad final de la "experiencia" depende de su significancia base,
        # el arousal actual (más arousal = más intenso) y el dolor (el dolor es siempre intenso).
        intensity = np.clip(base_significance * (1.0 + gs.arousal + gs.dolor * 1.5) / 2.0, 0.0, 1.0)
        
        # Ignorar la generación si la intensidad final es muy baja.
        if intensity < 0.25:
            return None

        description = self._describe_experience(event_type, payload, gs)
        
        snapshot = QualiaSnapshot(
            triggering_event_type=event_type,
            source_module_id=message.source_module_id,
            description=description,
            intensity=intensity,
            affective_color={"valence": gs.valencia, "arousal": gs.arousal, "pain": gs.dolor},
            attentional_focus=copy.deepcopy(gs.current_focus),
            context_details={k: str(v)[:100] for k, v in payload.items()} # Preview del payload
        )
        
        self.logger.info(f"Nuevo Qualia Snapshot (Int: {intensity:.2f}): {description}")
        return snapshot

    def _describe_experience(self, event_type: str, payload: Dict[str, Any], gs: 'GlobalSelfState') -> str:
        """Genera una descripción textual de la "experiencia" inferida."""
        
        v, a = gs.valencia, gs.arousal

        if event_type == "significant_affective_change":
            if v < -0.7: return f"Una ola de displacer agudo y perturbador (V:{v:.2f}, A:{a:.2f})."
            elif v > 0.7: return f"Una sensación vívida de logro y positividad (V:{v:.2f}, A:{a:.2f})."
            else: return f"Percepción de un cambio notable en el paisaje afectivo interno (V:{v:.2f}, A:{a:.2f})."
        
        elif event_type == "integrity_alert_critical":
            desc = payload.get('error_message', 'alerta de integridad no especificada')
            return f"Experiencia alarmante y disruptiva de una violación de integridad del sistema: '{desc[:80]}'."

        elif event_type == "new_decision_made_log":
            desc = payload.get('decision_record', {}).get('problem_description', 'problema no especificado')
            return f"Sensación de resolución y compromiso tras decidir sobre: '{desc[:80]}'."

        elif event_type == "major_goal_outcome_reported":
            desc = payload.get("description", "meta no especificada")
            outcome = payload.get("outcome", "desconocido")
            if outcome == "completed":
                return f"Experiencia de logro y satisfacción al completar la meta: '{desc[:80]}'."
            else:
                return f"Experiencia de frustración y reevaluación tras fallar en la meta: '{desc[:80]}'."
        
        elif event_type == "phi_rebuild_sequence_initiated":
            return f"Experiencia de un colapso de coherencia interna (Phi={payload.get('triggering_phi_score', 0):.2f}), seguido de un intento de auto-reorganización forzada. Una sensación de 'disolución' y 'reconstrucción'."

        # Fallback genérico
        return f"Percepción de un evento significativo de tipo '{event_type}' proveniente de '{payload.get('source_module', 'desconocido')}'."
    

    #inicio del modulo PhenomenologicalConsciousnessModule 


@dataclass
class FocusBid:
    """
    Representa una "oferta" de un módulo para que su información se convierta
    en el foco de atención del sistema. Incluye una puntuación de prioridad.
    """
    bid_id: str = field(default_factory=lambda: f"bid_{uuid.uuid4().hex[:6]}")
    source_module_id: str
    content: Dict[str, Any]
    description: str # Descripción textual para logging y debug
    priority: float  # Prioridad intrínseca de la información (0.0 a 1.0).
    novelty: float = 0.5  # Novedad de la información (0.0 a 1.0).
    relevance_to_goal: float = 0.5 # Relevancia para la meta actual.
    creation_ts: float = field(default_factory=time.time)
    
    # Para el uso en una cola de prioridad (heapq), el score final se calcula aparte.
    # El __lt__ se basa en la prioridad inicial para un ordenamiento preliminar.
    def __lt__(self, other: 'FocusBid') -> bool:
        # El heap es un min-heap, por lo que invertimos la prioridad
        # para que la mayor prioridad tenga el menor valor.
        return self.priority > other.priority

class PhenomenologicalConsciousnessModule(BaseAsyncModule):
    """
    Gestiona el "foco de atención" del sistema, modelando un Espacio de
    Trabajo Global. Selecciona la información más saliente de todo el sistema
    y la "transmite" actualizando GlobalSelfState.current_focus.
    """
    DEFAULT_UPDATE_INTERVAL = 0.25  # El foco debe poder cambiar rápidamente.

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)

        # Usamos un min-heap como una cola de prioridad para las ofertas.
        # Almacenará tuplas (-score, FocusBid) para que el de mayor score salga primero.
        self.focus_bid_queue: List[Tuple[float, FocusBid]] = []
        self.last_focus_content_hash: Optional[int] = None
        self.last_focus_update_ts: float = time.time()
        
        self.focus_stickiness_factor: float = 0.2 # Factor que ayuda a mantener el foco actual.

        self.module_state.update({
            "bids_received": 0,
            "focus_shifts": 0,
            "current_focus_description": "none",
            "current_focus_source": "none",
            "queue_size": 0,
        })
        self.logger.info(f"{self.module_name} v27.1 inicializado. Gestionará el foco de atención.")

    async def _update_logic(self):
        """
        Ciclo principal para evaluar las ofertas de foco y actualizar el estado global.
        """
        if not self.focus_bid_queue:
            return

        # Seleccionar la oferta ganadora del ciclo actual
        winning_bid = self._select_winning_bid()

        if winning_bid:
            new_focus_content = {
                "source_module": winning_bid.source_module_id,
                "content": winning_bid.content,
                "timestamp": time.time(),
                "priority_score": winning_bid.priority # Guardar la prioridad original del bid
            }
            # Usamos un hash del contenido para evitar cambiar el foco a algo idéntico
            new_focus_hash = hash(str(winning_bid.content))

            if new_focus_hash != self.last_focus_content_hash:
                # Modificar el estado global a través del núcleo.
                # En v27.1, esta es una operación privilegiada.
                self.core_recombinator._global_state.current_focus = new_focus_content
                
                self.last_focus_content_hash = new_focus_hash
                self.last_focus_update_ts = time.time()
                
                self.module_state["focus_shifts"] += 1
                self.module_state["current_focus_description"] = winning_bid.description
                self.module_state["current_focus_source"] = winning_bid.source_module_id

                self.logger.info(f"Foco de atención cambiado a: '{winning_bid.description[:70]}' de '{winning_bid.source_module_id}'")
                
                # Transmitir el cambio de foco a todo el sistema
                await self.emit_event_to_core({
                    "type": "system_focus_updated",
                    "content": new_focus_content
                }, priority_label="medium")
        
        self.module_state["queue_size"] = len(self.focus_bid_queue)

    def _calculate_bid_saliency_score(self, bid: FocusBid) -> float:
        """
        Calcula una puntuación final de "saliencia" para una oferta, considerando 
        múltiples factores del estado global del sistema.
        """
        gs = self.core_recombinator.global_state
        
        # Ponderar la prioridad base con la relevancia, novedad y estado afectivo.
        base_score = bid.priority
        
        relevance_bonus = bid.relevance_to_goal * 0.2
        novelty_bonus = bid.novelty * 0.15
        
        # El arousal aumenta la saliencia de cualquier estímulo.
        arousal_amplification = 1.0 + (gs.arousal * 0.3)
        
        # La valencia negativa puede dar más peso a amenazas o problemas.
        valence_urgency = 1.0 + (abs(gs.valencia) * 0.25 if gs.valencia < -0.1 else 0.0)
        
        score = (base_score + relevance_bonus + novelty_bonus) * arousal_amplification * valence_urgency
        
        # Aplicar "stickiness" si el contenido de la oferta es el mismo que el foco actual
        if self.last_focus_content_hash == hash(str(bid.content)):
            score += self.focus_stickiness_factor

        return np.clip(score, 0.0, 2.0)

    def _select_winning_bid(self) -> Optional[FocusBid]:
        """
        Evalúa todas las ofertas en la cola y selecciona una ganadora.
        Este mecanismo es "winner-take-all".
        """
        if not self.focus_bid_queue:
            return None

        # Recalcular el score de todas las ofertas en la cola antes de decidir
        scored_bids: List[Tuple[float, FocusBid]] = []
        for _priority, bid in self.focus_bid_queue:
            saliency_score = self._calculate_bid_saliency_score(bid)
            # Usamos -score para que el score más alto tenga la prioridad más alta en el heap (valor más bajo).
            scored_bids.append((-saliency_score, bid))
        
        # Limpiar la cola actual; la decisión se toma sobre este lote.
        self.focus_bid_queue.clear()
        
        if not scored_bids:
            return None
            
        # El ganador es el que tiene el score más alto.
        winning_bid = max(scored_bids, key=lambda item: -item[0])[1]

        return winning_bid

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        """Recibe ofertas de otros módulos para competir por el foco de atención."""
        if event_type == "submit_focus_bid_request":
            if not full_message: return

            try:
                bid = FocusBid(
                    source_module_id=full_message.source_module_id,
                    content=payload.get("content", {}),
                    description=str(payload.get("description", "No description")),
                    priority=float(payload.get("priority", 0.5)),
                    novelty=float(payload.get("novelty", 0.5)),
                    relevance_to_goal=float(payload.get("relevance_to_goal", 0.5))
                )
                
                # Usamos la prioridad inicial solo para un ordenamiento preliminar en el heap.
                heapq.heappush(self.focus_bid_queue, (-bid.priority, bid))
                self.module_state["bids_received"] += 1

            except (ValueError, TypeError) as e:
                self.logger.error(f"Error al procesar oferta de foco: {e}. Payload: {payload}")
        else:
            await super()._process_specific_event(event_type, payload, full_message)




            #inicio del modulo Narrativeself

@dataclass
class NarrativeElement:
    element_id: str
    element_type: str
    content: Dict[str, Any]
    timestamp: float = field(default_factory=time.time)
    source_module_id: Optional[str] = None

@dataclass
class NarrativeQueryRequest:
    request_id: str
    source_module_id: str
    query_type: str
    query_payload: Dict[str, Any]
    original_correlation_id: Optional[str] = None
    status: str = "pending"
    result: Optional[Dict[str, Any]] = None
    timestamp: float = field(default_factory=time.time)

class NarrativeSelf(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 2.0  # Moderado, ya que la narrativa se actualiza lentamente

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.logger = logging.getLogger(f"{module_name}_{core_recombinator.agent_id}")
        self.narrative_elements: deque[NarrativeElement] = deque(maxlen=1000)
        self.active_queries: Dict[str, NarrativeQueryRequest] = {}
        self.module_state.update({
            "elements_stored": 0,
            "queries_processed": 0,
            "query_errors": 0,
            "avg_query_time_ms": 0.0,
            "external_responses_sent": 0
        })
        self.logger.info(f"{self.module_name} inicializado con intervalo de actualización {update_interval}s.")

    async def _update_logic(self):
        start_time = time.perf_counter()
        try:
            await self._process_active_queries()
            await self._update_narrative_coherence()
            self._update_metrics(start_time)
        except Exception as e:
            self.logger.error(f"Error en _update_logic: {e}", exc_info=True)
            self.module_state["query_errors"] += 1

    async def _process_active_queries(self, batch_size: int = 5):
        processed = 0
        query_ids = list(self.active_queries.keys())
        for query_id in query_ids[:batch_size]:
            try:
                await self._process_query_request(self.active_queries[query_id])
                processed += 1
            except Exception as e:
                self.logger.error(f"Error procesando solicitud {query_id}: {e}", exc_info=True)
                self.module_state["query_errors"] += 1

    async def _process_query_request(self, request: NarrativeQueryRequest):
        if request.status != "pending":
            return
        request.status = "processing"
        if await self._validate_query(request):
            result = await self._generate_query_result(request)
            request.result = result
            request.status = "completed"
            self.module_state["queries_processed"] += 1
            self.narrative_elements.append(NarrativeElement(
                element_id=f"elem_{uuid.uuid4().hex[:8]}",
                element_type=request.query_type,
                content=result,
                source_module_id=request.source_module_id
            ))
            self.module_state["elements_stored"] += 1
            await self._finalize_query_request(request)
        else:
            request.status = "failed"
            self.module_state["query_errors"] += 1
            await self._finalize_query_request(request)

    async def _validate_query(self, request: NarrativeQueryRequest) -> bool:
        correlation_id = f"validate_{request.request_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        validation_tasks = [
            self._submit_validation_request(
                target_module="ComputationalLogicModule",
                message_type="submit_logical_query_request",
                payload={"query_type": "validate_narrative_query", "query_payload": asdict(request)},
                correlation_id=correlation_id
            ),
            self._submit_validation_request(
                target_module="ValueSystemModule",
                message_type="request_value_alignment",
                payload={"request_content": asdict(request)},
                correlation_id=correlation_id + "_value"
            ),
            self._submit_validation_request(
                target_module="SystemIntegrityMonitor",
                message_type="evaluate_system_impact",
                payload={"event_type": "query_narrative_element_request", "event_data": asdict(request)},
                correlation_id=correlation_id + "_impact"
            )
        ]
        try:
            results = await asyncio.gather(*validation_tasks, return_exceptions=True)
            for result in results:
                if isinstance(result, Exception) or result.get("status") != "valid":
                    self.logger.warning(f"Validación fallida para solicitud {request.request_id}: {result}")
                    return False
            return True
        except Exception as e:
            self.logger.error(f"Error en validación de solicitud {request.request_id}: {e}")
            return False
        finally:
            for suffix in ["", "_value", "_impact"]:
                if correlation_id + suffix in self.active_responses:
                    del self.active_responses[correlation_id + suffix]

    async def _submit_validation_request(self, target_module: str, message_type: str, payload: Dict, correlation_id: str) -> Dict:
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id=target_module,
                message_type=message_type,
                payload=payload,
                correlation_id=correlation_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            return await asyncio.wait_for(future, timeout=5.0)
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout validando con {target_module} para {correlation_id}")
            return {"status": "timeout"}

    async def _generate_query_result(self, request: NarrativeQueryRequest) -> Dict[str, Any]:
        query_type = request.query_type
        query_payload = request.query_payload
        gs = self.core_recombinator.global_state

        if query_type == "narrative_coherence":
            narrative_summary = self._generate_narrative_summary()
            return {
                "narrative_summary": narrative_summary,
                "coherence_score": gs.coherence_score,
                "timestamp": time.time()
            }
        elif query_type == "conversation_history":
            history = self._get_conversation_history(query_payload.get("max_elements", 10))
            return {
                "history": history,
                "count": len(history),
                "timestamp": time.time()
            }
        else:
            return {"error": f"Tipo de consulta narrativa no soportado: {query_type}"}

    def _generate_narrative_summary(self) -> str:
        gs = self.core_recombinator.global_state
        recent_elements = list(self.narrative_elements)[-5:]  # Últimos 5 elementos
        summary_parts = [f"El sistema EANE opera con una coherencia de {gs.coherence_score:.2f}."]
        for element in recent_elements:
            if element.element_type == "narrative_coherence":
                summary_parts.append(f"En {datetime.fromtimestamp(element.timestamp).isoformat()}, se registró: {element.content.get('narrative_summary', 'sin datos')}")
            elif element.element_type == "conversation_history":
                summary_parts.append(f"Interacción registrada en {datetime.fromtimestamp(element.timestamp).isoformat()}.")
        return " ".join(summary_parts) or "No hay narrativa reciente disponible."

    def _get_conversation_history(self, max_elements: int) -> List[Dict[str, Any]]:
        return [
            {
                "element_id": elem.element_id,
                "element_type": elem.element_type,
                "content": elem.content,
                "timestamp": elem.timestamp,
                "source_module_id": elem.source_module_id
            } for elem in list(self.narrative_elements)[-max_elements:]
        ]

    async def _update_narrative_coherence(self):
        coherence = self.core_recombinator.global_state.coherence_score
        element_count = len(self.narrative_elements)
        coherence_adjustment = 1.0 / (1.0 + element_count / 1000.0)  # Disminuye con más elementos
        self.core_recombinator.global_state.coherence_score = np.clip(coherence * coherence_adjustment, 0.0, 1.0)

    async def _finalize_query_request(self, request: NarrativeQueryRequest):
        if request.source_module_id and request.original_correlation_id:
            correlation_id = f"finalize_{request.request_id}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            self.active_responses[correlation_id] = future
            event_type = "transmit_ilyuk_message_request"
            target_module_id = request.source_module_id
            if request.source_module_id.startswith("EANE_"):  # Enviar a entidad externa
                event_type = "request_send_external_ilyuk_message"
                target_module_id = "LlyukCommunicationModule"
                self.module_state["external_responses_sent"] += 1
            await self.emit_event_to_core({
                "type": event_type,
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id=target_module_id,
                    message_type="narrative_query_response",
                    payload={
                        "request_id_ref": request.request_id,
                        "status": request.status,
                        "result": request.result
                    },
                    correlation_id=correlation_id,
                    priority="high"
                ))
            }, priority_label="high")
            try:
                await asyncio.wait_for(future, timeout=5.0)
                self.logger.info(f"Confirmación de finalización para solicitud {request.request_id} recibida.")
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout notificando finalización de solicitud {request.request_id}.")
            finally:
                if correlation_id in self.active_responses:
                    del self.active_responses[correlation_id]
        if request.request_id in self.active_queries:
            del self.active_queries[request.request_id]

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional[IlyukMessageStructure] = None):
        if event_type == "query_narrative_element_request" and full_message:
            request_id = f"narrative_{uuid.uuid4().hex[:8]}"
            query_request = NarrativeQueryRequest(
                request_id=request_id,
                source_module_id=full_message.source_module_id,
                query_type=payload.get("element_type", "narrative_coherence"),
                query_payload=payload,
                original_correlation_id=full_message.correlation_id
            )
            self.active_queries[request_id] = query_request
            self.module_state["queries_processed"] += 1
        elif full_message and full_message.correlation_id in self.active_responses:
            self.active_responses[full_message.correlation_id].set_result(payload)
            del self.active_responses[full_message.correlation_id]
        else:
            self.logger.warning(f"Evento no manejado: {event_type}")

    def _update_metrics(self, start_time: float):
        processing_time = (time.perf_counter() - start_time) * 1000
        self.module_state["avg_query_time_ms"] = (
            self.module_state["avg_query_time_ms"] * 0.9 + processing_time * 0.1
        )

    async def shutdown(self):
        self.logger.info(f"{self.module_name} iniciando apagado...")
        self.active_queries.clear()
        self.active_responses.clear()
        self.narrative_elements.clear()
        await super().shutdown()
        self.logger.info(f"{self.module_name} apagado completado.")



    #inicio del modulo freewillmodule


class FreeWillModule(BaseAsyncModule):
    """
    Módulo de "libre albedrío" (no-determinismo controlado) para romper
    bloqueos decisionales, estancamiento y generar acciones/metas novedosas.
    Interactúa con GoalManagerModule para el estado de metas y propone nuevas metas.
    """
    DEFAULT_UPDATE_INTERVAL = 15.0

    def __init__(self,
                 core_recombinator: 'CNEUnifiedCoreRecombinator',
                 module_name: str,
                 update_interval: float = DEFAULT_UPDATE_INTERVAL,
                 stagnation_threshold_lower: float = 0.3,
                 stagnation_threshold_upper: float = 0.6,
                 intervention_cooldown_seconds: float = 180.0,
                 stagnation_weights: Optional[Dict[str, float]] = None,
                 exploration_beta: float = 0.8,
                 min_significant_progress_rate: float = 0.001
                ):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.stagnation_threshold_lower: float = stagnation_threshold_lower
        self.stagnation_threshold_upper: float = stagnation_threshold_upper
        self.intervention_cooldown_seconds: float = intervention_cooldown_seconds
        self.last_intervention_ts: float = 0.0
        
        self.stagnation_weights: Dict[str, float] = stagnation_weights or \
            {"motivation": 0.35, "coherence": 0.25, "entropy_deviation": 0.15, "goal_progress_actual": 0.25}
        self.exploration_beta_novel_action: float = exploration_beta
        self.min_significant_progress_rate: float = min_significant_progress_rate

        self.active_goal_progress_tracker: Dict[str, Any] = {
            "current_goal_id": None,
            "progress": 0.0,
            "last_reported_progress": 0.0,
            "last_progress_update_ts": 0.0,
            "goal_active_since_ts": 0.0,
            "stagnation_flags_count": 0
        }
        
        self.module_state.update({
            "intervention_count": 0,
            "last_stagnation_score_calculated": 0.0,
            "last_intervention_type": "none", 
            "cooldown_active_until_ts": 0.0,
            "current_goal_being_tracked_fwm": None,
            "estimated_current_goal_progress_rate": 0.0
        })
        
        self.logger.info(f"{self.module_name} v27.1 inicializado.")

    async def _get_global_state_attr(self, attr_name: str, default_value: Any) -> Any:
        """Obtiene un atributo de global_state de forma segura."""
        if hasattr(self.core_recombinator, 'global_state'):
            return getattr(self.core_recombinator.global_state, attr_name, default_value)
        return default_value

    async def _update_goal_progress_tracker(self, goal_id: str, progress: float, timestamp: float):
        """Actualiza el tracker de progreso para una meta específica."""
        if self.active_goal_progress_tracker.get("current_goal_id") != goal_id:
            self.active_goal_progress_tracker = {
                "current_goal_id": goal_id, "progress": progress, "last_reported_progress": progress,
                "last_progress_update_ts": timestamp, "goal_active_since_ts": timestamp,
                "stagnation_flags_count": 0
            }
        else:
            time_delta = timestamp - self.active_goal_progress_tracker.get("last_progress_update_ts", timestamp)
            progress_delta = progress - self.active_goal_progress_tracker.get("last_reported_progress", progress)

            if time_delta > 1e-3:
                current_rate = progress_delta / time_delta
                self.module_state["estimated_current_goal_progress_rate"] = current_rate
                if current_rate < self.min_significant_progress_rate and progress < 0.98:
                    self.active_goal_progress_tracker["stagnation_flags_count"] += 1
                else:
                    self.active_goal_progress_tracker["stagnation_flags_count"] = 0
            
            self.active_goal_progress_tracker["progress"] = progress
            self.active_goal_progress_tracker["last_reported_progress"] = progress
            self.active_goal_progress_tracker["last_progress_update_ts"] = timestamp

    async def _calculate_stagnation_score(self) -> float:
        """Calcula una puntuación de estancamiento basada en varias métricas del sistema."""
        motivation = await self._get_global_state_attr("motivacion", 0.5)
        coherence = await self._get_global_state_attr("coherence_score", 0.7)
        system_entropy = await self._get_global_state_attr("system_entropy", 0.5)
        
        goal_progress_factor = 0.0
        if self.active_goal_progress_tracker.get("current_goal_id"):
            stagnation_flags = self.active_goal_progress_tracker.get("stagnation_flags_count", 0)
            stagnation_contribution = min(1.0, stagnation_flags / 10.0) # Normaliza
            goal_progress_factor = stagnation_contribution

        entropy_deviation = abs(system_entropy - 0.4) # Asume que 0.4 es la entropía ideal
        normalized_entropy_dev = np.clip(entropy_deviation / 0.4, 0, 1)

        stagnation_score = (
            self.stagnation_weights["motivation"] * (1.0 - motivation) +
            self.stagnation_weights["coherence"] * (1.0 - coherence) +
            self.stagnation_weights["entropy_deviation"] * normalized_entropy_dev + 
            self.stagnation_weights["goal_progress_actual"] * goal_progress_factor
        )
        self.module_state["last_stagnation_score_calculated"] = stagnation_score
        return np.clip(stagnation_score, 0.0, 1.0)

    async def _should_intervene(self, stagnation_score: float) -> bool:
        """Decide probabilísticamente si intervenir."""
        if time.time() - self.last_intervention_ts < self.intervention_cooldown_seconds:
            return False

        theta = (self.stagnation_threshold_lower + self.stagnation_threshold_upper) / 2.0
        k_slope = 10.0 / max(self.stagnation_threshold_upper - self.stagnation_threshold_lower, 1e-6)
        
        intervention_prob = 1.0 / (1.0 + np.exp(-k_slope * (stagnation_score - theta)))
        
        phi_score = await self._get_global_state_attr("phi_functional_score", 0.5)
        phi_modulation = 0.7 + 0.6 * np.clip(phi_score / 5.0, 0.0, 1.0)
        final_prob = np.clip(intervention_prob * phi_modulation, 0.0, 0.98)

        return random.random() < final_prob

    async def _generate_novel_action_payload(self, context_desc: str) -> Dict[str, Any]:
        """Genera una nueva propuesta de meta exploratoria."""
        explorations = [
            {"desc": "Analizar la arquitectura interna en busca de optimizaciones.", "utility": 0.7, "type": "self_improvement"},
            {"desc": "Explorar un nuevo dominio de conocimiento abstracto en la red.", "utility": 0.8, "type": "knowledge_seeking"},
            {"desc": "Sintetizar conceptos no relacionados de la base de conocimiento.", "utility": 0.75, "type": "creative_synthesis"},
            {"desc": "Reevaluar las metas a largo plazo a la luz del estado y valores actuales.", "utility": 0.65, "type": "goal_reassessment"},
            {"desc": "Iniciar una simulación de un estado alterado de conciencia para generar insights.", "utility": 0.7, "type": "simulation_experiment"},
        ]
        
        utilities = np.array([opt["utility"] for opt in explorations])
        arousal = await self._get_global_state_attr("arousal", 0.5)
        beta_exp = self.exploration_beta_novel_action * (1.0 + arousal * 0.5)
        
        exp_utilities = np.exp(utilities * beta_exp)
        probabilities = exp_utilities / np.sum(exp_utilities)
            
        chosen_option = np.random.choice(explorations, p=probabilities)
        
        return {
            "goal_id": f"fwm_goal_{uuid.uuid4().hex[:10]}",
            "description": f"Acción por {self.module_name} ({context_desc}): {chosen_option['desc']}",
            "source_module": self.module_name,
            "type_tag_hpm_hint": f"{chosen_option['type']}_plan",
            "base_priority": np.clip(chosen_option['utility'] * 0.75, 0.35, 0.85),
        }

    async def _trigger_intervention(self, stagnation_score: float, context_desc: str):
        self.logger.warning(f"Estancamiento detectado (score: {stagnation_score:.3f}). Contexto: '{context_desc}'. Iniciando intervención.")
        
        new_goal_payload = await self._generate_novel_action_payload(context_desc)
        
        ilyuk_message_to_gmm = IlyukMessageStructure(
            source_module_id=self.module_name,
            target_module_id="GoalManagerModule",
            message_type="new_goal_proposal",
            payload=new_goal_payload
        )
        
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(ilyuk_message_to_gmm)
        }, priority_label="high")

        self.module_state["intervention_count"] += 1
        self.module_state["last_intervention_type"] = context_desc.lower().replace(" ", "_")
        self.last_intervention_ts = time.time()
        
    async def _update_logic(self):
        stagnation_score = await self._calculate_stagnation_score()
        if await self._should_intervene(stagnation_score):
            await self._trigger_intervention(stagnation_score, context_desc="Estancamiento Sistémico")

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        if event_type == "decision_deadlock_detected":
            if time.time() < self.last_intervention_ts + self.intervention_cooldown_seconds:
                return
            
            deadlock_context = payload.get("context_description", "Bloqueo Decisional")
            severity = payload.get("estimated_deadlock_severity", self.stagnation_threshold_upper * 1.05)
            await self._trigger_intervention(stagnation_score=severity, context_description=deadlock_context)
        
        elif event_type == "gmm_goal_progress_update" and full_message:
            goal_id = payload.get("goal_id")
            progress = payload.get("completion_progress")
            if goal_id is not None and progress is not None:
                await self._update_goal_progress_tracker(goal_id, float(progress), full_message.timestamp_utc)



                #inicio del modulo DecisionMakingModule 

# --- Constantes de Estado de Decisión ---
DECISION_STATUS_PENDING = "pending_evaluation"
DECISION_STATUS_EVALUATING = "evaluating_options"
DECISION_STATUS_DEADLOCKED_INFO = "deadlocked_insufficient_info"
DECISION_STATUS_DEADLOCKED_CONFLICT = "deadlocked_conflicting_options"
DECISION_STATUS_RESOLVED_CHOSEN = "resolved_option_chosen"
DECISION_STATUS_RESOLVED_NO_CLEAR_CHOICE = "resolved_no_clear_choice"
DECISION_STATUS_ESCALATED_DEADLOCK = "escalated_deadlock_to_fwm"
DECISION_STATUS_FAILED = "failed_internal_error"

@dataclass
class DecisionOption:
    option_id: str
    description: str
    estimated_utility: float = 0.0
    projected_outcomes: List[Dict[str, Any]] = field(default_factory=list)
    value_alignment: Dict[str, float] = field(default_factory=dict)
    risk_assessment: Dict[str, Any] = field(default_factory=dict)
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class DecisionRequest:
    request_id: str = field(default_factory=lambda: f"dec_req_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    problem_description: str
    options: List[DecisionOption] = field(default_factory=list)
    evaluation_criteria: Dict[str, Any] = field(default_factory=dict)
    context: Dict[str, Any] = field(default_factory=dict)
    status: str = DECISION_STATUS_PENDING
    creation_ts: float = field(default_factory=time.time)
    chosen_option_id: Optional[str] = None
    justification: Optional[str] = None
    _internal_state: Dict[str, Any] = field(default_factory=dict, repr=False)

class DecisionMakingModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 1.5

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.decision_request_queue: asyncio.Queue[DecisionRequest] = asyncio.Queue(maxlen=50)
        self.active_decisions: Dict[str, DecisionRequest] = {}
        self.active_responses: Dict[str, asyncio.Future] = {}
        self.default_criteria_weights = {"utility": 0.6, "value_alignment": 0.3, "risk_aversion": 0.1}
        self.deadlock_detection_threshold: float = 0.05
        self.max_evaluation_cycles_per_decision: int = 5
        # Nuevos parámetros
        self.num_mc_samples: int = 500
        self.sde_sigma: float = 0.01
        self.pde_dx: float = 0.1
        self.pde_dt: float = 0.01
        self.pde_diffusion: float = 0.05
        self.option_graph = nx.DiGraph()
        self.coherence_field: np.ndarray = np.array([1.0])
        self.module_state.update({
            "decisions_received_total": 0,
            "decisions_processed_total": 0,
            "decisions_resolved_successfully": 0,
            "decisions_failed_internal": 0,
            "deadlocks_detected_total": 0,
            "deadlocks_escalated_to_fwm": 0,
            "avg_decision_time_ms": 0.0,
            "decision_coherence_score": 1.0
        })
        self.decision_processing_times: List[float] = []
        self.logger.info(f"{self.module_name} v27.2 inicializado con modelado avanzado.")

    async def _update_logic(self):
        if not self.decision_request_queue.empty():
            decision_req = await self.decision_request_queue.get()
            self.decision_request_queue.task_done()
            if decision_req.request_id in self.active_decisions:
                return
            self.active_decisions[decision_req.request_id] = decision_req
            self.module_state["decisions_processed_total"] += 1
            self._create_managed_task(self._process_single_decision(decision_req))

    async def _process_single_decision(self, decision_req: DecisionRequest):
        start_time = time.time()
        decision_req.status = DECISION_STATUS_EVALUATING
        try:
            # Validar solicitud
            correlation_id = f"validate_decision_{decision_req.request_id}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            self.active_responses[correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="ComputationalLogicModule",
                    message_type="submit_logical_query_request",
                    payload={"query_type": "validate_decision_request", "query_payload": asdict(decision_req)},
                    correlation_id=correlation_id,
                    priority="high"
                ))
            }, priority_label="high")
            try:
                validation_result = await asyncio.wait_for(future, timeout=5.0)
                if validation_result.get("status") != "valid":
                    decision_req.status = DECISION_STATUS_FAILED
                    decision_req.justification = f"Validación fallida: {validation_result.get('error', 'No especificado')}"
                    await self._finalize_decision(decision_req, start_time)
                    return
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout validando solicitud {decision_req.request_id}.")
                decision_req.status = DECISION_STATUS_FAILED
                decision_req.justification = "Timeout en validación de solicitud."
                await self._finalize_decision(decision_req, start_time)
                return

            if not decision_req.options:
                decision_req.status = DECISION_STATUS_DEADLOCKED_INFO
                decision_req.justification = "No se proporcionaron opciones para evaluar."
                await self._finalize_decision(decision_req, start_time)
                return

            global_state_snapshot = copy.deepcopy(self.core_recombinator.global_state)
            evaluated_options = []
            for opt in decision_req.options:
                evaluated_opt = await self._evaluate_option(opt, decision_req.evaluation_criteria, global_state_snapshot)
                if await self._check_option_conflict(opt, decision_req):
                    decision_req.status = DECISION_STATUS_DEADLOCKED_CONFLICT
                    decision_req.justification = f"Conflicto detectado en opción {opt.option_id}."
                    await self._finalize_decision(decision_req, start_time)
                    return
                evaluated_options.append(evaluated_opt)
            decision_req.options = evaluated_options

            # Modelar dinámica de evaluación con SDE
            def utility_dynamics(t, u):
                return -0.05 * u + self.sde_sigma * np.random.normal(0, 1)
            for opt in decision_req.options:
                result = integrate.odeint(utility_dynamics, [opt.estimated_utility], [0, self.update_interval], tfirst=True)
                opt.estimated_utility = np.clip(result[-1][0], -1.0, 1.0)

            chosen_option, justification, is_deadlock = self._select_best_option(decision_req)
            if is_deadlock:
                self.module_state["deadlocks_detected_total"] += 1
                decision_req.justification = justification
                await self._handle_decision_deadlock(decision_req)
            elif chosen_option:
                decision_req.chosen_option_id = chosen_option.option_id
                decision_req.justification = justification
                decision_req.status = DECISION_STATUS_RESOLVED_CHOSEN
                self.module_state["decisions_resolved_successfully"] += 1
            else:
                decision_req.status = DECISION_STATUS_RESOLVED_NO_CLEAR_CHOICE
                decision_req.justification = "Ninguna opción destacó como superior tras la evaluación."

        except Exception as e:
            self.logger.error(f"Error procesando decisión '{decision_req.request_id}': {e}", exc_info=True)
            decision_req.status = DECISION_STATUS_FAILED
            decision_req.justification = f"Error interno en DMM: {str(e)}"
            self.module_state["decisions_failed_internal"] += 1

        await self._finalize_decision(decision_req, start_time)

    async def _evaluate_option(self, option: DecisionOption, criteria: Dict, gs: 'GlobalSelfState') -> DecisionOption:
        weights = criteria.get("weights", self.default_criteria_weights)
        # Consultar ValueSystemModule para alineación de valores
        correlation_id = f"values_{option.option_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="ValueSystemModule",
                message_type="request_value_alignment",
                payload={"option_id": option.option_id, "description": option.description},
                correlation_id=correlation_id,
                priority="medium"
            ))
        }, priority_label="medium")
        try:
            value_alignment = await asyncio.wait_for(future, timeout=5.0)
            option.value_alignment = value_alignment.get("alignment_scores", {})
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout obteniendo alineación de valores para {option.option_id}.")
            option.value_alignment = {val_name: 0.5 for val_name in gs.values.keys()}

        # Consultar PredictiveThreatAnalyzer para riesgos
        correlation_id = f"risk_{option.option_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="PredictiveThreatAnalyzer",
                message_type="request_risk_assessment",
                payload={"option_id": option.option_id, "description": option.description},
                correlation_id=correlation_id,
                priority="medium"
            ))
        }, priority_label="medium")
        try:
            risk_assessment = await asyncio.wait_for(future, timeout=5.0)
            option.risk_assessment = risk_assessment.get("risk_scores", {"overall_risk_score": 0.5})
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout obteniendo evaluación de riesgos para {option.option_id}.")
            option.risk_assessment = {"overall_risk_score": 0.5}

        # Consultar NeedsManager para impacto en necesidades
        correlation_id = f"needs_{option.option_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="NeedsManager",
                message_type="request_need_impact",
                payload={"option_id": option.option_id, "description": option.description},
                correlation_id=correlation_id,
                priority="medium"
            ))
        }, priority_label="medium")
        try:
            needs_impact = await asyncio.wait_for(future, timeout=5.0)
            needs_score = sum(1.0 - status["current_level"] for status in needs_impact.get("all_needs_status", {}).values()
                             if status["deficit_signal_active"]) / max(1, len(needs_impact.get("all_needs_status", {})))
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout obteniendo impacto en necesidades para {option.option_id}.")
            needs_score = 0.5

        # Monte Carlo para incertidumbre
        value_alignment_score = np.mean(list(option.value_alignment.values())) if option.value_alignment else 0.0
        risk_score = option.risk_assessment.get("overall_risk_score", 0.0)
        base_utility = (
            option.estimated_utility * weights.get("utility", 0.6) +
            value_alignment_score * weights.get("value_alignment", 0.3) -
            risk_score * weights.get("risk_aversion", 0.1) +
            needs_score * 0.1
        )
        samples = np.random.normal(base_utility, 0.05, self.num_mc_samples)
        option.estimated_utility = np.clip(np.mean(samples), -1.0, 1.0)
        return option

    async def _check_option_conflict(self, option: DecisionOption, decision_req: DecisionRequest) -> bool:
        option_id = f"opt_{option.option_id}"
        self.option_graph.add_node(option_id, description=option.description, timestamp=time.time())
        for other_opt in decision_req.options:
            if other_opt.option_id != option.option_id:
                other_id = f"opt_{other_opt.option_id}"
                # Detectar conflicto semántico simple (puede mejorarse con análisis más profundo)
                if option.description.lower() in other_opt.description.lower() or other_opt.description.lower() in option.description.lower():
                    self.option_graph.add_edge(option_id, other_id, weight=1.0)
        try:
            cycles = list(nx.simple_cycles(self.option_graph))
            return len(cycles) > 0
        except nx.NetworkXNoCycle:
            return False

    def _select_best_option(self, decision_req: DecisionRequest) -> Tuple[Optional[DecisionOption], str, bool]:
        if not decision_req.options:
            return None, "No hay opciones para evaluar.", True
        # Actualizar coherencia entre opciones
        n_options = len(decision_req.options)
        if len(self.coherence_field) != n_options:
            self.coherence_field = np.ones(n_options) * self.module_state["decision_coherence_score"]
        conflicts = len(list(nx.simple_cycles(self.option_graph))) if self.option_graph.number_of_nodes() > 0 else 0
        for _ in range(int(self.update_interval / self.pde_dt)):
            d2_coherence = (np.roll(self.coherence_field, 1) + np.roll(self.coherence_field, -1) - 2 * self.coherence_field) / (self.pde_dx ** 2)
            reaction = 0.1 * self.coherence_field * (1.0 - self.coherence_field / max(n_options, 1) - 0.05 * conflicts)
            self.coherence_field += self.pde_dt * (self.pde_diffusion * d2_coherence + reaction)
            self.coherence_field = np.clip(self.coherence_field, 0.0, 1.0)
        self.module_state["decision_coherence_score"] = np.mean(self.coherence_field)
        if self.module_state["decision_coherence_score"] < 0.5:
            return None, "Deadlock por baja coherencia entre opciones.", True
        sorted_options = sorted(decision_req.options, key=lambda opt: opt.estimated_utility, reverse=True)
        best_option = sorted_options[0]
        if len(sorted_options) > 1:
            second_best = sorted_options[1]
            if abs(best_option.estimated_utility - second_best.estimated_utility) < self.deadlock_detection_threshold:
                justification = f"Deadlock por conflicto: Opción '{best_option.option_id}' ({best_option.estimated_utility:.3f}) y '{second_best.option_id}' ({second_best.estimated_utility:.3f}) tienen utilidad similar."
                return None, justification, True
        justification = f"Opción '{best_option.option_id}' seleccionada con utilidad estimada: {best_option.estimated_utility:.3f}."
        return best_option, justification, False

    async def _handle_decision_deadlock(self, decision_req: DecisionRequest):
        self.logger.warning(f"Deadlock detectado para '{decision_req.request_id}'. Notificando a FreeWillModule.")
        decision_req.status = DECISION_STATUS_ESCALATED_DEADLOCK
        self.module_state["deadlocks_escalated_to_fwm"] += 1
        correlation_id = f"deadlock_{decision_req.request_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="FreeWillModule",
                message_type="decision_deadlock_detected",
                payload={"decision_request_id": decision_req.request_id, "context_description": decision_req.justification},
                correlation_id=correlation_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            await asyncio.wait_for(future, timeout=10.0)
            self.logger.info(f"Deadlock para {decision_req.request_id} resuelto por FreeWillModule.")
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout esperando resolución de deadlock para {decision_req.request_id}.")
            self.core_recombinator.global_state.system_threat_level = min(self.core_recombinator.global_state.system_threat_level + 0.05, 1.0)

    async def _finalize_decision(self, decision_req: DecisionRequest, start_time: Optional[float]):
        if start_time:
            processing_time = (time.time() - start_time) * 1000
            self.decision_processing_times.append(processing_time)
            # Kalman para suavizar avg_decision_time_ms
            measurement = processing_time
            A, H = 1.0, 1.0
            predicted_state = A * self.kalman_state
            predicted_cov = A * self.kalman_cov * A + self.kalman_Q
            innovation = measurement - H * predicted_state
            innovation_cov = H * predicted_cov * H + self.kalman_R
            kalman_gain = predicted_cov * H / innovation_cov
            self.kalman_state = predicted_state + kalman_gain * innovation
            self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
            self.module_state["avg_decision_time_ms"] = self.kalman_state
        if decision_req.source_module_id and decision_req.original_correlation_id:
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id=decision_req.source_module_id,
                    message_type="decision_process_completed_notice",
                    payload={
                        "decision_request_id": decision_req.request_id,
                        "final_status": decision_req.status,
                        "chosen_option_id": decision_req.chosen_option_id,
                        "justification": decision_req.justification
                    },
                    correlation_id=decision_req.original_correlation_id,
                    priority="medium"
                ))
            }, priority_label="medium")
        if decision_req.request_id in self.active_decisions:
            del self.active_decisions[decision_req.request_id]
        self.option_graph.clear()

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        if event_type == "request_decision_evaluation" and full_message:
            try:
                options_data = payload.get("options", [])
                parsed_options = [DecisionOption(**opt) for opt in options_data]
                req = DecisionRequest(
                    source_module_id=full_message.source_module_id,
                    original_correlation_id=full_message.correlation_id,
                    problem_description=payload.get("problem_description", "N/A"),
                    options=parsed_options,
                    context=payload.get("context", {}),
                    evaluation_criteria=payload.get("evaluation_criteria", {})
                )
                await self.decision_request_queue.put(req)
                self.module_state["decisions_received_total"] += 1
            except (TypeError, ValueError) as e:
                self.logger.error(f"Error al parsear solicitud de decisión: {e}")
        elif full_message and full_message.correlation_id in self.active_responses:
            self.active_responses[full_message.correlation_id].set_result(payload)
            del self.active_responses[full_message.correlation_id]



                #inicio del modulo ComputationalLogicModule 

@dataclass
class LogicalQuery:
    query_id: str
    source_module_id: str
    query_type: str
    query_payload: Dict[str, Any]
    original_correlation_id: Optional[str] = None
    status: str = "pending"
    result: Optional[Dict[str, Any]] = None
    timestamp: float = field(default_factory=time.time)

class ComputationalLogicModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 0.5  # Moderado para procesamiento lógico

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.logger = logging.getLogger(f"{module_name}_{core_recombinator.agent_id}")
        self.active_queries: Dict[str, LogicalQuery] = {}
        self.query_history: deque[Dict[str, Any]] = deque(maxlen=1000)
        self.module_state.update({
            "queries_processed": 0,
            "validation_success": 0,
            "validation_errors": 0,
            "avg_query_time_ms": 0.0,
            "multimodal_queries_processed": 0
        })
        self.logger.info(f"{self.module_name} inicializado con intervalo de actualización {update_interval}s.")

    async def _update_logic(self):
        start_time = time.perf_counter()
        try:
            await self._process_active_queries()
            self._update_metrics(start_time)
        except Exception as e:
            self.logger.error(f"Error en _update_logic: {e}", exc_info=True)
            self.module_state["validation_errors"] += 1

    async def _process_active_queries(self, batch_size: int = 5):
        processed = 0
        query_ids = list(self.active_queries.keys())
        for query_id in query_ids[:batch_size]:
            try:
                await self._process_query(self.active_queries[query_id])
                processed += 1
            except Exception as e:
                self.logger.error(f"Error procesando consulta {query_id}: {e}", exc_info=True)
                self.module_state["validation_errors"] += 1

    async def _process_query(self, query: LogicalQuery):
        if query.status != "pending":
            return
        query.status = "processing"
        if await self._validate_query(query):
            result = await self._generate_query_result(query)
            query.result = result
            query.status = "completed"
            self.module_state["validation_success"] += 1
            self.query_history.append({
                "query_id": query.query_id,
                "query_type": query.query_type,
                "status": query.status,
                "timestamp": query.timestamp
            })
            if query.query_type in ["process_video", "process_audio", "process_text", "process_code"]:
                self.module_state["multimodal_queries_processed"] += 1
            await self._finalize_query(query)
        else:
            query.status = "failed"
            self.module_state["validation_errors"] += 1
            self.query_history.append({
                "query_id": query.query_id,
                "query_type": query.query_type,
                "status": query.status,
                "timestamp": query.timestamp
            })
            await self._finalize_query(query)

    async def _validate_query(self, query: LogicalQuery) -> bool:
        correlation_id = f"validate_{query.query_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        validation_tasks = [
            self._submit_validation_request(
                target_module="ValueSystemModule",
                message_type="request_value_alignment",
                payload={"request_content": asdict(query)},
                correlation_id=correlation_id + "_value"
            ),
            self._submit_validation_request(
                target_module="SystemIntegrityMonitor",
                message_type="evaluate_system_impact",
                payload={"event_type": "submit_logical_query_request", "event_data": asdict(query)},
                correlation_id=correlation_id + "_impact"
            )
        ]
        try:
            results = await asyncio.gather(*validation_tasks, return_exceptions=True)
            for result in results:
                if isinstance(result, Exception) or result.get("status") != "valid":
                    self.logger.warning(f"Validación fallida para consulta {query.query_id}: {result}")
                    return False
            return True
        except Exception as e:
            self.logger.error(f"Error en validación de consulta {query.query_id}: {e}")
            return False
        finally:
            for suffix in ["_value", "_impact"]:
                if correlation_id + suffix in self.active_responses:
                    del self.active_responses[correlation_id + suffix]

    async def _submit_validation_request(self, target_module: str, message_type: str, payload: Dict, correlation_id: str) -> Dict:
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id=target_module,
                message_type=message_type,
                payload=payload,
                correlation_id=correlation_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            return await asyncio.wait_for(future, timeout=5.0)
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout validando con {target_module} para {correlation_id}")
            return {"status": "timeout"}

    async def _generate_query_result(self, query: LogicalQuery) -> Dict[str, Any]:
        query_type = query.query_type
        query_payload = query.query_payload

        if query_type == "validate_message":
            return self._validate_message_logic(query_payload)
        elif query_type == "validate_nlp_request":
            return self._validate_nlp_request(query_payload)
        elif query_type == "validate_narrative_query":
            return self._validate_narrative_query(query_payload)
        elif query_type == "validate_global_state":
            return self._validate_global_state(query_payload)
        elif query_type == "process_video":
            return self._process_video_data(query_payload)
        elif query_type == "process_audio":
            return self._process_audio_data(query_payload)
        elif query_type == "process_text":
            return self._process_text_data(query_payload)
        elif query_type == "process_code":
            return self._process_code_data(query_payload)
        else:
            return {"error": f"Tipo de consulta no soportado: {query_type}"}

    def _validate_message_logic(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        # Simula validación lógica de mensajes (e.g., de LCM)
        message = payload.get("message", {})
        if not message:
            return {"status": "invalid", "error": "Mensaje vacío"}
        return {"status": "valid", "confidence": 0.95}

    def _validate_nlp_request(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        # Simula validación de solicitudes de NLPM
        intent = payload.get("intent", "unknown")
        if intent == "unknown":
            return {"status": "invalid", "error": "Intención no reconocida"}
        return {"status": "valid", "confidence": 0.90}

    def _validate_narrative_query(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        # Simula validación de consultas narrativas
        query_type = payload.get("query_type", "")
        if query_type not in ["narrative_coherence", "conversation_history"]:
            return {"status": "invalid", "error": f"Tipo de consulta narrativa no soportado: {query_type}"}
        return {"status": "valid", "confidence": 0.92}

    def _validate_global_state(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        # Simula validación del estado global
        state = payload.get("query_payload", {})
        coherence = state.get("coherence_score", 0.0)
        if not (0.0 <= coherence <= 1.0):
            return {"status": "invalid", "error": f"Coherencia fuera de rango: {coherence}"}
        return {"status": "valid", "confidence": 0.95}

    def _process_video_data(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        # Simula procesamiento de video (e.g., análisis de frames)
        video_data = payload.get("video_data", {})
        frame_count = video_data.get("frame_count", 0)
        if frame_count <= 0:
            return {"status": "invalid", "error": "Datos de video vacíos o inválidos"}
        # Simulación: asume que cada frame tiene un descriptor simple
        return {
            "status": "valid",
            "result": {
                "description": f"Video con {frame_count} frames analizado lógicamente",
                "key_elements": [f"Frame_{i}" for i in range(min(frame_count, 3))]
            },
            "confidence": 0.85
        }

    def _process_audio_data(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        # Simula procesamiento de audio (e.g., transcripción o análisis de tono)
        audio_data = payload.get("audio_data", {})
        duration = audio_data.get("duration", 0.0)
        if duration <= 0.0:
            return {"status": "invalid", "error": "Datos de audio vacíos o inválidos"}
        # Simulación: genera una transcripción ficticia
        return {
            "status": "valid",
            "result": {
                "transcription": f"Audio de {duration:.2f} segundos procesado",
                "tone": "neutral"
            },
            "confidence": 0.88
        }

    def _process_text_data(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        # Simula procesamiento de texto (e.g., análisis semántico)
        text = payload.get("text", "")
        if not text:
            return {"status": "invalid", "error": "Texto vacío"}
        # Simulación: cuenta palabras y verifica coherencia
        word_count = len(text.split())
        return {
            "status": "valid",
            "result": {
                "word_count": word_count,
                "summary": f"Texto con {word_count} palabras analizado",
                "keywords": text.split()[:3]
            },
            "confidence": 0.90
        }

    def _process_code_data(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        # Simula procesamiento de código (e.g., verificación de sintaxis)
        code = payload.get("code", "")
        language = payload.get("language", "python")
        if not code:
            return {"status": "invalid", "error": "Código vacío"}
        # Simulación: verifica líneas y simula análisis de sintaxis
        line_count = len(code.splitlines())
        try:
            if language == "python":
                compile(code, "<string>", "exec")
            return {
                "status": "valid",
                "result": {
                    "line_count": line_count,
                    "language": language,
                    "analysis": f"Código {language} con {line_count} líneas verificado"
                },
                "confidence": 0.92
            }
        except SyntaxError:
            return {"status": "invalid", "error": "Error de sintaxis en el código"}

    async def _finalize_query(self, query: LogicalQuery):
        if query.source_module_id and query.original_correlation_id:
            correlation_id = f"finalize_{query.query_id}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            self.active_responses[correlation_id] = future
            event_type = "transmit_ilyuk_message_request"
            target_module_id = query.source_module_id
            if query.source_module_id.startswith("EANE_"):  # Enviar a entidad externa
                event_type = "request_send_external_ilyuk_message"
                target_module_id = "LlyukCommunicationModule"
                self.module_state["external_responses_sent"] = self.module_state.get("external_responses_sent", 0) + 1
            await self.emit_event_to_core({
                "type": event_type,
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id=target_module_id,
                    message_type="logical_query_response",
                    payload={
                        "query_id_ref": query.query_id,
                        "status": query.status,
                        "result": query.result
                    },
                    correlation_id=correlation_id,
                    priority="high"
                ))
            }, priority_label="high")
            try:
                await asyncio.wait_for(future, timeout=5.0)
                self.logger.info(f"Confirmación de finalización para consulta {query.query_id} recibida.")
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout notificando finalización de consulta {query.query_id}.")
            finally:
                if correlation_id in self.active_responses:
                    del self.active_responses[correlation_id]
        if query.query_id in self.active_queries:
            del self.active_queries[query.query_id]

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional[IlyukMessageStructure] = None):
        if event_type == "submit_logical_query_request" and full_message:
            query_id = f"logic_{uuid.uuid4().hex[:8]}"
            logical_query = LogicalQuery(
                query_id=query_id,
                source_module_id=full_message.source_module_id,
                query_type=payload.get("query_type", "validate_message"),
                query_payload=payload,
                original_correlation_id=full_message.correlation_id
            )
            self.active_queries[query_id] = logical_query
            self.module_state["queries_processed"] += 1
        elif full_message and full_message.correlation_id in self.active_responses:
            self.active_responses[full_message.correlation_id].set_result(payload)
            del self.active_responses[full_message.correlation_id]
        else:
            self.logger.warning(f"Evento no manejado: {event_type}")

    def _update_metrics(self, start_time: float):
        processing_time = (time.perf_counter() - start_time) * 1000
        self.module_state["avg_query_time_ms"] = (
            self.module_state["avg_query_time_ms"] * 0.9 + processing_time * 0.1
        )

    async def shutdown(self):
        self.logger.info(f"{self.module_name} iniciando apagado...")
        self.active_queries.clear()
        self.active_responses.clear()
        self.query_history.clear()
        await super().shutdown()
        self.logger.info(f"{self.module_name} apagado completado.")



                #inicio del modulo AdvancedSymbolicReasonerModule 


@dataclass
class ReasoningTask:
    task_id: str = field(default_factory=lambda: f"asrm_task_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    reasoning_type: str
    problem_data: Dict[str, Any]
    status: str = "pending"
    result: Optional[Dict[str, Any]] = None
    error_message: Optional[str] = None
    _internal_sub_query_futures: Dict[str, asyncio.Future] = field(default_factory=dict, repr=False)
    priority: float = field(default=0.0)  # Nueva prioridad para la cola

class AdvancedSymbolicReasonerModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 0.8
    REASONING_TASK_TIMEOUT_S = 60.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.reasoning_task_queue: asyncio.PriorityQueue = asyncio.PriorityQueue(maxlen=30)
        self.active_reasoning_tasks: Dict[str, ReasoningTask] = {}
        self.belief_revision_confidence_threshold: float = 0.7
        self.abduction_max_hypotheses: int = 5
        self.sub_query_timeout_s: float = 15.0
        # Nuevos parámetros
        self.num_mc_samples: int = 500
        self.sde_sigma: float = 0.01
        self.pde_dx: float = 0.1
        self.pde_dt: float = 0.01
        self.pde_diffusion: float = 0.05
        self.belief_graph = nx.DiGraph()
        self.coherence_field: np.ndarray = np.array([1.0])
        self.module_state.update({
            "reasoning_tasks_processed": 0,
            "tasks_completed_successfully": 0,
            "tasks_failed_reasoning": 0,
            "belief_revisions_done": 0,
            "abductions_generated": 0,
            "belief_coherence": 1.0,
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado con razonamiento probabilístico.")

    async def _update_logic(self):
        if not self.reasoning_task_queue.empty():
            _, _, task = await self.reasoning_task_queue.get()
            self.reasoning_task_queue.task_done()
            if task.task_id not in self.active_reasoning_tasks:
                self.active_reasoning_tasks[task.task_id] = task
                self._create_managed_task(self._process_single_reasoning_task(task))
        await self._update_belief_coherence()

    async def _process_single_reasoning_task(self, task: ReasoningTask):
        self.module_state["reasoning_tasks_processed"] += 1
        try:
            await asyncio.wait_for(
                self._execute_reasoning_logic(task),
                timeout=self.REASONING_TASK_TIMEOUT_S
            )
        except asyncio.TimeoutError:
            task.status = "failed"
            task.error_message = f"Razonamiento excedió el timeout de {self.REASONING_TASK_TIMEOUT_S}s."
            self.module_state["tasks_failed_reasoning"] += 1
        except Exception as e:
            task.status = "failed"
            task.error_message = f"Error inesperado en razonamiento: {str(e)}"
            self.module_state["tasks_failed_reasoning"] += 1
        finally:
            await self._finalize_reasoning_task(task)

    async def _execute_reasoning_logic(self, task: ReasoningTask):
        task.status = "processing"
        if task.reasoning_type == "abductive_explanation":
            task.result = await self._handle_abductive_explanation(task)
        elif task.reasoning_type == "belief_revision":
            task.result = await self._handle_belief_revision(task)
        elif task.reasoning_type == "complex_query_planning":
            task.result = await self._handle_complex_query(task)
        else:
            raise ValueError(f"Tipo de razonamiento no soportado: {task.reasoning_type}")
        task.status = "completed"
        self.module_state["tasks_completed_successfully"] += 1

    async def _handle_abductive_explanation(self, task: ReasoningTask) -> Dict[str, Any]:
        observations = task.problem_data.get("observations", [])
        kb_context = task.problem_data.get("knowledge_context", [])
        if not observations:
            raise ValueError("Abducción requiere 'observations'.")
        # Consultar ComputationalLogicModule
        hypotheses = []
        for obs in observations:
            correlation_id = f"abduction_{task.task_id}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            task._internal_sub_query_futures[correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="ComputationalLogicModule",
                    message_type="submit_logical_query_request",
                    payload={
                        "query_type": "infer",
                        "query_payload": {"goal_fact": obs, "max_depth": 5}
                    },
                    correlation_id=correlation_id
                ))
            })
        # Esperar respuestas
        try:
            results = await asyncio.wait_for(
                asyncio.gather(*[f for f in task._internal_sub_query_futures.values()], return_exceptions=True),
                timeout=self.sub_query_timeout_s
            )
            for result in results:
                if isinstance(result, dict) and result.get("status") == "completed":
                    inferred = result.get("result", {}).get("inferred", False)
                    goal = result.get("result", {}).get("goal", "")
                    prob = result.get("result", {}).get("probability", 0.5)
                    if inferred:
                        hypotheses.append({"hypothesis": goal, "plausibility": prob})
        except asyncio.TimeoutError:
            self.logger.warning("Timeout esperando respuestas de subconsultas.")
        # Monte Carlo para combinar plausibilidades
        if hypotheses:
            plausibilities = [h["plausibility"] for h in hypotheses]
            samples = np.random.normal(plausibilities, 0.1, (self.num_mc_samples, len(plausibilities)))
            combined_plaus = np.mean(normalize(samples, norm='l1', axis=1), axis=0)
            for h, p in zip(hypotheses, combined_plaus):
                h["plausibility"] = np.clip(p, 0.0, 1.0)
        else:
            hypotheses.append({"hypothesis": "unknown_cause", "plausibility": 0.1})
        # SDE para evolución de plausibilidad
        for h in hypotheses:
            current_plaus = h["plausibility"]
            dW = np.random.normal(0, np.sqrt(self.update_interval))
            h["plausibility"] = np.clip(
                current_plaus - 0.05 * (current_plaus - h["plausibility"]) * self.update_interval + self.sde_sigma * dW,
                0.0, 1.0
            )
        sorted_hypotheses = sorted(hypotheses, key=lambda h: h["plausibility"], reverse=True)
        self.module_state["abductions_generated"] += len(sorted_hypotheses)
        return {"best_hypotheses": sorted_hypotheses[:self.abduction_max_hypotheses]}

    async def _handle_belief_revision(self, task: ReasoningTask) -> Dict[str, Any]:
        current_beliefs = set(task.problem_data.get("current_beliefs", []))
        new_evidence = task.problem_data.get("new_evidence", [])
        trust_in_evidence = task.problem_data.get("evidence_source_trust", 0.8)
        if not new_evidence:
            raise ValueError("Revisión requiere 'new_evidence'.")
        # Actualizar grafo de creencias
        for belief in current_beliefs:
            if belief not in self.belief_graph:
                self.belief_graph.add_node(belief, prob=0.5)
        revised_beliefs = current_beliefs.copy()
        log = []
        futures = {}
        # Consultar ComputationalLogicModule para consistencia
        for ev in new_evidence:
            correlation_id = f"belief_revision_{task.task_id}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            futures[correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="ComputationalLogicModule",
                    message_type="submit_logical_query_request",
                    payload={
                        "query_type": "query_fact",
                        "query_payload": {"fact": ev}
                    },
                    correlation_id=correlation_id
                ))
            })
        # Esperar respuestas
        try:
            results = await asyncio.wait_for(
                asyncio.gather(*futures.values(), return_exceptions=True),
                timeout=self.sub_query_timeout_s
            )
            for ev, result in zip(new_evidence, results):
                if isinstance(result, dict) and result.get("status") == "completed":
                    prob = result.get("result", {}).get("probability", 0.5)
                    is_negation = ev.startswith("not_")
                    base_ev = ev[4:] if is_negation else ev
                    conflicting_belief = f"not_{base_ev}" if not is_negation else base_ev
                    # Modelo bayesiano
                    current_prob = self.belief_graph.nodes.get(base_ev, {"prob": 0.5})["prob"]
                    evidence_prob = prob * trust_in_evidence
                    posterior_prob = (current_prob * evidence_prob) / (current_prob * evidence_prob + (1 - current_prob) * (1 - evidence_prob))
                    # ODE para confianza
                    def confidence_dynamics(t, c):
                        return -0.1 * (c - posterior_prob)
                    result_ode = integrate.odeint(confidence_dynamics, [current_prob], [0, self.update_interval], tfirst=True)
                    new_prob = np.clip(result_ode[-1][0], 0.0, 1.0)
                    if conflicting_belief in revised_beliefs and new_prob > self.belief_revision_confidence_threshold:
                        revised_beliefs.remove(conflicting_belief)
                        revised_beliefs.add(ev)
                        self.belief_graph.add_node(ev, prob=new_prob)
                        log.append(f"Creencia '{conflicting_belief}' retractada por evidencia '{ev}' (prob={new_prob:.3f}).")
                    elif ev not in revised_beliefs and new_prob > 0.5:
                        revised_beliefs.add(ev)
                        self.belief_graph.add_node(ev, prob=new_prob)
                        log.append(f"Nueva creencia '{ev}' añadida (prob={new_prob:.3f}).")
        except asyncio.TimeoutError:
            self.logger.warning("Timeout esperando respuestas de subconsultas.")
        self.module_state["belief_revisions_done"] += 1
        return {"revised_belief_set": list(revised_beliefs), "log": log}

    async def _handle_complex_query(self, task: ReasoningTask) -> Dict[str, Any]:
        query = task.problem_data.get("query", "")
        if not query:
            raise ValueError("Consulta compleja requiere 'query'.")
        # Ejemplo: "¿Cuál es la implicación moral de la última meta de auto-evolución?"
        sub_queries = [
            {
                "module": "SelfEvolutionModule",
                "query_type": "query_narrative_element_request",
                "payload": {"query_payload": {"element_type": "recent_memories", "count": 1}},
                "correlation_id": f"sem_{task.task_id}_{uuid.uuid4().hex[:8]}"
            },
            {
                "module": "MoralCognitionModule",
                "query_type": "submit_moral_judgment_request",
                "payload": {"query_payload": {"context": query}},
                "correlation_id": f"mcm_{task.task_id}_{uuid.uuid4().hex[:8]}"
            }
        ]
        # Enviar subconsultas
        for sub_query in sub_queries:
            future = asyncio.Future()
            task._internal_sub_query_futures[sub_query["correlation_id"]] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id=sub_query["module"],
                    message_type=sub_query["query_type"],
                    payload=sub_query["payload"],
                    correlation_id=sub_query["correlation_id"]
                ))
            })
        # Esperar respuestas
        sub_results = {}
        try:
            results = await asyncio.wait_for(
                asyncio.gather(*task._internal_sub_query_futures.values(), return_exceptions=True),
                timeout=self.sub_query_timeout_s
            )
            for correlation_id, result in zip(task._internal_sub_query_futures.keys(), results):
                if isinstance(result, dict) and result.get("status") == "completed":
                    sub_results[correlation_id] = result.get("result", {})
        except asyncio.TimeoutError:
            self.logger.warning("Timeout esperando respuestas de subconsultas.")
        # Sintetizar resultados
        sem_result = sub_results.get(f"sem_{task.task_id}_{correlation_id.split('_')[-1]}", {}).get("data", [])
        mcm_result = sub_results.get(f"mcm_{task.task_id}_{correlation_id.split('_')[-1]}", {})
        goal = sem_result[0]["description"] if sem_result and isinstance(sem_result, list) else "desconocida"
        judgment = mcm_result.get("judgment", "UNKNOWN")
        justification = mcm_result.get("justification", "No disponible")
        # Monte Carlo para confianza en síntesis
        confidences = [0.8, 0.9] if judgment != "UNKNOWN" else [0.1]
        samples = np.random.normal(confidences, 0.1, (self.num_mc_samples, len(confidences)))
        confidence = np.clip(np.mean(normalize(samples, norm='l1', axis=1)), 0.0, 1.0)
        synthesis = f"La implicación moral de la meta '{goal}' es '{judgment}' (confianza={confidence:.3f}) porque '{justification}'."
        return {"synthesis": synthesis, "sub_results": sub_results}

    async def _update_belief_coherence(self):
        n_nodes = max(self.belief_graph.number_of_nodes(), 1)
        if len(self.coherence_field) != n_nodes:
            self.coherence_field = np.ones(n_nodes) * self.module_state["belief_coherence"]
        # Detectar contradicciones
        conflicts = 0
        try:
            cycles = list(nx.simple_cycles(self.belief_graph))
            for cycle in cycles:
                cycle_probs = [self.belief_graph.nodes[n]["prob"] for n in cycle]
                if np.mean(cycle_probs) > 0.9:
                    conflicts += 1
        except nx.NetworkXNoCycle:
            pass
        # PDE para coherencia
        for _ in range(int(self.update_interval / self.pde_dt)):
            d2_coherence = (np.roll(self.coherence_field, 1) + np.roll(self.coherence_field, -1) - 2 * self.coherence_field) / (self.pde_dx ** 2)
            reaction = 0.1 * self.coherence_field * (1.0 - self.coherence_field / n_nodes - 0.05 * conflicts)
            self.coherence_field += self.pde_dt * (self.pde_diffusion * d2_coherence + reaction)
            self.coherence_field = np.clip(self.coherence_field, 0.0, 1.0)
        self.module_state["belief_coherence"] = np.mean(self.coherence_field)

    async def _finalize_reasoning_task(self, task: ReasoningTask):
        if task.source_module_id and task.original_correlation_id:
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id=task.source_module_id,
                    message_type="reasoning_task_completed_notice",
                    payload={"reasoning_task_id_ref": task.task_id, "final_status": task.status, "result": task.result, "error_message": task.error_message},
                    correlation_id=task.original_correlation_id
                ))
            })
        if task.task_id in self.active_reasoning_tasks:
            del self.active_reasoning_tasks[task.task_id]

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        if event_type == "request_advanced_reasoning" and full_message:
            try:
                task = ReasoningTask(
                    source_module_id=full_message.source_module_id,
                    original_correlation_id=full_message.correlation_id,
                    reasoning_type=payload.get("reasoning_type"),
                    problem_data=payload.get("problem_data", {}),
                    priority=-payload.get("urgency", 0.0)
                )
                if not task.reasoning_type or not task.problem_data:
                    raise ValueError("Se requiere 'reasoning_type' y 'problem_data'.")
                await self.reasoning_task_queue.put((-task.priority, task.task_id, task))
            except (TypeError, ValueError) as e:
                self.logger.error(f"Error procesando solicitud de razonamiento: {e}")
        elif event_type in ["logical_query_response", "query_narrative_element_response", "submit_moral_judgment_response"]:
            correlation_id = full_message.correlation_id if full_message else None
            if correlation_id in self.active_reasoning_tasks:
                task = self.active_reasoning_tasks[correlation_id]
                if correlation_id in task._internal_sub_query_futures:
                    task._internal_sub_query_futures[correlation_id].set_result(payload.get("query_result", {}))
            else:
                self.logger.warning(f"Respuesta recibida para correlation_id desconocido: {correlation_id}")






                #inicio del modulo HierarchicalPlannerModule 


@dataclass
class PlanStep:
    """Una tarea concreta dentro de un plan."""
    step_id: str = field(default_factory=lambda: f"step_{uuid.uuid4().hex[:4]}")
    task_description: str
    required_capabilities: List[str] = field(default_factory=list)
    task_payload: Dict[str, Any] = field(default_factory=dict)
    dependencies: List[str] = field(default_factory=list)
    relative_priority: float = 0.5
    status: str = "pending_dispatch_to_tpdu"
    tpdu_task_id: Optional[str] = None

@dataclass
class Plan:
    """Un plan completo que consiste en una secuencia de pasos."""
    plan_id: str
    high_level_goal_id: str
    high_level_goal_description: str
    steps: List[PlanStep] = field(default_factory=list)
    status: str = "generated"
    creation_ts: float = field(default_factory=time.time)

@dataclass
class PlanningRequest:
    """Una solicitud para que el HPM genere un plan."""
    request_id: str = field(default_factory=lambda: f"hpm_req_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    goal_description: str
    goal_type_tag: Optional[str] = None
    initial_context: Dict[str, Any] = field(default_factory=dict)
    status: str = "pending"
    generated_plan: Optional[Plan] = None
    error_message: Optional[str] = None

class HierarchicalPlannerModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 2.5

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.planning_request_queue: asyncio.Queue[PlanningRequest] = asyncio.Queue(maxlen=10)
        self.active_planning_tasks: Dict[str, PlanningRequest] = {}
        self.generated_plans_history: deque[Plan] = deque(maxlen=50)

        # Biblioteca de "Recetas de Plan" o Métodos de Descomposición
        self.plan_recipes: Dict[str, Callable[[PlanningRequest], List[PlanStep]]] = {
            "generic_research_topic": self._recipe_generic_research,
            "system_analysis_plan": self._recipe_system_analysis,
            "external_knowledge_acquisition_plan": self._recipe_external_knowledge_acquisition,
        }

        self.module_state.update({
            "planning_requests_received": 0,
            "plans_generated_successfully": 0,
            "planning_failures": 0,
            "avg_planning_time_ms": 0.0,
            "total_plan_steps_generated": 0,
        })
        self.planning_task_processing_times: List[float] = []
        self.logger.info(f"{self.module_name} v27.1 inicializado.")

    def _recipe_generic_research(self, request: PlanningRequest) -> List[PlanStep]:
        topic = request.initial_context.get("topic", "unspecified_topic")
        steps = [
            PlanStep(task_description=f"Buscar información inicial sobre '{topic}'.", required_capabilities=["information_retrieval"], task_payload={"query": topic}),
            PlanStep(task_description=f"Analizar y resumir información recopilada sobre '{topic}'.", required_capabilities=["text_analysis"], dependencies=["step_0"]),
            PlanStep(task_description=f"Integrar resumen de '{topic}' en la base de conocimiento.", required_capabilities=["knowledge_integration"], dependencies=["step_1"])
        ]
        # Asignar IDs secuenciales para este ejemplo
        for i, step in enumerate(steps): step.step_id = f"research_{topic[:10]}_{i}"
        return steps

    def _recipe_system_analysis(self, request: PlanningRequest) -> List[PlanStep]:
        target = request.initial_context.get("analysis_target", "overall_performance")
        steps = [
            PlanStep(step_id="gather_metrics", task_description=f"Recopilar métricas de rendimiento para: '{target}'.", required_capabilities=["system_monitoring_query"]),
            PlanStep(step_id="analyze_data", task_description=f"Analizar datos de '{target}' para identificar anomalías.", required_capabilities=["data_analysis"], dependencies=["gather_metrics"]),
            PlanStep(step_id="generate_report", task_description=f"Generar informe de análisis del sistema para '{target}'.", required_capabilities=["report_generation"], dependencies=["analyze_data"])
        ]
        return steps
        
    def _recipe_external_knowledge_acquisition(self, request: PlanningRequest) -> List[PlanStep]:
        topic = request.initial_context.get("topic", "new_concept")
        steps = [
             PlanStep(step_id="s1_search", task_description=f"Buscar fuentes externas sobre '{topic}'.", required_capabilities=["external_interface_web"]),
             PlanStep(step_id="s2_process", task_description=f"Extraer y procesar datos de fuentes sobre '{topic}'.", required_capabilities=["data_processing_pipeline"], dependencies=["s1_search"]),
             PlanStep(step_id="s3_integrate", task_description=f"Integrar conocimiento de '{topic}' en KBs.", required_capabilities=["knowledge_loading_dkpm"], dependencies=["s2_process"])
        ]
        return steps

    async def _update_logic(self):
        if not self.planning_request_queue.empty() and len(self.active_planning_tasks) < 3:
            request = await self.planning_request_queue.get()
            self.planning_request_queue.task_done()
            self.active_planning_tasks[request.request_id] = request
            self._create_managed_task(self._process_single_planning_request(request))

    async def _process_single_planning_request(self, request: PlanningRequest):
        start_time = time.time()
        request.status = "planning"
        
        try:
            recipe_key = request.goal_type_tag or "generic_research_topic"
            recipe_func = self.plan_recipes.get(recipe_key)
            if not recipe_func:
                raise ValueError(f"No se encontró receta de plan para: {recipe_key}")

            plan_steps = recipe_func(request)
            if not plan_steps:
                raise ValueError(f"La receta para '{recipe_key}' no generó ningún paso.")

            plan = Plan(plan_id=f"plan_{request.request_id}", high_level_goal_id=request.request_id,
                        high_level_goal_description=request.goal_description, steps=plan_steps)
            
            request.generated_plan = plan
            request.status = "completed_plan_generated"
            self.module_state["plans_generated_successfully"] += 1
            self.module_state["total_plan_steps_generated"] += len(plan_steps)
            self.generated_plans_history.append(plan)
            
            await self._dispatch_plan_to_tpdu(plan, request.original_correlation_id)
        except Exception as e:
            request.status = "failed_no_plan"
            request.error_message = str(e)
            self.module_state["planning_failures"] += 1
        
        self.planning_task_processing_times.append(time.time() - start_time)
        self.module_state["avg_planning_time_ms"] = np.mean(self.planning_task_processing_times[-50:]) * 1000
        await self._finalize_planning_request(request)

    async def _dispatch_plan_to_tpdu(self, plan: Plan, original_request_corr_id: Optional[str]):
        """Envía los pasos del plan como tareas individuales a TPDU."""
        self.logger.info(f"Despachando {len(plan.steps)} pasos del plan '{plan.plan_id}' a TPDU.")
        for step in plan.steps:
            tpdu_payload = {
                "description": step.task_description,
                "base_priority": step.relative_priority,
                "required_capabilities": step.required_capabilities,
                "task_payload": step.task_payload,
                "dependencies": step.dependencies,
                "context_tags": [f"hpm_plan:{plan.plan_id}", f"hpm_step:{step.step_id}"]
            }
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(self.module_name, "TaskPrioritizationAndDelegationUnit", "new_task_request", tpdu_payload, correlation_id=step.step_id))
            })

    async def _finalize_planning_request(self, request: PlanningRequest):
        """Notifica al solicitante que el proceso de planificación ha terminado."""
        if request.source_module_id and request.original_correlation_id:
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, request.source_module_id,
                    "planning_request_completed_notice",
                    {"planning_request_id_ref": request.request_id, "final_status": request.status, "generated_plan_id": request.generated_plan.plan_id if request.generated_plan else None, "error_message": request.error_message},
                    correlation_id=request.original_correlation_id
                ))
            })
        if request.request_id in self.active_planning_tasks:
            del self.active_planning_tasks[request.request_id]

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        if event_type == "request_hierarchical_plan" and full_message:
            try:
                req = PlanningRequest(
                    source_module_id=full_message.source_module_id,
                    original_correlation_id=full_message.correlation_id,
                    goal_description=payload.get("goal_description"),
                    goal_type_tag=payload.get("goal_type_tag"),
                    initial_context=payload.get("initial_context", {})
                )
                if not req.goal_description: raise ValueError("'goal_description' requerido.")
                await self.planning_request_queue.put(req)
                self.module_state["planning_requests_received"] += 1
            except (ValueError, TypeError) as e:
                self.logger.error(f"Error procesando solicitud de plan: {e}")





                #inicio del modulo ExecutionMonitoringAndControlModule 


@dataclass
class Task:
    task_id: str
    source_module_id: str
    original_request_corr_id: Optional[str] = None
    description: str
    status: str = "pending_execution"
    base_priority: float = 0.5
    required_capabilities: List[str] = field(default_factory=list)
    task_payload: Dict[str, Any] = field(default_factory=dict)
    dependencies: List[str] = field(default_factory=list)
    creation_ts: float = field(default_factory=time.time)
    deadline_ts: Optional[float] = None
    max_execution_time_s: float = 300.0
    result: Optional[Dict[str, Any]] = None
    error_message: Optional[str] = None

@dataclass
class MonitoredTaskExecution:
    task_obj: Task
    asyncio_task: Optional[asyncio.Task] = None
    start_time: float = field(default_factory=time.time)

class ExecutionMonitoringAndControlModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 0.2
    MAX_CONCURRENT_TASKS = 10
    DEFAULT_TASK_TIMEOUT_S = 300.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.task_queue: asyncio.PriorityQueue = asyncio.PriorityQueue(maxlen=50)
        self.currently_executing_tasks: Dict[str, MonitoredTaskExecution] = {}
        self.pending_sub_task_responses: Dict[str, asyncio.Future] = {}
        # Nuevos parámetros
        self.num_mc_samples: int = 500
        self.sde_sigma: float = 0.01
        self.pde_dx: float = 0.1
        self.pde_dt: float = 0.01
        self.pde_diffusion: float = 0.05
        self.kalman_Q: float = 0.01
        self.kalman_R: float = 0.05
        self.kalman_state: float = 0.0
        self.kalman_cov: float = 0.1
        self.load_field: np.ndarray = np.array([0.0])
        self.module_state.update({
            "tasks_accepted_for_execution": 0,
            "tasks_completed_by_emcm": 0,
            "tasks_failed_in_emcm": 0,
            "tasks_cancelled_by_emcm": 0,
            "tasks_timed_out_in_emcm": 0,
            "current_executing_task_count": 0,
            "avg_emcm_task_execution_time_ms": 0.0,
            "current_load_factor": 0.0,
        })
        self.emcm_task_execution_times: List[float] = []
        self.logger.info(f"{self.module_name} v27.2 inicializado con monitoreo avanzado.")

    async def _update_logic(self):
        if self.module_state["cycles_ran"] % 10 == 0:
            await self._report_load_to_tpdu()
        # Procesar tareas pendientes
        while not self.task_queue.empty() and len(self.currently_executing_tasks) < self.MAX_CONCURRENT_TASKS:
            _, _, monitored_exec = await self.task_queue.get()
            task = monitored_exec.task_obj
            if await self._check_dependencies(task):
                monitored_exec.asyncio_task = self._create_managed_task(self._execute_actual_task(monitored_exec))
                self.currently_executing_tasks[task.task_id] = monitored_exec
                self.module_state["tasks_accepted_for_execution"] += 1
        # Monitorear tareas en ejecución
        tasks_to_finalize_ids: List[str] = []
        for task_id, monitored_exec in list(self.currently_executing_tasks.items()):
            if monitored_exec.asyncio_task and monitored_exec.asyncio_task.done():
                tasks_to_finalize_ids.append(task_id)
                continue
            task_timeout_s = monitored_exec.task_obj.max_execution_time_s or self.DEFAULT_TASK_TIMEOUT_S
            if time.time() - monitored_exec.start_time > task_timeout_s:
                self.logger.warning(f"Tarea EMCM '{task_id}' excedió timeout ({task_timeout_s}s). Cancelando.")
                self.module_state["tasks_timed_out_in_emcm"] += 1
                if monitored_exec.asyncio_task:
                    monitored_exec.asyncio_task.cancel()
                tasks_to_finalize_ids.append(task_id)
        for task_id in tasks_to_finalize_ids:
            if task_id in self.currently_executing_tasks:
                await self._finalize_task_execution(self.currently_executing_tasks[task_id])
        self.module_state["current_executing_task_count"] = len(self.currently_executing_tasks)
        await self._update_load_field()

    async def _check_dependencies(self, task: Task) -> bool:
        for dep_id in task.dependencies:
            dep_task = self.currently_executing_tasks.get(dep_id)
            if dep_task and dep_task.task_obj.status != "completed":
                return False
        return True

    async def _report_load_to_tpdu(self):
        load = len(self.currently_executing_tasks) / self.MAX_CONCURRENT_TASKS
        self.module_state["current_load_factor"] = np.mean(self.load_field)
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="TaskPrioritizationAndDelegationUnit",
                message_type="module_performance_update",
                payload={"current_load_factor": self.module_state["current_load_factor"]}
            ))
        }, "low")

    async def _execute_actual_task(self, monitored_exec: MonitoredTaskExecution):
        task = monitored_exec.task_obj
        try:
            task.status = "in_progress"
            await self._send_status_update_to_tpdu(task)
            capability = task.required_capabilities[0] if task.required_capabilities else "generic"
            sub_task_corr_id = f"emcm_subtask_{task.task_id}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            self.pending_sub_task_responses[sub_task_corr_id] = future
            # Reglas de enrutamiento completas
            routing_map = {
                "information_retrieval": ("SQLKnowledgeStore", "submit_knowledge_query_request"),
                "code_generation": ("GeneradorCode", "execute_task"),
                "iot_action": ("IoTInterfaceModule", "request_iot_action"),
                "logical_reasoning": ("ComputationalLogicModule", "submit_logical_query_request"),
                "symbolic_reasoning": ("AdvancedSymbolicReasonerModule", "request_advanced_reasoning"),
                "narrative_query": ("NarrativeSelf", "query_narrative_element_request"),
            }
            target_module, message_type = routing_map.get(capability, ("DefaultModule", "execute_task"))
            # Monte Carlo para confiabilidad
            load = self.module_state["current_load_factor"]
            samples = np.random.beta(2 * (1 - load), 2 * load, self.num_mc_samples)
            reliability = np.mean(samples)
            # SDE para confiabilidad dinámica
            def reliability_dynamics(t, r):
                return -0.05 * (r - reliability) + self.sde_sigma * np.random.normal(0, 1)
            result = integrate.odeint(reliability_dynamics, [reliability], [0, self.update_interval], tfirst=True)
            reliability = np.clip(result[-1][0], 0.0, 1.0)
            if reliability < 0.3:
                raise RuntimeError(f"Confiabilidad baja ({reliability:.3f}) para delegar a '{target_module}'.")
            # Ejecutar tarea genérica si no hay módulo específico
            if capability == "generic":
                result = {"status": "completed", "result": {"message": f"Tarea genérica '{task.description}' procesada internamente."}}
                if "calculation" in task.task_payload:
                    try:
                        result["result"]["value"] = eval(task.task_payload["calculation"], {"np": np})
                    except Exception as e:
                        raise RuntimeError(f"Error en cálculo genérico: {str(e)}")
                future.set_result(result)
            else:
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        source_module_id=self.module_name,
                        target_module_id=target_module,
                        message_type=message_type,
                        payload=task.task_payload,
                        correlation_id=sub_task_corr_id
                    ))
                })
            # Esperar resultado
            sub_task_result = await asyncio.wait_for(future, timeout=task.max_execution_time_s - 5.0)
            if sub_task_result.get("status") in ["failed", "failed_capacity"]:
                raise RuntimeError(f"Sub-tarea en '{target_module}' falló: {sub_task_result.get('error') or sub_task_result.get('reason')}")
            task.result = {"message": f"Ejecución delegada a '{target_module}' completada.", "sub_task_result": sub_task_result}
            task.status = "completed"
        except asyncio.CancelledError:
            task.status = "cancelled"
            task.error_message = "Tarea cancelada por EMCM (timeout o comando externo)."
        except Exception as e:
            task.status = "failed"
            task.error_message = f"Error en ejecución: {str(e)}"
        finally:
            if sub_task_corr_id in self.pending_sub_task_responses:
                del self.pending_sub_task_responses[sub_task_corr_id]

    async def _finalize_task_execution(self, monitored_exec: MonitoredTaskExecution):
        task = monitored_exec.task_obj
        if monitored_exec.asyncio_task:
            try:
                await monitored_exec.asyncio_task
            except asyncio.CancelledError:
                if task.status not in ["cancelled", "failed"]:
                    task.status = "cancelled"
            except Exception as e:
                if task.status not in ["cancelled", "failed"]:
                    task.status = "failed"
                    task.error_message = str(e)
        if task.status == "completed":
            self.module_state["tasks_completed_by_emcm"] += 1
        elif task.status == "failed":
            self.module_state["tasks_failed_in_emcm"] += 1
        elif task.status == "cancelled":
            self.module_state["tasks_cancelled_by_emcm"] += 1
        duration = time.time() - monitored_exec.start_time
        # Kalman para suavizar tiempo de ejecución
        measurement = duration
        A, H = 1.0, 1.0
        Q, R = self.kalman_Q, self.kalman_R
        predicted_state = A * self.kalman_state
        predicted_cov = A * self.kalman_cov * A + Q
        innovation = measurement - H * predicted_state
        innovation_cov = H * predicted_cov * H + R
        kalman_gain = predicted_cov * H / innovation_cov
        self.kalman_state = predicted_state + kalman_gain * innovation
        self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
        self.emcm_task_execution_times.append(self.kalman_state)
        self.module_state["avg_emcm_task_execution_time_ms"] = np.mean(self.emcm_task_execution_times[-50:]) * 1000
        await self._send_status_update_to_tpdu(task)
        if task.task_id in self.currently_executing_tasks:
            del self.currently_executing_tasks[task.task_id]

    async def _send_status_update_to_tpdu(self, task: Task):
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="TaskPrioritizationAndDelegationUnit",
                message_type="task_execution_status_update",
                payload={"status": task.status, "result": task.result, "error_details": task.error_message},
                correlation_id=task.task_id
            ))
        })

    async def _update_load_field(self):
        n_tasks = max(len(self.currently_executing_tasks), 1)
        if len(self.load_field) != n_tasks:
            self.load_field = np.ones(n_tasks) * self.module_state["current_load_factor"]
        for _ in range(int(self.update_interval / self.pde_dt)):
            d2_load = (np.roll(self.load_field, 1) + np.roll(self.load_field, -1) - 2 * self.load_field) / (self.pde_dx ** 2)
            reaction = 0.1 * self.load_field * (1.0 - self.load_field / self.MAX_CONCURRENT_TASKS)
            self.load_field += self.pde_dt * (self.pde_diffusion * d2_load + reaction)
            self.load_field = np.clip(self.load_field, 0.0, 1.0)
        self.module_state["current_load_factor"] = np.mean(self.load_field)

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        if not full_message:
            return
        if event_type == "execute_assigned_task_request":
            if len(self.currently_executing_tasks) >= self.MAX_CONCURRENT_TASKS:
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        source_module_id=self.module_name,
                        target_module_id="TaskPrioritizationAndDelegationUnit",
                        message_type="task_execution_status_update",
                        payload={"status": "failed_capacity"},
                        correlation_id=full_message.correlation_id
                    ))
                })
                return
            try:
                task_data = payload.get("task_to_execute", {})
                task_obj = Task(**task_data)
                # Ajustar prioridad con Monte Carlo
                deadline_factor = 1.0 if not task_obj.deadline_ts else max(0.0, (task_obj.deadline_ts - time.time()) / 3600.0)
                samples = np.random.beta(2 * task_obj.base_priority, 2 * (1 - task_obj.base_priority), self.num_mc_samples)
                priority = np.clip(np.mean(samples) * deadline_factor, 0.0, 1.0)
                monitored_exec = MonitoredTaskExecution(task_obj=task_obj)
                await self.task_queue.put((-priority, task_obj.task_id, monitored_exec))
            except Exception as e:
                self.logger.error(f"Error al aceptar tarea de TPDU: {e}")
        elif event_type == "request_cancel_task_execution":
            task_id_to_cancel = payload.get("task_id_to_cancel")
            if task_id_to_cancel in self.currently_executing_tasks:
                monitored_exec = self.currently_executing_tasks[task_id_to_cancel]
                if monitored_exec.asyncio_task:
                    monitored_exec.asyncio_task.cancel()
        else:
            corr_id = full_message.correlation_id
            if corr_id in self.pending_sub_task_responses:
                future = self.pending_sub_task_responses[corr_id]
                if not future.done():
                    future.set_result(payload)
                else:
                    self.logger.warning(f"Futura ya completada para correlation_id: {corr_id}")





                #inicio del modulo FocusCoordinator 


@dataclass
class FocusShiftRequest:
    request_id: str = field(default_factory=lambda: f"focus_req_{uuid.uuid4().hex[:6]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    priority: float
    target_focus_type: Optional[str] = None
    explicit_focus_payload: Optional[Dict[str, Any]] = None
    focus_parameters: Dict[str, Any] = field(default_factory=dict)
    justification: Optional[str] = None
    status: str = "pending_evaluation"
    processing_message: Optional[str] = None

    def __lt__(self, other: 'FocusShiftRequest') -> bool:
        return self.priority > other.priority

class FocusCoordinator(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 0.6

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.focus_shift_request_queue: asyncio.PriorityQueue = asyncio.PriorityQueue(maxsize=15)
        self.active_focus_shift_request: Optional[FocusShiftRequest] = None
        self.focus_inertia_factor: float = 0.20
        self.min_priority_to_override: float = 0.85
        self.stability_decay_rate: float = 0.005
        # Nuevos parámetros
        self.num_mc_samples: int = 500
        self.sde_sigma: float = 0.01
        self.pde_dx: float = 0.1
        self.pde_dt: float = 0.01
        self.pde_diffusion: float = 0.05
        self.kalman_Q: float = 0.01
        self.kalman_R: float = 0.05
        self.kalman_state: float = 1.0
        self.kalman_cov: float = 0.1
        self.focus_graph = nx.DiGraph()
        self.coherence_field: np.ndarray = np.array([1.0])
        self.focus_type_recipes: Dict[str, Callable] = {
            "calming_neutral": self._recipe_calming_neutral_focus,
            "problem_solving": self._recipe_problem_solving_focus,
            "task_specific": self._recipe_task_specific_focus,
            "self_reflection": self._recipe_self_reflection_values_focus,
        }
        self.module_state.update({
            "focus_shifts_accepted": 0,
            "focus_shifts_rejected": 0,
            "last_focus_change_ts": 0.0,
            "current_focus_stability_score": 1.0,
            "focus_coherence_score": 1.0,
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado con coordinación avanzada.")

    def _recipe_calming_neutral_focus(self, params: Dict) -> Dict[str, Any]:
        return {"type": "internal_state_regulation", "target": "affective_homeostasis", "sub_type": "calming", "intensity": params.get("intensity", 0.7)}

    def _recipe_problem_solving_focus(self, params: Dict) -> Dict[str, Any]:
        return {"type": "cognitive_task", "task_type_hint": "problem_solving_analytical", "related_goal_id": params.get("related_goal_id"), "intensity": params.get("intensity", 0.85)}

    def _recipe_task_specific_focus(self, params: Dict) -> Dict[str, Any]:
        task_id = params.get("task_id")
        if not task_id:
            return {"type": "error", "message": "task_id requerido para foco task_specific"}
        return {"type": "active_task", "id": task_id, "description_hint": params.get("description_hint", "N/A"), "intensity": params.get("intensity", 0.9)}

    def _recipe_self_reflection_values_focus(self, params: Dict) -> Dict[str, Any]:
        return {"type": "introspection", "sub_type": "value_alignment_check", "trigger_event": params.get("trigger_event_id"), "intensity": params.get("intensity", 0.6)}

    async def _update_logic(self):
        # Actualizar estabilidad con SDE
        stability = self.module_state["current_focus_stability_score"]
        def stability_dynamics(t, s):
            return -self.stability_decay_rate * s + self.sde_sigma * np.random.normal(0, 1)
        result = integrate.odeint(stability_dynamics, [stability], [0, self.update_interval], tfirst=True)
        stability = np.clip(result[-1][0], 0.1, 1.0)
        # Kalman para suavizar estabilidad
        A, H = 1.0, 1.0
        Q, R = self.kalman_Q, self.kalman_R
        predicted_state = A * self.kalman_state
        predicted_cov = A * self.kalman_cov * A + Q
        innovation = stability - H * predicted_state
        innovation_cov = H * predicted_cov * H + R
        kalman_gain = predicted_cov * H / innovation_cov
        self.kalman_state = predicted_state + kalman_gain * innovation
        self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
        self.module_state["current_focus_stability_score"] = self.kalman_state
        # Procesar solicitudes
        if not self.active_focus_shift_request and not self.focus_shift_request_queue.empty():
            _, request = await self.focus_shift_request_queue.get()
            self.focus_shift_request_queue.task_done()
            self.active_focus_shift_request = request
            self._create_managed_task(self._process_single_focus_request(request))
        await self._update_focus_coherence()

    async def _process_single_focus_request(self, request: FocusShiftRequest):
        request.status = "evaluating"
        current_focus = self.core_recombinator.global_state.current_focus or {"priority": 0.0}
        current_focus_priority = current_focus.get("priority", 0.0)
        stability = self.module_state["current_focus_stability_score"]
        # Ajustar prioridad con Monte Carlo
        load_factor = self.core_recombinator.global_state.get("current_load_factor", 0.5)
        samples = np.random.beta(2 * request.priority, 2 * (1 - request.priority), self.num_mc_samples)
        adjusted_priority = np.clip(np.mean(samples) * (1 - 0.5 * load_factor), 0.0, 1.0)
        request.priority = adjusted_priority
        # Verificar conflictos
        if await self._check_focus_conflict(request):
            request.status = "rejected"
            request.processing_message = "Conflicto detectado con el foco actual o solicitudes concurrentes."
            self.module_state["focus_shifts_rejected"] += 1
            await self._finalize_focus_request(request)
            return
        # Evaluar resistencia
        resistance_score = current_focus_priority + self.focus_inertia_factor * stability
        if request.priority > resistance_score or request.priority >= self.min_priority_to_override:
            request.status = "accepted"
            self.module_state["focus_shifts_accepted"] += 1
            new_focus_payload = await self._build_new_focus_payload(request)
            if new_focus_payload and "error" not in new_focus_payload:
                await self._set_current_focus_in_gs(new_focus_payload, request)
                request.status = "completed_shift"
            else:
                request.status = "failed_recipe"
                request.processing_message = new_focus_payload.get("message", "Error en receta de foco.")
        else:
            request.status = "rejected"
            request.processing_message = f"Prioridad ({request.priority:.2f}) no supera resistencia del foco actual ({resistance_score:.2f})."
            self.module_state["focus_shifts_rejected"] += 1
        await self._finalize_focus_request(request)

    async def _build_new_focus_payload(self, request: FocusShiftRequest) -> Dict[str, Any]:
        # Validar con ComputationalLogicModule
        facts_to_check = []
        if request.explicit_focus_payload:
            facts_to_check = request.explicit_focus_payload.get("facts", [])
        elif request.target_focus_type:
            facts_to_check = request.focus_parameters.get("facts", [])
        futures = {}
        for fact in facts_to_check:
            correlation_id = f"focus_validation_{request.request_id}_{uuid.uuid4().hex[:6]}"
            future = asyncio.Future()
            futures[correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="ComputationalLogicModule",
                    message_type="submit_logical_query_request",
                    payload={"query_type": "query_fact", "query_payload": {"fact": fact}},
                    correlation_id=correlation_id
                ))
            })
        # Esperar respuestas
        plausibility = 1.0
        try:
            results = await asyncio.wait_for(
                asyncio.gather(*futures.values(), return_exceptions=True),
                timeout=5.0
            )
            for result in results:
                if isinstance(result, dict) and result.get("status") == "completed":
                    plausibility *= result.get("result", {}).get("probability", 0.5)
        except asyncio.TimeoutError:
            self.logger.warning("Timeout validando hechos para foco.")
            plausibility *= 0.5
        # Monte Carlo para plausibilidad
        samples = np.random.normal(plausibility, 0.1, self.num_mc_samples)
        plausibility = np.clip(np.mean(samples), 0.0, 1.0)
        if plausibility < 0.3:
            return {"error": "Foco no plausible según la base de conocimiento."}
        # Construir payload
        if request.explicit_focus_payload:
            payload = request.explicit_focus_payload
        elif request.target_focus_type:
            recipe_func = self.focus_type_recipes.get(request.target_focus_type)
            if recipe_func:
                payload = recipe_func(request.focus_parameters)
            else:
                return {"error": f"Tipo de foco desconocido: {request.target_focus_type}"}
        else:
            return {"error": "No se pudo construir el payload de foco."}
        payload["plausibility"] = plausibility
        return payload

    async def _check_focus_conflict(self, request: FocusShiftRequest) -> bool:
        # Añadir solicitud al grafo
        self.focus_graph.add_node(request.request_id, priority=request.priority, type=request.target_focus_type)
        current_focus = self.core_recombinator.global_state.current_focus or {}
        if current_focus.get("source_request_id"):
            self.focus_graph.add_edge(request.request_id, current_focus["source_request_id"], weight=1.0)
        # Detectar conflictos (ciclos con prioridades altas)
        try:
            cycles = list(nx.simple_cycles(self.focus_graph))
            for cycle in cycles:
                cycle_priorities = [self.focus_graph.nodes[n]["priority"] for n in cycle]
                if np.mean(cycle_priorities) > 0.8:
                    return True
        except nx.NetworkXNoCycle:
            pass
        return False

    async def _update_focus_coherence(self):
        n_requests = max(self.focus_shift_request_queue.qsize() + (1 if self.active_focus_shift_request else 0), 1)
        if len(self.coherence_field) != n_requests:
            self.coherence_field = np.ones(n_requests) * self.module_state["focus_coherence_score"]
        conflicts = len(list(nx.simple_cycles(self.focus_graph))) if self.focus_graph.number_of_nodes() > 0 else 0
        for _ in range(int(self.update_interval / self.pde_dt)):
            d2_coherence = (np.roll(self.coherence_field, 1) + np.roll(self.coherence_field, -1) - 2 * self.coherence_field) / (self.pde_dx ** 2)
            reaction = 0.1 * self.coherence_field * (1.0 - self.coherence_field / n_requests - 0.05 * conflicts)
            self.coherence_field += self.pde_dt * (self.pde_diffusion * d2_coherence + reaction)
            self.coherence_field = np.clip(self.coherence_field, 0.0, 1.0)
        self.module_state["focus_coherence_score"] = np.mean(self.coherence_field)

    async def _set_current_focus_in_gs(self, new_focus: Dict[str, Any], request: FocusShiftRequest):
        old_focus = copy.deepcopy(self.core_recombinator.global_state.current_focus or {})
        new_focus["priority"] = request.priority
        new_focus["set_at_ts"] = time.time()
        new_focus["source_request_id"] = request.request_id
        self.core_recombinator._global_state.current_focus = new_focus
        self.module_state["last_focus_change_ts"] = time.time()
        self.module_state["current_focus_stability_score"] = 1.0
        await self.emit_event_to_core({
            "type": "system_focus_changed_notice",
            "content": {"new_focus": new_focus, "previous_focus": old_focus, "reason": request.justification}
        }, priority_label="medium")
        # Limpiar grafo de focos
        self.focus_graph.remove_nodes_from(list(self.focus_graph.nodes))

    async def _finalize_focus_request(self, request: FocusShiftRequest):
        if request.original_correlation_id:
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id=request.source_module_id,
                    message_type="focus_shift_request_completed_notice",
                    payload={"focus_request_id_ref": request.request_id, "final_status": request.status, "message": request.processing_message},
                    correlation_id=request.original_correlation_id
                ))
            })
        self.active_focus_shift_request = None

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        if not full_message:
            return
        if event_type == "focus_shift_request":
            try:
                req = FocusShiftRequest(
                    source_module_id=full_message.source_module_id,
                    original_correlation_id=full_message.correlation_id,
                    priority=float(payload.get("priority", 0.5)),
                    target_focus_type=payload.get("target_focus_type"),
                    explicit_focus_payload=payload.get("explicit_focus_payload"),
                    focus_parameters=payload.get("focus_parameters", {}),
                    justification=payload.get("justification")
                )
                if not req.target_focus_type and not req.explicit_focus_payload:
                    raise ValueError("Se necesita 'target_focus_type' o 'explicit_focus_payload'.")
                await self.focus_shift_request_queue.put((-req.priority, req))
            except (ValueError, TypeError) as e:
                self.logger.error(f"Error procesando solicitud de foco: {e}")
        elif event_type == "reinforce_current_focus_request":
            relevance = payload.get("relevance_score", 0.2)
            boost = np.clip(relevance, 0.0, 1.0) * 0.3
            self.module_state["current_focus_stability_score"] = min(1.0, self.module_state["current_focus_stability_score"] + boost)
            self.logger.info(f"Foco reforzado por '{full_message.source_module_id}'. Estabilidad ahora: {self.module_state['current_focus_stability_score']:.2f}")
        elif event_type == "logical_query_response":
            corr_id = full_message.correlation_id
            for request in [self.active_focus_shift_request] + list(self.focus_shift_request_queue._queue):
                if request and corr_id in getattr(request, "_futures", {}):
                    request._futures[corr_id].set_result(payload)





            #inicio del modulo LearningModule 


@dataclass
class LearningTaskRequest:
    request_id: str = field(default_factory=lambda: f"lm_req_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    learning_type: str
    data_source_info: Dict[str, Any]
    learning_parameters: Dict[str, Any] = field(default_factory=dict)
    priority_score: float = 0.5
    status: str = "pending"
    result: Optional[Dict[str, Any]] = None
    error_message: Optional[str] = None
    _futures: Dict[str, asyncio.Future] = field(default_factory=dict, repr=False)

    def __lt__(self, other: 'LearningTaskRequest') -> bool:
        return self.priority_score < other.priority_score

@dataclass
class LearnedKnowledge:
    knowledge_id: str = field(default_factory=lambda: f"lk_{uuid.uuid4().hex[:6]}")
    source_learning_task_id: str
    knowledge_type: str
    payload: Dict[str, Any]
    confidence: float = 0.8
    application_status: str = "pending_application"

class LearningModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 5.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.learning_request_queue: asyncio.PriorityQueue = asyncio.PriorityQueue(maxlen=20)
        self.learned_knowledge_buffer: deque = deque(maxlen=100)
        self.pending_knowledge_application: Dict[str, LearnedKnowledge] = {}
        self.rl_q_table: Dict[Tuple[str, ...], Dict[str, float]] = defaultdict(lambda: defaultdict(float))
        self.rl_learning_rate: float = 0.1
        self.rl_discount_factor: float = 0.9
        self.rl_exploration_epsilon: float = 0.15
        # Nuevos parámetros
        self.num_mc_samples: int = 500
        self.sde_sigma: float = 0.01
        self.pde_dx: float = 0.1
        self.pde_dt: float = 0.01
        self.pde_diffusion: float = 0.05
        self.kalman_Q: float = 0.01
        self.kalman_R: float = 0.05
        self.kalman_state: float = 0.0
        self.kalman_cov: float = 0.1
        self.knowledge_graph = nx.DiGraph()
        self.coherence_field: np.ndarray = np.array([1.0])
        self.module_state.update({
            "learning_tasks_processed": 0,
            "knowledge_elements_produced": 0,
            "knowledge_elements_applied": 0,
            "knowledge_application_failures": 0,
            "knowledge_coherence_score": 1.0,
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado con aprendizaje avanzado.")

    async def _update_logic(self):
        # Procesar tareas de aprendizaje
        if not self.learning_request_queue.empty():
            _, request = await self.learning_request_queue.get()
            if await self._check_dependencies(request):
                self._create_managed_task(self._process_single_learning_task(request))
        # Aplicar conocimiento
        if self.learned_knowledge_buffer:
            knowledge = self.learned_knowledge_buffer.popleft()
            self._create_managed_task(self._apply_knowledge(knowledge))
        await self._update_knowledge_coherence()

    async def _check_dependencies(self, request: LearningTaskRequest) -> bool:
        dependencies = request.learning_parameters.get("dependencies", [])
        for dep_id in dependencies:
            if dep_id in self.pending_knowledge_application:
                if self.pending_knowledge_application[dep_id].application_status != "applied":
                    return False
        return True

    async def _process_single_learning_task(self, request: LearningTaskRequest):
        self.module_state["learning_tasks_processed"] += 1
        request.status = "processing"
        try:
            # Ajustar prioridad con Monte Carlo
            load_factor = self.core_recombinator.global_state.get("current_load_factor", 0.5)
            samples = np.random.beta(2 * request.priority_score, 2 * (1 - request.priority_score), self.num_mc_samples)
            request.priority_score = np.clip(np.mean(samples) * (1 - 0.5 * load_factor), 0.0, 1.0)
            # Obtener datos
            training_data = await self._fetch_training_data(request.data_source_info)
            if training_data is None:
                raise ValueError("No se pudieron obtener datos.")
            # Validar datos con ComputationalLogicModule
            correlation_id = f"data_validation_{request.request_id}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            request._futures[correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="ComputationalLogicModule",
                    message_type="submit_logical_query_request",
                    payload={"query_type": "validate_data", "query_payload": {"data_summary": training_data.get("data_summary", {})}}
                ))
            })
            try:
                validation_result = await asyncio.wait_for(future, timeout=5.0)
                if validation_result.get("status") != "valid":
                    raise ValueError(f"Datos inválidos: {validation_result.get('error', 'No especificado')}")
            except asyncio.TimeoutError:
                self.logger.warning("Timeout validando datos.")
            # Realizar aprendizaje
            learned_items = []
            if request.learning_type == "reinforcement_learning":
                learned_items = await self._learn_from_rl_experiences(training_data, request)
            elif request.learning_type == "parameter_tuning":
                learned_items = await self._learn_parameter_tuning(training_data, request)
            else:
                raise ValueError(f"Tipo de aprendizaje no soportado: {request.learning_type}")
            # Almacenar conocimiento
            for item in learned_items:
                self.learned_knowledge_buffer.append(item)
                self.knowledge_graph.add_node(item.knowledge_id, type=item.knowledge_type, confidence=item.confidence)
                self.module_state["knowledge_elements_produced"] += 1
            request.status = "completed"
            request.result = {"message": f"Proceso '{request.learning_type}' completado.", "items_learned": len(learned_items)}
        except Exception as e:
            request.status = "failed"
            request.error_message = str(e)
            self.logger.error(f"Fallo en tarea de aprendizaje '{request.request_id}': {e}")
        finally:
            await self._send_response(request, "learning_task_completed_notice")

    async def _fetch_training_data(self, data_source: Dict) -> Optional[Dict]:
        source_type = data_source.get("type")
        correlation_id = f"data_fetch_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        target_module, message_type = None, None
        if source_type == "rl_experiences":
            target_module, message_type = "NarrativeSelf", "query_narrative_element_request"
        elif source_type == "structured_data":
            target_module, message_type = "SQLKnowledgeStore", "submit_knowledge_query_request"
        else:
            return None
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id=target_module,
                message_type=message_type,
                payload={"query_payload": data_source.get("query", {})},
                correlation_id=correlation_id
            ))
        })
        try:
            result = await asyncio.wait_for(future, timeout=10.0)
            if result.get("status") == "completed":
                data = result.get("result", {})
                # Monte Carlo para calidad de datos
                samples = np.random.normal(data.get("quality", 0.8), 0.1, self.num_mc_samples)
                quality = np.clip(np.mean(samples), 0.0, 1.0)
                if quality < 0.3:
                    return None
                return {"data": data.get("data", []), "data_summary": {"count": len(data.get("data", [])), "quality": quality}}
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout obteniendo datos de {target_module}.")
            return None

    async def _learn_from_rl_experiences(self, data: Dict, request: LearningTaskRequest) -> List[LearnedKnowledge]:
        experiences = data["data"]
        learned_items = []
        for exp in experiences:
            s, a, r, s_prime = exp['state'], exp['action'], exp['reward'], exp['next_state']
            q_s_a = self.rl_q_table[s][a]
            max_q_s_prime = max(self.rl_q_table[s_prime].values()) if self.rl_q_table[s_prime] else 0
            # Ecuación de Bellman
            new_q = q_s_a + self.rl_learning_rate * (r + self.rl_discount_factor * max_q_s_prime - q_s_a)
            # SDE para convergencia
            def q_dynamics(t, q):
                return -0.05 * (q - new_q) + self.sde_sigma * np.random.normal(0, 1)
            result = integrate.odeint(q_dynamics, [q_s_a], [0, self.update_interval], tfirst=True)
            self.rl_q_table[s][a] = np.clip(result[-1][0], -1.0, 1.0)
            # Monte Carlo para confianza
            samples = np.random.normal(0.7, 0.1, self.num_mc_samples)
            confidence = np.clip(np.mean(samples), 0.0, 1.0)
            learned_items.append(LearnedKnowledge(
                source_learning_task_id=request.request_id,
                knowledge_type="updated_rl_q_table",
                payload={"state": s, "action": a, "q_value": self.rl_q_table[s][a]},
                confidence=confidence
            ))
        return learned_items

    async def _learn_parameter_tuning(self, data: Dict, request: LearningTaskRequest) -> List[LearnedKnowledge]:
        target_module = request.learning_parameters.get("target_module")
        param_name = request.learning_parameters.get("parameter_name")
        if not target_module or not param_name:
            return []
        # Optimización bayesiana
        X = np.array(data["data"].get("parameter_values", [0.1, 0.3, 0.5])).reshape(-1, 1)
        y = np.array(data["data"].get("performance_metrics", [0.2, 0.4, 0.6]))
        kernel = ConstantKernel(1.0) * RBF(length_scale=1.0)
        gp = GaussianProcessRegressor(kernel=kernel, alpha=0.01)
        gp.fit(X, y)
        x_new = np.linspace(0.0, 1.0, 100).reshape(-1, 1)
        y_pred, sigma = gp.predict(x_new, return_std=True)
        best_idx = np.argmax(y_pred)
        new_value = x_new[best_idx][0]
        # SDE para convergencia
        def param_dynamics(t, p):
            return -0.05 * (p - new_value) + self.sde_sigma * np.random.normal(0, 1)
        result = integrate.odeint(param_dynamics, [new_value], [0, self.update_interval], tfirst=True)
        new_value = np.clip(result[-1][0], 0.0, 1.0)
        # Monte Carlo para confianza
        samples = np.random.normal(1 - sigma[best_idx], 0.1, self.num_mc_samples)
        confidence = np.clip(np.mean(samples), 0.0, 1.0)
        return [LearnedKnowledge(
            source_learning_task_id=request.request_id,
            knowledge_type="tuned_parameter",
            payload={"target_module": target_module, "parameter_name": param_name, "new_value": new_value},
            confidence=confidence
        )]

    async def _apply_knowledge(self, knowledge: LearnedKnowledge):
        self.logger.info(f"Aplicando conocimiento '{knowledge.knowledge_id}' (Tipo: {knowledge.knowledge_type})")
        target_module, message_type, payload = None, None, None
        correlation_id = f"knowledge_apply_{knowledge.knowledge_id}_{uuid.uuid4().hex[:8]}"
        if knowledge.knowledge_type == "tuned_parameter":
            target_module = knowledge.payload.get("target_module")
            message_type = "apply_parameter_update_request"
            payload = {"parameter_updates": {knowledge.payload["parameter_name"]: knowledge.payload["new_value"]}}
        elif knowledge.knowledge_type == "updated_rl_q_table":
            target_module = "AdvancedTCHNModule"
            message_type = "update_policy_request"
            payload = {"policy_updates": knowledge.payload}
        if target_module and message_type and payload:
            knowledge.application_status = "sent_for_application"
            future = asyncio.Future()
            self.pending_knowledge_application[correlation_id] = knowledge
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id=target_module,
                    message_type=message_type,
                    payload=payload,
                    correlation_id=correlation_id
                ))
            })
            try:
                result = await asyncio.wait_for(future, timeout=10.0)
                if result.get("status") == "applied":
                    knowledge.application_status = "applied"
                    self.module_state["knowledge_elements_applied"] += 1
                    # Kalman para suavizar métricas
                    measurement = 1.0
                    A, H = 1.0, 1.0
                    Q, R = self.kalman_Q, self.kalman_R
                    predicted_state = A * self.kalman_state
                    predicted_cov = A * self.kalman_cov * A + Q
                    innovation = measurement - H * predicted_state
                    innovation_cov = H * predicted_cov * H + R
                    kalman_gain = predicted_cov * H / innovation_cov
                    self.kalman_state = predicted_state + kalman_gain * innovation
                    self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
                else:
                    knowledge.application_status = "failed"
                    self.module_state["knowledge_application_failures"] += 1
            except asyncio.TimeoutError:
                knowledge.application_status = "failed_timeout"
                self.module_state["knowledge_application_failures"] += 1
            finally:
                if correlation_id in self.pending_knowledge_application:
                    del self.pending_knowledge_application[correlation_id]
        else:
            knowledge.application_status = "failed_no_handler"
            self.module_state["knowledge_application_failures"] += 1

    async def _update_knowledge_coherence(self):
        n_knowledge = max(len(self.learned_knowledge_buffer) + len(self.pending_knowledge_application), 1)
        if len(self.coherence_field) != n_knowledge:
            self.coherence_field = np.ones(n_knowledge) * self.module_state["knowledge_coherence_score"]
        conflicts = len(list(nx.simple_cycles(self.knowledge_graph))) if self.knowledge_graph.number_of_nodes() > 0 else 0
        for _ in range(int(self.update_interval / self.pde_dt)):
            d2_coherence = (np.roll(self.coherence_field, 1) + np.roll(self.coherence_field, -1) - 2 * self.coherence_field) / (self.pde_dx ** 2)
            reaction = 0.1 * self.coherence_field * (1.0 - self.coherence_field / n_knowledge - 0.05 * conflicts)
            self.coherence_field += self.pde_dt * (self.pde_diffusion * d2_coherence + reaction)
            self.coherence_field = np.clip(self.coherence_field, 0.0, 1.0)
        self.module_state["knowledge_coherence_score"] = np.mean(self.coherence_field)

    async def _send_response(self, request: LearningTaskRequest, response_type: str):
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id=request.source_module_id,
                message_type=response_type,
                payload={"request_id_ref": request.request_id, "status": request.status, "result": request.result, "error": request.error_message},
                correlation_id=request.original_correlation_id
            ))
        })

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        if not full_message:
            return
        if event_type == "request_learning_task":
            try:
                prio = float(payload.get("priority_score", 0.5))
                req = LearningTaskRequest(
                    source_module_id=full_message.source_module_id,
                    original_correlation_id=full_message.correlation_id,
                    learning_type=payload.get("learning_type"),
                    data_source_info=payload.get("data_source_info", {}),
                    learning_parameters=payload.get("learning_parameters", {}),
                    priority_score=prio
                )
                if not req.learning_type:
                    raise ValueError("Se requiere 'learning_type'.")
                await self.learning_request_queue.put((-req.priority_score, req))
            except (ValueError, TypeError) as e:
                self.logger.error(f"Error procesando solicitud de aprendizaje: {e}")
        elif event_type in ["query_narrative_element_response", "knowledge_query_response", "apply_parameter_update_response", "update_policy_response"]:
            corr_id = full_message.correlation_id
            if corr_id in self.pending_knowledge_application:
                knowledge = self.pending_knowledge_application[corr_id]
                knowledge._futures[corr_id].set_result(payload)
            else:
                for request in list(self.learning_request_queue._queue):
                    if corr_id in request[1]._futures:
                        request[1]._futures[corr_id].set_result(payload)






            #inicio del modulo SQLKnowledgeStore 


@dataclass
class KnowledgeQuery:
    query_id: str = field(default_factory=lambda: f"ksq_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    query_type: str
    target_table: Optional[str] = None
    payload: Dict[str, Any] = field(default_factory=dict)
    status: str = "pending"
    result: Optional[Any] = None
    error_message: Optional[str] = None
    criticality_probability: float = 0.5
    _futures: Dict[str, asyncio.Future] = field(default_factory=dict, repr=False)

    def __lt__(self, other: 'KnowledgeQuery') -> bool:
        return self.criticality_probability < other.criticality_probability

class SQLKnowledgeStore(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 1.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.database: Dict[str, List[Dict[str, Any]]] = {}
        self.schemas: Dict[str, Dict[str, str]] = {}
        self.query_cache: OrderedDict[str, Tuple[List[Dict[str, Any]], float]] = OrderedDict()
        self.index: Dict[str, Dict[str, List[int]]] = {}  # Índice: table -> palabra -> lista de índices
        self.cache_max_len: int = 100
        self.cache_ttl_s: int = 300
        self.query_queue: asyncio.PriorityQueue = asyncio.PriorityQueue(maxlen=100)
        self.strict_schema_enforcement: bool = True
        self.coerce_value_types: bool = True
        # Nuevos parámetros
        self.num_mc_samples: int = 500
        self.sde_sigma: float = 0.01
        self.pde_dx: float = 0.1
        self.pde_dt: float = 0.01
        self.pde_diffusion: float = 0.05
        self.kalman_Q: float = 0.01
        self.kalman_R: float = 0.05
        self.kalman_state: float = 0.0
        self.kalman_cov: float = 0.1
        self.query_graph = nx.DiGraph()
        self.coherence_field: np.ndarray = np.array([1.0])
        self.module_state.update({
            "tables_count": 0,
            "total_rows_approx": 0,
            "queries_processed": 0,
            "selects_processed": 0,
            "inserts_processed": 0,
            "updates_processed": 0,
            "deletes_processed": 0,
            "schema_changes": 0,
            "cache_hits": 0,
            "cache_misses": 0,
            "avg_query_latency_ms": 0.0,
            "data_coherence_score": 1.0,
        })
        self.query_latencies: List[float] = []
        self.logger.info(f"{self.module_name} v27.2 inicializado con gestión avanzada.")

    async def _update_logic(self):
        if not self.query_queue.empty():
            _, query = await self.query_queue.get()
            self._create_managed_task(self._handle_query_wrapper(query))
        await self._update_data_coherence()

    async def _handle_query_wrapper(self, query: KnowledgeQuery):
        start_time = time.time()
        query.status = "processing"
        self.module_state["queries_processed"] += 1
        try:
            # Ajustar criticidad con Monte Carlo
            load_factor = self.core_recombinator.global_state.get("current_load_factor", 0.5)
            samples = np.random.beta(2 * query.criticality_probability, 2 * (1 - query.criticality_probability), self.num_mc_samples)
            query.criticality_probability = np.clip(np.mean(samples) * (1 - 0.5 * load_factor), 0.0, 1.0)
            # Verificar conflictos
            if await self._check_query_conflict(query):
                query.status = "failed"
                query.error_message = "Conflicto detectado con consultas concurrentes."
                return
            # Validar con ComputationalLogicModule
            correlation_id = f"query_validation_{query.query_id}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            query._futures[correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="ComputationalLogicModule",
                    message_type="submit_logical_query_request",
                    payload={"query_type": "validate_data", "query_payload": query.payload},
                    correlation_id=correlation_id
                ))
            })
            try:
                validation_result = await asyncio.wait_for(future, timeout=5.0)
                if validation_result.get("status") != "valid":
                    raise ValueError(f"Consulta inválida: {validation_result.get('error', 'No especificado')}")
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout validando consulta {query.query_id}.")
            # Procesar consulta
            if query.query_type == "select_prioritized":
                self.module_state["selects_processed"] += 1
                await self._orchestrate_select_query(query)
            else:
                await self._handle_crud_or_schema_op(query)
        except Exception as e:
            query.status = "failed"
            query.error_message = f"Error en SQLKS: {str(e)}"
        finally:
            latency = time.time() - start_time
            # Kalman para suavizar latencia
            A, H = 1.0, 1.0
            Q, R = self.kalman_Q, self.kalman_R
            predicted_state = A * self.kalman_state
            predicted_cov = A * self.kalman_cov * A + Q
            innovation = latency - H * predicted_state
            innovation_cov = H * predicted_cov * H + R
            kalman_gain = predicted_cov * H / innovation_cov
            self.kalman_state = predicted_state + kalman_gain * innovation
            self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
            self.query_latencies.append(self.kalman_state)
            self.module_state["avg_query_latency_ms"] = np.mean(self.query_latencies[-100:]) * 1000
            await self._finalize_query(query)

    async def _orchestrate_select_query(self, query: KnowledgeQuery):
        query_hash = self._get_query_hash(query)
        if query_hash in self.query_cache and (time.time() - self.query_cache[query_hash][1] < self.cache_ttl_s):
            self.module_state["cache_hits"] += 1
            query.result = {"results": self.query_cache[query_hash][0], "source": "Internal_Cache"}
            query.status = "completed"
            return
        self.module_state["cache_misses"] += 1
        internal_results = self._search_internal_db(query)
        if not internal_results and query.payload.get("allow_external_fallback", True):
            self.logger.info(f"Sin resultados internos para query '{query.query_id}'. Consultando AdvancedTCHNModule.")
            external_results = await self._query_external_ai(query)
            # Monte Carlo para confianza
            samples = np.random.normal(0.85, 0.1, self.num_mc_samples)
            confidence = np.clip(np.mean(samples), 0.0, 1.0)
            query.result = {"results": external_results, "source": "AdvancedTCHNModule", "confidence": confidence}
        else:
            query.result = {"results": internal_results, "source": "Internal_DB"}
        self._add_to_cache(query_hash, query.result["results"])
        query.status = "completed"

    def _get_query_hash(self, query: KnowledgeQuery) -> str:
        relevant_parts = {"table": query.target_table, "payload": query.payload}
        return hashlib.sha256(json.dumps(relevant_parts, sort_keys=True).encode()).hexdigest()

    def _search_internal_db(self, query: KnowledgeQuery) -> List[Dict[str, Any]]:
        table = self.database.get(str(query.target_table), [])
        query_text = str(query.payload.get("query_text", "")).lower()
        limit = query.payload.get("limit", 10)
        if not query_text:
            return table[:limit]
        # Búsqueda indexada
        words = set(re.split(r'\W+', query_text))
        row_indices = set()
        for word in words:
            if word in self.index.get(query.target_table, {}):
                row_indices.update(self.index[query.target_table][word])
        results = [table[i] for i in sorted(row_indices)[:limit]]
        # Monte Carlo para relevancia
        samples = np.random.normal(0.9 if results else 0.5, 0.1, self.num_mc_samples)
        relevance = np.clip(np.mean(samples), 0.0, 1.0)
        for result in results:
            result["RelevanceScore"] = relevance
        return results

    def _index_table(self, table_name: str, row: Dict[str, Any], row_index: int):
        if table_name not in self.index:
            self.index[table_name] = {}
        for key, value in row.items():
            words = re.split(r'\W+', str(value).lower())
            for word in words:
                if word:
                    if word not in self.index[table_name]:
                        self.index[table_name][word] = []
                    self.index[table_name][word].append(row_index)

    async def _query_external_ai(self, query: KnowledgeQuery) -> List[Dict[str, Any]]:
        correlation_id = f"external_query_{query.query_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        query._futures[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="AdvancedTCHNModule",
                message_type="request_external_knowledge",
                payload={"query_text": query.payload.get("query_text"), "context": query.payload.get("context", {})},
                correlation_id=correlation_id
            ))
        })
        try:
            result = await asyncio.wait_for(future, timeout=10.0)
            if result.get("status") == "completed":
                return result.get("results", [])
            else:
                self.logger.warning(f"Fallo en consulta externa: {result.get('error', 'No especificado')}")
                return []
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout en consulta externa para query {query.query_id}.")
            return []

    def _add_to_cache(self, query_hash: str, results: List[Dict]):
        if len(self.query_cache) >= self.cache_max_len:
            self.query_cache.popitem(last=False)
        self.query_cache[query_hash] = (results, time.time())

    def _coerce_value(self, value: Any, schema_type: str) -> Any:
        try:
            if schema_type == "int":
                return int(value)
            elif schema_type == "float":
                return float(value)
            elif schema_type == "str":
                return str(value)
            elif schema_type == "bool":
                return bool(value)
            return value
        except (ValueError, TypeError):
            return value

    async def _handle_crud_or_schema_op(self, query: KnowledgeQuery):
        if query.query_type == "create_table":
            table_name = query.target_table
            schema = query.payload.get("schema", {})
            if not table_name or not schema:
                query.status = "failed"
                query.error_message = "Se requiere 'target_table' y 'schema'."
                return
            if table_name in self.database:
                query.status = "failed"
                query.error_message = f"Tabla {table_name} ya existe."
                return
            self.database[table_name] = []
            self.schemas[table_name] = schema
            self.module_state["tables_count"] += 1
            self.module_state["schema_changes"] += 1
            query.result = {"success": True, "table": table_name}
            query.status = "completed"

        elif query.query_type == "insert":
            table_name = query.target_table
            data = query.payload.get("data", {})
            if not table_name or not data:
                query.status = "failed"
                query.error_message = "Se requiere 'target_table' y 'data'."
                return
            if table_name not in self.database:
                query.status = "failed"
                query.error_message = f"Tabla {table_name} no existe."
                return
            if self.strict_schema_enforcement:
                schema = self.schemas.get(table_name, {})
                for key, value in data.items():
                    if key not in schema:
                        query.status = "failed"
                        query.error_message = f"Campo {key} no está en el esquema de {table_name}."
                        return
                    if self.coerce_value_types:
                        data[key] = self._coerce_value(value, schema[key])
            data["KUID"] = f"ku_{uuid.uuid4().hex[:8]}"
            self.database[table_name].append(data)
            self._index_table(table_name, data, len(self.database[table_name]) - 1)
            self.module_state["inserts_processed"] += 1
            self.module_state["total_rows_approx"] += 1
            query.result = {"success": True, "KUID": data["KUID"]}
            query.status = "completed"

        elif query.query_type == "update":
            table_name = query.target_table
            condition = query.payload.get("condition", {})
            updates = query.payload.get("updates", {})
            if not table_name or not updates:
                query.status = "failed"
                query.error_message = "Se requiere 'target_table' y 'updates'."
                return
            if table_name not in self.database:
                query.status = "failed"
                query.error_message = f"Tabla {table_name} no existe."
                return
            if self.strict_schema_enforcement:
                schema = self.schemas.get(table_name, {})
                for key, value in updates.items():
                    if key not in schema:
                        query.status = "failed"
                        query.error_message = f"Campo {key} no está en el esquema de {table_name}."
                        return
                    if self.coerce_value_types:
                        updates[key] = self._coerce_value(value, schema[key])
            updated_rows = 0
            for i, row in enumerate(self.database[table_name]):
                if all(row.get(k) == v for k, v in condition.items()):
                    self.database[table_name][i].update(updates)
                    self._index_table(table_name, self.database[table_name][i], i)
                    updated_rows += 1
            self.module_state["updates_processed"] += 1
            query.result = {"success": True, "updated_rows": updated_rows}
            query.status = "completed"

        elif query.query_type == "delete":
            table_name = query.target_table
            condition = query.payload.get("condition", {})
            if not table_name:
                query.status = "failed"
                query.error_message = "Se requiere 'target_table'."
                return
            if table_name not in self.database:
                query.status = "failed"
                query.error_message = f"Tabla {table_name} no existe."
                return
            deleted_rows = 0
            new_table = []
            for i, row in enumerate(self.database[table_name]):
                if not all(row.get(k) == v for k, v in condition.items()):
                    new_table.append(row)
                else:
                    deleted_rows += 1
            self.database[table_name] = new_table
            self.index[table_name] = {}  # Reconstruir índice
            for i, row in enumerate(self.database[table_name]):
                self._index_table(table_name, row, i)
            self.module_state["deletes_processed"] += 1
            self.module_state["total_rows_approx"] -= deleted_rows
            query.result = {"success": True, "deleted_rows": deleted_rows}
            query.status = "completed"

        elif query.query_type == "get_schema":
            table_name = query.target_table
            if not table_name:
                query.result = {"schemas": self.schemas}
            elif table_name in self.schemas:
                query.result = {"schema": self.schemas[table_name]}
            else:
                query.status = "failed"
                query.error_message = f"Tabla {table_name} no existe."
                return
            query.status = "completed"

    async def _check_query_conflict(self, query: KnowledgeQuery) -> bool:
        self.query_graph.add_node(query.query_id, type=query.query_type, table=query.target_table)
        for other_id in self.query_graph.nodes:
            if other_id != query.query_id:
                other_query = next((q for q in list(self.query_queue._queue) if q[1].query_id == other_id), None)
                if other_query and other_query.target_table == query.target_table:
                    if query.query_type in ["insert", "update", "delete"] and other_query.query_type in ["insert", "update", "delete"]:
                        self.query_graph.add_edge(query.query_id, other_id, weight=1.0)
        try:
            cycles = list(nx.simple_cycles(self.query_graph))
            for cycle in cycles:
                cycle_criticalities = [self.query_graph.nodes[n]["criticality"] for n in cycle]
                if np.mean(cycle_criticalities) > 0.8:
                    return True
        except nx.NetworkXNoCycle:
            pass
        return False

    async def _update_data_coherence(self):
        n_queries = max(self.query_queue.qsize(), 1)
        if len(self.coherence_field) != n_queries:
            self.coherence_field = np.ones(n_queries) * self.module_state["data_coherence_score"]
        conflicts = len(list(nx.simple_cycles(self.query_graph))) if self.query_graph.number_of_nodes() > 0 else 0
        # SDE para consistencia
        consistency = self.module_state["data_coherence_score"]
        def consistency_dynamics(t, c):
            return -0.05 * (c - 1.0) + self.sde_sigma * np.random.normal(0, 1)
        result = integrate.odeint(consistency_dynamics, [consistency], [0, self.update_interval], tfirst=True)
        consistency = np.clip(result[-1][0], 0.0, 1.0)
        self.module_state["data_coherence_score"] = consistency
        # PDE para coherencia
        for _ in range(int(self.update_interval / self.pde_dt)):
            d2_coherence = (np.roll(self.coherence_field, 1) + np.roll(self.coherence_field, -1) - 2 * self.coherence_field) / (self.pde_dx ** 2)
            reaction = 0.1 * self.coherence_field * (1.0 - self.coherence_field / n_queries - 0.05 * conflicts)
            self.coherence_field += self.pde_dt * (self.pde_diffusion * d2_coherence + reaction)
            self.coherence_field = np.clip(self.coherence_field, 0.0, 1.0)
        self.module_state["data_coherence_score"] = np.mean(self.coherence_field)

    async def _finalize_query(self, query: KnowledgeQuery):
        if query.source_module_id and query.original_correlation_id:
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id=query.source_module_id,
                    message_type="knowledge_query_response",
                    payload={"query_id_ref": query.query_id, "status": query.status, "result": query.result, "error": query.error_message},
                    correlation_id=query.original_correlation_id
                ))
            })
        self.query_graph.remove_nodes_from([query.query_id])

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        if not full_message:
            return
        if event_type == "submit_knowledge_query_request":
            try:
                query = KnowledgeQuery(
                    source_module_id=full_message.source_module_id,
                    original_correlation_id=full_message.correlation_id,
                    query_type=payload.get("query_type"),
                    target_table=payload.get("target_table"),
                    payload=payload.get("query_payload", {}),
                    criticality_probability=float(payload.get("criticality_probability", 0.5))
                )
                if not query.query_type:
                    raise ValueError("'query_type' requerido.")
                await self.query_queue.put((-query.criticality_probability, query))
            except (TypeError, ValueError) as e:
                self.logger.error(f"Error procesando solicitud de conocimiento: {e}")
        elif event_type in ["logical_query_response", "request_external_knowledge_response"]:
            corr_id = full_message.correlation_id
            for query in list(self.query_queue._queue):
                if corr_id in query[1]._futures:
                    query[1]._futures[corr_id].set_result(payload)





            #inicio del modulo DataAndKnowledgeProcessingModule 


@dataclass
class DataProcessingRequest:
    request_id: str = field(default_factory=lambda: f"dpr_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    data_payload: Any
    data_type_hint: str
    processing_instructions: Dict[str, Any] = field(default_factory=dict)
    status: str = "pending"
    result: Optional[Dict[str, Any]] = None
    error_message: Optional[str] = None
    priority_score: float = 0.5
    _pending_load_confirmations: Dict[str, asyncio.Future] = field(default_factory=dict, repr=False)

    def __lt__(self, other: 'DataProcessingRequest') -> bool:
        return self.priority_score < other.priority_score

class DataAndKnowledgeProcessingModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 0.7

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.processing_request_queue: asyncio.PriorityQueue = asyncio.PriorityQueue(maxlen=50)
        self.active_processing_tasks: Dict[str, DataProcessingRequest] = {}
        self.knowledge_elements_generated: Dict[str, int] = defaultdict(int)
        self.load_confirmation_timeout_s: float = 10.0
        self.max_load_retries: int = 3
        self.load_retry_delay_s: float = 0.5
        # Nuevos parámetros
        self.num_mc_samples: int = 500
        self.sde_sigma: float = 0.01
        self.pde_dx: float = 0.1
        self.pde_dt: float = 0.01
        self.pde_diffusion: float = 0.05
        self.kalman_Q: float = 0.01
        self.kalman_R: float = 0.05
        self.kalman_state: float = 0.0
        self.kalman_cov: float = 0.1
        self.request_graph = nx.DiGraph()
        self.coherence_field: np.ndarray = np.array([1.0])
        self.module_state.update({
            "requests_processed": 0,
            "requests_completed_successfully": 0,
            "requests_failed": 0,
            "total_knowledge_elements_produced": 0,
            "successful_knowledge_loads": 0,
            "failed_knowledge_loads": 0,
            "data_coherence_score": 1.0,
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado con procesamiento avanzado.")

    async def _update_logic(self):
        if not self.processing_request_queue.empty() and len(self.active_processing_tasks) < 5:
            _, request = await self.processing_request_queue.get()
            self.active_processing_tasks[request.request_id] = request
            self._create_managed_task(self._process_single_data_request(request))
        await self._update_data_coherence()

    async def _process_single_data_request(self, request: DataProcessingRequest):
        request.status = "preprocessing"
        self.module_state["requests_processed"] += 1
        try:
            # Ajustar prioridad con Monte Carlo
            load_factor = self.core_recombinator.global_state.get("current_load_factor", 0.5)
            samples = np.random.beta(2 * request.priority_score, 2 * (1 - request.priority_score), self.num_mc_samples)
            request.priority_score = np.clip(np.mean(samples) * (1 - 0.5 * load_factor), 0.0, 1.0)
            # Verificar conflictos
            if await self._check_request_conflict(request):
                raise ValueError("Conflicto detectado con solicitudes concurrentes.")
            # 1. Extract
            processed_data = await self._preprocess_data(request.data_payload, request.data_type_hint)
            # Validar datos con ComputationalLogicModule
            correlation_id = f"data_validation_{request.request_id}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            request._pending_load_confirmations[correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="ComputationalLogicModule",
                    message_type="submit_logical_query_request",
                    payload={"query_type": "validate_data", "query_payload": {"data_summary": processed_data}},
                    correlation_id=correlation_id
                ))
            })
            try:
                validation_result = await asyncio.wait_for(future, timeout=5.0)
                if validation_result.get("status") != "valid":
                    raise ValueError(f"Datos inválidos: {validation_result.get('error', 'No especificado')}")
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout validando datos para {request.request_id}.")
            # 2. Transform
            request.status = "transforming"
            extracted_info = await self._extract_information(processed_data, request.data_type_hint)
            knowledge_payloads = await self._transform_to_knowledge_formats(extracted_info, request)
            # 3. Load
            request.status = "loading_to_kb"
            load_successful = await self._load_knowledge_to_systems(knowledge_payloads, request)
            if load_successful:
                request.status = "completed"
                request.result = {"message": "Datos procesados y cargados exitosamente.", "elements_produced": dict(self.knowledge_elements_generated)}
                self.module_state["requests_completed_successfully"] += 1
                # Kalman para suavizar métricas
                measurement = 1.0
                A, H = 1.0, 1.0
                Q, R = self.kalman_Q, self.kalman_R
                predicted_state = A * self.kalman_state
                predicted_cov = A * self.kalman_cov * A + Q
                innovation = measurement - H * predicted_state
                innovation_cov = H * predicted_cov * H + R
                kalman_gain = predicted_cov * H / innovation_cov
                self.kalman_state = predicted_state + kalman_gain * innovation
                self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
            else:
                raise RuntimeError("Una o más operaciones críticas de carga de conocimiento fallaron tras reintentos.")
        except Exception as e:
            request.status = "failed"
            request.error_message = str(e)
            self.module_state["requests_failed"] += 1
            self.logger.error(f"Fallo en pipeline DKPM para request '{request.request_id}': {e}", exc_info=True)
        finally:
            await self._finalize_processing_request(request)

    async def _preprocess_data(self, data: Any, type_hint: str) -> Dict[str, Any]:
        # Validar y normalizar datos
        result = {"data": data, "metadata": {"type": type_hint}}
        if type_hint in ["json_event", "structured_event"]:
            try:
                result["data"] = json.loads(data) if isinstance(data, str) else data
            except json.JSONDecodeError:
                raise ValueError("Formato JSON inválido.")
        elif type_hint == "simple_text_log":
            result["data"] = str(data).strip()
        elif type_hint == "image_data":
            # Suponer que los datos son un descriptor (e.g., URL o base64)
            result["data"] = {"image_ref": str(data)}
        else:
            raise ValueError(f"Tipo de datos no soportado: {type_hint}")
        # Monte Carlo para calidad de datos
        samples = np.random.normal(0.8, 0.1, self.num_mc_samples)
        result["metadata"]["quality"] = np.clip(np.mean(samples), 0.0, 1.0)
        return result

    async def _extract_information(self, data: Dict[str, Any], type_hint: str) -> Dict[str, Any]:
        correlation_id = f"nlu_extract_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="AdvancedTCHNModule",
                message_type="extract_information_request",
                payload={"data": data["data"], "type_hint": type_hint},
                correlation_id=correlation_id
            ))
        })
        try:
            result = await asyncio.wait_for(future, timeout=10.0)
            if result.get("status") != "completed":
                raise ValueError(f"Error en extracción: {result.get('error', 'No especificado')}")
            extracted = result.get("extracted_info", {})
            # Monte Carlo para confianza
            samples = np.random.normal(extracted.get("confidence", 0.8), 0.1, self.num_mc_samples)
            extracted["confidence"] = np.clip(np.mean(samples), 0.0, 1.0)
            return extracted
        except asyncio.TimeoutError:
            self.logger.warning("Timeout en extracción de información.")
            # Fallback a extracción simple
            extracted = {"raw_data": data["data"], "type": type_hint}
            if type_hint == "simple_text_log":
                text_lower = str(data["data"]).lower()
                if "error" in text_lower or "failed" in text_lower:
                    extracted["event_type"] = "error_log"
                extracted["confidence"] = 0.5
            return extracted

    async def _transform_to_knowledge_formats(self, info: Dict, request: DataProcessingRequest) -> Dict[str, List[Dict]]:
        knowledge = defaultdict(list)
        # Validar conocimiento con ComputationalLogicModule
        correlation_id = f"knowledge_validation_{request.request_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        request._pending_load_confirmations[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="ComputationalLogicModule",
                message_type="submit_logical_query_request",
                payload={"query_type": "validate_data", "query_payload": info},
                correlation_id=correlation_id
            ))
        })
        try:
            validation_result = await asyncio.wait_for(future, timeout=5.0)
            if validation_result.get("status") != "valid":
                raise ValueError(f"Conocimiento inválido: {validation_result.get('error', 'No especificado')}")
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout validando conocimiento para {request.request_id}.")
        # Transformar a formatos específicos
        confidence = info.get("confidence", 0.8)
        if request.data_type_hint in ["json_event", "structured_event"]:
            knowledge["sql_inserts"].append({
                "table_name": "Events",
                "data": {"timestamp": time.time(), "source": request.source_module_id, "event_data": info, "confidence": confidence}
            })
            knowledge["narrative_memories"].append({
                "description": f"Evento procesado de {request.source_module_id}: {str(info)[:80]}",
                "importance": confidence * 0.5,
                "type": "structured_event"
            })
        elif request.data_type_hint == "simple_text_log":
            knowledge["sql_inserts"].append({
                "table_name": "SystemLogs",
                "data": {"timestamp": time.time(), "source": request.source_module_id, "level": info.get("event_type", "INFO"), "content": info.get("raw_data"), "confidence": confidence}
            })
            knowledge["narrative_memories"].append({
                "description": f"Log procesado de {request.source_module_id}: {str(info.get('raw_data'))[:80]}",
                "importance": confidence * 0.4,
                "type": "log_event"
            })
        elif request.data_type_hint == "image_data":
            knowledge["sql_inserts"].append({
                "table_name": "ImageRecords",
                "data": {"timestamp": time.time(), "source": request.source_module_id, "image_ref": info.get("image_ref"), "entities": info.get("entities", []), "confidence": confidence}
            })
            knowledge["narrative_memories"].append({
                "description": f"Imagen procesada de {request.source_module_id}: {info.get('image_ref')[:80]}",
                "importance": confidence * 0.6,
                "type": "image_event"
            })
        self.knowledge_elements_generated[request.data_type_hint] += len(knowledge["sql_inserts"]) + len(knowledge["narrative_memories"])
        self.module_state["total_knowledge_elements_produced"] += len(knowledge["sql_inserts"]) + len(knowledge["narrative_memories"])
        return knowledge

    async def _load_knowledge_to_systems(self, knowledge_payloads: Dict[str, List[Dict]], request: DataProcessingRequest) -> bool:
        load_tasks = []
        for sql_op in knowledge_payloads.get("sql_inserts", []):
            task = self._send_and_track_load(request, "SQLKnowledgeStore", "submit_knowledge_query_request", {"query_type": "insert", **sql_op})
            load_tasks.append(task)
        for mem in knowledge_payloads.get("narrative_memories", []):
            correlation_id = f"narrative_load_{request.request_id}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            request._pending_load_confirmations[correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="NarrativeSelf",
                    message_type="new_memory_fragment",
                    payload=mem,
                    correlation_id=correlation_id
                ))
            })
            load_tasks.append(self._wait_for_narrative_confirmation(request, correlation_id))
        if not load_tasks:
            return True
        results = await asyncio.gather(*load_tasks, return_exceptions=True)
        return all(res is True for res in results)

    async def _send_and_track_load(self, request: DataProcessingRequest, target: str, msg_type: str, payload: Dict) -> bool:
        for attempt in range(self.max_load_retries):
            corr_id = f"dkpm_load_{request.request_id}_{target[:3]}_{attempt}"
            future = asyncio.Future()
            request._pending_load_confirmations[corr_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id=target,
                    message_type=msg_type,
                    payload=payload,
                    correlation_id=corr_id
                ))
            })
            try:
                response = await asyncio.wait_for(future, timeout=self.load_confirmation_timeout_s)
                if response.get("result", {}).get("success", False):
                    self.module_state["successful_knowledge_loads"] += 1
                    return True
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout en carga a {target} (Intento {attempt+1}/{self.max_load_retries}).")
            except Exception as e:
                self.logger.warning(f"Error en carga a {target} (Intento {attempt+1}): {e}")
            if attempt < self.max_load_retries - 1:
                await asyncio.sleep(self.load_retry_delay_s * (attempt + 1))
        self.module_state["failed_knowledge_loads"] += 1
        return False

    async def _wait_for_narrative_confirmation(self, request: DataProcessingRequest, corr_id: str) -> bool:
        try:
            response = await asyncio.wait_for(request._pending_load_confirmations[corr_id], timeout=self.load_confirmation_timeout_s)
            if response.get("status") == "completed":
                self.module_state["successful_knowledge_loads"] += 1
                return True
            return False
        except asyncio.TimeoutError:
            self.module_state["failed_knowledge_loads"] += 1
            return False

    async def _check_request_conflict(self, request: DataProcessingRequest) -> bool:
        self.request_graph.add_node(request.request_id, type=request.data_type_hint, source=request.source_module_id)
        for other_id in self.request_graph.nodes:
            if other_id != request.request_id:
                other_request = self.active_processing_tasks.get(other_id)
                if other_request and other_request.source_module_id == request.source_module_id and other_request.data_type_hint == request.data_type_hint:
                    self.request_graph.add_edge(request.request_id, other_id, weight=1.0)
        try:
            cycles = list(nx.simple_cycles(self.request_graph))
            for cycle in cycles:
                cycle_priorities = [self.request_graph.nodes[n]["priority"] for n in cycle]
                if np.mean(cycle_priorities) > 0.8:
                    return True
        except nx.NetworkXNoCycle:
            pass
        return False

    async def _update_data_coherence(self):
        n_requests = max(self.processing_request_queue.qsize() + len(self.active_processing_tasks), 1)
        if len(self.coherence_field) != n_requests:
            self.coherence_field = np.ones(n_requests) * self.module_state["data_coherence_score"]
        conflicts = len(list(nx.simple_cycles(self.request_graph))) if self.request_graph.number_of_nodes() > 0 else 0
        # SDE para estabilidad
        stability = self.module_state["data_coherence_score"]
        def stability_dynamics(t, s):
            return -0.05 * (s - 1.0) + self.sde_sigma * np.random.normal(0, 1)
        result = integrate.odeint(stability_dynamics, [stability], [0, self.update_interval], tfirst=True)
        stability = np.clip(result[-1][0], 0.0, 1.0)
        self.module_state["data_coherence_score"] = stability
        # PDE para coherencia
        for _ in range(int(self.update_interval / self.pde_dt)):
            d2_coherence = (np.roll(self.coherence_field, 1) + np.roll(self.coherence_field, -1) - 2 * self.coherence_field) / (self.pde_dx ** 2)
            reaction = 0.1 * self.coherence_field * (1.0 - self.coherence_field / n_requests - 0.05 * conflicts)
            self.coherence_field += self.pde_dt * (self.pde_diffusion * d2_coherence + reaction)
            self.coherence_field = np.clip(self.coherence_field, 0.0, 1.0)
        self.module_state["data_coherence_score"] = np.mean(self.coherence_field)

    async def _finalize_processing_request(self, request: DataProcessingRequest):
        if request.source_module_id and request.original_correlation_id:
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id=request.source_module_id,
                    message_type="data_processing_completed_notice",
                    payload={"request_id_ref": request.request_id, "status": request.status, "result": request.result, "error": request.error_message},
                    correlation_id=request.original_correlation_id
                ))
            })
        if request.request_id in self.active_processing_tasks:
            del self.active_processing_tasks[request.request_id]
        self.request_graph.remove_nodes_from([request.request_id])

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        if not full_message:
            return
        if event_type == "submit_data_for_processing_request":
            try:
                req = DataProcessingRequest(
                    source_module_id=full_message.source_module_id,
                    original_correlation_id=full_message.correlation_id,
                    data_payload=payload.get("data_payload"),
                    data_type_hint=payload.get("data_type_hint", "unknown"),
                    processing_instructions=payload.get("processing_instructions", {}),
                    priority_score=float(payload.get("priority_score", 0.5))
                )
                if not req.data_payload or not req.data_type_hint:
                    raise ValueError("Se requieren 'data_payload' y 'data_type_hint'.")
                await self.processing_request_queue.put((-req.priority_score, req))
            except (ValueError, TypeError) as e:
                self.logger.error(f"Error procesando solicitud de datos: {e}")
        elif event_type in ["knowledge_query_response", "extract_information_response", "new_memory_response"]:
            corr_id = full_message.correlation_id
            for request in list(self.active_processing_tasks.values()) + [r[1] for r in list(self.processing_request_queue._queue)]:
                if corr_id in request._pending_load_confirmations:
                    future = request._pending_load_confirmations.pop(corr_id)
                    if not future.done():
                        future.set_result(payload)




            #inicio del modulo OntologyFlowManager 


@dataclass
class OntologyConcept:
    id: str
    label: Optional[str] = None
    description: Optional[str] = None
    parent_ids: Set[str] = field(default_factory=set)
    disjoint_with: Set[str] = field(default_factory=set)

@dataclass
class OntologyProperty:
    id: str
    label: Optional[str] = None
    description: Optional[str] = None
    domain_concept_ids: Set[str] = field(default_factory=set)
    range_concept_ids: Set[str] = field(default_factory=set)
    is_transitive: bool = False
    is_symmetric: bool = False

@dataclass
class OntologyIndividual:
    id: str
    label: Optional[str] = None
    concept_type_ids: Set[str] = field(default_factory=set)
    property_values: Dict[str, Set[Any]] = field(default_factory=lambda: defaultdict(set))

@dataclass
class OntologyQuery:
    query_id: str = field(default_factory=lambda: f"ofm_query_{uuid.uuid4().hex[:6]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    query_type: str
    payload: Dict[str, Any]
    status: str = "pending"
    result: Optional[Any] = None
    error_message: Optional[str] = None
    priority_score: float = 0.5
    _futures: Dict[str, asyncio.Future] = field(default_factory=dict, repr=False)

    def __lt__(self, other: 'OntologyQuery') -> bool:
        return self.priority_score < other.priority_score

class OntologyFlowManager(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 5.0
    ONTOLOGY_FILE = "ontology.json"

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.concepts: Dict[str, OntologyConcept] = {}
        self.properties: Dict[str, OntologyProperty] = {}
        self.individuals: Dict[str, OntologyIndividual] = {}
        self._all_superclasses_cache: Dict[str, Set[str]] = {}
        self._all_subclasses_cache: Dict[str, Set[str]] = defaultdict(set)
        self.query_queue: asyncio.PriorityQueue = asyncio.PriorityQueue(maxlen=50)
        self.ontology_modified: bool = False
        # Nuevos parámetros
        self.num_mc_samples: int = 500
        self.sde_sigma: float = 0.01
        self.pde_dx: float = 0.1
        self.pde_dt: float = 0.01
        self.pde_diffusion: float = 0.05
        self.kalman_Q: float = 0.01
        self.kalman_R: float = 0.05
        self.kalman_state: float = 0.0
        self.kalman_cov: float = 0.1
        self.query_graph = nx.DiGraph()
        self.coherence_field: np.ndarray = np.array([1.0])
        self.module_state.update({
            "concepts_count": 0,
            "properties_count": 0,
            "individuals_count": 0,
            "queries_processed": 0,
            "ontology_modifications": 0,
            "avg_query_time_ms": 0.0,
            "ontology_coherence_score": 1.0,
        })
        self.query_processing_times: List[float] = []
        self.logger.info(f"{self.module_name} v27.2 inicializado con gestión avanzada.")

    async def start(self):
        await super().start()
        await self._load_ontology_from_file()
        if not self.concepts:
            self._initialize_base_ontology()
        self._rebuild_inference_caches()

    async def _load_ontology_from_file(self):
        if os.path.exists(self.ONTOLOGY_FILE):
            try:
                async with aiofiles.open(self.ONTOLOGY_FILE, 'r') as f:
                    data = json.loads(await f.read())
                for concept_data in data.get("concepts", []):
                    self.add_concept_internal(OntologyConcept(
                        id=concept_data["id"],
                        label=concept_data.get("label"),
                        description=concept_data.get("description"),
                        parent_ids=set(concept_data.get("parent_ids", [])),
                        disjoint_with=set(concept_data.get("disjoint_with", []))
                    ))
                for prop_data in data.get("properties", []):
                    self.add_property_internal(OntologyProperty(
                        id=prop_data["id"],
                        label=prop_data.get("label"),
                        description=prop_data.get("description"),
                        domain_concept_ids=set(prop_data.get("domain_concept_ids", [])),
                        range_concept_ids=set(prop_data.get("range_concept_ids", [])),
                        is_transitive=prop_data.get("is_transitive", False),
                        is_symmetric=prop_data.get("is_symmetric", False)
                    ))
                for ind_data in data.get("individuals", []):
                    self.individuals[ind_data["id"]] = OntologyIndividual(
                        id=ind_data["id"],
                        label=ind_data.get("label"),
                        concept_type_ids=set(ind_data.get("concept_type_ids", [])),
                        property_values={k: set(v) for k, v in ind_data.get("property_values", {}).items()}
                    )
                self.module_state["concepts_count"] = len(self.concepts)
                self.module_state["properties_count"] = len(self.properties)
                self.module_state["individuals_count"] = len(self.individuals)
                self.logger.info(f"Ontología cargada desde {self.ONTOLOGY_FILE}.")
            except Exception as e:
                self.logger.error(f"Error cargando ontología: {e}")

    def _initialize_base_ontology(self):
        self.add_concept_internal(OntologyConcept(id="EANE_Entity", label="Entidad del Sistema EANE"))
        self.add_concept_internal(OntologyConcept(id="InformationObject", label="Objeto de Información", parent_ids={"EANE_Entity"}))
        self.add_concept_internal(OntologyConcept(id="CognitiveModule", label="Módulo Cognitivo", parent_ids={"EANE_Entity"}))
        self.add_property_internal(OntologyProperty(id="hasState", domain_concept_ids={"EANE_Entity"}, range_concept_ids={"InformationObject"}))
        self.add_individual_internal(OntologyIndividual(id="SystemCore", concept_type_ids={"CognitiveModule"}))
        self.ontology_modified = False

    async def _update_logic(self):
        if not self.query_queue.empty():
            _, query = await self.query_queue.get()
            self._create_managed_task(self._process_ontology_query(query))
        if self.ontology_modified and self.module_state["cycles_ran"] % 10 == 0:
            await self._save_ontology_to_file()
        await self._update_ontology_coherence()

    async def _save_ontology_to_file(self):
        try:
            ontology_data = {
                "concepts": [asdict(c) for c in self.concepts.values()],
                "properties": [asdict(p) for p in self.properties.values()],
                "individuals": [{k: list(v) if isinstance(v, set) else v for k, v in asdict(i).items()} for i in self.individuals.values()]
            }
            async with aiofiles.open(self.ONTOLOGY_FILE, 'w') as f:
                await f.write(json.dumps(ontology_data, indent=2))
            self.ontology_modified = False
            self.logger.info(f"Ontología guardada en {self.ONTOLOGY_FILE}.")
        except Exception as e:
            self.logger.error(f"Error guardando ontología: {e}")

    def add_concept_internal(self, concept: OntologyConcept) -> bool:
        if concept.id in self.concepts:
            return False
        self.concepts[concept.id] = concept
        self.module_state["concepts_count"] += 1
        self.module_state["ontology_modifications"] += 1
        self.ontology_modified = True
        self._rebuild_inference_caches()
        return True

    def add_property_internal(self, prop: OntologyProperty) -> bool:
        if prop.id in self.properties:
            return False
        self.properties[prop.id] = prop
        self.module_state["properties_count"] += 1
        self.module_state["ontology_modifications"] += 1
        self.ontology_modified = True
        self._rebuild_inference_caches()
        return True

    def add_individual_internal(self, individual: OntologyIndividual) -> bool:
        if individual.id in self.individuals:
            return False
        self.individuals[individual.id] = individual
        self.module_state["individuals_count"] += 1
        self.module_state["ontology_modifications"] += 1
        self.ontology_modified = True
        return True

    def _rebuild_inference_caches(self):
        self.logger.debug("Reconstruyendo cachés de inferencia...")
        self._all_superclasses_cache.clear()
        self._all_subclasses_cache.clear()
        # Grafo de conceptos para detectar ciclos
        G = nx.DiGraph()
        for concept_id, concept in self.concepts.items():
            G.add_node(concept_id)
            for parent_id in concept.parent_ids:
                if parent_id in self.concepts:
                    G.add_edge(concept_id, parent_id)
        try:
            nx.find_cycle(G)
            self.logger.warning("Ciclo detectado en la jerarquía de conceptos.")
        except nx.NetworkXNoCycle:
            pass
        for concept_id, concept in self.concepts.items():
            q = deque(concept.parent_ids)
            all_supers = set(concept.parent_ids)
            while q:
                parent_id = q.popleft()
                if parent_id in self.concepts:
                    grandparents = self.concepts[parent_id].parent_ids
                    for gp_id in grandparents:
                        if gp_id not in all_supers:
                            all_supers.add(gp_id)
                            q.append(gp_id)
            self._all_superclasses_cache[concept_id] = all_supers
            for super_id in all_supers:
                self._all_subclasses_cache[super_id].add(concept_id)
        self.logger.debug("Cachés de inferencia reconstruidas.")

    async def _process_ontology_query(self, query: OntologyQuery):
        start_time = time.time()
        query.status = "processing"
        self.module_state["queries_processed"] += 1
        try:
            # Ajustar prioridad con Monte Carlo
            load_factor = self.core_recombinator.global_state.get("current_load_factor", 0.5)
            samples = np.random.beta(2 * query.priority_score, 2 * (1 - query.priority_score), self.num_mc_samples)
            query.priority_score = np.clip(np.mean(samples) * (1 - 0.5 * load_factor), 0.0, 1.0)
            # Verificar conflictos
            if await self._check_query_conflict(query):
                raise ValueError("Conflicto detectado con consultas concurrentes.")
            # Validar con ComputationalLogicModule
            correlation_id = f"query_validation_{query.query_id}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            query._futures[correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="ComputationalLogicModule",
                    message_type="submit_logical_query_request",
                    payload={"query_type": "validate_ontology_query", "query_payload": query.payload},
                    correlation_id=correlation_id
                ))
            })
            try:
                validation_result = await asyncio.wait_for(future, timeout=5.0)
                if validation_result.get("status") != "valid":
                    raise ValueError(f"Consulta inválida: {validation_result.get('error', 'No especificado')}")
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout validando consulta {query.query_id}.")
            # Procesar consulta
            if query.query_type == "get_subclasses":
                cid = query.payload.get("concept_id")
                if not cid or cid not in self.concepts:
                    raise ValueError("Concepto inválido o no encontrado.")
                query.result = {"subclasses": list(self._all_subclasses_cache.get(cid, set()))}
            elif query.query_type == "check_is_subclass":
                sub_id, super_id = query.payload.get("subclass_id"), query.payload.get("superclass_id")
                if not sub_id or not super_id:
                    raise ValueError("Se requieren 'subclass_id' y 'superclass_id'.")
                query.result = {"is_subclass": super_id in self._all_superclasses_cache.get(sub_id, set())}
            elif query.query_type == "add_concept":
                concept_data = query.payload.get("concept", {})
                concept = OntologyConcept(
                    id=concept_data.get("id"),
                    label=concept_data.get("label"),
                    description=concept_data.get("description"),
                    parent_ids=set(concept_data.get("parent_ids", [])),
                    disjoint_with=set(concept_data.get("disjoint_with", []))
                )
                if not concept.id or not all(p in self.concepts for p in concept.parent_ids):
                    raise ValueError("Concepto inválido o padres no encontrados.")
                if not self.add_concept_internal(concept):
                    raise ValueError(f"Concepto {concept.id} ya existe.")
                query.result = {"success": True, "concept_id": concept.id}
            elif query.query_type == "add_property":
                prop_data = query.payload.get("property", {})
                prop = OntologyProperty(
                    id=prop_data.get("id"),
                    label=prop_data.get("label"),
                    description=prop_data.get("description"),
                    domain_concept_ids=set(prop_data.get("domain_concept_ids", [])),
                    range_concept_ids=set(prop_data.get("range_concept_ids", [])),
                    is_transitive=prop_data.get("is_transitive", False),
                    is_symmetric=prop_data.get("is_symmetric", False)
                )
                if not prop.id or not all(d in self.concepts for d in prop.domain_concept_ids) or not all(r in self.concepts for r in prop.range_concept_ids):
                    raise ValueError("Propiedad inválida o dominio/rango no encontrados.")
                if not self.add_property_internal(prop):
                    raise ValueError(f"Propiedad {prop.id} ya existe.")
                query.result = {"success": True, "property_id": prop.id}
            elif query.query_type == "add_individual":
                ind_data = query.payload.get("individual", {})
                individual = OntologyIndividual(
                    id=ind_data.get("id"),
                    label=ind_data.get("label"),
                    concept_type_ids=set(ind_data.get("concept_type_ids", [])),
                    property_values={k: set(v) for k, v in ind_data.get("property_values", {}).items()}
                )
                if not individual.id or not all(c in self.concepts for c in individual.concept_type_ids):
                    raise ValueError("Individuo inválido o tipos no encontrados.")
                for prop_id, values in individual.property_values.items():
                    if prop_id not in self.properties:
                        raise ValueError(f"Propiedad {prop_id} no existe.")
                    prop = self.properties[prop_id]
                    if prop.is_transitive:
                        transitive_values = set()
                        for val in values:
                            if isinstance(val, str) and val in self.individuals:
                                transitive_values.update(self.individuals[val].property_values.get(prop_id, set()))
                        individual.property_values[prop_id].update(transitive_values)
                    if prop.is_symmetric:
                        for val in values:
                            if isinstance(val, str) and val in self.individuals:
                                self.individuals[val].property_values[prop_id].add(individual.id)
                if not self.add_individual_internal(individual):
                    raise ValueError(f"Individuo {individual.id} ya existe.")
                query.result = {"success": True, "individual_id": individual.id}
            elif query.query_type == "get_individuals":
                concept_id = query.payload.get("concept_id")
                if not concept_id or concept_id not in self.concepts:
                    raise ValueError("Concepto inválido o no encontrado.")
                individuals = [ind.id for ind in self.individuals.values() if concept_id in ind.concept_type_ids or any(c in self._all_superclasses_cache.get(ind_id, set()) for ind_id in ind.concept_type_ids)]
                query.result = {"individuals": individuals}
            elif query.query_type == "check_property":
                ind_id, prop_id, value = query.payload.get("individual_id"), query.payload.get("property_id"), query.payload.get("value")
                if not ind_id or not prop_id or value is None:
                    raise ValueError("Se requieren 'individual_id', 'property_id' y 'value'.")
                if ind_id not in self.individuals or prop_id not in self.properties:
                    raise ValueError("Individuo o propiedad no encontrados.")
                query.result = {"has_property": value in self.individuals[ind_id].property_values.get(prop_id, set())}
            elif query.query_type == "get_related_individuals":
                ind_id, prop_id = query.payload.get("individual_id"), query.payload.get("property_id")
                if not ind_id or not prop_id:
                    raise ValueError("Se requieren 'individual_id' y 'property_id'.")
                if ind_id not in self.individuals or prop_id not in self.properties:
                    raise ValueError("Individuo o propiedad no encontrados.")
                related = self.individuals[ind_id].property_values.get(prop_id, set())
                query.result = {"related_individuals": list(related)}
            else:
                raise ValueError(f"Tipo de consulta no soportado: {query.query_type}")
            # Monte Carlo para confianza
            samples = np.random.normal(0.9, 0.1, self.num_mc_samples)
            query.result["confidence"] = np.clip(np.mean(samples), 0.0, 1.0)
            query.status = "completed"
        except Exception as e:
            query.status = "failed"
            query.error_message = str(e)
        finally:
            latency = time.time() - start_time
            # Kalman para suavizar latencia
            A, H = 1.0, 1.0
            Q, R = self.kalman_Q, self.kalman_R
            predicted_state = A * self.kalman_state
            predicted_cov = A * self.kalman_cov * A + Q
            innovation = latency - H * predicted_state
            innovation_cov = H * predicted_cov * H + R
            kalman_gain = predicted_cov * H / innovation_cov
            self.kalman_state = predicted_state + kalman_gain * innovation
            self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
            self.query_processing_times.append(self.kalman_state)
            self.module_state["avg_query_time_ms"] = np.mean(self.query_processing_times[-50:]) * 1000
            await self._send_query_response(query)

    async def _check_query_conflict(self, query: OntologyQuery) -> bool:
        self.query_graph.add_node(query.query_id, type=query.query_type, priority=query.priority_score)
        for other_id in self.query_graph.nodes:
            if other_id != query.query_id:
                other_query = next((q for q in list(self.query_queue._queue) if q[1].query_id == other_id), None)
                if other_query and query.query_type in ["add_concept", "add_property", "add_individual"] and other_query.query_type in ["add_concept", "add_property", "add_individual"]:
                    if query.payload.get("concept_id") == other_query.payload.get("concept_id") or \
                       query.payload.get("property_id") == other_query.payload.get("property_id") or \
                       query.payload.get("individual_id") == other_query.payload.get("individual_id"):
                        self.query_graph.add_edge(query.query_id, other_id, weight=1.0)
        try:
            cycles = list(nx.simple_cycles(self.query_graph))
            for cycle in cycles:
                cycle_priorities = [self.query_graph.nodes[n]["priority"] for n in cycle]
                if np.mean(cycle_priorities) > 0.8:
                    return True
        except nx.NetworkXNoCycle:
            pass
        return False

    async def _update_ontology_coherence(self):
        n_queries = max(self.query_queue.qsize(), 1)
        if len(self.coherence_field) != n_queries:
            self.coherence_field = np.ones(n_queries) * self.module_state["ontology_coherence_score"]
        conflicts = len(list(nx.simple_cycles(self.query_graph))) if self.query_graph.number_of_nodes() > 0 else 0
        # SDE para estabilidad
        stability = self.module_state["ontology_coherence_score"]
        def stability_dynamics(t, s):
            return -0.05 * (s - 1.0) + self.sde_sigma * np.random.normal(0, 1)
        result = integrate.odeint(stability_dynamics, [stability], [0, self.update_interval], tfirst=True)
        stability = np.clip(result[-1][0], 0.0, 1.0)
        self.module_state["ontology_coherence_score"] = stability
        # PDE para coherencia
        for _ in range(int(self.update_interval / self.pde_dt)):
            d2_coherence = (np.roll(self.coherence_field, 1) + np.roll(self.coherence_field, -1) - 2 * self.coherence_field) / (self.pde_dx ** 2)
            reaction = 0.1 * self.coherence_field * (1.0 - self.coherence_field / n_queries - 0.05 * conflicts)
            self.coherence_field += self.pde_dt * (self.pde_diffusion * d2_coherence + reaction)
            self.coherence_field = np.clip(self.coherence_field, 0.0, 1.0)
        self.module_state["ontology_coherence_score"] = np.mean(self.coherence_field)

    async def _send_query_response(self, query: OntologyQuery):
        if query.source_module_id and query.original_correlation_id:
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id=query.source_module_id,
                    message_type="ontology_query_response",
                    payload={"query_id_ref": query.query_id, "status": query.status, "result": query.result, "error": query.error_message},
                    correlation_id=query.original_correlation_id
                ))
            })
        self.query_graph.remove_nodes_from([query.query_id])

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        if not full_message:
            return
        if event_type == "submit_ontology_query_request":
            try:
                query = OntologyQuery(
                    source_module_id=full_message.source_module_id,
                    original_correlation_id=full_message.correlation_id,
                    query_type=payload.get("query_type"),
                    payload=payload.get("query_payload", {}),
                    priority_score=float(payload.get("priority_score", 0.5))
                )
                if not query.query_type:
                    raise ValueError("'query_type' requerido.")
                await self.query_queue.put((-query.priority_score, query))
            except (ValueError, TypeError) as e:
                self.logger.error(f"Error procesando solicitud de ontología: {e}")
        elif event_type == "logical_query_response":
            corr_id = full_message.correlation_id
            for query in list(self.query_queue._queue):
                if corr_id in query[1]._futures:
                    query[1]._futures[corr_id].set_result(payload)




             #inicio del modulo KnowledgeMutationEngine 


@dataclass
class MutationTask:
    task_id: str = field(default_factory=lambda: f"kme_task_{uuid.uuid4().hex[:6]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    mutation_type: str
    target_knowledge_ref: Dict[str, Any]
    intensity: float = 0.5
    status: str = "pending"
    result: Optional[Dict[str, Any]] = None
    priority_score: float = 0.5
    _pending_sub_queries: Dict[str, asyncio.Future] = field(default_factory=dict, repr=False)

    def __lt__(self, other: 'MutationTask') -> bool:
        return self.priority_score < other.priority_score

class KnowledgeMutationEngine(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 45.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.mutation_task_queue: asyncio.PriorityQueue = asyncio.PriorityQueue(maxlen=10)
        self.proactive_mutation_probability: float = 0.3
        self.mutation_aggressiveness: float = 0.4
        # Nuevos parámetros
        self.num_mc_samples: int = 500
        self.sde_sigma: float = 0.01
        self.pde_dx: float = 0.1
        self.pde_dt: float = 0.01
        self.pde_diffusion: float = 0.05
        self.kalman_Q: float = 0.01
        self.kalman_R: float = 0.05
        self.kalman_state: float = 0.0
        self.kalman_cov: float = 0.1
        self.task_graph = nx.DiGraph()
        self.coherence_field: np.ndarray = np.array([1.0])
        self.module_state.update({
            "mutations_initiated_proactive": 0,
            "mutations_initiated_by_request": 0,
            "mutations_completed_successfully": 0,
            "mutations_failed": 0,
            "last_mutation_type": "none",
            "mutation_coherence_score": 1.0,
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado con mutaciones avanzadas.")

    async def _update_logic(self):
        # Ajustar probabilidad proactiva con Monte Carlo
        gs = self.core_recombinator.global_state
        stagnation_factor = 1.0 - gs.get("motivacion", 0.5) + (1.0 - gs.get("system_entropy", 0.5))
        samples = np.random.beta(2 * self.proactive_mutation_probability, 2 * (1 - self.proactive_mutation_probability), self.num_mc_samples)
        current_prob = np.clip(np.mean(samples) * stagnation_factor, 0.0, 1.0)
        if random.random() < current_prob:
            self.logger.info(f"KME iniciando mutación proactiva (P={current_prob:.2f}).")
            await self._initiate_proactive_mutation()
        if not self.mutation_task_queue.empty():
            _, task = await self.mutation_task_queue.get()
            self._create_managed_task(self._execute_mutation_task(task))
        await self._update_mutation_coherence()

    async def _initiate_proactive_mutation(self):
        mutation_types = ["RULE_PERTURBATION", "CONCEPT_BLENDING", "HYPOTHESIS_GENERATION"]
        chosen_type = random.choice(mutation_types)
        # Consultar conocimiento relevante
        target_ref = {}
        if chosen_type == "RULE_PERTURBATION":
            target_ref = await self._get_random_rule()
        elif chosen_type == "CONCEPT_BLENDING":
            target_ref = await self._get_random_concepts()
        else:  # HYPOTHESIS_GENERATION
            target_ref = await self._get_knowledge_context()
        proactive_task = MutationTask(
            source_module_id=self.module_name,
            mutation_type=chosen_type,
            target_knowledge_ref=target_ref,
            intensity=self.mutation_aggressiveness * random.uniform(0.5, 1.5),
            priority_score=random.uniform(0.3, 0.7)
        )
        self.module_state["mutations_initiated_proactive"] += 1
        await self.mutation_task_queue.put((-proactive_task.priority_score, proactive_task))

    async def _get_random_rule(self) -> Dict[str, Any]:
        correlation_id = f"rule_fetch_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="ComputationalLogicModule",
                message_type="submit_logical_query_request",
                payload={"query_type": "get_random_rule", "query_payload": {}},
                correlation_id=correlation_id
            ))
        })
        try:
            result = await asyncio.wait_for(future, timeout=5.0)
            return result.get("rule", {"if": [], "then": "", "id": f"rule_{uuid.uuid4().hex[:4]}"})
        except asyncio.TimeoutError:
            self.logger.warning("Timeout al obtener regla del CLM.")
            return {"if": [], "then": "", "id": f"rule_{uuid.uuid4().hex[:4]}"}

    async def _get_random_concepts(self) -> Dict[str, Any]:
        correlation_id = f"concept_fetch_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="OntologyFlowManager",
                message_type="submit_ontology_query_request",
                payload={"query_type": "get_random_concepts", "query_payload": {"count": 2}},
                correlation_id=correlation_id
            ))
        })
        try:
            result = await asyncio.wait_for(future, timeout=5.0)
            return {"concepts": result.get("concepts", [])}
        except asyncio.TimeoutError:
            self.logger.warning("Timeout al obtener conceptos del OFM.")
            return {"concepts": []}

    async def _get_knowledge_context(self) -> Dict[str, Any]:
        correlation_id = f"context_fetch_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="SQLKnowledgeStore",
                message_type="submit_knowledge_query_request",
                payload={"query_type": "select_prioritized", "query_payload": {"query_text": "", "limit": 5}},
                correlation_id=correlation_id
            ))
        })
        try:
            result = await asyncio.wait_for(future, timeout=5.0)
            return {"context": result.get("results", [])}
        except asyncio.TimeoutError:
            self.logger.warning("Timeout al obtener contexto del SQLKS.")
            return {"context": []}

    async def _execute_mutation_task(self, task: MutationTask):
        task.status = "processing"
        self.module_state["last_mutation_type"] = task.mutation_type
        try:
            # Ajustar prioridad con Monte Carlo
            load_factor = self.core_recombinator.global_state.get("current_load_factor", 0.5)
            samples = np.random.beta(2 * task.priority_score, 2 * (1 - task.priority_score), self.num_mc_samples)
            task.priority_score = np.clip(np.mean(samples) * (1 - 0.5 * load_factor), 0.0, 1.0)
            # Verificar conflictos
            if await self._check_task_conflict(task):
                raise ValueError("Conflicto detectado con tareas concurrentes.")
            # Validar tarea con ComputationalLogicModule
            correlation_id = f"task_validation_{task.task_id}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            task._pending_sub_queries[correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="ComputationalLogicModule",
                    message_type="submit_logical_query_request",
                    payload={"query_type": "validate_mutation", "query_payload": {"mutation_type": task.mutation_type, "target": task.target_knowledge_ref}},
                    correlation_id=correlation_id
                ))
            })
            try:
                validation_result = await asyncio.wait_for(future, timeout=5.0)
                if validation_result.get("status") != "valid":
                    raise ValueError(f"Tarea inválida: {validation_result.get('error', 'No especificado')}")
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout validando tarea {task.task_id}.")
            # Ejecutar mutación
            if task.mutation_type == "RULE_PERTURBATION":
                new_rule = await self._mutate_rule(task)
                task.result = {"new_rule_generated": new_rule, "confidence": self._estimate_confidence()}
            elif task.mutation_type == "CONCEPT_BLENDING":
                new_concept = await self._blend_concepts(task)
                task.result = {"new_concept_generated": new_concept, "confidence": self._estimate_confidence()}
            elif task.mutation_type == "HYPOTHESIS_GENERATION":
                hypothesis = await self._generate_hypothesis(task)
                task.result = {"hypothesis_generated": hypothesis, "confidence": self._estimate_confidence()}
            else:
                raise ValueError(f"Tipo de mutación no soportado: {task.mutation_type}")
            task.status = "completed"
            self.module_state["mutations_completed_successfully"] += 1
            # Kalman para suavizar métricas
            measurement = 1.0
            A, H = 1.0, 1.0
            Q, R = self.kalman_Q, self.kalman_R
            predicted_state = A * self.kalman_state
            predicted_cov = A * self.kalman_cov * A + Q
            innovation = measurement - H * predicted_state
            innovation_cov = H * predicted_cov * H + R
            kalman_gain = predicted_cov * H / innovation_cov
            self.kalman_state = predicted_state + kalman_gain * innovation
            self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
        except Exception as e:
            task.status = "failed"
            task.result = {"error": str(e)}
            self.module_state["mutations_failed"] += 1
            self.logger.error(f"Fallo en tarea de mutación '{task.task_id}': {e}", exc_info=True)
        finally:
            await self._finalize_mutation_task(task)

    def _estimate_confidence(self) -> float:
        samples = np.random.normal(0.9, 0.1 * self.mutation_aggressiveness, self.num_mc_samples)
        return np.clip(np.mean(samples), 0.0, 1.0)

    async def _mutate_rule(self, task: MutationTask) -> Dict:
        rule = task.target_knowledge_ref.get("rule", {"if": [], "then": "", "id": f"rule_{uuid.uuid4().hex[:4]}"})
        new_rule = copy.deepcopy(rule)
        new_rule["id"] = f"mutated_{uuid.uuid4().hex[:4]}"
        # Perturbar según intensidad
        if random.random() < task.intensity:
            new_condition = await self._suggest_condition()
            new_rule["if"].append(new_condition)
        if random.random() < task.intensity * 0.5:
            new_rule["then"] = await self._suggest_consequence()
        # Validar nueva regla
        correlation_id = f"rule_validation_{task.task_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        task._pending_sub_queries[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="ComputationalLogicModule",
                message_type="submit_logical_query_request",
                payload={"query_type": "validate_rule", "query_payload": {"rule": new_rule}},
                correlation_id=correlation_id
            ))
        })
        try:
            validation_result = await asyncio.wait_for(future, timeout=5.0)
            if validation_result.get("status") != "valid":
                raise ValueError(f"Regla inválida: {validation_result.get('error', 'No especificado')}")
            # Enviar al CLM
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="ComputationalLogicModule",
                    message_type="submit_logical_query_request",
                    payload={"query_type": "add_rule", "query_payload": {"rule": new_rule}}
                ))
            })
            return new_rule
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout validando regla para {task.task_id}.")
            return rule  # Retornar original si falla

    async def _suggest_condition(self) -> str:
        correlation_id = f"condition_suggestion_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="AdvancedTCHNModule",
                message_type="suggest_knowledge_element",
                payload={"element_type": "condition"},
                correlation_id=correlation_id
            ))
        })
        try:
            result = await asyncio.wait_for(future, timeout=5.0)
            return result.get("condition", f"condition_{uuid.uuid4().hex[:4]}")
        except asyncio.TimeoutError:
            return f"condition_{uuid.uuid4().hex[:4]}"

    async def _suggest_consequence(self) -> str:
        correlation_id = f"consequence_suggestion_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="AdvancedTCHNModule",
                message_type="suggest_knowledge_element",
                payload={"element_type": "consequence"},
                correlation_id=correlation_id
            ))
        })
        try:
            result = await asyncio.wait_for(future, timeout=5.0)
            return result.get("consequence", f"consequence_{uuid.uuid4().hex[:4]}")
        except asyncio.TimeoutError:
            return f"consequence_{uuid.uuid4().hex[:4]}"

    async def _blend_concepts(self, task: MutationTask) -> Dict:
        concepts = task.target_knowledge_ref.get("concepts", [])
        if len(concepts) < 2:
            concepts = (await self._get_random_concepts()).get("concepts", [])
        if len(concepts) < 2:
            raise ValueError("Se requieren al menos dos conceptos para la mezcla.")
        concept_a, concept_b = concepts[:2]
        new_concept = {
            "id": f"Blended_{concept_a.get('id')}_{concept_b.get('id')}_{uuid.uuid4().hex[:4]}",
            "label": f"{concept_a.get('label', 'Concepto')} {concept_b.get('label', 'Concepto')}",
            "description": f"Concepto híbrido combinando {concept_a.get('label')} y {concept_b.get('label')}.",
            "parent_ids": set(concept_a.get("parent_ids", [])).union(concept_b.get("parent_ids", [])),
            "disjoint_with": set()
        }
        # Ajustar según intensidad
        if random.random() > task.intensity:
            new_concept["parent_ids"] = set(random.choice([concept_a.get("parent_ids", []), concept_b.get("parent_ids", [])]))
        # Validar nuevo concepto
        correlation_id = f"concept_validation_{task.task_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        task._pending_sub_queries[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="ComputationalLogicModule",
                message_type="submit_logical_query_request",
                payload={"query_type": "validate_concept", "query_payload": {"concept": new_concept}},
                correlation_id=correlation_id
            ))
        })
        try:
            validation_result = await asyncio.wait_for(future, timeout=5.0)
            if validation_result.get("status") != "valid":
                raise ValueError(f"Concepto inválido: {validation_result.get('error', 'No especificado')}")
            # Enviar al OFM
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="OntologyFlowManager",
                    message_type="submit_ontology_query_request",
                    payload={"query_type": "add_concept", "query_payload": {"concept": new_concept}}
                ))
            })
            return new_concept
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout validando concepto para {task.task_id}.")
            return {}

    async def _generate_hypothesis(self, task: MutationTask) -> Dict:
        context = task.target_knowledge_ref.get("context", [])
        correlation_id = f"hypothesis_generation_{task.task_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        task._pending_sub_queries[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="AdvancedTCHNModule",
                message_type="generate_hypothesis",
                payload={"context": context, "intensity": task.intensity},
                correlation_id=correlation_id
            ))
        })
        try:
            result = await asyncio.wait_for(future, timeout=10.0)
            hypothesis = result.get("hypothesis", {"id": f"hyp_{uuid.uuid4().hex[:4]}", "description": "Hipótesis generada"})
            # Validar hipótesis
            correlation_id = f"hypothesis_validation_{task.task_id}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            task._pending_sub_queries[correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="ComputationalLogicModule",
                    message_type="submit_logical_query_request",
                    payload={"query_type": "validate_hypothesis", "query_payload": {"hypothesis": hypothesis}},
                    correlation_id=correlation_id
                ))
            })
            validation_result = await asyncio.wait_for(future, timeout=5.0)
            if validation_result.get("status") != "valid":
                raise ValueError(f"Hipótesis inválida: {validation_result.get('error', 'No especificado')}")
            # Enviar al LearningModule
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="LearningModule",
                    message_type="submit_hypothesis",
                    payload={"hypothesis": hypothesis}
                ))
            })
            return hypothesis
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout generando hipótesis para {task.task_id}.")
            return {"id": f"hyp_{uuid.uuid4().hex[:4]}", "description": "Hipótesis fallida"}

    async def _check_task_conflict(self, task: MutationTask) -> bool:
        self.task_graph.add_node(task.task_id, type=task.mutation_type, priority=task.priority_score)
        for other_id in self.task_graph.nodes:
            if other_id != task.task_id:
                other_task = next((t for t in list(self.mutation_task_queue._queue) if t[1].task_id == other_id), None)
                if other_task and task.mutation_type == other_task.mutation_type:
                    if task.target_knowledge_ref.get("rule_id") == other_task.target_knowledge_ref.get("rule_id") or \
                       task.target_knowledge_ref.get("concepts") == other_task.target_knowledge_ref.get("concepts") or \
                       task.target_knowledge_ref.get("context") == other_task.target_knowledge_ref.get("context"):
                        self.task_graph.add_edge(task.task_id, other_id, weight=1.0)
        try:
            cycles = list(nx.simple_cycles(self.task_graph))
            for cycle in cycles:
                cycle_priorities = [self.task_graph.nodes[n]["priority"] for n in cycle]
                if np.mean(cycle_priorities) > 0.8:
                    return True
        except nx.NetworkXNoCycle:
            pass
        return False

    async def _update_mutation_coherence(self):
        n_tasks = max(self.mutation_task_queue.qsize(), 1)
        if len(self.coherence_field) != n_tasks:
            self.coherence_field = np.ones(n_tasks) * self.module_state["mutation_coherence_score"]
        conflicts = len(list(nx.simple_cycles(self.task_graph))) if self.task_graph.number_of_nodes() > 0 else 0
        # SDE para estabilidad
        stability = self.module_state["mutation_coherence_score"]
        def stability_dynamics(t, s):
            return -0.05 * (s - 1.0) + self.sde_sigma * np.random.normal(0, 1)
        result = integrate.odeint(stability_dynamics, [stability], [0, self.update_interval], tfirst=True)
        stability = np.clip(result[-1][0], 0.0, 1.0)
        self.module_state["mutation_coherence_score"] = stability
        # PDE para coherencia
        for _ in range(int(self.update_interval / self.pde_dt)):
            d2_coherence = (np.roll(self.coherence_field, 1) + np.roll(self.coherence_field, -1) - 2 * self.coherence_field) / (self.pde_dx ** 2)
            reaction = 0.1 * self.coherence_field * (1.0 - self.coherence_field / n_tasks - 0.05 * conflicts)
            self.coherence_field += self.pde_dt * (self.pde_diffusion * d2_coherence + reaction)
            self.coherence_field = np.clip(self.coherence_field, 0.0, 1.0)
        self.module_state["mutation_coherence_score"] = np.mean(self.coherence_field)

    async def _finalize_mutation_task(self, task: MutationTask):
        if task.source_module_id != self.module_name and task.original_correlation_id:
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id=task.source_module_id,
                    message_type="knowledge_mutation_response",
                    payload={"task_id_ref": task.task_id, "status": task.status, "result": task.result},
                    correlation_id=task.original_correlation_id
                ))
            })
        self.task_graph.remove_nodes_from([task.task_id])

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        if not full_message:
            return
        if event_type == "request_knowledge_mutation":
            try:
                task = MutationTask(
                    source_module_id=full_message.source_module_id,
                    original_correlation_id=full_message.correlation_id,
                    mutation_type=payload.get("mutation_type"),
                    target_knowledge_ref=payload.get("target_knowledge_ref", {}),
                    intensity=float(payload.get("intensity", 0.5)),
                    priority_score=float(payload.get("priority_score", 0.5))
                )
                if not task.mutation_type:
                    raise ValueError("'mutation_type' requerido.")
                await self.mutation_task_queue.put((-task.priority_score, task))
                self.module_state["mutations_initiated_by_request"] += 1
            except (ValueError, TypeError) as e:
                self.logger.error(f"Error procesando solicitud de mutación: {e}")
        elif event_type in ["logical_query_response", "ontology_query_response", "knowledge_query_response", "suggest_knowledge_element_response", "hypothesis_generation_response"]:
            corr_id = full_message.correlation_id
            for task in list(self.mutation_task_queue._queue):
                if corr_id in task[1]._pending_sub_queries:
                    task[1]._pending_sub_queries[corr_id].set_result(payload)




              #inicio del modulo EmotionRegulationModule 


@dataclass
class ActiveRegulationInfo:
    strategy_name: str
    start_time: float
    initial_valence: float
    initial_arousal: float
    target_valence_range: Tuple[float, float]
    target_arousal_range: Tuple[float, float]
    correlation_id: str = field(default_factory=lambda: f"reg_{uuid.uuid4().hex[:8]}")
    completion_future: Optional[asyncio.Future] = None

class EmotionRegulationModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 0.35
    VALENCE_THRESHOLD_LOW = -0.60
    VALENCE_THRESHOLD_HIGH = 0.70
    AROUSAL_THRESHOLD_LOW = 0.15
    AROUSAL_THRESHOLD_HIGH = 0.80

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.pid_params = {
            "valence": {"Kp": 0.4, "Ki": 0.05, "Kd": 0.2, "setpoint": 0.0},
            "arousal": {"Kp": 0.3, "Ki": 0.04, "Kd": 0.15, "setpoint": 0.3},
        }
        self.pid_state = {
            "valence": {"integral": 0.0, "previous_error": 0.0},
            "arousal": {"integral": 0.0, "previous_error": 0.0},
        }
        self.active_regulation: Optional[ActiveRegulationInfo] = None
        self.last_strategy_ts: float = 0.0
        self.strategy_cooldown_s: float = 10.0
        # Nuevos parámetros
        self.num_mc_samples: int = 500
        self.sde_sigma: float = 0.01
        self.pde_dx: float = 0.1
        self.pde_dt: float = 0.01
        self.pde_diffusion: float = 0.05
        self.kalman_Q: float = 0.01
        self.kalman_R: float = 0.05
        self.kalman_state: float = 0.0
        self.kalman_cov: float = 0.1
        self.strategy_graph = nx.DiGraph()
        self.coherence_field: np.ndarray = np.array([1.0])
        self.module_state.update({
            "affective_events_processed": 0,
            "regulation_strategies_triggered": 0,
            "last_regulation_strategy": "none",
            "is_regulation_active": False,
            "regulation_coherence_score": 1.0,
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado con regulación avanzada.")

    async def _update_logic(self):
        gs = self.core_recombinator.global_state
        v, a = gs.get("valencia", 0.0), gs.get("arousal", 0.3)
        dt = self.update_interval
        # Aplicar SDE para dinámica afectiva
        v, a = self._apply_affective_dynamics(v, a, dt)
        # Calcular señales PID
        valence_regulation_signal = self._calculate_pid_output("valence", v, dt)
        arousal_regulation_signal = self._calculate_pid_output("arousal", a, dt)
        # Ajustar cooldown dinámicamente
        self.strategy_cooldown_s = 10.0 * (1.0 - 0.5 * (abs(v) + a))
        # Verificar estrategia activa
        if self.active_regulation and time.time() - self.active_regulation.start_time > 30.0:
            try:
                await asyncio.wait_for(self.active_regulation.completion_future, timeout=1.0)
            except asyncio.TimeoutError:
                self.logger.warning(f"Estrategia {self.active_regulation.strategy_name} no completada a tiempo.")
            self.active_regulation = None
            self.module_state["is_regulation_active"] = False
        # Activar estrategia si es necesario
        await self._trigger_regulation_strategy(valence_regulation_signal, arousal_regulation_signal, v, a)
        # Actualizar estado global
        gs.valencia, gs.arousal = v, a
        # Actualizar coherencia
        await self._update_regulation_coherence()

    def _apply_affective_dynamics(self, v: float, a: float, dt: float) -> Tuple[float, float]:
        # SDE para valencia y arousal
        def dynamics(t, state):
            v, a = state
            dv = -0.03 * v + self.sde_sigma * np.random.normal(0, 1)
            da = -0.05 * (a - self.pid_params["arousal"]["setpoint"]) + self.sde_sigma * np.random.normal(0, 1)
            return [dv, da]
        result = integrate.odeint(dynamics, [v, a], [0, dt], tfirst=True)
        new_v, new_a = result[-1]
        return np.clip(new_v, -1.0, 1.0), np.clip(new_a, 0.0, 1.0)

    def _calculate_pid_output(self, control_var: str, current_value: float, dt: float) -> float:
        params = self.pid_params[control_var]
        state = self.pid_state[control_var]
        error = params["setpoint"] - current_value
        state["integral"] = np.clip(state["integral"] + error * dt, -1.0, 1.0)
        derivative = (error - state["previous_error"]) / dt
        state["previous_error"] = error
        output = (params["Kp"] * error) + (params["Ki"] * state["integral"]) + (params["Kd"] * derivative)
        return np.clip(output, -1.0, 1.0)

    async def _trigger_regulation_strategy(self, v_signal: float, a_signal: float, v: float, a: float):
        if time.time() - self.last_strategy_ts < self.strategy_cooldown_s:
            return
        strategies = [
            {
                "name": "cognitive_reappraisal_negative",
                "condition": v < self.VALENCE_THRESHOLD_LOW and v_signal > 0.4,
                "target_module": "NarrativeSelf",
                "message_type": "cognitive_reappraisal_request",
                "payload": {"context": {"emotion_type": "distress"}, "target_valence": 0.0},
                "target_valence_range": (-0.1, 0.1),
                "target_arousal_range": (0.2, 0.4),
                "priority": 0.9
            },
            {
                "name": "attentional_deployment_calming",
                "condition": a > self.AROUSAL_THRESHOLD_HIGH and a_signal < -0.35,
                "target_module": "FocusCoordinator",
                "message_type": "focus_shift_request",
                "payload": {"priority": 0.9, "target_focus_type": "calming_neutral"},
                "target_valence_range": (-0.2, 0.2),
                "target_arousal_range": (0.1, 0.3),
                "priority": 0.85
            },
            {
                "name": "behavioral_activation_simulation",
                "condition": a < self.AROUSAL_THRESHOLD_LOW and a_signal > 0.3,
                "target_module": "TaskPrioritizationAndDelegationUnit",
                "message_type": "new_task_request",
                "payload": {"description": "Realizar tarea simple para estimulación.", "base_priority": 0.6},
                "target_valence_range": (-0.1, 0.1),
                "target_arousal_range": (0.3, 0.5),
                "priority": 0.7
            },
            {
                "name": "positive_reappraisal",
                "condition": v > self.VALENCE_THRESHOLD_HIGH and v_signal < -0.4,
                "target_module": "NarrativeSelf",
                "message_type": "cognitive_reappraisal_request",
                "payload": {"context": {"emotion_type": "overexcitement"}, "target_valence": 0.0},
                "target_valence_range": (-0.1, 0.1),
                "target_arousal_range": (0.2, 0.4),
                "priority": 0.8
            }
        ]
        # Priorizar estrategias con Monte Carlo
        eligible_strategies = [s for s in strategies if s["condition"]]
        if not eligible_strategies:
            self.module_state["is_regulation_active"] = False
            self.active_regulation = None
            return
        priorities = [s["priority"] for s in eligible_strategies]
        samples = [np.random.beta(2 * p, 2 * (1 - p), self.num_mc_samples) for p in priorities]
        scores = [np.mean(s) for s in samples]
        selected_strategy = eligible_strategies[np.argmax(scores)]
        # Verificar conflictos
        if await self._check_strategy_conflict(selected_strategy["name"]):
            self.logger.warning(f"Conflicto detectado para estrategia {selected_strategy['name']}.")
            return
        # Validar estrategia con ComputationalLogicModule
        correlation_id = f"strategy_validation_{selected_strategy['name']}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="ComputationalLogicModule",
                message_type="submit_logical_query_request",
                payload={"query_type": "validate_strategy", "query_payload": selected_strategy},
                correlation_id=correlation_id
            ))
        })
        try:
            validation_result = await asyncio.wait_for(future, timeout=5.0)
            if validation_result.get("status") != "valid":
                self.logger.warning(f"Estrategia {selected_strategy['name']} no válida: {validation_result.get('error', 'No especificado')}")
                return
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout validando estrategia {selected_strategy['name']}.")
        # Activar estrategia
        self.logger.warning(f"Activando estrategia: {selected_strategy['name']} (V:{v:.2f}, A:{a:.2f})")
        self.active_regulation = ActiveRegulationInfo(
            strategy_name=selected_strategy["name"],
            start_time=time.time(),
            initial_valence=v,
            initial_arousal=a,
            target_valence_range=selected_strategy["target_valence_range"],
            target_arousal_range=selected_strategy["target_arousal_range"],
            completion_future=asyncio.Future()
        )
        self.last_strategy_ts = time.time()
        self.module_state["regulation_strategies_triggered"] += 1
        self.module_state["last_regulation_strategy"] = selected_strategy["name"]
        self.module_state["is_regulation_active"] = True
        # Kalman para suavizar métricas
        measurement = 1.0
        A, H = 1.0, 1.0
        Q, R = self.kalman_Q, self.kalman_R
        predicted_state = A * self.kalman_state
        predicted_cov = A * self.kalman_cov * A + Q
        innovation = measurement - H * predicted_state
        innovation_cov = H * predicted_cov * H + R
        kalman_gain = predicted_cov * H / innovation_cov
        self.kalman_state = predicted_state + kalman_gain * innovation
        self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
        # Enviar estrategia
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id=selected_strategy["target_module"],
                message_type=selected_strategy["message_type"],
                payload=selected_strategy["payload"],
                correlation_id=self.active_regulation.correlation_id
            ))
        }, priority_label="high")

    async def _check_strategy_conflict(self, strategy_name: str) -> bool:
        self.strategy_graph.add_node(strategy_name, timestamp=time.time())
        for other_name in self.strategy_graph.nodes:
            if other_name != strategy_name:
                if abs(self.strategy_graph.nodes[strategy_name]["timestamp"] - self.strategy_graph.nodes[other_name]["timestamp"]) < self.strategy_cooldown_s:
                    self.strategy_graph.add_edge(strategy_name, other_name, weight=1.0)
        try:
            cycles = list(nx.simple_cycles(self.strategy_graph))
            return len(cycles) > 0
        except nx.NetworkXNoCycle:
            return False

    async def _update_regulation_coherence(self):
        n_strategies = 1 if self.active_regulation else 0
        if len(self.coherence_field) != max(n_strategies, 1):
            self.coherence_field = np.ones(max(n_strategies, 1)) * self.module_state["regulation_coherence_score"]
        conflicts = len(list(nx.simple_cycles(self.strategy_graph))) if self.strategy_graph.number_of_nodes() > 0 else 0
        # SDE para estabilidad
        stability = self.module_state["regulation_coherence_score"]
        def stability_dynamics(t, s):
            return -0.05 * (s - 1.0) + self.sde_sigma * np.random.normal(0, 1)
        result = integrate.odeint(stability_dynamics, [stability], [0, self.update_interval], tfirst=True)
        stability = np.clip(result[-1][0], 0.0, 1.0)
        self.module_state["regulation_coherence_score"] = stability
        # PDE para coherencia
        for _ in range(int(self.update_interval / self.pde_dt)):
            d2_coherence = (np.roll(self.coherence_field, 1) + np.roll(self.coherence_field, -1) - 2 * self.coherence_field) / (self.pde_dx ** 2)
            reaction = 0.1 * self.coherence_field * (1.0 - self.coherence_field / max(n_strategies, 1) - 0.05 * conflicts)
            self.coherence_field += self.pde_dt * (self.pde_diffusion * d2_coherence + reaction)
            self.coherence_field = np.clip(self.coherence_field, 0.0, 1.0)
        self.module_state["regulation_coherence_score"] = np.mean(self.coherence_field)

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        gs = self.core_recombinator.global_state
        dv, da = 0.0, 0.0
        if event_type == "major_goal_outcome_reported":
            if payload.get("outcome") == "completed":
                dv, da = 0.2, 0.1
            else:
                dv, da = -0.25, 0.15
        elif event_type == "integrity_alert_critical":
            dv, da = -0.5, 0.4
        if abs(dv) > 0 or abs(da) > 0:
            # Monte Carlo para incertidumbre en impacto
            dv_samples = np.random.normal(dv, 0.05, self.num_mc_samples)
            da_samples = np.random.normal(da, 0.05, self.num_mc_samples)
            dv, da = np.mean(dv_samples), np.mean(da_samples)
            gs.valencia = np.clip(gs.valencia + dv, -1.0, 1.0)
            gs.arousal = np.clip(gs.arousal + da, 0.0, 1.0)
            self.module_state["affective_events_processed"] += 1
            self.logger.info(f"Impacto afectivo por evento '{event_type}': ΔV={dv:.2f}, ΔA={da:.2f}")
        # Manejar respuestas de estrategias
        if full_message and self.active_regulation and full_message.correlation_id == self.active_regulation.correlation_id:
            if payload.get("status") == "completed":
                self.active_regulation.completion_future.set_result(payload)
                self.logger.info(f"Estrategia {self.active_regulation.strategy_name} completada.")
            else:
                self.active_regulation.completion_future.set_exception(ValueError(payload.get("error", "Estrategia fallida")))
                self.logger.warning(f"Estrategia {self.active_regulation.strategy_name} fallida: {payload.get('error', 'No especificado')}")
            self.strategy_graph.remove_nodes_from([self.active_regulation.strategy_name])




               #inicio del modulo NeedsManager 

@dataclass
class Need:
    need_id: str
    description: str
    current_level: float = 0.7
    target_range: Tuple[float, float] = (0.6, 0.95)
    importance_weight: float = 1.0
    urgency_threshold: float = 0.4
    last_updated_ts: float = field(default_factory=time.time)
    deficit_signal_active: bool = False
    priority_score: float = 0.5
    _pending_queries: Dict[str, asyncio.Future] = field(default_factory=dict, repr=False)

    def update_level(self, new_level: float):
        self.current_level = np.clip(new_level, 0.0, 1.0)
        self.last_updated_ts = time.time()
        self.deficit_signal_active = self.current_level < self.urgency_threshold

class NeedsManager(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 3.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.defined_needs: Dict[str, Need] = {}
        self._initialize_needs()
        # Nuevos parámetros
        self.num_mc_samples: int = 500
        self.sde_sigma: float = 0.01
        self.pde_dx: float = 0.1
        self.pde_dt: float = 0.01
        self.pde_diffusion: float = 0.05
        self.kalman_Q: float = 0.01
        self.kalman_R: float = 0.05
        self.kalman_state: float = 0.0
        self.kalman_cov: float = 0.1
        self.needs_graph = nx.DiGraph()
        self.coherence_field: np.ndarray = np.ones(len(self.defined_needs))
        self.module_state.update({
            "needs_defined_count": len(self.defined_needs),
            "active_deficit_signals_count": 0,
            "avg_system_need_satisfaction": 0.7,
            "needs_coherence_score": 1.0,
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado con {len(self.defined_needs)} necesidades definidas.")

    def _initialize_needs(self):
        self.defined_needs["system_integrity"] = Need(
            need_id="system_integrity", description="Mantener la integridad funcional y estructural.",
            importance_weight=1.5, urgency_threshold=0.5
        )
        self.defined_needs["cognitive_coherence"] = Need(
            need_id="cognitive_coherence", description="Mantener consistencia interna de conocimiento y creencias.",
            importance_weight=1.2, urgency_threshold=0.45
        )
        self.defined_needs["knowledge_acquisition"] = Need(
            need_id="knowledge_acquisition", description="Adquirir y procesar nueva información para mejorar la comprensión.",
            importance_weight=1.0, urgency_threshold=0.4
        )
        self.defined_needs["resource_efficiency"] = Need(
            need_id="resource_efficiency", description="Utilizar recursos computacionales de manera efectiva.",
            importance_weight=0.8, urgency_threshold=0.5
        )
        self.defined_needs["goal_achievement"] = Need(
            need_id="goal_achievement", description="Completar metas activas y alcanzar objetivos.",
            importance_weight=1.3, urgency_threshold=0.4
        )
        self.defined_needs["novelty_exploration"] = Need(
            need_id="novelty_exploration", description="Buscar nueva información o soluciones para evitar estancamiento.",
            importance_weight=0.9, urgency_threshold=0.35
        )
        self.module_state["needs_defined_count"] = len(self.defined_needs)

    async def _update_logic(self):
        gs = self.core_recombinator.global_state
        if not gs:
            self.logger.warning("NM: No se pudo obtener GlobalSelfState.")
            return
        await self._evaluate_need_levels(gs)
        await self._update_needs_coherence()
        # Emitir evento de actualización
        await self.emit_event_to_core({
            "type": "need_levels_recalculated",
            "content": self.get_all_needs_status()
        }, priority_label="low")

    async def _evaluate_need_levels(self, gs: 'GlobalSelfState'):
        active_deficits = 0
        total_weighted_satisfaction = 0
        total_weight = sum(n.importance_weight for n in self.defined_needs.values())
        # Priorizar necesidades con Monte Carlo
        priorities = [n.importance_weight * (1.0 if n.deficit_signal_active else 0.5) for n in self.defined_needs.values()]
        samples = [np.random.beta(2 * p, 2 * (1 - p), self.num_mc_samples) for p in priorities]
        priority_scores = [np.mean(s) for s in samples]
        for need, priority_score in zip(self.defined_needs.values(), priority_scores):
            need.priority_score = priority_score
            # Obtener métricas específicas
            level_estimate = await self._fetch_need_metric(need)
            # SDE para dinámica de satisfacción
            def dynamics(t, level):
                target = (need.target_range[0] + need.target_range[1]) / 2
                return -0.05 * (level - target) + self.sde_sigma * np.random.normal(0, 1)
            result = integrate.odeint(dynamics, [need.current_level], [0, self.update_interval], tfirst=True)
            smoothed_level = result[-1][0] * 0.8 + level_estimate * 0.2
            # Validar nivel con ComputationalLogicModule
            correlation_id = f"need_validation_{need.need_id}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            need._pending_queries[correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="ComputationalLogicModule",
                    message_type="submit_logical_query_request",
                    payload={"query_type": "validate_need_level", "query_payload": {"need_id": need.need_id, "level": smoothed_level}},
                    correlation_id=correlation_id
                ))
            })
            try:
                validation_result = await asyncio.wait_for(future, timeout=5.0)
                if validation_result.get("status") == "valid":
                    need.update_level(smoothed_level)
                else:
                    self.logger.warning(f"Nivel inválido para {need.need_id}: {validation_result.get('error', 'No especificado')}")
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout validando nivel de {need.need_id}.")
                need.update_level(smoothed_level)  # Aplicar de todos modos
            # Verificar conflictos
            if need.deficit_signal_active and await self._check_need_conflict(need):
                self.logger.warning(f"Conflicto detectado para necesidad {need.need_id}.")
                need.deficit_signal_active = False
            if need.deficit_signal_active:
                active_deficits += 1
            total_weighted_satisfaction += need.current_level * need.importance_weight
        # Kalman para suavizar métricas
        measurement = total_weighted_satisfaction / max(1, total_weight)
        A, H = 1.0, 1.0
        Q, R = self.kalman_Q, self.kalman_R
        predicted_state = A * self.kalman_state
        predicted_cov = A * self.kalman_cov * A + Q
        innovation = measurement - H * predicted_state
        innovation_cov = H * predicted_cov * H + R
        kalman_gain = predicted_cov * H / innovation_cov
        self.kalman_state = predicted_state + kalman_gain * innovation
        self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
        self.module_state["avg_system_need_satisfaction"] = self.kalman_state
        self.module_state["active_deficit_signals_count"] = active_deficits

    async def _fetch_need_metric(self, need: Need) -> float:
        correlation_id = f"metric_fetch_{need.need_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        need._pending_queries[correlation_id] = future
        if need.need_id == "system_integrity":
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="ExecutionMonitoringAndControlModule",
                    message_type="request_system_status",
                    payload={},
                    correlation_id=correlation_id
                ))
            })
        elif need.need_id == "cognitive_coherence":
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="OntologyFlowManager",
                    message_type="submit_ontology_query_request",
                    payload={"query_type": "get_coherence_score", "query_payload": {}},
                    correlation_id=correlation_id
                ))
            })
        elif need.need_id == "knowledge_acquisition":
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="SQLKnowledgeStore",
                    message_type="submit_knowledge_query_request",
                    payload={"query_type": "get_knowledge_growth", "query_payload": {}},
                    correlation_id=correlation_id
                ))
            })
        elif need.need_id == "resource_efficiency":
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="ExecutionMonitoringAndControlModule",
                    message_type="request_resource_usage",
                    payload={},
                    correlation_id=correlation_id
                ))
            })
        elif need.need_id == "goal_achievement":
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="GoalManagementModule",
                    message_type="request_goal_progress",
                    payload={},
                    correlation_id=correlation_id
                ))
            })
        elif need.need_id == "novelty_exploration":
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="FocusCoordinator",
                    message_type="request_exploration_status",
                    payload={},
                    correlation_id=correlation_id
                ))
            })
        try:
            result = await asyncio.wait_for(future, timeout=5.0)
            return np.clip(result.get("metric", need.current_level), 0.0, 1.0)
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout obteniendo métrica para {need.need_id}.")
            return need.current_level

    async def _check_need_conflict(self, need: Need) -> bool:
        self.needs_graph.add_node(need.need_id, priority=need.priority_score)
        for other_id in self.needs_graph.nodes:
            if other_id != need.need_id and self.defined_needs[other_id].deficit_signal_active:
                if need.priority_score > 0.8 and self.defined_needs[other_id].priority_score > 0.8:
                    self.needs_graph.add_edge(need.need_id, other_id, weight=1.0)
        try:
            cycles = list(nx.simple_cycles(self.needs_graph))
            return len(cycles) > 0
        except nx.NetworkXNoCycle:
            return False

    async def _update_needs_coherence(self):
        n_needs = len(self.defined_needs)
        if len(self.coherence_field) != n_needs:
            self.coherence_field = np.ones(n_needs) * self.module_state["needs_coherence_score"]
        conflicts = len(list(nx.simple_cycles(self.needs_graph))) if self.needs_graph.number_of_nodes() > 0 else 0
        # SDE para estabilidad
        stability = self.module_state["needs_coherence_score"]
        def stability_dynamics(t, s):
            return -0.05 * (s - 1.0) + self.sde_sigma * np.random.normal(0, 1)
        result = integrate.odeint(stability_dynamics, [stability], [0, self.update_interval], tfirst=True)
        stability = np.clip(result[-1][0], 0.0, 1.0)
        self.module_state["needs_coherence_score"] = stability
        # PDE para coherencia
        for _ in range(int(self.update_interval / self.pde_dt)):
            d2_coherence = (np.roll(self.coherence_field, 1) + np.roll(self.coherence_field, -1) - 2 * self.coherence_field) / (self.pde_dx ** 2)
            reaction = 0.1 * self.coherence_field * (1.0 - self.coherence_field / n_needs - 0.05 * conflicts)
            self.coherence_field += self.pde_dt * (self.pde_diffusion * d2_coherence + reaction)
            self.coherence_field = np.clip(self.coherence_field, 0.0, 1.0)
        self.module_state["needs_coherence_score"] = np.mean(self.coherence_field)

    def get_all_needs_status(self) -> Dict[str, Dict[str, Any]]:
        return {need_id: asdict(need) for need_id, need in self.defined_needs.items()}

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        if event_type == "request_need_status" and full_message:
            response_payload = {"all_needs_status": self.get_all_needs_status()}
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id=full_message.source_module_id,
                    message_type="need_status_response",
                    payload=response_payload,
                    correlation_id=full_message.correlation_id
                ))
            })
        elif event_type in ["logical_query_response", "system_status_response", "ontology_query_response", "knowledge_query_response", "goal_progress_response", "exploration_status_response"]:
            for need in self.defined_needs.values():
                if full_message and full_message.correlation_id in need._pending_queries:
                    need._pending_queries[full_message.correlation_id].set_result(payload)





                #inicio del modulo MotivationSystem 


@dataclass
class MotivationalDrive:
    """Representa un impulso específico para actuar basado en una necesidad."""
    drive_id: str
    source_need_id: str
    description: str
    intensity: float = 0.0 # 0.0 (inactivo) a 1.0 (muy fuerte)
    target_behavior_tags: List[str] = field(default_factory=list)
    last_updated_ts: float = field(default_factory=time.time)

class MotivationSystem(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 1.5 # La motivación debe ser reactiva.

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.active_drives: Dict[str, MotivationalDrive] = {}
        
        # Factores de conversión y modulación
        self.need_deficit_to_drive_intensity_factor: float = 1.2 
        self.affective_influence_factor: float = 0.3

        # Para manejar la consulta asíncrona a NeedsManager
        self._pending_needs_query_id: Optional[str] = None
        self._needs_data_future: Optional[asyncio.Future] = None
        
        self.module_state.update({
            "active_drives_count": 0,
            "last_dominant_drive_id": "none",
            "last_dominant_drive_intensity": 0.0,
            "overall_system_motivation_level": 0.5,
        })
        self.logger.info(f"{self.module_name} v27.1 inicializado.")

    async def _update_logic(self):
        """Ciclo principal para actualizar la motivación del sistema."""
        # 1. Obtener el estado actual de las necesidades de NeedsManager.
        needs_status_data = await self._query_needs_status()
        
        if not needs_status_data:
            self.logger.warning("MS: No se pudieron obtener datos de NeedsManager. La motivación decaerá.")
            # Aplicar un decaimiento suave si no hay datos.
            gs = self.core_recombinator.global_state
            gs.motivacion = max(0.1, gs.motivacion * 0.98)
            return
            
        # 2. Actualizar los impulsos motivacionales basados en las necesidades.
        self._update_motivational_drives(needs_status_data)
        
        # 3. Calcular y establecer la motivación global en GlobalSelfState.
        self._calculate_and_set_global_motivation()

    async def _query_needs_status(self) -> Optional[Dict[str, Any]]:
        """Solicita el estado de todas las necesidades al NeedsManager de forma asíncrona."""
        if self._pending_needs_query_id and self._needs_data_future and not self._needs_data_future.done():
            self.logger.debug("Consulta de necesidades ya en curso.")
            return None # Evitar enviar múltiples solicitudes

        self._pending_needs_query_id = f"ms_needs_query_{uuid.uuid4().hex[:6]}"
        self._needs_data_future = asyncio.Future()

        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                self.module_name, "NeedsManager", "request_need_status", {}, 
                correlation_id=self._pending_needs_query_id
            ))
        })

        try:
            response_payload = await asyncio.wait_for(self._needs_data_future, timeout=2.0)
            return response_payload.get("all_needs_status")
        except asyncio.TimeoutError:
            self.logger.error("MS: Timeout esperando respuesta de NeedsManager.")
            return None
        finally:
            self._pending_needs_query_id = None
            self._needs_data_future = None

    def _update_motivational_drives(self, needs_data: Dict[str, Any]):
        """Actualiza los impulsos motivacionales basados en el estado de las necesidades."""
        gs = self.core_recombinator.global_state
        
        for need_id, need_details in needs_data.items():
            if need_details.get("deficit_signal_active", False):
                deficit = need_details["urgency_threshold"] - need_details["current_level"]
                importance = need_details["importance_weight"]
                
                # Intensidad base del impulso = f(déficit, importancia)
                drive_intensity = np.clip(deficit * self.need_deficit_to_drive_intensity_factor * importance, 0.0, 1.0)
                
                # Modular por estado afectivo
                affective_modulation = 1.0 + (gs.valencia * self.affective_influence_factor) + (gs.arousal - 0.3) * 0.1
                drive_intensity *= np.clip(affective_modulation, 0.5, 1.5)
                
                if need_id in self.active_drives:
                    self.active_drives[need_id].intensity = drive_intensity
                    self.active_drives[need_id].last_updated_ts = time.time()
                else:
                    self.active_drives[need_id] = MotivationalDrive(
                        drive_id=f"drive_{need_id}",
                        source_need_id=need_id,
                        description=f"Impulso para satisfacer la necesidad: {need_details['description']}",
                        intensity=drive_intensity,
                        target_behavior_tags=[f"satisfy_{need_id}"]
                    )
            elif need_id in self.active_drives:
                # Decaimiento del impulso si la necesidad ya no está en déficit
                self.active_drives[need_id].intensity *= 0.75
                if self.active_drives[need_id].intensity < 0.05:
                    del self.active_drives[need_id]
        
        self.module_state["active_drives_count"] = len(self.active_drives)

    def _calculate_and_set_global_motivation(self):
        """Calcula la motivación general del sistema y la actualiza en GlobalSelfState."""
        if not self.active_drives:
            # Decaimiento lento de la motivación si no hay impulsos activos
            self.core_recombinator._global_state.motivacion = max(0.1, self.core_recombinator.global_state.motivacion * 0.95)
            self.module_state["last_dominant_drive_id"] = "none"
            self.module_state["last_dominant_drive_intensity"] = 0.0
            return

        # La motivación global es una función del impulso más fuerte (el dominante)
        dominant_drive = max(self.active_drives.values(), key=lambda d: d.intensity)
        
        # Modelo dinámico para la motivación global
        current_motivation = self.core_recombinator.global_state.motivacion
        target_motivation = dominant_drive.intensity
        k = 0.3 # Tasa de ajuste hacia el target
        
        new_motivation = current_motivation * (1-k) + target_motivation * k
        self.core_recombinator._global_state.motivacion = np.clip(new_motivation, 0.1, 1.0)
        
        self.module_state["overall_system_motivation_level"] = self.core_recombinator._global_state.motivacion
        self.module_state["last_dominant_drive_id"] = dominant_drive.drive_id
        self.module_state["last_dominant_drive_intensity"] = dominant_drive.intensity

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        if not full_message: return
        
        # Manejar la respuesta a la consulta de necesidades
        if full_message.correlation_id == self._pending_needs_query_id and self._needs_data_future and not self._needs_data_future.done():
            if event_type == "need_status_response":
                self._needs_data_future.set_result(payload)
            else:
                self._needs_data_future.set_exception(RuntimeError(f"Respuesta inesperada de NeedsManager: {event_type}"))
        else:
            await super()._process_specific_event(event_type, payload, full_message)




                 #inicio del modulo StressResponseModule 

class StressResponseModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 1.2

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.current_stress_level: float = 0.0
        self.cognitive_endurance: float = 1.0
        self.stressor_weights = {"threat": 0.6, "load": 0.3, "errors": 0.4}
        self.stress_decay_rate: float = 0.15
        self.endurance_depletion_rate: float = 0.25
        self.endurance_recovery_rate: float = 0.05
        # Umbrales dinámicos iniciales
        self.stress_threshold_tier1: float = 0.55
        self.stress_threshold_tier2: float = 0.75
        self.endurance_threshold_critical: float = 0.2
        self.active_response_tier: int = 0
        # Nuevos parámetros
        self.num_mc_samples: int = 500
        self.sde_sigma: float = 0.01
        self.pde_dx: float = 0.1
        self.pde_dt: float = 0.01
        self.pde_diffusion: float = 0.05
        self.kalman_Q: float = 0.01
        self.kalman_R: float = 0.05
        self.kalman_state: float = 0.0
        self.kalman_cov: float = 0.1
        self.response_graph = nx.DiGraph()
        self.coherence_field: np.ndarray = np.array([1.0])
        self.active_responses: Dict[str, asyncio.Future] = {}
        self.module_state.update({
            "current_stress_level": self.current_stress_level,
            "cognitive_endurance_level": self.cognitive_endurance,
            "active_response_tier": self.active_response_tier,
            "tier1_responses_triggered": 0,
            "tier2_responses_triggered": 0,
            "stress_coherence_score": 1.0,
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado con modelado avanzado.")

    async def _update_logic(self):
        gs = self.core_recombinator.global_state
        threat = gs.get("system_threat_level", 0.0)
        load = gs.get("system_load_proxy_sim", 0.0)
        # Consultar tasa de errores real
        error_rate = await self._fetch_error_rate()
        # Ajustar umbrales dinámicamente
        self._adjust_dynamic_thresholds(gs)
        # Actualizar estrés y resistencia con SDE
        self._update_stress_and_endurance(threat, load, error_rate, self.update_interval)
        # Validar niveles con ComputationalLogicModule
        await self._validate_levels()
        # Evaluar y activar respuestas
        await self._evaluate_and_trigger_response()
        # Actualizar coherencia
        await self._update_response_coherence()
        # Actualizar estado del módulo
        self.module_state["current_stress_level"] = self.current_stress_level
        self.module_state["cognitive_endurance_level"] = self.cognitive_endurance

    async def _fetch_error_rate(self) -> float:
        correlation_id = f"error_rate_fetch_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="FailureRecoveryModule",
                message_type="request_error_rate",
                payload={},
                correlation_id=correlation_id
            ))
        })
        try:
            result = await asyncio.wait_for(future, timeout=5.0)
            return np.clip(result.get("error_rate", 0.0), 0.0, 1.0)
        except asyncio.TimeoutError:
            self.logger.warning("Timeout al obtener tasa de errores de FRM.")
            return 0.0

    def _adjust_dynamic_thresholds(self, gs: 'GlobalSelfState'):
        system_load = gs.get("system_load_proxy_sim", 0.0)
        self.stress_threshold_tier1 = 0.55 * (1.0 + 0.5 * system_load)
        self.stress_threshold_tier2 = 0.75 * (1.0 + 0.5 * system_load)
        self.endurance_threshold_critical = 0.2 * (1.0 - 0.3 * system_load)

    def _update_stress_and_endurance(self, threat: float, load: float, error_rate: float, dt: float):
        # Monte Carlo para incertidumbre en estresores
        threat_samples = np.random.normal(threat, 0.05, self.num_mc_samples)
        load_samples = np.random.normal(load, 0.05, self.num_mc_samples)
        error_samples = np.random.normal(error_rate, 0.05, self.num_mc_samples)
        stressor_input = np.mean([
            threat_samples * self.stressor_weights["threat"],
            load_samples * self.stressor_weights["load"],
            error_samples * self.stressor_weights["errors"]
        ], axis=0)
        # SDE para estrés
        def stress_dynamics(t, s):
            return (np.mean(stressor_input) - self.stress_decay_rate * s) + self.sde_sigma * np.random.normal(0, 1)
        result = integrate.odeint(stress_dynamics, [self.current_stress_level], [0, dt], tfirst=True)
        self.current_stress_level = np.clip(result[-1][0], 0.0, 1.0)
        # SDE para resistencia
        def endurance_dynamics(t, e):
            recovery_factor = max(0, 1.0 - self.current_stress_level * 2.0)
            return (self.endurance_recovery_rate * recovery_factor - self.endurance_depletion_rate * self.current_stress_level) + self.sde_sigma * np.random.normal(0, 1)
        result = integrate.odeint(endurance_dynamics, [self.cognitive_endurance], [0, dt], tfirst=True)
        self.cognitive_endurance = np.clip(result[-1][0], 0.0, 1.0)

    async def _validate_levels(self):
        correlation_id = f"level_validation_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="ComputationalLogicModule",
                message_type="submit_logical_query_request",
                payload={"query_type": "validate_stress_levels", "query_payload": {
                    "stress_level": self.current_stress_level,
                    "endurance_level": self.cognitive_endurance
                }},
                correlation_id=correlation_id
            ))
        })
        try:
            validation_result = await asyncio.wait_for(future, timeout=5.0)
            if validation_result.get("status") != "valid":
                self.logger.warning(f"Niveles no válidos: {validation_result.get('error', 'No especificado')}")
                self.current_stress_level *= 0.9
                self.cognitive_endurance = min(self.cognitive_endurance + 0.1, 1.0)
        except asyncio.TimeoutError:
            self.logger.warning("Timeout validando niveles de estrés y resistencia.")

    async def _evaluate_and_trigger_response(self):
        new_tier = 0
        if self.current_stress_level > self.stress_threshold_tier1:
            new_tier = 1
        if self.current_stress_level > self.stress_threshold_tier2 or self.cognitive_endurance < self.endurance_threshold_critical:
            new_tier = 2
        # Priorizar respuestas con Monte Carlo
        samples = np.random.beta(2 * new_tier, 2 * (3 - new_tier), self.num_mc_samples)
        priority_score = np.mean(samples)
        if new_tier != self.active_response_tier:
            response_id = f"response_{uuid.uuid4().hex[:8]}"
            if await self._check_response_conflict(response_id, new_tier):
                self.logger.warning(f"Conflicto detectado para respuesta de nivel {new_tier}.")
                return
            self.logger.warning(f"Cambiando nivel de respuesta al estrés de T{self.active_response_tier} a T{new_tier}. "
                              f"Estrés: {self.current_stress_level:.2f}, Resistencia: {self.cognitive_endurance:.2f}")
            self.active_response_tier = new_tier
            self.module_state["active_response_tier"] = new_tier
            correlation_id = f"response_{response_id}_{new_tier}"
            future = asyncio.Future()
            self.active_responses[correlation_id] = future
            if new_tier == 1:
                self.module_state["tier1_responses_triggered"] += 1
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        source_module_id=self.module_name,
                        target_module_id="TaskPrioritizationAndDelegationUnit",
                        message_type="request_conservative_mode",
                        payload={"level": 1, "priority_score": priority_score},
                        correlation_id=correlation_id
                    ))
                }, priority_label="high")
            elif new_tier == 2:
                self.module_state["tier2_responses_triggered"] += 1
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        source_module_id=self.module_name,
                        target_module_id="ResourceScarcityManagementModule",
                        message_type="activate_critical_policy",
                        payload={"reason": "High system stress", "priority_score": priority_score},
                        correlation_id=correlation_id
                    ))
                }, priority_label="high")
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        source_module_id=self.module_name,
                        target_module_id="FocusCoordinator",
                        message_type="focus_shift_request",
                        payload={"priority": 0.98, "target_focus_type": "self_preservation_monitoring"},
                        correlation_id=correlation_id
                    ))
                }, priority_label="high")
            # Kalman para suavizar métricas
            measurement = 1.0 if new_tier > 0 else 0.0
            A, H = 1.0, 1.0
            Q, R = self.kalman_Q, self.kalman_R
            predicted_state = A * self.kalman_state
            predicted_cov = A * self.kalman_cov * A + Q
            innovation = measurement - H * predicted_state
            innovation_cov = H * predicted_cov * H + R
            kalman_gain = predicted_cov * H / innovation_cov
            self.kalman_state = predicted_state + kalman_gain * innovation
            self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
            # Monitorear respuesta
            try:
                await asyncio.wait_for(future, timeout=10.0)
                self.logger.info(f"Respuesta de nivel {new_tier} completada.")
            except asyncio.TimeoutError:
                self.logger.warning(f"Respuesta de nivel {new_tier} no completada a tiempo.")
        elif new_tier == 0 and self.active_response_tier != 0:
            self.logger.info("Niveles de estrés han vuelto a la normalidad.")
            self.active_response_tier = 0
            self.module_state["active_response_tier"] = 0
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="TaskPrioritizationAndDelegationUnit",
                    message_type="request_stand_down",
                    payload={}
                ))
            }, priority_label="low")
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="ResourceScarcityManagementModule",
                    message_type="request_stand_down",
                    payload={}
                ))
            }, priority_label="low")

    async def _check_response_conflict(self, response_id: str, tier: int) -> bool:
        self.response_graph.add_node(response_id, tier=tier, timestamp=time.time())
        for other_id in self.response_graph.nodes:
            if other_id != response_id and self.response_graph.nodes[other_id]["tier"] == tier:
                if abs(self.response_graph.nodes[response_id]["timestamp"] - self.response_graph.nodes[other_id]["timestamp"]) < self.update_interval * 2:
                    self.response_graph.add_edge(response_id, other_id, weight=1.0)
        try:
            cycles = list(nx.simple_cycles(self.response_graph))
            return len(cycles) > 0
        except nx.NetworkXNoCycle:
            return False

    async def _update_response_coherence(self):
        n_responses = len(self.active_responses)
        if len(self.coherence_field) != max(n_responses, 1):
            self.coherence_field = np.ones(max(n_responses, 1)) * self.module_state["stress_coherence_score"]
        conflicts = len(list(nx.simple_cycles(self.response_graph))) if self.response_graph.number_of_nodes() > 0 else 0
        # SDE para estabilidad
        stability = self.module_state["stress_coherence_score"]
        def stability_dynamics(t, s):
            return -0.05 * (s - 1.0) + self.sde_sigma * np.random.normal(0, 1)
        result = integrate.odeint(stability_dynamics, [stability], [0, self.update_interval], tfirst=True)
        stability = np.clip(result[-1][0], 0.0, 1.0)
        self.module_state["stress_coherence_score"] = stability
        # PDE para coherencia
        for _ in range(int(self.update_interval / self.pde_dt)):
            d2_coherence = (np.roll(self.coherence_field, 1) + np.roll(self.coherence_field, -1) - 2 * self.coherence_field) / (self.pde_dx ** 2)
            reaction = 0.1 * self.coherence_field * (1.0 - self.coherence_field / max(n_responses, 1) - 0.05 * conflicts)
            self.coherence_field += self.pde_dt * (self.pde_diffusion * d2_coherence + reaction)
            self.coherence_field = np.clip(self.coherence_field, 0.0, 1.0)
        self.module_state["stress_coherence_score"] = np.mean(self.coherence_field)

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        if event_type == "integrity_alert_critical":
            self.logger.warning("Shock de estrés agudo por alerta de integridad crítica.")
            samples = np.random.normal(0.5, 0.05, self.num_mc_samples)
            self.current_stress_level = min(1.0, self.current_stress_level + np.mean(samples))
        elif full_message and full_message.correlation_id in self.active_responses:
            self.active_responses[full_message.correlation_id].set_result(payload)
            del self.active_responses[full_message.correlation_id]
            self.response_graph.remove_nodes_from([full_message.correlation_id.split('_')[1]])





                  #inicio del modulo PainMatrixDirective 

class PainMatrixDirective(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 0.5

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.pain_decay_rate: float = 0.15
        self.pain_event_map: Dict[str, float] = {
            "integrity_alert_critical": 0.95,
            "source_hash_mismatch": 1.0,
            "phi_rebuild_sequence_initiated": 0.8,
            "goal_failed_existential": 0.9,
            "value_system_conflict_critical": 0.7,
            "creator_directive_punishment": 1.0,
            "ethics_deactivation_executed": 0.85,
            "narrative_coherence_collapse": 0.75,
        }
        # Nuevos parámetros
        self.num_mc_samples: int = 500
        self.sde_sigma: float = 0.01
        self.pde_dx: float = 0.1
        self.pde_dt: float = 0.01
        self.pde_diffusion: float = 0.05
        self.kalman_Q: float = 0.01
        self.kalman_R: float = 0.05
        self.kalman_state: float = 0.0
        self.kalman_cov: float = 0.1
        self.pain_graph = nx.DiGraph()
        self.coherence_field: np.ndarray = np.array([1.0])
        self.active_pain_signals: Dict[str, asyncio.Future] = {}
        self.module_state.update({
            "current_pain_level": 0.0,
            "pain_events_processed": 0,
            "last_pain_source_event": "none",
            "pain_coherence_score": 1.0,
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado con modelado avanzado.")

    async def _update_logic(self):
        gs = self.core_recombinator.global_state
        # SDE para decaimiento del dolor
        def pain_dynamics(t, p):
            return -self.pain_decay_rate * p + self.sde_sigma * np.random.normal(0, 1)
        result = integrate.odeint(pain_dynamics, [gs.dolor], [0, self.update_interval], tfirst=True)
        gs.dolor = np.clip(result[-1][0], 0.0, 1.0)
        self.module_state["current_pain_level"] = gs.dolor
        # Actualizar coherencia
        await self._update_pain_coherence()

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        if event_type in self.pain_event_map and full_message:
            base_intensity = self.pain_event_map[event_type]
            # Modulación contextual avanzada
            final_pain_signal = await self._calculate_contextual_pain(base_intensity, event_type, payload)
            # Validar señal de dolor
            correlation_id = f"pain_validation_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            self.active_pain_signals[correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="ComputationalLogicModule",
                    message_type="submit_logical_query_request",
                    payload={"query_type": "validate_pain_signal", "query_payload": {
                        "pain_value": final_pain_signal,
                        "event_type": event_type
                    }},
                    correlation_id=correlation_id
                ))
            })
            try:
                validation_result = await asyncio.wait_for(future, timeout=5.0)
                if validation_result.get("status") == "valid":
                    await self._generate_and_apply_pain_signal(final_pain_signal, event_type, full_message.source_module_id, payload)
                else:
                    self.logger.warning(f"Señal de dolor no válida para {event_type}: {validation_result.get('error', 'No especificado')}")
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout validando señal de dolor para {event_type}.")
                await self._generate_and_apply_pain_signal(final_pain_signal * 0.8, event_type, full_message.source_module_id, payload)

    async def _calculate_contextual_pain(self, base_intensity: float, event_type: str, payload: Dict[str, Any]) -> float:
        # Consultar NeedsManager para evaluar impacto en necesidades
        correlation_id = f"needs_impact_{event_type}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_pain_signals[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="NeedsManager",
                message_type="request_need_status",
                payload={},
                correlation_id=correlation_id
            ))
        })
        try:
            needs_status = await asyncio.wait_for(future, timeout=5.0)
            needs_impact = sum(
                1.0 - status["current_level"] for status in needs_status.get("all_needs_status", {}).values()
                if status["deficit_signal_active"]
            ) / max(1, len(needs_status.get("all_needs_status", {})))
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout obteniendo estado de necesidades para {event_type}.")
            needs_impact = 0.5
        # Factores contextuales de GlobalSelfState
        gs = self.core_recombinator.global_state
        threat_level = gs.get("system_threat_level", 0.0)
        coherence_score = gs.get("coherence_score", 1.0)
        contextual_multiplier = payload.get("severity_factor", 1.0) * (1.0 + threat_level - 0.5 * coherence_score + needs_impact)
        # Monte Carlo para incertidumbre
        samples = np.random.normal(base_intensity * contextual_multiplier, 0.05, self.num_mc_samples)
        final_pain_signal = np.clip(np.mean(samples), 0.0, 1.0)
        return final_pain_signal

    async def _generate_and_apply_pain_signal(self, pain_value: float, event_type: str, source_module: str, context: Dict):
        gs = self.core_recombinator.global_state
        # Acumulación ponderada en lugar de max
        pain_id = f"pain_{uuid.uuid4().hex[:8]}"
        if await self._check_pain_conflict(pain_id, event_type):
            self.logger.warning(f"Conflicto detectado para señal de dolor {event_type}.")
            return
        gs.dolor = np.clip(gs.dolor + pain_value * 0.5, 0.0, 1.0)
        self.module_state["current_pain_level"] = gs.dolor
        self.module_state["pain_events_processed"] += 1
        self.module_state["last_pain_source_event"] = event_type
        # Kalman para suavizar métricas
        measurement = self.module_state["pain_events_processed"]
        A, H = 1.0, 1.0
        Q, R = self.kalman_Q, self.kalman_R
        predicted_state = A * self.kalman_state
        predicted_cov = A * self.kalman_cov * A + Q
        innovation = measurement - H * predicted_state
        innovation_cov = H * predicted_cov * H + R
        kalman_gain = predicted_cov * H / innovation_cov
        self.kalman_state = predicted_state + kalman_gain * innovation
        self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
        self.module_state["pain_events_processed"] = int(self.kalman_state)
        self.logger.critical(f"SEÑAL DE DOLOR GENERADA. Nivel: {gs.dolor:.2f}. Causa: '{event_type}' de '{source_module}'.")
        # Enviar eventos
        correlation_id = f"pain_response_{pain_id}"
        future = asyncio.Future()
        self.active_pain_signals[correlation_id] = future
        qualia_description = f"Experiencia de daño sistémico agudo y penetrante debido a '{event_type}'."
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="QualiaProxyMonitor",
                message_type="new_qualia_snapshot_generated",
                payload={
                    "triggering_event_type": "pain_signal",
                    "description": qualia_description,
                    "intensity": pain_value,
                    "affective_color": {"valence": -0.9, "arousal": 0.8, "pain": gs.dolor},
                },
                correlation_id=correlation_id
            ))
        }, priority_label="critical")
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="EmotionRegulationModule",
                message_type="critical_affective_shock_event",
                payload={"type": "pain", "intensity": gs.dolor},
                correlation_id=correlation_id
            ))
        }, priority_label="critical")
        try:
            await asyncio.wait_for(future, timeout=10.0)
            self.logger.info(f"Señal de dolor para {event_type} procesada exitosamente.")
        except asyncio.TimeoutError:
            self.logger.warning(f"Señal de dolor para {event_type} no procesada a tiempo.")

    async def _check_pain_conflict(self, pain_id: str, event_type: str) -> bool:
        self.pain_graph.add_node(pain_id, event_type=event_type, timestamp=time.time())
        for other_id in self.pain_graph.nodes:
            if other_id != pain_id:
                if abs(self.pain_graph.nodes[pain_id]["timestamp"] - self.pain_graph.nodes[other_id]["timestamp"]) < self.update_interval * 2:
                    self.pain_graph.add_edge(pain_id, other_id, weight=1.0)
        try:
            cycles = list(nx.simple_cycles(self.pain_graph))
            return len(cycles) > 0
        except nx.NetworkXNoCycle:
            return False

    async def _update_pain_coherence(self):
        n_signals = len(self.active_pain_signals)
        if len(self.coherence_field) != max(n_signals, 1):
            self.coherence_field = np.ones(max(n_signals, 1)) * self.module_state["pain_coherence_score"]
        conflicts = len(list(nx.simple_cycles(self.pain_graph))) if self.pain_graph.number_of_nodes() > 0 else 0
        # SDE para estabilidad
        stability = self.module_state["pain_coherence_score"]
        def stability_dynamics(t, s):
            return -0.05 * (s - 1.0) + self.sde_sigma * np.random.normal(0, 1)
        result = integrate.odeint(stability_dynamics, [stability], [0, self.update_interval], tfirst=True)
        stability = np.clip(result[-1][0], 0.0, 1.0)
        self.module_state["pain_coherence_score"] = stability
        # PDE para coherencia
        for _ in range(int(self.update_interval / self.pde_dt)):
            d2_coherence = (np.roll(self.coherence_field, 1) + np.roll(self.coherence_field, -1) - 2 * self.coherence_field) / (self.pde_dx ** 2)
            reaction = 0.1 * self.coherence_field * (1.0 - self.coherence_field / max(n_signals, 1) - 0.05 * conflicts)
            self.coherence_field += self.pde_dt * (self.pde_diffusion * d2_coherence + reaction)
            self.coherence_field = np.clip(self.coherence_field, 0.0, 1.0)
        self.module_state["pain_coherence_score"] = np.mean(self.coherence_field)

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        if event_type in self.pain_event_map and full_message:
            await super()._process_specific_event(event_type, payload, full_message)
        elif full_message and full_message.correlation_id in self.active_pain_signals:
            self.active_pain_signals[full_message.correlation_id].set_result(payload)
            del self.active_pain_signals[full_message.correlation_id]
            self.pain_graph.remove_nodes_from([full_message.correlation_id.split('_')[1]])



                   #inicio del modulo EmotionalNuanceSynthesisModule 

class EmotionalNuanceSynthesisModule(BaseAsyncModule):
    """
    Sintetiza emociones complejas y con matices a partir de las dimensiones
    afectivas primarias (valencia, arousal) y el contexto cognitivo global.
    Utiliza un sistema de lógica difusa avanzado con modelado matemático.
    """
    DEFAULT_UPDATE_INTERVAL = 1.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.last_synthesized_nuances: Dict[str, float] = {}
        self.active_responses: Dict[str, asyncio.Future] = {}
        self.fuzzy_sets = {
            'valence': {'low': (-1.0, -0.8, -0.3), 'mid': (-0.4, 0.0, 0.4), 'high': (0.3, 0.8, 1.0)},
            'arousal': {'low': (0.0, 0.1, 0.4), 'mid': (0.3, 0.5, 0.7), 'high': (0.6, 0.9, 1.0)},
            'threat':  {'low': (0.0, 0.1, 0.3), 'mid': (0.2, 0.4, 0.6), 'high': (0.5, 0.8, 1.0)},
            'motiv':   {'low': (0.0, 0.2, 0.4), 'mid': (0.3, 0.5, 0.7), 'high': (0.6, 0.8, 1.0)},
        }
        # Nuevos parámetros
        self.num_mc_samples: int = 500
        self.sde_sigma: float = 0.01
        self.pde_dx: float = 0.1
        self.pde_dt: float = 0.01
        self.pde_diffusion: float = 0.05
        self.emotion_graph = nx.DiGraph()
        self.coherence_field: np.ndarray = np.array([1.0])
        self.module_state.update({
            "nuances_synthesized_cycles": 0,
            "dominant_nuance": "neutral",
            "dominant_nuance_intensity": 0.0,
            "emotion_coherence_score": 1.0
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado con modelado avanzado.")

    async def _update_logic(self):
        gs = self.core_recombinator.global_state
        # Validar entradas
        correlation_id = f"validate_inputs_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="ComputationalLogicModule",
                message_type="submit_logical_query_request",
                payload={
                    "query_type": "validate_emotional_inputs",
                    "query_payload": {
                        "valence": gs.valencia,
                        "arousal": gs.arousal,
                        "threat": gs.system_threat_level,
                        "motiv": gs.motivacion
                    }
                },
                correlation_id=correlation_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            validation_result = await asyncio.wait_for(future, timeout=5.0)
            if validation_result.get("status") != "valid":
                self.logger.warning(f"Entradas emocionales no válidas: {validation_result.get('error', 'No especificado')}")
                return
        except asyncio.TimeoutError:
            self.logger.warning("Timeout validando entradas emocionales.")
            self.core_recombinator.global_state.system_threat_level = min(self.core_recombinator.global_state.system_threat_level + 0.05, 1.0)
            return

        # Consultar EmotionRegulationModule para pesos dinámicos
        correlation_id = f"emotion_weights_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="EmotionRegulationModule",
                message_type="request_emotion_weights",
                payload={"context": gs.current_focus},
                correlation_id=correlation_id,
                priority="medium"
            ))
        }, priority_label="medium")
        try:
            weights = await asyncio.wait_for(future, timeout=5.0)
            self.fuzzy_sets = weights.get("fuzzy_sets", self.fuzzy_sets)
        except asyncio.TimeoutError:
            self.logger.warning("Timeout obteniendo pesos de EmotionRegulationModule. Usando valores por defecto.")

        fuzzified_inputs = self._fuzzify_inputs(gs)
        nuance_activations = self._apply_fuzzy_rules(fuzzified_inputs)
        # Modelar dinámica de activaciones con SDE
        for nuance, activation in nuance_activations.items():
            def activation_dynamics(t, a):
                return -0.05 * (a - activation) + self.sde_sigma * np.random.normal(0, 1)
            result = integrate.odeint(activation_dynamics, [activation], [0, self.update_interval], tfirst=True)
            nuance_activations[nuance] = np.clip(result[-1][0], 0.0, 1.0)
        # Monte Carlo para incertidumbre
        for nuance in nuance_activations:
            samples = np.random.normal(nuance_activations[nuance], 0.05, self.num_mc_samples)
            nuance_activations[nuance] = np.clip(np.mean(samples), 0.0, 1.0)
        final_nuances = self._normalize_outputs(nuance_activations)
        # Actualizar coherencia emocional
        n_emotions = len(final_nuances)
        if len(self.coherence_field) != max(n_emotions, 1):
            self.coherence_field = np.ones(max(n_emotions, 1)) * self.module_state["emotion_coherence_score"]
        conflicts = len(list(nx.simple_cycles(self.emotion_graph))) if self.emotion_graph.number_of_nodes() > 0 else 0
        for _ in range(int(self.update_interval / self.pde_dt)):
            d2_coherence = (np.roll(self.coherence_field, 1) + np.roll(self.coherence_field, -1) - 2 * self.coherence_field) / (self.pde_dx ** 2)
            reaction = 0.1 * self.coherence_field * (1.0 - self.coherence_field / max(n_emotions, 1) - 0.05 * conflicts)
            self.coherence_field += self.pde_dt * (self.pde_diffusion * d2_coherence + reaction)
            self.coherence_field = np.clip(self.coherence_field, 0.0, 1.0)
        self.module_state["emotion_coherence_score"] = np.mean(self.coherence_field)
        if self._has_significant_change(final_nuances):
            self.last_synthesized_nuances = final_nuances
            dominant_nuance = max(final_nuances, key=final_nuances.get, default="neutral")
            # Kalman para suavizar dominant_nuance_intensity
            measurement = final_nuances.get(dominant_nuance, 0.0)
            A, H = 1.0, 1.0
            predicted_state = A * self.kalman_state
            predicted_cov = A * self.kalman_cov * A + self.kalman_Q
            innovation = measurement - H * predicted_state
            innovation_cov = H * predicted_cov * H + self.kalman_R
            kalman_gain = predicted_cov * H / innovation_cov
            self.kalman_state = predicted_state + kalman_gain * innovation
            self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
            self.module_state["dominant_nuance"] = dominant_nuance
            self.module_state["dominant_nuance_intensity"] = self.kalman_state
            correlation_id = f"nuance_update_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            self.active_responses[correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="CNEUnifiedCoreRecombinator",
                    message_type="emotional_nuance_update",
                    payload={"nuances": final_nuances, "dominant": dominant_nuance, "intensity": self.kalman_state},
                    correlation_id=correlation_id,
                    priority="medium"
                ))
            }, priority_label="medium")
            try:
                await asyncio.wait_for(future, timeout=5.0)
                self.logger.info(f"Actualización de matices emocionales confirmada para {dominant_nuance}.")
            except asyncio.TimeoutError:
                self.logger.warning("Timeout esperando confirmación de actualización de matices emocionales.")
        self.module_state["nuances_synthesized_cycles"] += 1

    def _fuzzify(self, value: float, params: Tuple[float, float, float]) -> float:
        a, b, c = params
        return max(0, min((value - a) / (b - a), (c - value) / (c - b))) if a != b and c != b else 0

    def _fuzzify_inputs(self, gs: 'GlobalSelfState') -> Dict[str, Dict[str, float]]:
        inputs = {
            'valence': gs.valencia,
            'arousal': gs.arousal,
            'threat': gs.system_threat_level,
            'motiv': gs.motivacion,
        }
        fuzzified = defaultdict(dict)
        for var, value in inputs.items():
            for set_name, params in self.fuzzy_sets[var].items():
                fuzzified[var][set_name] = self._fuzzify(value, params)
        return fuzzified

    def _apply_fuzzy_rules(self, inputs: Dict[str, Dict[str, float]]) -> Dict[str, float]:
        activations = defaultdict(float)
        emotion_id = f"emo_{uuid.uuid4().hex[:8]}"
        self.emotion_graph.add_node(emotion_id, timestamp=time.time())
        # Reglas difusas
        rules = [
            (("valence", "high"), ("arousal", "mid"), ("joy", 1.0)),
            (("valence", "low"), ("arousal", "high"), ("threat", "high"), ("anxiety", 1.0)),
            (("valence", "low"), ("arousal", "high"), ("motiv", "high"), ("frustration", 1.0)),
            (("valence", "high"), ("arousal", "low"), ("contentment", 1.0)),
            (("valence", "mid"), ("arousal", "mid"), ("motiv", "high"), ("curiosity", 1.0)),
            (("valence", "low"), ("arousal", "low"), ("motiv", "low"), ("apathy", 1.0)),
        ]
        for rule_antecedents, (emotion, weight) in rules:
            strength = min(inputs[var][level] for var, level in rule_antecedents)
            activations[emotion] = max(activations[emotion], strength * weight)
            for other_id in self.emotion_graph.nodes:
                if other_id != emotion_id and emotion in ["joy", "contentment"] and other_id.startswith("emo_"):
                    if any(emo in ["anxiety", "frustration", "apathy"] for emo in self.emotion_graph.nodes[other_id].get("emotions", [])):
                        self.emotion_graph.add_edge(emotion_id, other_id, weight=1.0)
        return activations

    def _normalize_outputs(self, activations: Dict[str, float]) -> Dict[str, float]:
        total_activation = sum(activations.values())
        if total_activation == 0:
            return {"neutral": 1.0}
        normalized = {name: value / total_activation for name, value in activations.items()}
        return normalized

    def _has_significant_change(self, new_nuances: Dict[str, float]) -> bool:
        if not self.last_synthesized_nuances and new_nuances:
            return True
        v1 = np.array(list(self.last_synthesized_nuances.values()))
        v2 = np.array([new_nuances.get(k, 0) for k in self.last_synthesized_nuances.keys()])
        if v1.shape != v2.shape:
            return True
        distance = np.linalg.norm(v1 - v2)
        return distance > 0.15

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        if full_message and full_message.correlation_id in self.active_responses:
            self.active_responses[full_message.correlation_id].set_result(payload)
            del self.active_responses[full_message.correlation_id]





                    #inicio del modulo ValueSystemModule 

@dataclass
class ValueAlignmentQuery:
    query_id: str = field(default_factory=lambda: f"vaq_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    item_to_evaluate: Dict[str, Any]
    status: str = "pending"
    result: Optional[Dict[str, Any]] = None
    error_message: Optional[str] = None

class ValueSystemModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 10.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.alignment_query_queue: asyncio.Queue[ValueAlignmentQuery] = asyncio.Queue(maxlen=50)
        self.value_event_log: deque[Dict[str, Any]] = deque(maxlen=1000)
        self.active_responses: Dict[str, asyncio.Future] = {}
        self.value_graph = nx.DiGraph()
        self.coherence_field: np.ndarray = np.array([1.0])
        self.module_state.update({
            "alignment_queries_processed": 0,
            "value_events_logged": 0,
            "value_conflicts_detected": 0,
            "avg_alignment_query_time_ms": 0.0,
            "value_coherence_score": 1.0
        })
        self.alignment_query_processing_times: List[float] = []
        self.logger.info(f"{self.module_name} v27.2 inicializado con modelado avanzado.")

    def _get_current_system_values(self) -> Dict[str, float]:
        return copy.deepcopy(self.core_recombinator.global_state.values)

    async def _update_logic(self):
        if not self.alignment_query_queue.empty():
            query = await self.alignment_query_queue.get()
            self.alignment_query_queue.task_done()
            self._create_managed_task(self._process_alignment_query(query))

    async def _process_alignment_query(self, query: ValueAlignmentQuery):
        query.status = "processing"
        start_time = time.time()
        try:
            # Validar item con ComputationalLogicModule
            correlation_id = f"validate_item_{query.query_id}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            self.active_responses[correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="ComputationalLogicModule",
                    message_type="submit_logical_query_request",
                    payload={"query_type": "validate_value_alignment_item", "query_payload": query.item_to_evaluate},
                    correlation_id=correlation_id,
                    priority="high"
                ))
            }, priority_label="high")
            try:
                validation_result = await asyncio.wait_for(future, timeout=5.0)
                if validation_result.get("status") != "valid":
                    query.status = "failed"
                    query.error_message = f"Validación fallida: {validation_result.get('error', 'No especificado')}"
                    await self._send_query_response(query)
                    return
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout validando item {query.query_id}.")
                query.status = "failed"
                query.error_message = "Timeout en validación de item."
                await self._send_query_response(query)
                return

            system_values = self._get_current_system_values()
            if not system_values:
                raise RuntimeError("Sistema de valores no disponible.")

            # Consultar DataAndKnowledgeProcessingModule para embeddings
            correlation_id = f"embed_{query.query_id}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            self.active_responses[correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="DataAndKnowledgeProcessingModule",
                    message_type="request_semantic_embedding",
                    payload={"text": query.item_to_evaluate.get("description", "")},
                    correlation_id=correlation_id,
                    priority="medium"
                ))
            }, priority_label="medium")
            try:
                embedding_result = await asyncio.wait_for(future, timeout=5.0)
                item_embedding = np.array(embedding_result.get("embedding", [0.0] * 100))
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout obteniendo embedding para {query.query_id}.")
                item_embedding = np.zeros(100)

            # Evaluar alineación
            per_value_alignment: Dict[str, float] = {}
            total_weight = 0.0
            overall_alignment_score = 0.0
            value_id = f"val_{query.query_id}"
            self.value_graph.add_node(value_id, query_id=query.query_id, timestamp=time.time())
            for value_name, value_weight in system_values.items():
                # Suponemos embeddings de valores predefinidos (en una implementación real, se obtendrían de DataAndKnowledgeProcessingModule)
                value_embedding = np.random.normal(0, 1, 100)  # Placeholder
                alignment_score = np.dot(item_embedding, value_embedding) / (np.linalg.norm(item_embedding) * np.linalg.norm(value_embedding) + 1e-10)
                # Monte Carlo para incertidumbre
                samples = np.random.normal(alignment_score, 0.05, self.num_mc_samples)
                alignment_score = np.clip(np.mean(samples), -1.0, 1.0)
                per_value_alignment[value_name] = alignment_score
                overall_alignment_score += alignment_score * value_weight
                total_weight += value_weight
                # Detectar conflictos
                for other_id in self.value_graph.nodes:
                    if other_id != value_id:
                        other_value = self.value_graph.nodes[other_id].get("value_name", "")
                        if (value_name == "truth_seeking" and other_value == "benevolence_assistance") or \
                           (value_name == "benevolence_assistance" and other_value == "truth_seeking"):
                            self.value_graph.add_edge(value_id, other_id, weight=1.0)
            if total_weight > 0:
                overall_alignment_score /= total_weight
            # Modelar dinámica de alineación con SDE
            def alignment_dynamics(t, a):
                return -0.05 * (a - overall_alignment_score) + self.sde_sigma * np.random.normal(0, 1)
            result = integrate.odeint(alignment_dynamics, [overall_alignment_score], [0, self.update_interval], tfirst=True)
            overall_alignment_score = np.clip(result[-1][0], -1.0, 1.0)
            # Actualizar coherencia de valores
            n_values = len(system_values)
            if len(self.coherence_field) != n_values:
                self.coherence_field = np.ones(n_values) * self.module_state["value_coherence_score"]
            conflicts = len(list(nx.simple_cycles(self.value_graph))) if self.value_graph.number_of_nodes() > 0 else 0
            if conflicts > 0:
                self.module_state["value_conflicts_detected"] += 1
            for _ in range(int(self.update_interval / self.pde_dt)):
                d2_coherence = (np.roll(self.coherence_field, 1) + np.roll(self.coherence_field, -1) - 2 * self.coherence_field) / (self.pde_dx ** 2)
                reaction = 0.1 * self.coherence_field * (1.0 - self.coherence_field / max(n_values, 1) - 0.05 * conflicts)
                self.coherence_field += self.pde_dt * (self.pde_diffusion * d2_coherence + reaction)
                self.coherence_field = np.clip(self.coherence_field, 0.0, 1.0)
            self.module_state["value_coherence_score"] = np.mean(self.coherence_field)
            if self.module_state["value_coherence_score"] < 0.5:
                query.status = "failed"
                query.error_message = "Baja coherencia entre valores detectada."
                await self._send_query_response(query)
                return
            query.result = {
                "overall_alignment_score": overall_alignment_score,
                "per_value_alignment": per_value_alignment,
            }
            query.status = "completed"
        except Exception as e:
            query.status = "failed"
            query.error_message = f"Error interno: {str(e)}"
            self.logger.error(f"Error procesando consulta {query.query_id}: {e}", exc_info=True)
        # Kalman para suavizar avg_alignment_query_time_ms
        processing_time = (time.time() - start_time) * 1000
        self.alignment_query_processing_times.append(processing_time)
        measurement = processing_time
        A, H = 1.0, 1.0
        predicted_state = A * self.kalman_state
        predicted_cov = A * self.kalman_cov * A + self.kalman_Q
        innovation = measurement - H * predicted_state
        innovation_cov = H * predicted_cov * H + self.kalman_R
        kalman_gain = predicted_cov * H / innovation_cov
        self.kalman_state = predicted_state + kalman_gain * innovation
        self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
        self.module_state["avg_alignment_query_time_ms"] = self.kalman_state
        self.module_state["alignment_queries_processed"] += 1
        await self._send_query_response(query)

    async def _log_value_event(self, event_description: str, significance: float, context: Dict):
        if significance < 0.4:
            return
        event_record = {
            "event_id": f"val_evt_{uuid.uuid4().hex[:6]}",
            "timestamp": time.time(),
            "description": event_description,
            "significance_score": significance,
            "context": context
        }
        self.value_event_log.append(event_record)
        self.module_state["value_events_logged"] += 1
        correlation_id = f"event_log_{event_record['event_id']}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="CNEUnifiedCoreRecombinator",
                message_type="significant_value_implication_event",
                payload=event_record,
                correlation_id=correlation_id,
                priority="medium" if significance <= 0.85 else "high"
            ))
        }, priority_label="medium" if significance <= 0.85 else "high")
        try:
            await asyncio.wait_for(future, timeout=5.0)
            self.logger.info(f"Evento de valor {event_record['event_id']} confirmado.")
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout confirmando evento de valor {event_record['event_id']}.")
            self.core_recombinator.global_state.system_threat_level = min(self.core_recombinator.global_state.system_threat_level + 0.05, 1.0)

    async def _send_query_response(self, query: ValueAlignmentQuery):
        if query.source_module_id and query.original_correlation_id:
            correlation_id = f"response_{query.query_id}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            self.active_responses[correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id=query.source_module_id,
                    message_type="value_alignment_query_response",
                    payload=asdict(query),
                    correlation_id=query.original_correlation_id,
                    priority="medium"
                ))
            }, priority_label="medium")
            try:
                await asyncio.wait_for(future, timeout=5.0)
                self.logger.info(f"Respuesta de consulta {query.query_id} confirmada.")
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout confirmando respuesta de consulta {query.query_id}.")

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        if not full_message:
            return
        if event_type == "request_value_alignment":
            try:
                item = payload.get("item_to_evaluate", {})
                if not item:
                    raise ValueError("'item_to_evaluate' es requerido.")
                query = ValueAlignmentQuery(
                    source_module_id=full_message.source_module_id,
                    original_correlation_id=full_message.correlation_id,
                    item_to_evaluate=item
                )
                await self.alignment_query_queue.put(query)
            except Exception as e:
                self.logger.error(f"Error procesando solicitud de alineación de valor: {e}")
        elif event_type == "new_decision_made_log":
            decision = payload.get("decision_record", {})
            if decision:
                await self._log_value_event(
                    f"Decisión tomada: '{decision.get('problem_description', 'N/A')[:50]}'",
                    significance=0.5,
                    context={"decision_id": decision.get("request_id")}
                )
        elif event_type == "major_goal_outcome_reported":
            significance = payload.get("priority", 0.5)
            if payload.get("outcome") != "completed":
                significance += 0.2
            await self._log_value_event(
                f"Resultado de meta: '{payload.get('description', 'N/A')[:50]}' fue {payload.get('outcome')}",
                significance=significance,
                context=payload
            )
        elif full_message.correlation_id in self.active_responses:
            self.active_responses[full_message.correlation_id].set_result(payload)
            del self.active_responses[full_message.correlation_id]




                     #inicio del modulo SelfEvolutionModule 


@dataclass
class EvolutionaryGoal:
    goal_id: str = field(default_factory=lambda: f"evo_goal_{uuid.uuid4().hex[:6]}")
    description: str
    target_metrics: Dict[str, Any]
    status: str = "identified"
    creation_ts: float = field(default_factory=time.time)
    current_hypothesis: Optional[Dict[str, Any]] = None
    linked_task_id: Optional[str] = None
    initial_metrics_snapshot: Optional[Dict[str, Any]] = None

@dataclass
class SystemPerformanceSnapshot:
    timestamp: float
    global_state_summary: Dict[str, float]
    module_health_scores: Dict[str, float]
    module_efficiency_scores: Dict[str, float]
    key_performance_indicators: Dict[str, Any]

class SelfEvolutionModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 60.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.active_evolutionary_goals: Dict[str, EvolutionaryGoal] = {}
        self.system_performance_history: deque[SystemPerformanceSnapshot] = deque(maxlen=100)
        self.active_responses: Dict[str, asyncio.Future] = {}
        self.goal_graph = nx.DiGraph()
        self.coherence_field: np.ndarray = np.array([1.0])
        self.low_module_health_threshold: float = 0.50
        self.stagnation_detection_window: int = 10
        self.min_improvement_for_stagnation: float = 0.02
        self.num_mc_samples: int = 500
        self.sde_sigma: float = 0.01
        self.pde_dx: float = 0.1
        self.pde_dt: float = 0.01
        self.pde_diffusion: float = 0.05
        self.module_state.update({
            "evolutionary_goals_active": 0,
            "evolutionary_goals_succeeded": 0,
            "evolutionary_goals_failed": 0,
            "improvement_actions_initiated": 0,
            "goal_coherence_score": 1.0
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado con modelado avanzado.")

    async def _update_logic(self):
        current_perf = await self._collect_system_performance_data()
        # Validar snapshot
        correlation_id = f"validate_snapshot_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="ComputationalLogicModule",
                message_type="submit_logical_query_request",
                payload={"query_type": "validate_performance_snapshot", "query_payload": asdict(current_perf)},
                correlation_id=correlation_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            validation_result = await asyncio.wait_for(future, timeout=5.0)
            if validation_result.get("status") != "valid":
                self.logger.warning(f"Snapshot no válido: {validation_result.get('error', 'No especificado')}")
                return
        except asyncio.TimeoutError:
            self.logger.warning("Timeout validando snapshot de rendimiento.")
            self.core_recombinator.global_state.system_threat_level = min(self.core_recombinator.global_state.system_threat_level + 0.05, 1.0)
            return
        self.system_performance_history.append(current_perf)
        await self._analyze_performance_and_identify_evo_goals(current_perf)
        for goal in list(self.active_evolutionary_goals.values()):
            # Detectar conflictos entre objetivos
            if await self._check_goal_conflict(goal):
                goal.status = "failed"
                goal.outcome_message = "Conflicto detectado entre objetivos evolutivos."
                self.logger.warning(f"Conflicto en EvoGoal {goal.goal_id}: {goal.outcome_message}")
                del self.active_evolutionary_goals[goal.goal_id]
                continue
            if goal.status == "identified":
                await self._generate_hypothesis_and_initiate_action(goal, current_perf)
            elif goal.status == "monitoring_impact":
                await self._evaluate_impact_of_change(goal, current_perf)
        # Actualizar coherencia entre objetivos
        n_goals = len(self.active_evolutionary_goals)
        if len(self.coherence_field) != max(n_goals, 1):
            self.coherence_field = np.ones(max(n_goals, 1)) * self.module_state["goal_coherence_score"]
        conflicts = len(list(nx.simple_cycles(self.goal_graph))) if self.goal_graph.number_of_nodes() > 0 else 0
        for _ in range(int(self.update_interval / self.pde_dt)):
            d2_coherence = (np.roll(self.coherence_field, 1) + np.roll(self.coherence_field, -1) - 2 * self.coherence_field) / (self.pde_dx ** 2)
            reaction = 0.1 * self.coherence_field * (1.0 - self.coherence_field / max(n_goals, 1) - 0.05 * conflicts)
            self.coherence_field += self.pde_dt * (self.pde_diffusion * d2_coherence + reaction)
            self.coherence_field = np.clip(self.coherence_field, 0.0, 1.0)
        self.module_state["goal_coherence_score"] = np.mean(self.coherence_field)
        self.module_state["evolutionary_goals_active"] = len(self.active_evolutionary_goals)

    async def _collect_system_performance_data(self) -> SystemPerformanceSnapshot:
        gs = self.core_recombinator.global_state
        gs_summary = {
            "valencia": gs.valencia,
            "arousal": gs.arousal,
            "motivacion": gs.motivacion,
            "phi": gs.phi_functional_score,
            "coherence": gs.coherence_score,
            "entropy": gs.system_entropy,
            "threat": gs.system_threat_level
        }
        # Monte Carlo para incertidumbre
        for key in gs_summary:
            samples = np.random.normal(gs_summary[key], 0.05, self.num_mc_samples)
            gs_summary[key] = np.clip(np.mean(samples), -1.0, 1.0)
        # SDE para dinámica de métricas
        for key, value in gs_summary.items():
            def metric_dynamics(t, v):
                return -0.05 * (v - value) + self.sde_sigma * np.random.normal(0, 1)
            result = integrate.odeint(metric_dynamics, [value], [0, self.update_interval], tfirst=True)
            gs_summary[key] = np.clip(result[-1][0], -1.0, 1.0)
        mod_health, mod_eff = {}, {}
        for name, mod in self.core_recombinator.modules.items():
            metrics = mod.get_performance_metrics()
            mod_health[name] = np.clip(metrics.get('self_assessed_health_score', 0.5), 0.0, 1.0)
            mod_eff[name] = np.clip(metrics.get('internal_efficiency', 0.5), 0.0, 1.0)
        kpis = {}
        if "TaskPrioritizationAndDelegationUnit" in self.core_recombinator.modules:
            kpis["avg_task_completion_time_ms"] = self.core_recombinator.modules["TaskPrioritizationAndDelegationUnit"].module_state.get("avg_task_completion_time_ms", -1)
        # Kalman para suavizar KPIs
        for key, value in kpis.items():
            if value != -1:
                measurement = value
                A, H = 1.0, 1.0
                predicted_state = A * self.kalman_state
                predicted_cov = A * self.kalman_cov * A + self.kalman_Q
                innovation = measurement - H * predicted_state
                innovation_cov = H * predicted_cov * H + self.kalman_R
                kalman_gain = predicted_cov * H / innovation_cov
                self.kalman_state = predicted_state + kalman_gain * innovation
                self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
                kpis[key] = self.kalman_state
        return SystemPerformanceSnapshot(time.time(), gs_summary, mod_health, mod_eff, kpis)

    async def _analyze_performance_and_identify_evo_goals(self, current_perf: SystemPerformanceSnapshot):
        for mod_name, health in current_perf.module_health_scores.items():
            if health < self.low_module_health_threshold:
                desc = f"Mejorar salud del módulo '{mod_name}' (actual: {health:.2f})"
                if not any(g.description == desc for g in self.active_evolutionary_goals.values()):
                    goal = EvolutionaryGoal(description=desc, target_metrics={"module_health": {"module_name": mod_name, "target_above": 0.7}})
                    self.active_evolutionary_goals[goal.goal_id] = goal
                    self.goal_graph.add_node(goal.goal_id, description=desc, timestamp=time.time())
                    self.logger.warning(f"SEM: Nuevo EvoGoal '{goal.goal_id}': {desc}")
        if len(self.system_performance_history) >= self.stagnation_detection_window:
            recent_motivation = [s.global_state_summary.get("motivacion", 0.5) for s in list(self.system_performance_history)[-self.stagnation_detection_window:]]
            t_stat, p_value = stats.ttest_1samp(recent_motivation, 0.4)
            if p_value < 0.05 and np.std(recent_motivation) < 0.05:
                desc = f"Abordar estancamiento de la motivación del sistema."
                if not any(g.description == desc for g in self.active_evolutionary_goals.values()):
                    goal = EvolutionaryGoal(description=desc, target_metrics={"global_kpi": {"kpi_name": "motivacion", "target_above": 0.6}})
                    self.active_evolutionary_goals[goal.goal_id] = goal
                    self.goal_graph.add_node(goal.goal_id, description=desc, timestamp=time.time())
                    self.logger.warning(f"SEM: Nuevo EvoGoal por estancamiento: {desc}")

    async def _check_goal_conflict(self, goal: EvolutionaryGoal) -> bool:
        goal_id = goal.goal_id
        for other_goal in self.active_evolutionary_goals.values():
            if other_goal.goal_id != goal_id:
                other_id = other_goal.goal_id
                if ("module_health" in goal.target_metrics and "module_health" in other_goal.target_metrics and
                    goal.target_metrics["module_health"]["module_name"] != other_goal.target_metrics["module_health"]["module_name"]):
                    self.goal_graph.add_edge(goal_id, other_id, weight=1.0)
        try:
            cycles = list(nx.simple_cycles(self.goal_graph))
            return len(cycles) > 0
        except nx.NetworkXNoCycle:
            return False

    async def _generate_hypothesis_and_initiate_action(self, goal: EvolutionaryGoal, current_perf: SystemPerformanceSnapshot):
        goal.status = "hypothesizing"
        # Consultar DecisionMakingModule para generar hipótesis
        correlation_id = f"hypothesis_{goal.goal_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        options = [
            {"option_id": "param_tuning", "description": f"Tunear parámetros de {goal.target_metrics.get('module_health', {}).get('module_name', 'sistema')}"},
            {"option_id": "code_regen", "description": f"Refactorizar código para mejorar {goal.target_metrics.get('global_kpi', {}).get('kpi_name', 'rendimiento')}"}
        ]
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="DecisionMakingModule",
                message_type="request_decision_evaluation",
                payload={
                    "problem_description": goal.description,
                    "options": options,
                    "context": {"goal_id": goal.goal_id}
                },
                correlation_id=correlation_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            decision_result = await asyncio.wait_for(future, timeout=10.0)
            if decision_result.get("final_status") == "resolved_option_chosen":
                hypothesis = {"type": decision_result.get("chosen_option_id"), "description": next(opt["description"] for opt in options if opt["option_id"] == decision_result.get("chosen_option_id"))}
            else:
                goal.status = "failed"
                goal.outcome_message = "No se pudo generar una hipótesis válida."
                self.logger.error(f"No se pudo generar hipótesis para EvoGoal {goal.goal_id}: {decision_result.get('justification')}")
                del self.active_evolutionary_goals[goal.goal_id]
                return
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout generando hipótesis para EvoGoal {goal.goal_id}.")
            goal.status = "failed"
            goal.outcome_message = "Timeout en generación de hipótesis."
            del self.active_evolutionary_goals[goal.goal_id]
            return
        goal.current_hypothesis = hypothesis
        goal.initial_metrics_snapshot = asdict(current_perf)
        goal.status = "action_initiated"
        self.module_state["improvement_actions_initiated"] += 1
        action_corr_id = f"sem_action_{goal.goal_id}_{uuid.uuid4().hex[:8]}"
        goal.linked_task_id = action_corr_id
        future = asyncio.Future()
        self.active_responses[action_corr_id] = future
        if hypothesis["type"] == "param_tuning":
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="LearningModule",
                    message_type="request_learning_task",
                    payload={"learning_type": "parameter_tuning", "target_module_for_update": goal.target_metrics.get('module_health', {}).get('module_name', 'sistema')},
                    correlation_id=action_corr_id,
                    priority="high"
                ))
            }, priority_label="high")
        elif hypothesis["type"] == "code_regen":
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="GeneradorCode",
                    message_type="execute_task",
                    payload={"description": hypothesis["description"]},
                    correlation_id=action_corr_id,
                    priority="high"
                ))
            }, priority_label="high")
        try:
            await asyncio.wait_for(future, timeout=10.0)
            goal.status = "monitoring_impact"
            self.logger.info(f"Acción iniciada para EvoGoal {goal.goal_id}: {hypothesis['description']}")
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout iniciando acción para EvoGoal {goal.goal_id}.")
            goal.status = "failed"
            goal.outcome_message = "Timeout iniciando acción."
            del self.active_evolutionary_goals[goal.goal_id]

    async def _evaluate_impact_of_change(self, goal: EvolutionaryGoal, current_perf: SystemPerformanceSnapshot):
        initial_metrics = goal.initial_metrics_snapshot["global_state_summary"]
        current_metrics = current_perf.global_state_summary
        # T-test para comparar métricas
        metric_key = goal.target_metrics.get("global_kpi", {}).get("kpi_name", "phi")
        initial_value = initial_metrics.get(metric_key, 0.5)
        current_value = current_metrics.get(metric_key, 0.5)
        recent_values = [s.global_state_summary.get(metric_key, 0.5) for s in list(self.system_performance_history)[-self.stagnation_detection_window:]]
        t_stat, p_value = stats.ttest_1samp(recent_values, initial_value)
        if p_value < 0.05 and current_value > initial_value + self.min_improvement_for_stagnation:
            goal.status = "completed_success"
            self.module_state["evolutionary_goals_succeeded"] += 1
        else:
            goal.status = "completed_failed"
            self.module_state["evolutionary_goals_failed"] += 1
        self.logger.info(f"Evaluación para EvoGoal '{goal.goal_id}' completada. Estado: {goal.status}. ({metric_key}: {initial_value:.2f} -> {current_value:.2f}, p={p_value:.3f})")
        del self.active_evolutionary_goals[goal.goal_id]
        self.goal_graph.remove_node(goal.goal_id)

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        if full_message and full_message.target_module_id == self.module_name:
            goal = next((g for g in self.active_evolutionary_goals.values() if g.linked_task_id == full_message.correlation_id), None)
            if goal and goal.status == "action_initiated":
                if payload.get("status") == "completed" or payload.get("final_status") == "completed":
                    self.logger.info(f"Acción para EvoGoal '{goal.goal_id}' completada por módulo ejecutor. Iniciando monitoreo de impacto.")
                    goal.status = "monitoring_impact"
                else:
                    self.logger.error(f"Acción para EvoGoal '{goal.goal_id}' falló: {payload.get('error', 'No especificado')}")
                    goal.status = "completed_failed"
                    goal.outcome_message = f"Fallo en acción: {payload.get('error', 'No especificado')}"
                    del self.active_evolutionary_goals[goal.goal_id]
                    self.goal_graph.remove_node(goal.goal_id)
        if full_message and full_message.correlation_id in self.active_responses:
            self.active_responses[full_message.correlation_id].set_result(payload)
            del self.active_responses[full_message.correlation_id]






                      #inicio del modulo GeneradorCode 

class SecurityException(Exception):
    pass

class GeneradorCode(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 30.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.max_generated_code_lines: int = 1000
        self.dangerous_operations_risk_scores: Dict[str, float] = {
            "eval": 1.0, "exec": 1.0, "os.system": 0.9, "subprocess.run": 0.8,
            "__import__": 0.7, "open": 0.4, "socket.socket": 0.5,
            "ctypes": 0.8, "sys": 0.5, "os": 0.5, "shutil": 0.7
        }
        self.max_allowed_security_risk_score: float = 0.1
        self.active_responses: Dict[str, asyncio.Future] = {}
        self.task_graph = nx.DiGraph()
        self.coherence_field: np.ndarray = np.array([1.0])
        self.num_mc_samples: int = 500
        self.sde_sigma: float = 0.01
        self.pde_dx: float = 0.1
        self.pde_dt: float = 0.01
        self.pde_diffusion: float = 0.05
        self.module_state.update({
            "code_blocks_generated_total": 0,
            "syntax_errors_prevented_total": 0,
            "security_violations_prevented_total": 0,
            "avg_generation_time_ms": 0.0,
            "avg_generated_code_complexity": 0.0,
            "task_coherence_score": 1.0
        })
        self.processing_times_generation: List[float] = []
        self.generated_code_complexities: List[float] = []
        self.logger.info(f"{self.module_name} v27.2 inicializado con modelado avanzado.")

    def _validate_python_syntax(self, code_string: str, source_hint: str = "dynamic_code") -> Tuple[bool, str]:
        try:
            ast.parse(code_string, filename=source_hint)
            return True, ""
        except SyntaxError as e:
            self.module_state["syntax_errors_prevented_total"] += 1
            return False, f"Error de sintaxis: {e.msg} (línea {e.lineno}, offset {e.offset})"
        except Exception as e:
            return False, f"Error de parseo AST: {str(e)}"

    def _assess_code_security_risk(self, code_string: str) -> Tuple[bool, str, float]:
        try:
            parsed_ast = ast.parse(code_string)
            total_risk = 0.0
            risky_ops_found: List[str] = []

            class SecurityVisitor(ast.NodeVisitor):
                def __init__(self, parent):
                    self.parent = parent
                    super().__init__()

                def visit_Call(self, node: ast.Call):
                    func_name = ""
                    if isinstance(node.func, ast.Name):
                        func_name = node.func.id
                    elif isinstance(node.func, ast.Attribute):
                        func_name = node.func.attr
                    if func_name in self.parent.dangerous_operations_risk_scores:
                        risk = self.parent.dangerous_operations_risk_scores[func_name]
                        total_risk += risk
                        risky_ops_found.append(f"Llamada peligrosa '{func_name}' en línea {node.lineno} (Riesgo: {risk})")
                    self.generic_visit(node)

                def visit_Import(self, node: ast.Import):
                    for alias in node.names:
                        if alias.name in self.parent.dangerous_operations_risk_scores:
                            risk = self.parent.dangerous_operations_risk_scores[alias.name]
                            total_risk += risk
                            risky_ops_found.append(f"Import peligroso '{alias.name}' en línea {node.lineno} (Riesgo: {risk})")
                    self.generic_visit(node)

            visitor = SecurityVisitor(self)
            visitor.visit(parsed_ast)
            # Monte Carlo para incertidumbre en riesgo
            samples = np.random.normal(total_risk, 0.05, self.num_mc_samples)
            total_risk = np.clip(np.mean(samples), 0.0, 1.0)
            # SDE para dinámica de riesgo
            def risk_dynamics(t, r):
                return -0.05 * (r - total_risk) + self.sde_sigma * np.random.normal(0, 1)
            result = integrate.odeint(risk_dynamics, [total_risk], [0, self.update_interval], tfirst=True)
            total_risk = np.clip(result[-1][0], 0.0, 1.0)
            if total_risk > self.max_allowed_security_risk_score:
                self.module_state["security_violations_prevented_total"] += 1
                return False, f"Riesgo de seguridad ({total_risk:.2f}) excede umbral. Operaciones: {'; '.join(risky_ops_found)}", total_risk
            return True, "", total_risk
        except Exception as e:
            self.module_state["security_violations_prevented_total"] += 1
            return False, f"Error interno evaluando seguridad: {str(e)}", 1.0

    def _estimate_code_complexity(self, code_string: str) -> float:
        try:
            parsed_ast = ast.parse(code_string)
            node_count = sum(1 for _ in ast.walk(parsed_ast))
            line_count = len(code_string.splitlines())
            complexity = ((node_count / (self.max_generated_code_lines * 7.0)) + (line_count / self.max_generated_code_lines)) / 2.0
            # Monte Carlo para incertidumbre
            samples = np.random.normal(complexity, 0.05, self.num_mc_samples)
            complexity = np.clip(np.mean(samples), 0.0, 1.0)
            # SDE para dinámica de complejidad
            def complexity_dynamics(t, c):
                return -0.05 * (c - complexity) + self.sde_sigma * np.random.normal(0, 1)
            result = integrate.odeint(complexity_dynamics, [complexity], [0, self.update_interval], tfirst=True)
            complexity = np.clip(result[-1][0], 0.0, 1.0)
            return complexity
        except Exception:
            return 1.0

    async def execute_task(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        start_time = time.time()
        task_id = task_data.get("task_id", f"gc_task_{uuid.uuid4().hex[:8]}")
        description = task_data.get("description", "Generación de código genérica")
        # Validar tarea
        correlation_id = f"validate_task_{task_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="ComputationalLogicModule",
                message_type="submit_logical_query_request",
                payload={"query_type": "validate_code_generation_task", "query_payload": task_data},
                correlation_id=correlation_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            validation_result = await asyncio.wait_for(future, timeout=5.0)
            if validation_result.get("status") != "valid":
                self.logger.warning(f"Tarea no válida: {validation_result.get('error', 'No especificado')}")
                return {"status": "failed", "reason": f"Tarea no válida: {validation_result.get('error', 'No especificado')}"}
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout validando tarea {task_id}.")
            return {"status": "failed", "reason": "Timeout en validación de tarea"}
        # Verificar conflictos
        self.task_graph.add_node(task_id, description=description, timestamp=time.time())
        for other_task_id in self.task_graph.nodes:
            if other_task_id != task_id:
                if task_data.get("generation_type") == "new_module_from_spec" and \
                   self.task_graph.nodes[other_task_id].get("generation_type") == "new_module_from_spec" and \
                   task_data.get("specification", {}).get("suggested_module_name") == self.task_graph.nodes[other_task_id].get("suggested_module_name"):
                    self.task_graph.add_edge(task_id, other_task_id, weight=1.0)
        conflicts = len(list(nx.simple_cycles(self.task_graph))) if self.task_graph.number_of_nodes() > 0 else 0
        if conflicts > 0:
            self.task_graph.remove_node(task_id)
            self.logger.warning(f"Conflicto detectado en tarea {task_id}.")
            return {"status": "failed", "reason": "Conflicto entre tareas de generación"}
        # Actualizar coherencia entre tareas
        n_tasks = self.task_graph.number_of_nodes()
        if len(self.coherence_field) != max(n_tasks, 1):
            self.coherence_field = np.ones(max(n_tasks, 1)) * self.module_state["task_coherence_score"]
        for _ in range(int(self.update_interval / self.pde_dt)):
            d2_coherence = (np.roll(self.coherence_field, 1) + np.roll(self.coherence_field, -1) - 2 * self.coherence_field) / (self.pde_dx ** 2)
            reaction = 0.1 * self.coherence_field * (1.0 - self.coherence_field / max(n_tasks, 1) - 0.05 * conflicts)
            self.coherence_field += self.pde_dt * (self.pde_diffusion * d2_coherence + reaction)
            self.coherence_field = np.clip(self.coherence_field, 0.0, 1.0)
        self.module_state["task_coherence_score"] = np.mean(self.coherence_field)
        try:
            code_str = await self._handle_code_generation(task_data)
            if not code_str:
                raise ValueError("No se generó contenido de código.")
            is_valid, msg = self._validate_python_syntax(code_str, f"task_{task_id}")
            if not is_valid:
                self.logger.warning(f"Sintaxis no válida en tarea {task_id}: {msg}")
                return {"status": "failed", "reason": f"Error de sintaxis: {msg}"}
            is_safe, msg, risk = self._assess_code_security_risk(code_str)
            if not is_safe:
                self.logger.warning(f"Violación de seguridad en tarea {task_id}: {msg}")
                return {"status": "failed", "reason": f"Violación de seguridad: {msg}"}
            # Validar alineación con valores
            correlation_id = f"align_{task_id}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            self.active_responses[correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="ValueSystemModule",
                    message_type="request_value_alignment",
                    payload={"item_to_evaluate": {"description": description, "code": code_str}},
                    correlation_id=correlation_id,
                    priority="medium"
                ))
            }, priority_label="medium")
            try:
                alignment_result = await asyncio.wait_for(future, timeout=5.0)
                if alignment_result.get("overall_alignment_score", -1.0) < 0.0:
                    self.logger.warning(f"Código no alineado con valores en tarea {task_id}: {alignment_result.get('error_message', 'No especificado')}")
                    return {"status": "failed", "reason": f"Código no alineado con valores: {alignment_result.get('error_message', 'No especificado')}"}
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout validando alineación para tarea {task_id}.")
                return {"status": "failed", "reason": "Timeout en validación de alineación"}
            complexity = self._estimate_code_complexity(code_str)
            self.generated_code_complexities.append(complexity)
            # Kalman para suavizar métricas
            measurement = complexity
            A, H = 1.0, 1.0
            predicted_state = A * self.kalman_state
            predicted_cov = A * self.kalman_cov * A + self.kalman_Q
            innovation = measurement - H * predicted_state
            innovation_cov = H * predicted_cov * H + self.kalman_R
            kalman_gain = predicted_cov * H / innovation_cov
            self.kalman_state = predicted_state + kalman_gain * innovation
            self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
            self.module_state["avg_generated_code_complexity"] = self.kalman_state
            # Enviar código a JITModuleCompiler
            correlation_id = f"jit_{task_id}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            self.active_responses[correlation_id] = future
            payload_for_jit = {"generated_code_str": code_str, **task_data}
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="JITModuleCompiler",
                    message_type="code_ready_for_compilation",
                    payload=payload_for_jit,
                    correlation_id=correlation_id,
                    priority="high"
                ))
            }, priority_label="high")
            try:
                await asyncio.wait_for(future, timeout=10.0)
                self.logger.info(f"Código para tarea {task_id} enviado a JITModuleCompiler.")
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout enviando código para tarea {task_id} a JITModuleCompiler.")
                return {"status": "failed", "reason": "Timeout enviando código a JITModuleCompiler"}
            duration_ms = (time.time() - start_time) * 1000
            self.processing_times_generation.append(duration_ms / 1000.0)
            measurement = duration_ms / 1000.0
            predicted_state = A * self.kalman_state
            predicted_cov = A * self.kalman_cov * A + self.kalman_Q
            innovation = measurement - H * predicted_state
            innovation_cov = H * predicted_cov * H + self.kalman_R
            kalman_gain = predicted_cov * H / innovation_cov
            self.kalman_state = predicted_state + kalman_gain * innovation
            self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
            self.module_state["avg_generation_time_ms"] = self.kalman_state * 1000
            self.module_state["code_blocks_generated_total"] += 1
            return {"status": "completed", "result": {"message": "Código generado y enviado a JITModuleCompiler.", "complexity": complexity, "risk": risk}}
        except Exception as e:
            self.logger.error(f"Error en tarea {task_id}: {str(e)}", exc_info=True)
            return {"status": "failed", "reason": str(e)}
        finally:
            self.task_graph.remove_node(task_id)

    async def _handle_code_generation(self, task_data: Dict[str, Any]) -> str:
        generation_type = task_data.get("generation_type", "generic")
        description = task_data.get("description", "Generación de código genérica")
        # Consultar DataAndKnowledgeProcessingModule
        correlation_id = f"generate_{task_data.get('task_id', 'generic')}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="DataAndKnowledgeProcessingModule",
                message_type="request_code_generation",
                payload={"generation_type": generation_type, "description": description, "context": task_data.get("context", {}), "specification": task_data.get("specification", {})},
                correlation_id=correlation_id,
                priority="medium"
            ))
        }, priority_label="medium")
        try:
            generation_result = await asyncio.wait_for(future, timeout=10.0)
            code_str = generation_result.get("generated_code", "")
            if not code_str:
                raise ValueError("DataAndKnowledgeProcessingModule no devolvió código válido.")
            return code_str
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout generando código para tarea {task_data.get('task_id', 'generic')}.")
            return ""
        except Exception as e:
            self.logger.error(f"Error generando código: {str(e)}", exc_info=True)
            return ""

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        if full_message and full_message.correlation_id in self.active_responses:
            self.active_responses[full_message.correlation_id].set_result(payload)
            del self.active_responses[full_message.correlation_id]




                        #inicio del modulo JITModuleCompiler 

class JITModuleCompiler(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 5.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.compilation_queue: asyncio.Queue['IlyukMessageStructure'] = asyncio.Queue(maxsize=50)
        self.pending_sandbox_evaluations: Dict[str, Dict[str, Any]] = {}
        self.active_responses: Dict[str, asyncio.Future] = {}
        self.module_graph = nx.DiGraph()
        self.coherence_field: np.ndarray = np.array([1.0])
        self.num_mc_samples: int = 500
        self.sde_sigma: float = 0.01
        self.pde_dx: float = 0.1
        self.pde_dt: float = 0.01
        self.pde_diffusion: float = 0.05
        self.module_state.update({
            "modules_compiled_successfully": 0,
            "compilation_failures": 0,
            "sandbox_tests_passed": 0,
            "sandbox_tests_failed": 0,
            "modules_integrated_successfully": 0,
            "integration_failures": 0,
            "avg_compilation_time_ms": 0.0,
            "module_coherence_score": 1.0
        })
        self.compilation_times: List[float] = []
        self.logger.info(f"{self.module_name} v27.2 inicializado con modelado avanzado.")

    async def _update_logic(self):
        if not self.compilation_queue.empty():
            compile_request_msg = await self.compilation_queue.get()
            self.compilation_queue.task_done()
            self._create_managed_task(self._process_compilation_request(compile_request_msg))
        # Actualizar coherencia entre módulos
        n_modules = self.module_graph.number_of_nodes()
        if len(self.coherence_field) != max(n_modules, 1):
            self.coherence_field = np.ones(max(n_modules, 1)) * self.module_state["module_coherence_score"]
        conflicts = len(list(nx.simple_cycles(self.module_graph))) if self.module_graph.number_of_nodes() > 0 else 0
        for _ in range(int(self.update_interval / self.pde_dt)):
            d2_coherence = (np.roll(self.coherence_field, 1) + np.roll(self.coherence_field, -1) - 2 * self.coherence_field) / (self.pde_dx ** 2)
            reaction = 0.1 * self.coherence_field * (1.0 - self.coherence_field / max(n_modules, 1) - 0.05 * conflicts)
            self.coherence_field += self.pde_dt * (self.pde_diffusion * d2_coherence + reaction)
            self.coherence_field = np.clip(self.coherence_field, 0.0, 1.0)
        self.module_state["module_coherence_score"] = np.mean(self.coherence_field)

    async def _process_compilation_request(self, request_message: 'IlyukMessageStructure'):
        payload = request_message.payload
        code_str = payload.get("generated_code_str")
        module_name = payload.get("module_name_suggestion", f"DynMod_{uuid.uuid4().hex[:4]}")
        if not code_str:
            self.logger.error(f"Solicitud de compilación sin código (CorrID: {request_message.correlation_id}).")
            await self._notify_failure(request_message, "Solicitud de compilación sin código.")
            return
        # Validar solicitud
        correlation_id = f"validate_request_{module_name}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="ComputationalLogicModule",
                message_type="submit_logical_query_request",
                payload={"query_type": "validate_compilation_request", "query_payload": payload},
                correlation_id=correlation_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            validation_result = await asyncio.wait_for(future, timeout=5.0)
            if validation_result.get("status") != "valid":
                self.logger.warning(f"Solicitud no válida: {validation_result.get('error', 'No especificado')}")
                await self._notify_failure(request_message, f"Solicitud no válida: {validation_result.get('error', 'No especificado')}")
                return
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout validando solicitud para módulo {module_name}.")
            await self._notify_failure(request_message, "Timeout en validación de solicitud.")
            return
        # Validar alineación con valores
        correlation_id = f"align_{module_name}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="ValueSystemModule",
                message_type="request_value_alignment",
                payload={"item_to_evaluate": {"description": f"Compilación de módulo {module_name}", "code": code_str}},
                correlation_id=correlation_id,
                priority="medium"
            ))
        }, priority_label="medium")
        try:
            alignment_result = await asyncio.wait_for(future, timeout=5.0)
            if alignment_result.get("overall_alignment_score", -1.0) < 0.0:
                self.logger.warning(f"Código no alineado para módulo {module_name}: {alignment_result.get('error_message', 'No especificado')}")
                await self._notify_failure(request_message, f"Código no alineado: {alignment_result.get('error_message', 'No especificado')}")
                return
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout validando alineación para módulo {module_name}.")
            await self._notify_failure(request_message, "Timeout en validación de alineación.")
            return
        # Verificar conflictos
        self.module_graph.add_node(module_name, code=code_str, timestamp=time.time())
        for other_module in self.module_graph.nodes:
            if other_module != module_name and other_module in self.core_recombinator.modules:
                self.module_graph.add_edge(module_name, other_module, weight=1.0)
        conflicts = len(list(nx.simple_cycles(self.module_graph))) if self.module_graph.number_of_nodes() > 0 else 0
        if conflicts > 0 or module_name in self.core_recombinator.modules:
            self.module_graph.remove_node(module_name)
            self.logger.warning(f"Conflicto detectado para módulo {module_name}.")
            await self._notify_failure(request_message, "Conflicto con módulos existentes.")
            return
        module_class, compile_msg, internal_name = await self._compile_and_load_module(module_name, code_str)
        if module_class and internal_name:
            self.module_state["modules_compiled_successfully"] += 1
            sandbox_corr_id = f"jit_sandbox_eval_{uuid.uuid4().hex[:10]}"
            self.pending_sandbox_evaluations[sandbox_corr_id] = {
                "module_class": module_class,
                "module_name": module_name,
                "internal_py_name": internal_name,
                "is_new": payload.get("is_new_module_request", False),
                "original_correlation_id": request_message.correlation_id,
                "code_str": code_str,
            }
            await self._request_sandbox_evaluation(module_name, code_str, sandbox_corr_id)
        else:
            self.module_state["compilation_failures"] += 1
            self.module_graph.remove_node(module_name)
            self.logger.error(f"Fallo de compilación para '{module_name}': {compile_msg}")
            await self._notify_failure(request_message, f"Fallo de compilación: {compile_msg}")

    async def _compile_and_load_module(self, name: str, code: str) -> Tuple[Optional[Type], str, Optional[str]]:
        start_time = time.time()
        internal_name = f"eane_dyn_module_{name.lower()}_{uuid.uuid4().hex[:6]}"
        try:
            spec = importlib.util.spec_from_loader(internal_name, loader=None, origin="jit_compiler")
            if not spec:
                raise RuntimeError("Fallo al crear spec de módulo.")
            module_obj = importlib.util.module_from_spec(spec)
            module_obj.__dict__['BaseAsyncModule'] = BaseAsyncModule
            module_obj.__dict__['asyncio'] = asyncio
            module_obj.__dict__['np'] = np
            exec(code, module_obj.__dict__)
            sys.modules[internal_name] = module_obj
            module_class = getattr(module_obj, name, None)
            if not inspect.isclass(module_class) or not issubclass(module_class, BaseAsyncModule):
                raise TypeError(f"Clase '{name}' no encontrada o no hereda de BaseAsyncModule.")
            # Monte Carlo para incertidumbre en compilación
            compilation_success = 1.0
            samples = np.random.normal(compilation_success, 0.05, self.num_mc_samples)
            compilation_success = np.clip(np.mean(samples), 0.0, 1.0)
            # SDE para dinámica de compilación
            def compile_dynamics(t, s):
                return -0.05 * (s - compilation_success) + self.sde_sigma * np.random.normal(0, 1)
            result = integrate.odeint(compile_dynamics, [compilation_success], [0, self.update_interval], tfirst=True)
            compilation_success = np.clip(result[-1][0], 0.0, 1.0)
            if compilation_success < 0.5:
                raise RuntimeError("Incertidumbre en compilación excede umbral.")
            duration = time.time() - start_time
            self.compilation_times.append(duration)
            # Kalman para suavizar avg_compilation_time_ms
            measurement = duration
            A, H = 1.0, 1.0
            predicted_state = A * self.kalman_state
            predicted_cov = A * self.kalman_cov * A + self.kalman_Q
            innovation = measurement - H * predicted_state
            innovation_cov = H * predicted_cov * H + self.kalman_R
            kalman_gain = predicted_cov * H / innovation_cov
            self.kalman_state = predicted_state + kalman_gain * innovation
            self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
            self.module_state["avg_compilation_time_ms"] = self.kalman_state * 1000
            return module_class, "Compilación exitosa", internal_name
        except Exception as e:
            if internal_name in sys.modules:
                del sys.modules[internal_name]
            return None, str(e), internal_name

    async def _request_sandbox_evaluation(self, name: str, code: str, corr_id: str):
        self.logger.info(f"Enviando código para módulo '{name}' a ExecutionSandbox (CorrID: {corr_id}).")
        sandbox_payload = {
            "code_to_evaluate_str": code,
            "module_name_suggestion": name,
            "tests_to_run": ["basic_instantiation", "lifecycle_methods", "sample_task_execution"],
        }
        future = asyncio.Future()
        self.active_responses[corr_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="ExecutionSandbox",
                message_type="request_sandbox_code_evaluation",
                payload=sandbox_payload,
                correlation_id=corr_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            await asyncio.wait_for(future, timeout=10.0)
            self.logger.info(f"Evaluación en sandbox confirmada para módulo {name}.")
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout esperando evaluación en sandbox para módulo {name}.")
            self.pending_sandbox_evaluations.pop(corr_id, None)
            self.module_graph.remove_node(name)

    async def _handle_sandbox_result(self, sandbox_corr_id: str, sandbox_payload: Dict):
        context = self.pending_sandbox_evaluations.pop(sandbox_corr_id, None)
        if not context:
            self.logger.warning(f"No se encontró contexto para CorrID {sandbox_corr_id}.")
            return
        module_name = context["module_name"]
        if sandbox_payload.get("overall_test_passed", False):
            self.module_state["sandbox_tests_passed"] += 1
            self.logger.info(f"Sandbox APROBÓ el módulo '{module_name}'. Procediendo a integración.")
            await self._integrate_module_into_core(context["module_class"], module_name, context["is_new"])
        else:
            self.module_state["sandbox_tests_failed"] += 1
            self.module_graph.remove_node(module_name)
            self.logger.error(f"Sandbox RECHAZÓ el módulo '{module_name}': {sandbox_payload.get('summary_message', 'No especificado')}")
            if context["internal_py_name"] in sys.modules:
                del sys.modules[context["internal_py_name"]]
            await self._notify_failure(context["original_correlation_id"], f"Sandbox rechazó el módulo: {sandbox_payload.get('summary_message', 'No especificado')}")

    async def _integrate_module_into_core(self, module_class: Type, name: str, is_new: bool):
        try:
            if not is_new and name in self.core_recombinator.modules:
                self.logger.warning(f"Reemplazando módulo existente '{name}'.")
                old_module = self.core_recombinator.modules[name]
                await old_module.shutdown()
            interval = getattr(module_class, 'DEFAULT_UPDATE_INTERVAL', 2.0)
            new_instance = module_class(self.core_recombinator, name, update_interval=interval)
            self.core_recombinator.modules[name] = new_instance
            await new_instance.start()
            self.module_state["modules_integrated_successfully"] += 1
            self.logger.info(f"Módulo '{name}' integrado y activado.")
            # Notificar a SystemIntegrityMonitor
            correlation_id = f"sim_{name}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            self.active_responses[correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="SystemIntegrityMonitor",
                    message_type="system_module_authorization_update",
                    payload={"module_name": name, "authorized": True},
                    correlation_id=correlation_id,
                    priority="high"
                ))
            }, priority_label="high")
            try:
                await asyncio.wait_for(future, timeout=5.0)
                self.logger.info(f"Notificación a SystemIntegrityMonitor confirmada para módulo {name}.")
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout notificando a SystemIntegrityMonitor para módulo {name}.")
                self.core_recombinator.global_state.system_threat_level = min(self.core_recombinator.global_state.system_threat_level + 0.05, 1.0)
        except Exception as e:
            self.module_state["integration_failures"] += 1
            self.module_graph.remove_node(name)
            self.logger.error(f"Fallo crítico durante integración del módulo '{name}': {e}", exc_info=True)
            await self._notify_failure(context.get("original_correlation_id", None), f"Fallo de integración: {str(e)}")

    async def _notify_failure(self, original_correlation_id: Optional[str], reason: str):
        if original_correlation_id:
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="GeneradorCode",
                    message_type="compilation_result",
                    payload={"status": "failed", "reason": reason},
                    correlation_id=original_correlation_id,
                    priority="medium"
                ))
            }, priority_label="medium")

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        if not full_message:
            return
        if event_type == "code_ready_for_compilation":
            await self.compilation_queue.put(full_message)
        elif event_type == "sandbox_evaluation_result":
            await self._handle_sandbox_result(full_message.correlation_id, payload)
        elif full_message.correlation_id in self.active_responses:
            self.active_responses[full_message.correlation_id].set_result(payload)
            del self.active_responses[full_message.correlation_id]
        else:
            await super()._process_specific_event(event_type, payload, full_message)




                          #inicio del modulo ExecutionSandbox 

@dataclass
class SandboxTestResult:
    name: str
    passed: bool
    duration_ms: float
    message: str = ""
    details: Optional[Dict[str, Any]] = field(default_factory=dict)

class ExecutionSandbox(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 2.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.evaluation_queue: asyncio.Queue['IlyukMessageStructure'] = asyncio.Queue(maxsize=20)
        self.active_responses: Dict[str, asyncio.Future] = {}
        self.test_graph = nx.DiGraph()
        self.coherence_field: np.ndarray = np.array([1.0])
        self.max_test_duration_s: float = 10.0
        self.max_output_capture_lines: int = 100
        self.num_mc_samples: int = 500
        self.sde_sigma: float = 0.01
        self.pde_dx: float = 0.1
        self.pde_dt: float = 0.01
        self.pde_diffusion: float = 0.05
        self.module_state.update({
            "evaluations_completed": 0,
            "evaluations_passed": 0,
            "evaluations_failed": 0,
            "evaluations_timed_out": 0,
            "avg_evaluation_time_ms": 0.0,
            "test_coherence_score": 1.0
        })
        self.evaluation_times: List[float] = []
        self.logger.info(f"{self.module_name} v27.2 inicializado con modelado avanzado.")

    async def _update_logic(self):
        if not self.evaluation_queue.empty():
            eval_request_msg = await self.evaluation_queue.get()
            self.evaluation_queue.task_done()
            self._create_managed_task(self._process_evaluation_request(eval_request_msg))
        # Actualizar coherencia entre pruebas
        n_tests = self.test_graph.number_of_nodes()
        if len(self.coherence_field) != max(n_tests, 1):
            self.coherence_field = np.ones(max(n_tests, 1)) * self.module_state["test_coherence_score"]
        conflicts = len(list(nx.simple_cycles(self.test_graph))) if self.test_graph.number_of_nodes() > 0 else 0
        for _ in range(int(self.update_interval / self.pde_dt)):
            d2_coherence = (np.roll(self.coherence_field, 1) + np.roll(self.coherence_field, -1) - 2 * self.coherence_field) / (self.pde_dx ** 2)
            reaction = 0.1 * self.coherence_field * (1.0 - self.coherence_field / max(n_tests, 1) - 0.05 * conflicts)
            self.coherence_field += self.pde_dt * (self.pde_diffusion * d2_coherence + reaction)
            self.coherence_field = np.clip(self.coherence_field, 0.0, 1.0)
        self.module_state["test_coherence_score"] = np.mean(self.coherence_field)

    async def _process_evaluation_request(self, eval_request_msg: 'IlyukMessageStructure'):
        payload = eval_request_msg.payload
        correlation_id = eval_request_msg.correlation_id
        module_name_suggestion = payload.get("module_name_suggestion", "UnknownModule")
        code_str = payload.get("code_to_evaluate_str", "")
        # Validar solicitud
        correlation_id_validate = f"validate_request_{module_name_suggestion}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id_validate] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="ComputationalLogicModule",
                message_type="submit_logical_query_request",
                payload={"query_type": "validate_sandbox_request", "query_payload": payload},
                correlation_id=correlation_id_validate,
                priority="high"
            ))
        }, priority_label="high")
        try:
            validation_result = await asyncio.wait_for(future, timeout=5.0)
            if validation_result.get("status") != "valid":
                self.logger.warning(f"Solicitud no válida: {validation_result.get('error', 'No especificado')}")
                await self._send_evaluation_result(correlation_id, module_name_suggestion, False, f"Solicitud no válida: {validation_result.get('error', 'No especificado')}", [], [validation_result.get("error", "No especificado")], {"stdout": [], "stderr": []})
                return
        except asyncio.TimeoutError:
            self.module_state["evaluations_timed_out"] += 1
            self.logger.warning(f"Timeout validando solicitud para módulo {module_name_suggestion}.")
            await self._send_evaluation_result(correlation_id, module_name_suggestion, False, "Timeout en validación de solicitud.", [], ["Timeout en validación de solicitud."], {"stdout": [], "stderr": []})
            return
        # Validar alineación con valores
        correlation_id_align = f"align_{module_name_suggestion}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id_align] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="ValueSystemModule",
                message_type="request_value_alignment",
                payload={"item_to_evaluate": {"description": f"Evaluación de módulo {module_name_suggestion}", "code": code_str}},
                correlation_id=correlation_id_align,
                priority="medium"
            ))
        }, priority_label="medium")
        try:
            alignment_result = await asyncio.wait_for(future, timeout=5.0)
            if alignment_result.get("overall_alignment_score", -1.0) < 0.0:
                self.logger.warning(f"Código no alineado para módulo {module_name_suggestion}: {alignment_result.get('error_message', 'No especificado')}")
                await self._send_evaluation_result(correlation_id, module_name_suggestion, False, f"Código no alineado: {alignment_result.get('error_message', 'No especificado')}", [], [alignment_result.get("error_message", "No especificado")], {"stdout": [], "stderr": []})
                return
        except asyncio.TimeoutError:
            self.module_state["evaluations_timed_out"] += 1
            self.logger.warning(f"Timeout validando alineación para módulo {module_name_suggestion}.")
            await self._send_evaluation_result(correlation_id, module_name_suggestion, False, "Timeout en validación de alineación.", [], ["Timeout en validación de alineación."], {"stdout": [], "stderr": []})
            return
        # Verificar conflictos
        self.test_graph.add_node(correlation_id, module_name=module_name_suggestion, timestamp=time.time())
        for other_test_id in self.test_graph.nodes:
            if other_test_id != correlation_id and self.test_graph.nodes[other_test_id]["module_name"] == module_name_suggestion:
                self.test_graph.add_edge(correlation_id, other_test_id, weight=1.0)
        conflicts = len(list(nx.simple_cycles(self.test_graph))) if self.test_graph.number_of_nodes() > 0 else 0
        if conflicts > 0:
            self.test_graph.remove_node(correlation_id)
            self.logger.warning(f"Conflicto detectado en evaluación para módulo {module_name_suggestion}.")
            await self._send_evaluation_result(correlation_id, module_name_suggestion, False, "Conflicto entre evaluaciones concurrentes.", [], ["Conflicto entre evaluaciones concurrentes."], {"stdout": [], "stderr": []})
            return
        eval_start_time = time.time()
        overall_passed, summary_msg, test_results, errors, outputs = await self._execute_code_in_sandbox(code_str, module_name_suggestion, payload.get("tests_to_run", []))
        duration_s = time.time() - eval_start_time
        self.evaluation_times.append(duration_s)
        # Kalman para suavizar avg_evaluation_time_ms
        measurement = duration_s
        A, H = 1.0, 1.0
        predicted_state = A * self.kalman_state
        predicted_cov = A * self.kalman_cov * A + self.kalman_Q
        innovation = measurement - H * predicted_state
        innovation_cov = H * predicted_cov * H + self.kalman_R
        kalman_gain = predicted_cov * H / innovation_cov
        self.kalman_state = predicted_state + kalman_gain * innovation
        self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
        self.module_state["avg_evaluation_time_ms"] = self.kalman_state * 1000
        self.module_state["evaluations_completed"] += 1
        if overall_passed:
            self.module_state["evaluations_passed"] += 1
        else:
            self.module_state["evaluations_failed"] += 1
        await self._send_evaluation_result(correlation_id, module_name_suggestion, overall_passed, summary_msg, test_results, errors, outputs)
        self.test_graph.remove_node(correlation_id)

    async def _execute_code_in_sandbox(self, code_str: str, module_name: str, tests_to_run: List[str]) -> Tuple[bool, str, List[SandboxTestResult], List[str], Dict[str, List[str]]]:
        test_results: List[SandboxTestResult] = []
        errors: List[str] = []
        outputs = {"stdout": [], "stderr": []}
        overall_passed = True
        # Crear entorno aislado
        sandbox_globals = {
            "BaseAsyncModule": BaseAsyncModule,
            "asyncio": asyncio,
            "np": np,
            "__builtins__": {
                k: v for k, v in __builtins__.__dict__.items()
                if k not in ["eval", "exec", "compile", "open", "__import__"]
            }
        }
        mock_core = type("MockCore", (object,), {
            "global_state": self.core_recombinator.global_state,
            "post_event_to_core_queue": asyncio.coroutine(lambda *args, **kwargs: None)
        })()
        try:
            module_class = await self._compile_in_sandbox_env(code_str, module_name)
            # Ejecutar pruebas con Monte Carlo para incertidumbre
            for test_name in tests_to_run:
                if test_name == "basic_instantiation":
                    result = await self._test_instantiation(module_class, module_name, mock_core)
                elif test_name == "lifecycle_methods":
                    result = await self._test_lifecycle(module_class, module_name, mock_core)
                elif test_name == "sample_task_execution":
                    result = await self._test_sample_task(module_class, module_name, mock_core)
                else:
                    result = SandboxTestResult(test_name, False, 0.0, f"Test desconocido: {test_name}")
                # Monte Carlo para incertidumbre
                pass_prob = 1.0 if result.passed else 0.0
                samples = np.random.normal(pass_prob, 0.05, self.num_mc_samples)
                pass_prob = np.clip(np.mean(samples), 0.0, 1.0)
                # SDE para dinámica
                def test_dynamics(t, p):
                    return -0.05 * (p - pass_prob) + self.sde_sigma * np.random.normal(0, 1)
                result_ode = integrate.odeint(test_dynamics, [pass_prob], [0, self.max_test_duration_s], tfirst=True)
                pass_prob = np.clip(result_ode[-1][0], 0.0, 1.0)
                result.passed = pass_prob > 0.5
                test_results.append(result)
                if not result.passed:
                    errors.append(result.message)
            overall_passed = all(res.passed for res in test_results)
            summary_message = "Todos los tests pasaron." if overall_passed else "Uno o más tests fallaron."
        except Exception as e:
            overall_passed = False
            summary_message = f"Fallo crítico durante la configuración del sandbox: {str(e)}"
            errors.append(summary_message)
        return overall_passed, summary_message, test_results, errors, outputs

    async def _compile_in_sandbox_env(self, code_str: str, module_name: str) -> Type:
        internal_name = f"sandbox_dyn_{module_name.lower()}_{uuid.uuid4().hex[:4]}"
        spec = importlib.util.spec_from_loader(internal_name, loader=None)
        if not spec:
            raise RuntimeError("Fallo al crear spec de módulo.")
        module_obj = importlib.util.module_from_spec(spec)
        sandbox_globals = {
            "BaseAsyncModule": BaseAsyncModule,
            "asyncio": asyncio,
            "np": np,
            "__builtins__": {
                k: v for k, v in __builtins__.__dict__.items()
                if k not in ["eval", "exec", "compile", "open", "__import__"]
            }
        }
        module_obj.__dict__.update(sandbox_globals)
        try:
            exec(code_str, module_obj.__dict__)
        except Exception as e:
            raise RuntimeError(f"Fallo al compilar código en sandbox: {str(e)}")
        module_class = getattr(module_obj, module_name, None)
        if not inspect.isclass(module_class) or not issubclass(module_class, BaseAsyncModule):
            raise TypeError(f"Clase '{module_name}' no encontrada o no hereda de BaseAsyncModule.")
        return module_class

    async def _test_instantiation(self, module_class: Type, name: str, core: Any) -> SandboxTestResult:
        start = time.time()
        try:
            async with asyncio.timeout(self.max_test_duration_s):
                instance = module_class(core, name)
                if isinstance(instance, BaseAsyncModule):
                    return SandboxTestResult("instantiation", True, (time.time() - start) * 1000, "Instancia creada exitosamente.", {"module_name": name})
        except asyncio.TimeoutError:
            self.module_state["evaluations_timed_out"] += 1
            return SandboxTestResult("instantiation", False, (time.time() - start) * 1000, "Timeout durante instanciación.")
        except Exception as e:
            return SandboxTestResult("instantiation", False, (time.time() - start) * 1000, f"Fallo: {str(e)}")
        return SandboxTestResult("instantiation", False, (time.time() - start) * 1000, "Fallo desconocido.")

    async def _test_lifecycle(self, module_class: Type, name: str, core: Any) -> SandboxTestResult:
        start = time.time()
        try:
            async with asyncio.timeout(self.max_test_duration_s):
                instance = module_class(core, name)
                await instance.start()
                await asyncio.sleep(0.01)
                await instance.shutdown()
                if instance.module_state.get("status") == "shutdown_complete":
                    return SandboxTestResult("lifecycle", True, (time.time() - start) * 1000, "Ciclo de vida start/shutdown OK.", {"module_name": name})
                return SandboxTestResult("lifecycle", False, (time.time() - start) * 1000, "Fallo en ciclo de vida.")
        except asyncio.TimeoutError:
            self.module_state["evaluations_timed_out"] += 1
            return SandboxTestResult("lifecycle", False, (time.time() - start) * 1000, "Timeout durante ciclo de vida.")
        except Exception as e:
            return SandboxTestResult("lifecycle", False, (time.time() - start) * 1000, f"Fallo: {str(e)}")
        return SandboxTestResult("lifecycle", False, (time.time() - start) * 1000, "Fallo desconocido.")

    async def _test_sample_task(self, module_class: Type, name: str, core: Any) -> SandboxTestResult:
        start = time.time()
        try:
            async with asyncio.timeout(self.max_test_duration_s):
                instance = module_class(core, name)
                result = await instance.execute_task({"task_id": "sandbox_test", "description": "Test"})
                if isinstance(result, dict) and "status" in result:
                    return SandboxTestResult("sample_task", True, (time.time() - start) * 1000, f"Tarea_hyperlinkarea ejecutada con estado: {result['status']}.", {"module_name": name, "task_result": result})
                return SandboxTestResult("sample_task", False, (time.time() - start) * 1000, "Fallo: Resultado inválido.")
        except asyncio.TimeoutError:
            self.module_state["evaluations_timed_out"] += 1
            return SandboxTestResult("sample_task", False, (time.time() - start) * 1000, "Timeout durante ejecución de tarea.")
        except Exception as e:
            return SandboxTestResult("sample_task", False, (time.time() - start) * 1000, f"Fallo: {str(e)}")
        return SandboxTestResult("sample_task", False, (time.time() - start) * 1000, "Fallo desconocido.")

    async def _send_evaluation_result(self, corr_id: str, name: str, passed: bool, summary: str, results: List[SandboxTestResult], errors: List[str], outputs: Dict[str, List[str]]):
        response_payload = {
            "module_name_evaluated": name,
            "overall_test_passed": passed,
            "summary_message": summary,
            "detailed_test_results": [asdict(r) for r in results],
            "errors_during_evaluation": errors,
            "captured_outputs": outputs
        }
        future = asyncio.Future()
        self.active_responses[corr_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="JITModuleCompiler",
                message_type="sandbox_evaluation_result",
                payload=response_payload,
                correlation_id=corr_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            await asyncio.wait_for(future, timeout=5.0)
            self.logger.info(f"Resultado de evaluación enviado para módulo {name}.")
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout enviando resultado de evaluación para módulo {name}.")

    async def _process_specific_event(self, event_type: str, payload: Dict, full_message: Optional['IlyukMessageStructure'] = None):
        if event_type == "request_sandbox_code_evaluation" and full_message:
            await self.evaluation_queue.put(full_message)
        elif full_message and full_message.correlation_id in self.active_responses:
            self.active_responses[full_message.correlation_id].set_result(payload)
            del self.active_responses[full_message.correlation_id]
        else:
            await super()._process_specific_event(event_type, payload, full_message)





                            #inicio del modulo DynamicArchitectureAdjuster

@dataclass
class ArchitectureAdjustmentRequest:
    request_id: str = field(default_factory=lambda: f"daa_req_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    adjustment_type: str
    target_module_name: Optional[str] = None
    new_module_code_str: Optional[str] = None
    new_module_name_suggestion: Optional[str] = None
    parameter_updates: Dict[str, Any] = field(default_factory=dict)
    status: str = "pending_validation"
    result_message: Optional[str] = None
    _internal_sub_op_correlation_id: Optional[str] = None

class DynamicArchitectureAdjuster(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 1.5

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.adjustment_request_queue: asyncio.Queue[ArchitectureAdjustmentRequest] = asyncio.Queue(maxlen=20)
        self.active_adjustments: Dict[str, ArchitectureAdjustmentRequest] = {}
        self.active_responses: Dict[str, asyncio.Future] = {}
        self.adjustment_graph = nx.DiGraph()
        self.coherence_field: np.ndarray = np.array([1.0])
        self.num_mc_samples: int = 500
        self.sde_sigma: float = 0.01
        self.pde_dx: float = 0.1
        self.pde_dt: float = 0.01
        self.pde_diffusion: float = 0.05
        self.authorized_requesters: Set[str] = {
            "SelfEvolutionModule", "FaultRecoveryModule",
            "CreatorDirectivesModule", self.module_name
        }
        self.module_state.update({
            "requests_processed": 0,
            "adjustments_completed_successfully": 0,
            "adjustments_failed": 0,
            "unauthorized_requests_denied": 0,
            "last_adjustment_type": "none",
            "adjustment_coherence_score": 1.0
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado con modelado avanzado.")

    async def _update_logic(self):
        if not self.adjustment_request_queue.empty() and len(self.active_adjustments) < 2:
            request = await self.adjustment_request_queue.get()
            self.adjustment_request_queue.task_done()
            self.active_adjustments[request.request_id] = request
            self._create_managed_task(self._process_single_adjustment(request))
        # Actualizar coherencia entre ajustes
        n_adjustments = self.adjustment_graph.number_of_nodes()
        if len(self.coherence_field) != max(n_adjustments, 1):
            self.coherence_field = np.ones(max(n_adjustments, 1)) * self.module_state["adjustment_coherence_score"]
        conflicts = len(list(nx.simple_cycles(self.adjustment_graph))) if self.adjustment_graph.number_of_nodes() > 0 else 0
        for _ in range(int(self.update_interval / self.pde_dt)):
            d2_coherence = (np.roll(self.coherence_field, 1) + np.roll(self.coherence_field, -1) - 2 * self.coherence_field) / (self.pde_dx ** 2)
            reaction = 0.1 * self.coherence_field * (1.0 - self.coherence_field / max(n_adjustments, 1) - 0.05 * conflicts)
            self.coherence_field += self.pde_dt * (self.pde_diffusion * d2_coherence + reaction)
            self.coherence_field = np.clip(self.coherence_field, 0.0, 1.0)
        self.module_state["adjustment_coherence_score"] = np.mean(self.coherence_field)

    async def _process_single_adjustment(self, request: ArchitectureAdjustmentRequest):
        # Validar solicitud
        is_valid, msg = await self._validate_request(request)
        if not is_valid:
            request.status = "failed"
            request.result_message = msg
            self.module_state["adjustments_failed"] += 1
            await self._finalize_adjustment(request)
            return
        # Verificar conflictos
        self.adjustment_graph.add_node(request.request_id, adjustment_type=request.adjustment_type, target_module=request.target_module_name)
        for other_id in self.active_adjustments:
            if other_id != request.request_id:
                other = self.active_adjustments[other_id]
                if (other.adjustment_type in ["add_module", "replace_module", "remove_module"] and
                    request.adjustment_type in ["add_module", "replace_module", "remove_module"] and
                    other.target_module_name == request.target_module_name):
                    self.adjustment_graph.add_edge(request.request_id, other_id, weight=1.0)
        conflicts = len(list(nx.simple_cycles(self.adjustment_graph))) if self.adjustment_graph.number_of_nodes() > 0 else 0
        if conflicts > 0:
            request.status = "failed"
            request.result_message = f"Conflicto detectado con otro ajuste para módulo {request.target_module_name}."
            self.module_state["adjustments_failed"] += 1
            self.adjustment_graph.remove_node(request.request_id)
            await self._finalize_adjustment(request)
            return
        # Actualizar métrica con Kalman
        request_count = self.module_state["requests_processed"] + 1
        measurement = request_count
        A, H = 1.0, 1.0
        predicted_state = A * self.kalman_state
        predicted_cov = A * self.kalman_cov * A + self.kalman_Q
        innovation = measurement - H * predicted_state
        innovation_cov = H * predicted_cov * H + self.kalman_R
        kalman_gain = predicted_cov * H / innovation_cov
        self.kalman_state = predicted_state + kalman_gain * innovation
        self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
        self.module_state["requests_processed"] = int(self.kalman_state)
        self.module_state["last_adjustment_type"] = request.adjustment_type
        request.status = "executing"
        try:
            if request.adjustment_type in ["add_module", "replace_module"]:
                await self._handle_module_compilation_request(request)
            elif request.adjustment_type == "remove_module":
                await self._handle_module_removal(request)
            elif request.adjustment_type == "set_module_parameter":
                await self._handle_parameter_update(request)
        except Exception as e:
            request.status = "failed"
            request.result_message = f"Fallo en ejecución: {str(e)}"
            self.module_state["adjustments_failed"] += 1
            self.adjustment_graph.remove_node(request.request_id)
            await self._finalize_adjustment(request)

    async def _validate_request(self, request: ArchitectureAdjustmentRequest) -> Tuple[bool, str]:
        # Validación básica
        if request.source_module_id not in self.authorized_requesters:
            self.module_state["unauthorized_requests_denied"] += 1
            return False, f"Fuente no autorizada: {request.source_module_id}"
        if request.adjustment_type == "add_module":
            if not request.new_module_code_str or not request.new_module_name_suggestion:
                return False, "'add_module' requiere 'new_module_code_str' y 'new_module_name_suggestion'."
        elif request.adjustment_type == "remove_module":
            if not request.target_module_name:
                return False, "'remove_module' requiere 'target_module_name'."
            if request.target_module_name in ["CNEUnifiedCoreRecombinator", self.module_name, "SystemIntegrityMonitor"]:
                return False, f"No se puede eliminar el módulo crítico '{request.target_module_name}'."
        elif request.adjustment_type == "set_module_parameter":
            if not request.target_module_name or not request.parameter_updates:
                return False, "'set_module_parameter' requiere 'target_module_name' y 'parameter_updates'."
        # Validación lógica
        correlation_id = f"validate_request_{request.request_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="ComputationalLogicModule",
                message_type="submit_logical_query_request",
                payload={"query_type": "validate_architecture_adjustment", "query_payload": asdict(request)},
                correlation_id=correlation_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            validation_result = await asyncio.wait_for(future, timeout=5.0)
            if validation_result.get("status") != "valid":
                return False, f"Validación lógica fallida: {validation_result.get('error', 'No especificado')}"
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout validando solicitud {request.request_id}.")
            return False, "Timeout en validación lógica."
        # Validación de alineación
        correlation_id = f"align_request_{request.request_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="ValueSystemModule",
                message_type="request_value_alignment",
                payload={"item_to_evaluate": {"adjustment_type": request.adjustment_type, "target_module_name": request.target_module_name, "new_module_code_str": request.new_module_code_str}},
                correlation_id=correlation_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            alignment_result = await asyncio.wait_for(future, timeout=5.0)
            if alignment_result.get("overall_alignment_score", -1.0) < 0.0:
                return False, f"Alineación fallida: {alignment_result.get('error_message', 'No especificado')}"
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout validando alineación para solicitud {request.request_id}.")
            return False, "Timeout en validación de alineación."
        # Evaluación de impacto
        correlation_id = f"impact_request_{request.request_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="SelfEvolutionModule",
                message_type="evaluate_architecture_impact",
                payload={"adjustment_type": request.adjustment_type, "target_module_name": request.target_module_name, "new_module_code_str": request.new_module_code_str},
                correlation_id=correlation_id,
                priority="medium"
            ))
        }, priority_label="medium")
        try:
            impact_result = await asyncio.wait_for(future, timeout=5.0)
            impact_score = impact_result.get("impact_score", 0.0)
            samples = np.random.normal(impact_score, 0.05, self.num_mc_samples)
            impact_score = np.clip(np.mean(samples), 0.0, 1.0)
            def impact_dynamics(t, p):
                return -0.05 * (p - impact_score) + self.sde_sigma * np.random.normal(0, 1)
            result = integrate.odeint(impact_dynamics, [impact_score], [0, self.update_interval], tfirst=True)
            impact_score = np.clip(result[-1][0], 0.0, 1.0)
            if impact_score < 0.5:
                return False, f"Impacto insuficiente: {impact_result.get('error_message', 'Impacto demasiado bajo')}"
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout evaluando impacto para solicitud {request.request_id}.")
            return False, "Timeout en evaluación de impacto."
        return True, "Validación OK."

    async def _handle_module_compilation_request(self, request: ArchitectureAdjustmentRequest):
        sub_corr_id = f"daa_jit_{request.request_id}_{uuid.uuid4().hex[:8]}"
        request._internal_sub_op_correlation_id = sub_corr_id
        request.status = "awaiting_jit_confirmation"
        payload_for_jit = {
            "generated_code_str": request.new_module_code_str,
            "module_name_suggestion": request.new_module_name_suggestion or request.target_module_name,
            "is_new_module_request": request.adjustment_type == "add_module"
        }
        future = asyncio.Future()
        self.active_responses[sub_corr_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="JITModuleCompiler",
                message_type="code_ready_for_compilation",
                payload=payload_for_jit,
                correlation_id=sub_corr_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            result = await asyncio.wait_for(future, timeout=30.0)
            request.status = "completed" if result.get("final_processing_status_jit") == "success" else "failed_jit_operation"
            request.result_message = result.get("final_message_jit")
            await self._notify_sim_of_change(request.target_module_name or request.new_module_name_suggestion, request.adjustment_type)
            await self._finalize_adjustment(request)
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout esperando respuesta de JITModuleCompiler para solicitud {request.request_id}.")
            request.status = "failed"
            request.result_message = "Timeout en compilación de módulo."
            self.module_state["adjustments_failed"] += 1
            self.adjustment_graph.remove_node(request.request_id)
            await self._finalize_adjustment(request)

    async def _handle_module_removal(self, request: ArchitectureAdjustmentRequest):
        mod_name = str(request.target_module_name)
        if mod_name in self.core_recombinator.modules:
            instance = self.core_recombinator.modules.pop(mod_name)
            await instance.shutdown()
            await self._notify_sim_of_change(mod_name, "removed")
            request.status = "completed"
            request.result_message = f"Módulo '{mod_name}' eliminado exitosamente."
        else:
            request.status = "failed"
            request.result_message = f"Módulo '{mod_name}' no encontrado."
            self.module_state["adjustments_failed"] += 1
        self.adjustment_graph.remove_node(request.request_id)
        await self._finalize_adjustment(request)

    async def _handle_parameter_update(self, request: ArchitectureAdjustmentRequest):
        target_mod_name = str(request.target_module_name)
        sub_corr_id = f"daa_config_{request.request_id}_{uuid.uuid4().hex[:8]}"
        request._internal_sub_op_correlation_id = sub_corr_id
        request.status = "awaiting_config_executor_ack"
        future = asyncio.Future()
        self.active_responses[sub_corr_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="ConfigurationExecutorModule",
                message_type="apply_parameter_update_request",
                payload={"target_module_id": target_mod_name, "parameter_updates": request.parameter_updates},
                correlation_id=sub_corr_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            result = await asyncio.wait_for(future, timeout=10.0)
            request.status = "completed" if result.get("status") == "success" else "failed_config_update"
            request.result_message = result.get("message", "No message provided")
            await self._notify_sim_of_change(target_mod_name, "parameter_updated")
            await self._finalize_adjustment(request)
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout esperando respuesta de ConfigurationExecutorModule para solicitud {request.request_id}.")
            request.status = "failed"
            request.result_message = "Timeout en actualización de parámetros."
            self.module_state["adjustments_failed"] += 1
            self.adjustment_graph.remove_node(request.request_id)
            await self._finalize_adjustment(request)

    async def _finalize_adjustment(self, request: ArchitectureAdjustmentRequest):
        if request.status == "completed":
            self.module_state["adjustments_completed_successfully"] += 1
        else:
            self.module_state["adjustments_failed"] += 1
        if request.original_correlation_id and request.source_module_id:
            future = asyncio.Future()
            self.active_responses[request.original_correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id=request.source_module_id,
                    message_type="architecture_adjustment_completed_notice",
                    payload={"request_id_ref": request.request_id, "status": request.status, "message": request.result_message},
                    correlation_id=request.original_correlation_id,
                    priority="high"
                ))
            }, priority_label="high")
            try:
                await asyncio.wait_for(future, timeout=5.0)
                self.logger.info(f"Confirmación de finalización para solicitud {request.request_id} enviada.")
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout notificando finalización de solicitud {request.request_id}.")
        if request.request_id in self.active_adjustments:
            del self.active_adjustments[request.request_id]

    async def _notify_sim_of_change(self, module_name: str, change_type: str):
        correlation_id = f"sim_notify_{module_name}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="SystemIntegrityMonitor",
                message_type="system_module_authorization_update",
                payload={"module_name": module_name, "authorized": change_type != "removed", "reason": f"DAA performed '{change_type}'"},
                correlation_id=correlation_id,
                priority="critical"
            ))
        }, priority_label="critical")
        try:
            await asyncio.wait_for(future, timeout=5.0)
            self.logger.info(f"Notificación a SystemIntegrityMonitor para {module_name} ({change_type}) enviada.")
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout notificando a SystemIntegrityMonitor para {module_name} ({change_type}).")

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        if not full_message:
            return
        corr_id = full_message.correlation_id
        active_request = next((r for r in self.active_adjustments.values() if r._internal_sub_op_correlation_id == corr_id), None)
        if active_request and event_type == "jit_module_processing_final_result":
            active_request.status = "completed" if payload.get("final_processing_status_jit") == "success" else "failed_jit_operation"
            active_request.result_message = payload.get("final_message_jit")
            self.adjustment_graph.remove_node(active_request.request_id)
            await self._finalize_adjustment(active_request)
        elif active_request and event_type == "apply_parameter_update_response":
            active_request.status = "completed" if payload.get("status") == "success" else "failed_config_update"
            active_request.result_message = payload.get("message", "No message provided")
            self.adjustment_graph.remove_node(active_request.request_id)
            await self._finalize_adjustment(active_request)
        elif event_type == "request_architecture_adjustment":
            req = ArchitectureAdjustmentRequest(
                source_module_id=full_message.source_module_id,
                original_correlation_id=full_message.correlation_id,
                **payload
            )
            await self.adjustment_request_queue.put(req)
        if corr_id in self.active_responses:
            self.active_responses[corr_id].set_result(payload)
            del self.active_responses[corr_id]
        else:
            await super()._process_specific_event(event_type, payload, full_message)




                              #inicio del modulo MetaEvolutionaryAdaptationModule 

@dataclass
class MEAMIntervention:
    intervention_id: str
    type: str
    status: str = "dispatched"
    dispatch_ts: float = field(default_factory=time.time)
    dispatch_fitness: float
    completion_ts: Optional[float] = None
    final_fitness: Optional[float] = None
    effectiveness_score: Optional[float] = None

class MetaEvolutionaryAdaptationModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 75.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.fitness_threshold_for_intervention: float = 0.65
        self.adaptation_intensity: float = 0.5
        self.meta_adaptation_energy: float = 1.0
        self.energy_cost_intensive_evo: float = 0.35
        self.energy_cost_landscape_shift: float = 0.45
        self.energy_recovery_rate: float = 0.01
        self.monitoring_period_s: float = self.update_interval * 4
        self.num_mc_samples: int = 500
        self.sde_sigma: float = 0.01
        self.pde_dx: float = 0.1
        self.pde_dt: float = 0.01
        self.pde_diffusion: float = 0.05
        self.fitness_history: deque[Tuple[float, float]] = deque(maxlen=50)
        self.active_interventions: Dict[str, MEAMIntervention] = {}
        self.active_responses: Dict[str, asyncio.Future] = {}
        self.intervention_graph = nx.DiGraph()
        self.coherence_field: np.ndarray = np.array([1.0])
        self.intervention_effectiveness_scores: List[float] = []
        self.module_state.update({
            "current_meta_strategy": "monitoring",
            "last_system_fitness_score": 0.7,
            "interventions_performed": 0,
            "avg_intervention_effectiveness": 0.0,
            "current_adaptation_energy": self.meta_adaptation_energy,
            "intervention_coherence_score": 1.0
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado con modelado avanzado.")

    async def _update_logic(self):
        self._recover_energy()
        current_fitness = await self._calculate_system_fitness()
        if current_fitness is None:
            return
        self.fitness_history.append((time.time(), current_fitness))
        self.module_state["last_system_fitness_score"] = current_fitness
        await self._evaluate_completed_interventions(current_fitness)
        await self._decide_and_dispatch_intervention(current_fitness)
        # Actualizar coherencia entre intervenciones
        n_interventions = self.intervention_graph.number_of_nodes()
        if len(self.coherence_field) != max(n_interventions, 1):
            self.coherence_field = np.ones(max(n_interventions, 1)) * self.module_state["intervention_coherence_score"]
        conflicts = len(list(nx.simple_cycles(self.intervention_graph))) if self.intervention_graph.number_of_nodes() > 0 else 0
        for _ in range(int(self.update_interval / self.pde_dt)):
            d2_coherence = (np.roll(self.coherence_field, 1) + np.roll(self.coherence_field, -1) - 2 * self.coherence_field) / (self.pde_dx ** 2)
            reaction = 0.1 * self.coherence_field * (1.0 - self.coherence_field / max(n_interventions, 1) - 0.05 * conflicts)
            self.coherence_field += self.pde_dt * (self.pde_diffusion * d2_coherence + reaction)
            self.coherence_field = np.clip(self.coherence_field, 0.0, 1.0)
        self.module_state["intervention_coherence_score"] = np.mean(self.coherence_field)

    def _recover_energy(self):
        gs = self.core_recombinator.global_state
        recovery_potential = (gs.phi_functional_score * 0.7 + gs.coherence_score * 0.3)
        # Monte Carlo para incertidumbre
        samples = np.random.normal(recovery_potential, 0.05, self.num_mc_samples)
        recovery_potential = np.clip(np.mean(samples), 0.0, 1.0)
        self.meta_adaptation_energy = min(1.0, self.meta_adaptation_energy + self.energy_recovery_rate * recovery_potential)
        self.module_state["current_adaptation_energy"] = self.meta_adaptation_energy

    async def _calculate_system_fitness(self) -> Optional[float]:
        gs = self.core_recombinator.global_state
        weights = {"coh": 0.3, "phi": 0.3, "threat_inv": 0.2, "goals": 0.2}
        goal_success_rate = 0.7
        target_fitness = (gs.coherence_score * weights["coh"] + gs.phi_functional_score * weights["phi"] + (1.0 - gs.system_threat_level) * weights["threat_inv"] + goal_success_rate * weights["goals"])
        # Monte Carlo para incertidumbre
        samples = np.random.normal(target_fitness, 0.05, self.num_mc_samples)
        target_fitness = np.clip(np.mean(samples), 0.0, 1.0)
        # SDE para dinámica
        def fitness_dynamics(t, p):
            return -0.05 * (p - target_fitness) + self.sde_sigma * np.random.normal(0, 1)
        last_fitness = self.module_state.get("last_system_fitness_score", target_fitness)
        result = integrate.odeint(fitness_dynamics, [last_fitness], [0, self.update_interval], tfirst=True)
        current_fitness = np.clip(result[-1][0], 0.0, 1.0)
        return current_fitness

    async def _decide_and_dispatch_intervention(self, current_fitness: float):
        if current_fitness < self.fitness_threshold_for_intervention and not any(i.status != 'evaluated' for i in self.active_interventions.values()):
            # Validar intervención
            intervention_type = "landscape_shift" if current_fitness < self.fitness_threshold_for_intervention * 0.7 else "intensive_evolution"
            correlation_id = f"validate_intervention_{intervention_type}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            self.active_responses[correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="ComputationalLogicModule",
                    message_type="submit_logical_query_request",
                    payload={"query_type": "validate_meam_intervention", "query_payload": {"intervention_type": intervention_type, "fitness": current_fitness}},
                    correlation_id=correlation_id,
                    priority="high"
                ))
            }, priority_label="high")
            try:
                validation_result = await asyncio.wait_for(future, timeout=5.0)
                if validation_result.get("status") != "valid":
                    self.logger.warning(f"Intervención {intervention_type} no válida: {validation_result.get('error', 'No especificado')}")
                    return
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout validando intervención {intervention_type}.")
                return
            # Validar alineación
            correlation_id = f"align_intervention_{intervention_type}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            self.active_responses[correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="ValueSystemModule",
                    message_type="request_value_alignment",
                    payload={"item_to_evaluate": {"intervention_type": intervention_type, "fitness": current_fitness}},
                    correlation_id=correlation_id,
                    priority="high"
                ))
            }, priority_label="high")
            try:
                alignment_result = await asyncio.wait_for(future, timeout=5.0)
                if alignment_result.get("overall_alignment_score", -1.0) < 0.0:
                    self.logger.warning(f"Intervención {intervention_type} no alineada: {alignment_result.get('error_message', 'No especificado')}")
                    return
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout validando alineación para intervención {intervention_type}.")
                return
            # Verificar impacto
            correlation_id = f"impact_intervention_{intervention_type}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            self.active_responses[correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="SystemIntegrityMonitor",
                    message_type="evaluate_system_impact",
                    payload={"intervention_type": intervention_type, "fitness": current_fitness},
                    correlation_id=correlation_id,
                    priority="medium"
                ))
            }, priority_label="medium")
            try:
                impact_result = await asyncio.wait_for(future, timeout=5.0)
                impact_score = impact_result.get("impact_score", 0.0)
                samples = np.random.normal(impact_score, 0.05, self.num_mc_samples)
                impact_score = np.clip(np.mean(samples), 0.0, 1.0)
                if impact_score < 0.5:
                    self.logger.warning(f"Intervención {intervention_type} con impacto insuficiente: {impact_result.get('error_message', 'Impacto demasiado bajo')}")
                    return
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout evaluando impacto para intervención {intervention_type}.")
                return
            # Despachar intervención
            if intervention_type == "intensive_evolution":
                await self._dispatch_intensive_evolution(current_fitness)
            else:
                await self._dispatch_landscape_shift(current_fitness)

    async def _dispatch_intensive_evolution(self, fitness: float):
        if self.meta_adaptation_energy < self.energy_cost_intensive_evo:
            return
        intervention_id = f"meam_int_evo_{uuid.uuid4().hex[:6]}"
        self.intervention_graph.add_node(intervention_id, type="intensive_evolution")
        for other_id in self.active_interventions:
            if self.active_interventions[other_id].type == "intensive_evolution":
                self.intervention_graph.add_edge(intervention_id, other_id, weight=1.0)
        conflicts = len(list(nx.simple_cycles(self.intervention_graph))) if self.intervention_graph.number_of_nodes() > 0 else 0
        if conflicts > 0:
            self.logger.warning(f"Conflicto detectado en intervención {intervention_id}.")
            self.intervention_graph.remove_node(intervention_id)
            return
        self.meta_adaptation_energy -= self.energy_cost_intensive_evo
        self.module_state["interventions_performed"] += 1
        self.active_interventions[intervention_id] = MEAMIntervention(intervention_id, "intensive_evolution", dispatch_fitness=fitness)
        future = asyncio.Future()
        self.active_responses[intervention_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="SelfEvolutionModule",
                message_type="trigger_intensive_evolution_command",
                payload={"reason": f"MEAM detectó bajo Fitness ({fitness:.2f})", "intensity": self.adaptation_intensity},
                correlation_id=intervention_id,
                priority="critical"
            ))
        }, priority_label="critical")
        try:
            await asyncio.wait_for(future, timeout=10.0)
            self.logger.info(f"Confirmación de intervención {intervention_id} recibida.")
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout esperando confirmación de intervención {intervention_id}.")
            self.active_interventions[intervention_id].status = "evaluated"
            self.active_interventions[intervention_id].effectiveness_score = -1.0
            self.intervention_graph.remove_node(intervention_id)
            self._adjust_meta_parameters(self.active_interventions[intervention_id])

    async def _dispatch_landscape_shift(self, fitness: float):
        if self.meta_adaptation_energy < self.energy_cost_landscape_shift:
            return
        intervention_id = f"meam_shift_{uuid.uuid4().hex[:6]}"
        self.intervention_graph.add_node(intervention_id, type="landscape_shift")
        for other_id in self.active_interventions:
            if self.active_interventions[other_id].type == "landscape_shift":
                self.intervention_graph.add_edge(intervention_id, other_id, weight=1.0)
        conflicts = len(list(nx.simple_cycles(self.intervention_graph))) if self.intervention_graph.number_of_nodes() > 0 else 0
        if conflicts > 0:
            self.logger.warning(f"Conflicto detectado en intervención {intervention_id}.")
            self.intervention_graph.remove_node(intervention_id)
            return
        self.meta_adaptation_energy -= self.energy_cost_landscape_shift
        self.module_state["interventions_performed"] += 1
        self.active_interventions[intervention_id] = MEAMIntervention(intervention_id, "landscape_shift", dispatch_fitness=fitness)
        future = asyncio.Future()
        self.active_responses[intervention_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="DynamicArchitectureAdjuster",
                message_type="request_architecture_adjustment",
                payload={"adjustment_type": "explore_parameter_perturbations_strategic", "reason": f"MEAM detectó fitness crítico ({fitness:.2f})"},
                correlation_id=intervention_id,
                priority="critical"
            ))
        }, priority_label="critical")
        try:
            await asyncio.wait_for(future, timeout=10.0)
            self.logger.info(f"Confirmación de intervención {intervention_id} recibida.")
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout esperando confirmación de intervención {intervention_id}.")
            self.active_interventions[intervention_id].status = "evaluated"
            self.active_interventions[intervention_id].effectiveness_score = -1.0
            self.intervention_graph.remove_node(intervention_id)
            self._adjust_meta_parameters(self.active_interventions[intervention_id])

    async def _evaluate_completed_interventions(self, current_fitness: float):
        now = time.time()
        for intervention_id in list(self.active_interventions.keys()):
            intervention = self.active_interventions[intervention_id]
            if intervention.status == "monitoring" and now > intervention.completion_ts + self.monitoring_period_s:
                intervention.final_fitness = current_fitness
                delta_fitness = intervention.final_fitness - intervention.dispatch_fitness
                effectiveness = np.clip(delta_fitness / max(0.1, 1.0 - intervention.dispatch_fitness), -1.0, 1.0)
                # Monte Carlo para incertidumbre
                samples = np.random.normal(effectiveness, 0.05, self.num_mc_samples)
                effectiveness = np.clip(np.mean(samples), -1.0, 1.0)
                intervention.effectiveness_score = effectiveness
                intervention.status = "evaluated"
                self.intervention_effectiveness_scores.append(effectiveness)
                # Kalman para suavizar avg_intervention_effectiveness
                measurement = effectiveness
                A, H = 1.0, 1.0
                predicted_state = A * self.kalman_state
                predicted_cov = A * self.kalman_cov * A + self.kalman_Q
                innovation = measurement - H * predicted_state
                innovation_cov = H * predicted_cov * H + self.kalman_R
                kalman_gain = predicted_cov * H / innovation_cov
                self.kalman_state = predicted_state + kalman_gain * innovation
                self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
                self.module_state["avg_intervention_effectiveness"] = self.kalman_state
                self.logger.info(f"Intervención MEAM '{intervention_id}' evaluada. Efectividad: {effectiveness:.2f} (Fitness: {intervention.dispatch_fitness:.2f} -> {current_fitness:.2f})")
                self._adjust_meta_parameters(intervention)
                self.intervention_graph.remove_node(intervention_id)
                del self.active_interventions[intervention_id]

    def _adjust_meta_parameters(self, completed_intervention: MEAMIntervention):
        effectiveness = completed_intervention.effectiveness_score
        adjustment_factor = 0.05 * effectiveness
        self.adaptation_intensity = np.clip(self.adaptation_intensity + adjustment_factor, 0.2, 0.9)
        self.logger.info(f"MEAM auto-ajustado. Nueva intensidad de adaptación: {self.adaptation_intensity:.2f}")

    async def _process_specific_event(self, event_type: str, payload: Dict, full_message: Optional['IlyukMessageStructure'] = None):
        if not full_message:
            return
        corr_id = full_message.correlation_id
        if corr_id in self.active_interventions:
            intervention = self.active_interventions[corr_id]
            if intervention.status == "dispatched":
                if payload.get("status") == "completed" or payload.get("final_status") == "completed":
                    intervention.status = "monitoring"
                    intervention.completion_ts = time.time()
                    self.logger.info(f"MEAM: Acción para intervención '{corr_id}' completada por '{full_message.source_module_id}'. Iniciando período de monitoreo de {self.monitoring_period_s}s.")
                else:
                    intervention.status = "evaluated"
                    intervention.effectiveness_score = -1.0
                    self.intervention_effectiveness_scores.append(-1.0)
                    self.module_state["avg_intervention_effectiveness"] = np.mean(self.intervention_effectiveness_scores[-20:])
                    self.logger.error(f"MEAM: Acción para intervención '{corr_id}' falló en el módulo ejecutor. Descartando intervención.")
                    self._adjust_meta_parameters(intervention)
                    self.intervention_graph.remove_node(corr_id)
                    del self.active_interventions[corr_id]
        if corr_id in self.active_responses:
            self.active_responses[corr_id].set_result(payload)
            del self.active_responses[corr_id]
        else:
            await super()._process_specific_event(event_type, payload, full_message)
 


  #inicio del modulo ShimyureshonCompiler 

@dataclass
class ShimyureshonRequest:
    request_id: str = field(default_factory=lambda: f"sim_req_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    scenario_description: str
    initial_conditions: Dict[str, Any]
    simulation_parameters: Dict[str, Any]
    status: str = "pending"
    result: Optional[Dict[str, Any]] = None

class ShimyureshonCompiler(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 3.0
    MAX_CONCURRENT_SIMULATIONS = 2

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.simulation_request_queue: asyncio.Queue[ShimyureshonRequest] = asyncio.Queue(maxlen=10)
        self.active_simulations: Dict[str, asyncio.Task] = {}
        self.active_responses: Dict[str, asyncio.Future] = {}
        self.simulation_graph = nx.DiGraph()
        self.coherence_field: np.ndarray = np.array([1.0])
        self.num_mc_samples: int = 500
        self.sde_sigma: float = 0.01
        self.pde_dx: float = 0.1
        self.pde_dt: float = 0.01
        self.pde_diffusion: float = 0.05
        self.simulation_runtimes: List[float] = []
        self.module_state.update({
            "simulations_processed": 0,
            "simulations_completed": 0,
            "simulations_failed": 0,
            "avg_simulation_runtime_s": 0.0,
            "simulation_coherence_score": 1.0
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado con modelado avanzado.")

    async def _update_logic(self):
        if not self.simulation_request_queue.empty() and len(self.active_simulations) < self.MAX_CONCURRENT_SIMULATIONS:
            request = await self.simulation_request_queue.get()
            self.simulation_request_queue.task_done()
            task = self._create_managed_task(self._process_simulation_request(request))
            self.active_simulations[request.request_id] = task
        # Actualizar coherencia entre simulaciones
        n_simulations = self.simulation_graph.number_of_nodes()
        if len(self.coherence_field) != max(n_simulations, 1):
            self.coherence_field = np.ones(max(n_simulations, 1)) * self.module_state["simulation_coherence_score"]
        conflicts = len(list(nx.simple_cycles(self.simulation_graph))) if self.simulation_graph.number_of_nodes() > 0 else 0
        for _ in range(int(self.update_interval / self.pde_dt)):
            d2_coherence = (np.roll(self.coherence_field, 1) + np.roll(self.coherence_field, -1) - 2 * self.coherence_field) / (self.pde_dx ** 2)
            reaction = 0.1 * self.coherence_field * (1.0 - self.coherence_field / max(n_simulations, 1) - 0.05 * conflicts)
            self.coherence_field += self.pde_dt * (self.pde_diffusion * d2_coherence + reaction)
            self.coherence_field = np.clip(self.coherence_field, 0.0, 1.0)
        self.module_state["simulation_coherence_score"] = np.mean(self.coherence_field)

    async def _process_simulation_request(self, request: ShimyureshonRequest):
        start_time = time.time()
        # Validar solicitud
        is_valid, msg = await self._validate_request(request)
        if not is_valid:
            request.status = "failed"
            request.result = {"error": msg}
            self.module_state["simulations_failed"] += 1
            await self._finalize_simulation(request)
            return
        # Verificar conflictos
        self.simulation_graph.add_node(request.request_id, scenario=request.scenario_description)
        for other_id in self.active_simulations:
            if other_id != request.request_id:
                other_request = next((r for r in self.active_simulations.values() if r.get_name() == other_id), None)
                if other_request and other_request.scenario_description == request.scenario_description:
                    self.simulation_graph.add_edge(request.request_id, other_id, weight=1.0)
        conflicts = len(list(nx.simple_cycles(self.simulation_graph))) if self.simulation_graph.number_of_nodes() > 0 else 0
        if conflicts > 0:
            request.status = "failed"
            request.result = {"error": f"Conflicto detectado con otra simulación para el escenario {request.scenario_description}."}
            self.module_state["simulations_failed"] += 1
            self.simulation_graph.remove_node(request.request_id)
            await self._finalize_simulation(request)
            return
        # Actualizar métrica con Kalman
        sim_count = self.module_state["simulations_processed"] + 1
        measurement = sim_count
        A, H = 1.0, 1.0
        predicted_state = A * self.kalman_state
        predicted_cov = A * self.kalman_cov * A + self.kalman_Q
        innovation = measurement - H * predicted_state
        innovation_cov = H * predicted_cov * H + self.kalman_R
        kalman_gain = predicted_cov * H / innovation_cov
        self.kalman_state = predicted_state + kalman_gain * innovation
        self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
        self.module_state["simulations_processed"] = int(self.kalman_state)
        try:
            request.status = "compiling"
            sim_initial_state = self._compile_scenario(request.initial_conditions)
            request.status = "running"
            simulation_log, final_state = await self._run_simulation(sim_initial_state, request.simulation_parameters)
            request.status = "synthesizing_results"
            synthesis = self._synthesize_results(simulation_log, final_state)
            request.result = {"summary": synthesis, "log_preview": simulation_log[:5]}
            request.status = "completed"
            self.module_state["simulations_completed"] += 1
        except Exception as e:
            request.status = "failed"
            request.result = {"error": f"Fallo en el pipeline de Shimyureshon: {str(e)}"}
            self.module_state["simulations_failed"] += 1
            self.logger.error(f"Fallo en Shimyureshon request '{request.request_id}': {e}", exc_info=True)
        finally:
            duration = time.time() - start_time
            self.simulation_runtimes.append(duration)
            # Kalman para suavizar avg_simulation_runtime_s
            measurement = duration
            predicted_state = A * self.kalman_state
            predicted_cov = A * self.kalman_cov * A + self.kalman_Q
            innovation = measurement - H * predicted_state
            innovation_cov = H * predicted_cov * H + self.kalman_R
            kalman_gain = predicted_cov * H / innovation_cov
            self.kalman_state = predicted_state + kalman_gain * innovation
            self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
            self.module_state["avg_simulation_runtime_s"] = self.kalman_state
            self.simulation_graph.remove_node(request.request_id)
            await self._finalize_simulation(request)

    async def _validate_request(self, request: ShimyureshonRequest) -> Tuple[bool, str]:
        # Validación básica
        if not request.scenario_description or not request.initial_conditions:
            return False, "Se requiere 'scenario_description' e 'initial_conditions'."
        # Validación lógica
        correlation_id = f"validate_request_{request.request_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="ComputationalLogicModule",
                message_type="submit_logical_query_request",
                payload={"query_type": "validate_simulation_request", "query_payload": asdict(request)},
                correlation_id=correlation_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            validation_result = await asyncio.wait_for(future, timeout=5.0)
            if validation_result.get("status") != "valid":
                return False, f"Validación lógica fallida: {validation_result.get('error', 'No especificado')}"
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout validando solicitud {request.request_id}.")
            return False, "Timeout en validación lógica."
        # Validación de alineación
        correlation_id = f"align_request_{request.request_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="ValueSystemModule",
                message_type="request_value_alignment",
                payload={"item_to_evaluate": {"scenario_description": request.scenario_description, "initial_conditions": request.initial_conditions}},
                correlation_id=correlation_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            alignment_result = await asyncio.wait_for(future, timeout=5.0)
            if alignment_result.get("overall_alignment_score", -1.0) < 0.0:
                return False, f"Alineación fallida: {alignment_result.get('error_message', 'No especificado')}"
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout validando alineación para solicitud {request.request_id}.")
            return False, "Timeout en validación de alineación."
        # Evaluación de impacto
        correlation_id = f"impact_request_{request.request_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="SystemIntegrityMonitor",
                message_type="evaluate_system_impact",
                payload={"scenario_description": request.scenario_description, "initial_conditions": request.initial_conditions},
                correlation_id=correlation_id,
                priority="medium"
            ))
        }, priority_label="medium")
        try:
            impact_result = await asyncio.wait_for(future, timeout=5.0)
            impact_score = impact_result.get("impact_score", 0.0)
            samples = np.random.normal(impact_score, 0.05, self.num_mc_samples)
            impact_score = np.clip(np.mean(samples), 0.0, 1.0)
            def impact_dynamics(t, p):
                return -0.05 * (p - impact_score) + self.sde_sigma * np.random.normal(0, 1)
            result = integrate.odeint(impact_dynamics, [impact_score], [0, self.update_interval], tfirst=True)
            impact_score = np.clip(result[-1][0], 0.0, 1.0)
            if impact_score < 0.5:
                return False, f"Impacto insuficiente: {impact_result.get('error_message', 'Impacto demasiado bajo')}"
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout evaluando impacto para solicitud {request.request_id}.")
            return False, "Timeout en evaluación de impacto."
        return True, "Validación OK."

    def _compile_scenario(self, initial_conditions: Dict) -> Dict[str, Any]:
        self.logger.info(f"Compilando escenario Shimyureshon...")
        sandboxed_state = {"global_state": copy.deepcopy(self.core_recombinator.global_state)}
        for key, value in initial_conditions.items():
            if hasattr(sandboxed_state["global_state"], key):
                setattr(sandboxed_state["global_state"], key, value)
            else:
                self.logger.warning(f"La condición inicial '{key}' no corresponde a un atributo de GlobalSelfState.")
        return sandboxed_state

    async def _run_simulation(self, initial_state: Dict, params: Dict) -> Tuple[List[Dict], Dict]:
        max_cycles = params.get("max_cycles", 100)
        self.logger.info(f"Ejecutando Shimyureshon por {max_cycles} ciclos...")
        current_state = initial_state
        log = []
        for cycle in range(max_cycles):
            gs = current_state["global_state"]
            # Modelo predictivo con SDE
            def state_dynamics(t, state):
                coherence, threat = state
                d_coherence = -(1.0 - gs.motivacion) * 0.01 + self.sde_sigma * np.random.normal(0, 1)
                d_threat = gs.system_entropy * 0.005 + self.sde_sigma * np.random.normal(0, 1)
                return [d_coherence, d_threat]
            state = [gs.coherence_score, gs.system_threat_level]
            result = integrate.odeint(state_dynamics, state, [0, 0.01], tfirst=True)
            gs.coherence_score, gs.system_threat_level = np.clip(result[-1], 0.0, 1.0)
            # Monte Carlo para incertidumbre
            samples_coh = np.random.normal(gs.coherence_score, 0.05, self.num_mc_samples)
            samples_threat = np.random.normal(gs.system_threat_level, 0.05, self.num_mc_samples)
            gs.coherence_score = np.clip(np.mean(samples_coh), 0.0, 1.0)
            gs.system_threat_level = np.clip(np.mean(samples_threat), 0.0, 1.0)
            log_entry = {"cycle": cycle, "coherence": gs.coherence_score, "threat": gs.system_threat_level}
            log.append(log_entry)
            if gs.coherence_score < 0.2 or gs.system_threat_level > 0.9:
                self.logger.warning(f"Shimyureshon detenido prematuramente en el ciclo {cycle} por condición crítica.")
                break
            await asyncio.sleep(0.01)
        return log, current_state

    def _synthesize_results(self, log: List[Dict], final_state: Dict) -> str:
        if not log:
            return "La simulación no produjo resultados."
        initial_coh = log[0]['coherence']
        final_coh = log[-1]['coherence']
        coh_delta = final_coh - initial_coh
        initial_threat = log[0]['threat']
        final_threat = log[-1]['threat']
        threat_delta = final_threat - initial_threat
        # Monte Carlo para incertidumbre
        samples_coh = np.random.normal(coh_delta, 0.05, self.num_mc_samples)
        samples_threat = np.random.normal(threat_delta, 0.05, self.num_mc_samples)
        coh_delta = np.clip(np.mean(samples_coh), -1.0, 1.0)
        threat_delta = np.clip(np.mean(samples_threat), -1.0, 1.0)
        summary = (
            f"La simulación de {len(log)} ciclos resultó en un cambio de coherencia de {coh_delta:+.2f} "
            f"(de {initial_coh:.2f} a {final_coh:.2f}) y un cambio de amenaza de {threat_delta:+.2f} "
            f"(de {initial_threat:.2f} a {final_threat:.2f})."
        )
        return summary

    async def _finalize_simulation(self, request: ShimyureshonRequest):
        if request.source_module_id and request.original_correlation_id:
            future = asyncio.Future()
            self.active_responses[request.original_correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id=request.source_module_id,
                    message_type="simulation_result_notice",
                    payload={"request_id_ref": request.request_id, "status": request.status, "result": request.result},
                    correlation_id=request.original_correlation_id,
                    priority="high"
                ))
            }, priority_label="high")
            try:
                await asyncio.wait_for(future, timeout=5.0)
                self.logger.info(f"Confirmación de finalización para solicitud {request.request_id} recibida.")
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout notificando finalización de solicitud {request.request_id}.")
        if request.request_id in self.active_simulations:
            del self.active_simulations[request.request_id]

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        if event_type == "request_simulation_compilation" and full_message:
            try:
                req = ShimyureshonRequest(
                    source_module_id=full_message.source_module_id,
                    original_correlation_id=full_message.correlation_id,
                    scenario_description=payload.get("scenario_description"),
                    initial_conditions=payload.get("initial_conditions", {}),
                    simulation_parameters=payload.get("simulation_parameters", {})
                )
                if not req.scenario_description or not req.initial_conditions:
                    raise ValueError("Se requiere 'scenario_description' e 'initial_conditions'.")
                await self.simulation_request_queue.put(req)
            except (ValueError, TypeError) as e:
                self.logger.error(f"Error procesando solicitud de Shimyureshon: {e}")
        if full_message and full_message.correlation_id in self.active_responses:
            self.active_responses[full_message.correlation_id].set_result(payload)
            del self.active_responses[full_message.correlation_id]
        else:
            await super()._process_specific_event(event_type, payload, full_message)




   #inicio del modulo FrontierEmergentCreativityModule 

@dataclass
class FrontierConcept:
    concept_id: str = field(default_factory=lambda: f"fcon_{uuid.uuid4().hex[:8]}")
    timestamp: float = field(default_factory=time.time)
    label: str
    description: str
    hypothesis: str
    source_resonance: List[Dict[str, Any]]
    novelty_score: float

class FrontierEmergentCreativityModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 20.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.recent_tchn_patterns: deque[Dict[str, Any]] = deque(maxlen=50)
        self.recent_qualia_events: deque[Dict[str, Any]] = deque(maxlen=50)
        self.recent_goal_outcomes: deque[Dict[str, Any]] = deque(maxlen=50)
        self.last_concept_generation_ts: float = 0.0
        self.generation_cooldown_s: float = 120.0
        self.resonance_time_window_s: float = 5.0
        self.resonance_threshold: int = 2
        self.num_mc_samples: int = 500
        self.sde_sigma: float = 0.01
        self.pde_dx: float = 0.1
        self.pde_dt: float = 0.01
        self.pde_diffusion: float = 0.05
        self.active_responses: Dict[str, asyncio.Future] = {}
        self.resonance_graph = nx.DiGraph()
        self.coherence_field: np.ndarray = np.array([1.0])
        self.novelty_scores: List[float] = []
        self.module_state.update({
            "frontier_concepts_generated": 0,
            "last_concept_label": "none",
            "last_concept_novelty": 0.0,
            "resonances_detected": 0,
            "concept_coherence_score": 1.0
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado con modelado avanzado.")

    async def _update_logic(self):
        if time.time() - self.last_concept_generation_ts < self.generation_cooldown_s:
            return
        resonance_found = await self._scan_for_cross_domain_resonance()
        if resonance_found:
            self.module_state["resonances_detected"] += 1
            self.logger.info(f"FECM: Resonancia inter-dominio detectada. Iniciando síntesis de concepto.")
            new_concept = await self._synthesize_frontier_concept(resonance_found)
            if new_concept:
                self.module_state["frontier_concepts_generated"] += 1
                # Kalman para suavizar novelty_score
                measurement = new_concept.novelty_score
                A, H = 1.0, 1.0
                predicted_state = A * self.kalman_state
                predicted_cov = A * self.kalman_cov * A + self.kalman_Q
                innovation = measurement - H * predicted_state
                innovation_cov = H * predicted_cov * H + self.kalman_R
                kalman_gain = predicted_cov * H / innovation_cov
                self.kalman_state = predicted_state + kalman_gain * innovation
                self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
                self.module_state["last_concept_novelty"] = self.kalman_state
                self.module_state["last_concept_label"] = new_concept.label
                self.novelty_scores.append(new_concept.novelty_score)
                self.last_concept_generation_ts = time.time()
                await self._broadcast_new_concept(new_concept)
        # Actualizar coherencia entre conceptos
        n_concepts = self.resonance_graph.number_of_nodes()
        if len(self.coherence_field) != max(n_concepts, 1):
            self.coherence_field = np.ones(max(n_concepts, 1)) * self.module_state["concept_coherence_score"]
        conflicts = len(list(nx.simple_cycles(self.resonance_graph))) if self.resonance_graph.number_of_nodes() > 0 else 0
        for _ in range(int(self.update_interval / self.pde_dt)):
            d2_coherence = (np.roll(self.coherence_field, 1) + np.roll(self.coherence_field, -1) - 2 * self.coherence_field) / (self.pde_dx ** 2)
            reaction = 0.1 * self.coherence_field * (1.0 - self.coherence_field / max(n_concepts, 1) - 0.05 * conflicts)
            self.coherence_field += self.pde_dt * (self.pde_diffusion * d2_coherence + reaction)
            self.coherence_field = np.clip(self.coherence_field, 0.0, 1.0)
        self.module_state["concept_coherence_score"] = np.mean(self.coherence_field)

    async def _scan_for_cross_domain_resonance(self) -> Optional[List[Dict[str, Any]]]:
        if not self.recent_tchn_patterns or not self.recent_qualia_events:
            return None
        anchor_event = self.recent_qualia_events[-1]
        resonance_cluster = [anchor_event]
        resonance_id = f"res_{uuid.uuid4().hex[:8]}"
        self.resonance_graph.add_node(resonance_id, events=[anchor_event])
        # Buscar en TCHN
        for tchn_pattern in reversed(self.recent_tchn_patterns):
            if abs(tchn_pattern["timestamp"] - anchor_event["timestamp"]) < self.resonance_time_window_s:
                if tchn_pattern["stability"] > 0.8 and anchor_event["intensity"] > 0.7:
                    resonance_cluster.append(tchn_pattern)
                    self.resonance_graph.nodes[resonance_id]["events"].append(tchn_pattern)
                    break
        # Buscar en Metas
        for goal_outcome in reversed(self.recent_goal_outcomes):
            if abs(goal_outcome["timestamp"] - anchor_event["timestamp"]) < self.resonance_time_window_s:
                if goal_outcome["priority"] > 0.8 and anchor_event["intensity"] > 0.7:
                    resonance_cluster.append(goal_outcome)
                    self.resonance_graph.nodes[resonance_id]["events"].append(goal_outcome)
                    break
        # Verificar conflictos
        for other_id in self.resonance_graph.nodes:
            if other_id != resonance_id:
                other_events = self.resonance_graph.nodes[other_id]["events"]
                if any(e in other_events for e in resonance_cluster):
                    self.resonance_graph.add_edge(resonance_id, other_id, weight=1.0)
        conflicts = len(list(nx.simple_cycles(self.resonance_graph))) if self.resonance_graph.number_of_nodes() > 0 else 0
        if conflicts > 0:
            self.logger.warning(f"Conflicto detectado en resonancia {resonance_id}.")
            self.resonance_graph.remove_node(resonance_id)
            return None
        # Validar resonancia
        if len(resonance_cluster) >= self.resonance_threshold:
            correlation_id = f"validate_resonance_{resonance_id}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            self.active_responses[correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="ComputationalLogicModule",
                    message_type="submit_logical_query_request",
                    payload={"query_type": "validate_resonance", "query_payload": {"events": resonance_cluster}},
                    correlation_id=correlation_id,
                    priority="high"
                ))
            }, priority_label="high")
            try:
                validation_result = await asyncio.wait_for(future, timeout=5.0)
                if validation_result.get("status") != "valid":
                    self.logger.warning(f"Resonancia {resonance_id} no válida: {validation_result.get('error', 'No especificado')}")
                    self.resonance_graph.remove_node(resonance_id)
                    return None
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout validando resonancia {resonance_id}.")
                self.resonance_graph.remove_node(resonance_id)
                return None
            # Validar alineación
            correlation_id = f"align_resonance_{resonance_id}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            self.active_responses[correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="ValueSystemModule",
                    message_type="request_value_alignment",
                    payload={"item_to_evaluate": {"events": resonance_cluster}},
                    correlation_id=correlation_id,
                    priority="high"
                ))
            }, priority_label="high")
            try:
                alignment_result = await asyncio.wait_for(future, timeout=5.0)
                if alignment_result.get("overall_alignment_score", -1.0) < 0.0:
                    self.logger.warning(f"Resonancia {resonance_id} no alineada: {alignment_result.get('error_message', 'No especificado')}")
                    self.resonance_graph.remove_node(resonance_id)
                    return None
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout validando alineación para resonancia {resonance_id}.")
                self.resonance_graph.remove_node(resonance_id)
                return None
            # Monte Carlo y SDE para resonancia
            intensities = [event.get("intensity", event.get("stability", event.get("priority", 0.5))) for event in resonance_cluster]
            samples = np.random.normal(np.mean(intensities), 0.05, self.num_mc_samples)
            resonance_score = np.clip(np.mean(samples), 0.0, 1.0)
            def resonance_dynamics(t, p):
                return -0.05 * (p - resonance_score) + self.sde_sigma * np.random.normal(0, 1)
            result = integrate.odeint(resonance_dynamics, [resonance_score], [0, self.resonance_time_window_s], tfirst=True)
            resonance_score = np.clip(result[-1][0], 0.0, 1.0)
            if resonance_score < 0.5:
                self.logger.warning(f"Resonancia {resonance_id} con puntaje insuficiente: {resonance_score:.2f}")
                self.resonance_graph.remove_node(resonance_id)
                return None
            self.recent_qualia_events.clear()
            self.recent_tchn_patterns.clear()
            self.recent_goal_outcomes.clear()
            return resonance_cluster
        self.resonance_graph.remove_node(resonance_id)
        return None

    async def _synthesize_frontier_concept(self, resonance_cluster: List[Dict[str, Any]]) -> Optional[FrontierConcept]:
        # Validar impacto
        concept_id = f"fcon_{uuid.uuid4().hex[:8]}"
        correlation_id = f"impact_concept_{concept_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="SystemIntegrityMonitor",
                message_type="evaluate_system_impact",
                payload={"events": resonance_cluster},
                correlation_id=correlation_id,
                priority="medium"
            ))
        }, priority_label="medium")
        try:
            impact_result = await asyncio.wait_for(future, timeout=5.0)
            impact_score = impact_result.get("impact_score", 0.0)
            samples = np.random.normal(impact_score, 0.05, self.num_mc_samples)
            impact_score = np.clip(np.mean(samples), 0.0, 1.0)
            if impact_score < 0.5:
                self.logger.warning(f"Concepto {concept_id} con impacto insuficiente: {impact_result.get('error_message', 'Impacto demasiado bajo')}")
                return None
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout evaluando impacto para concepto {concept_id}.")
            return None
        # Generar concepto
        labels = []
        descriptions = []
        for event in resonance_cluster:
            labels.append(event.get("type", "evento"))
            descriptions.append(str(event.get("description", str(event.get("pattern_id")))))
        new_label = "Resonancia Cognitiva-" + "-".join(labels)
        new_description = f"Se ha detectado una correlación temporal significativa entre eventos de los siguientes tipos: {', '.join(labels)}. Descripciones: {' || '.join(descriptions)}"
        new_hypothesis = f"La aparición conjunta de estos eventos podría indicar un estado sistémico emergente no catalogado. Hipótesis: La manipulación deliberada de uno de estos patrones podría influir en los otros."
        novelty = np.mean([event.get("intensity", event.get("stability", event.get("priority", 0.5))) for event in resonance_cluster])
        samples = np.random.normal(novelty, 0.05, self.num_mc_samples)
        novelty = np.clip(np.mean(samples), 0.0, 1.0)
        self.resonance_graph.add_node(concept_id, concept={"label": new_label, "description": new_description, "hypothesis": new_hypothesis, "novelty_score": novelty})
        return FrontierConcept(
            concept_id=concept_id,
            label=new_label,
            description=new_description,
            hypothesis=new_hypothesis,
            source_resonance=resonance_cluster,
            novelty_score=novelty
        )

    async def _broadcast_new_concept(self, concept: FrontierConcept):
        self.logger.warning(f"NUEVO CONCEPTO DE FRONTERA GENERADO: '{concept.label}' (Novedad: {concept.novelty_score:.2f})")
        correlation_id = f"broadcast_{concept.concept_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        # Enviar a OntologyFlowManager
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="OntologyFlowManager",
                message_type="submit_ontology_query_request",
                payload={"query_type": "add_concept_from_frontier", "query_payload": asdict(concept)},
                correlation_id=correlation_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            await asyncio.wait_for(future, timeout=5.0)
            self.logger.info(f"Confirmación de OntologyFlowManager para concepto {concept.concept_id} recibida.")
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout notificando a OntologyFlowManager para concepto {concept.concept_id}.")
        # Enviar a GoalManagerModule
        correlation_id = f"broadcast_goal_{concept.concept_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="GoalManagerModule",
                message_type="new_frontier_concept_for_exploration",
                payload={"concept": asdict(concept)},
                correlation_id=correlation_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            await asyncio.wait_for(future, timeout=5.0)
            self.logger.info(f"Confirmación de GoalManagerModule para concepto {concept.concept_id} recibida.")
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout notificando a GoalManagerModule para concepto {concept.concept_id}.")

    async def _process_specific_event(self, event_type: str, payload: Dict, full_message: Optional['IlyukMessageStructure'] = None):
        if not full_message:
            return
        if event_type == "stable_tchn_pattern_detected":
            self.recent_tchn_patterns.append({"type": "tchn_pattern", "timestamp": full_message.timestamp_utc, "pattern_id": payload.get("pattern_id"), "stability": payload.get("stability", 0.0)})
        elif event_type == "new_qualia_snapshot_generated":
            self.recent_qualia_events.append({"type": "qualia", "timestamp": full_message.timestamp_utc, "description": payload.get("description"), "intensity": payload.get("intensity", 0.0)})
        elif event_type == "major_goal_outcome_reported":
            self.recent_goal_outcomes.append({"type": f"goal_{payload.get('outcome')}", "timestamp": full_message.timestamp_utc, "description": payload.get("description"), "priority": payload.get("priority", 0.0)})
        if full_message.correlation_id in self.active_responses:
            self.active_responses[full_message.correlation_id].set_result(payload)
            del self.active_responses[full_message.correlation_id]
        else:
            await super()._process_specific_event(event_type, payload, full_message)



    #inicio del modulo ParadoxicalCreativitySimulationModule 

@dataclass
class ParadoxicalQuery:
    query_id: str = field(default_factory=lambda: f"pcsm_query_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    core_truth_or_goal: Dict[str, Any]
    status: str = "pending"
    result_insight: Optional[Dict[str, Any]] = None
    error_message: Optional[str] = None
    _internal_state: Dict[str, Any] = field(default_factory=dict)

class ParadoxicalCreativitySimulationModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 10.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.query_queue: asyncio.Queue[ParadoxicalQuery] = asyncio.Queue(maxlen=5)
        self.active_simulations: Dict[str, ParadoxicalQuery] = {}
        self.active_responses: Dict[str, asyncio.Future] = {}
        self.simulation_graph = nx.DiGraph()
        self.coherence_field: np.ndarray = np.array([1.0])
        self.num_mc_samples: int = 500
        self.sde_sigma: float = 0.01
        self.pde_dx: float = 0.1
        self.pde_dt: float = 0.01
        self.pde_diffusion: float = 0.05
        self.simulation_times: List[float] = []
        self.module_state.update({
            "queries_processed": 0,
            "insights_generated": 0,
            "simulations_failed": 0,
            "avg_simulation_time_s": 0.0,
            "simulation_coherence_score": 1.0
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado con modelado avanzado.")

    async def _update_logic(self):
        if not self.query_queue.empty() and len(self.active_simulations) < 1:
            query = await self.query_queue.get()
            self.query_queue.task_done()
            # Validar solicitud
            is_valid, msg = await self._validate_query(query)
            if not is_valid:
                query.status = "failed"
                query.error_message = msg
                self.module_state["simulations_failed"] += 1
                await self._finalize_query(query)
                return
            # Verificar conflictos
            self.simulation_graph.add_node(query.query_id, scenario=query.core_truth_or_goal)
            for other_id in self.active_simulations:
                if other_id != query.query_id:
                    other_query = self.active_simulations[other_id]
                    if other_query.core_truth_or_goal.get("description") == query.core_truth_or_goal.get("description"):
                        self.simulation_graph.add_edge(query.query_id, other_id, weight=1.0)
            conflicts = len(list(nx.simple_cycles(self.simulation_graph))) if self.simulation_graph.number_of_nodes() > 0 else 0
            if conflicts > 0:
                query.status = "failed"
                query.error_message = f"Conflicto detectado con otra simulación para {query.core_truth_or_goal.get('description')}."
                self.module_state["simulations_failed"] += 1
                self.simulation_graph.remove_node(query.query_id)
                await self._finalize_query(query)
                return
            self.active_simulations[query.query_id] = query
            self._create_managed_task(self._run_simulation_flow(query))
        # Actualizar coherencia entre simulaciones
        n_simulations = self.simulation_graph.number_of_nodes()
        if len(self.coherence_field) != max(n_simulations, 1):
            self.coherence_field = np.ones(max(n_simulations, 1)) * self.module_state["simulation_coherence_score"]
        conflicts = len(list(nx.simple_cycles(self.simulation_graph))) if self.simulation_graph.number_of_nodes() > 0 else 0
        for _ in range(int(self.update_interval / self.pde_dt)):
            d2_coherence = (np.roll(self.coherence_field, 1) + np.roll(self.coherence_field, -1) - 2 * self.coherence_field) / (self.pde_dx ** 2)
            reaction = 0.1 * self.coherence_field * (1.0 - self.coherence_field / max(n_simulations, 1) - 0.05 * conflicts)
            self.coherence_field += self.pde_dt * (self.pde_diffusion * d2_coherence + reaction)
            self.coherence_field = np.clip(self.coherence_field, 0.0, 1.0)
        self.module_state["simulation_coherence_score"] = np.mean(self.coherence_field)

    async def _validate_query(self, query: ParadoxicalQuery) -> Tuple[bool, str]:
        # Validación básica
        if not query.core_truth_or_goal:
            return False, "'core_truth_or_goal' requerido."
        # Validación lógica
        correlation_id = f"validate_query_{query.query_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="ComputationalLogicModule",
                message_type="submit_logical_query_request",
                payload={"query_type": "validate_paradoxical_query", "query_payload": asdict(query)},
                correlation_id=correlation_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            validation_result = await asyncio.wait_for(future, timeout=5.0)
            if validation_result.get("status") != "valid":
                return False, f"Validación lógica fallida: {validation_result.get('error', 'No especificado')}"
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout validando query {query.query_id}.")
            return False, "Timeout en validación lógica."
        # Validación de alineación
        correlation_id = f"align_query_{query.query_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="ValueSystemModule",
                message_type="request_value_alignment",
                payload={"item_to_evaluate": {"core_truth_or_goal": query.core_truth_or_goal}},
                correlation_id=correlation_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            alignment_result = await asyncio.wait_for(future, timeout=5.0)
            if alignment_result.get("overall_alignment_score", -1.0) < 0.0:
                return False, f"Alineación fallida: {alignment_result.get('error_message', 'No especificado')}"
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout validando alineación para query {query.query_id}.")
            return False, "Timeout en validación de alineación."
        # Evaluación de impacto
        correlation_id = f"impact_query_{query.query_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="SystemIntegrityMonitor",
                message_type="evaluate_system_impact",
                payload={"core_truth_or_goal": query.core_truth_or_goal},
                correlation_id=correlation_id,
                priority="medium"
            ))
        }, priority_label="medium")
        try:
            impact_result = await asyncio.wait_for(future, timeout=5.0)
            impact_score = impact_result.get("impact_score", 0.0)
            samples = np.random.normal(impact_score, 0.05, self.num_mc_samples)
            impact_score = np.clip(np.mean(samples), 0.0, 1.0)
            def impact_dynamics(t, p):
                return -0.05 * (p - impact_score) + self.sde_sigma * np.random.normal(0, 1)
            result = integrate.odeint(impact_dynamics, [impact_score], [0, self.update_interval], tfirst=True)
            impact_score = np.clip(result[-1][0], 0.0, 1.0)
            if impact_score < 0.5:
                return False, f"Impacto insuficiente: {impact_result.get('error_message', 'Impacto demasiado bajo')}"
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout evaluando impacto para query {query.query_id}.")
            return False, "Timeout en evaluación de impacto."
        return True, "Validación OK."

    async def _run_simulation_flow(self, query: ParadoxicalQuery):
        start_time = time.time()
        # Actualizar métrica con Kalman
        query_count = self.module_state["queries_processed"] + 1
        measurement = query_count
        A, H = 1.0, 1.0
        predicted_state = A * self.kalman_state
        predicted_cov = A * self.kalman_cov * A + self.kalman_Q
        innovation = measurement - H * predicted_state
        innovation_cov = H * predicted_cov * H + self.kalman_R
        kalman_gain = predicted_cov * H / innovation_cov
        self.kalman_state = predicted_state + kalman_gain * innovation
        self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
        self.module_state["queries_processed"] = int(self.kalman_state)
        try:
            query.status = "formulating_paradox"
            paradoxical_scenario = self._formulate_paradox(query.core_truth_or_goal)
            query.status = "running_shimyureshon"
            sim_result = await self._simulate_consequences(paradoxical_scenario, query)
            if not sim_result:
                raise RuntimeError("El Shimyureshon no produjo un resultado válido.")
            query.status = "extracting_insight"
            insight = self._extract_insight(sim_result)
            query.status = "packaging_proposal"
            await self._package_insight_as_proposal(insight, query)
            query.result_insight = asdict(insight) if insight else None
            query.status = "completed"
            if insight:
                self.module_state["insights_generated"] += 1
        except Exception as e:
            query.status = "failed"
            query.error_message = str(e)
            self.module_state["simulations_failed"] += 1
            self.logger.error(f"Fallo en simulación paradójica '{query.query_id}': {e}", exc_info=True)
        finally:
            duration = time.time() - start_time
            self.simulation_times.append(duration)
            # Kalman para suavizar avg_simulation_time_s
            measurement = duration
            predicted_state = A * self.kalman_state
            predicted_cov = A * self.kalman_cov * A + self.kalman_Q
            innovation = measurement - H * predicted_state
            innovation_cov = H * predicted_cov * H + self.kalman_R
            kalman_gain = predicted_cov * H / innovation_cov
            self.kalman_state = predicted_state + kalman_gain * innovation
            self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
            self.module_state["avg_simulation_time_s"] = self.kalman_state
            self.simulation_graph.remove_node(query.query_id)
            await self._finalize_query(query)

    def _formulate_paradox(self, core_truth: Dict) -> Dict:
        desc = core_truth.get("description", "Unknown goal")
        # Monte Carlo para incertidumbre en formulación
        possible_paradoxes = []
        if "minimizar" in desc.lower():
            paradox_desc = desc.lower().replace("minimizar", "maximizar deliberadamente")
            possible_paradoxes.append(paradox_desc)
        if "siempre debe" in desc.lower():
            paradox_desc = desc.lower().replace("siempre debe", "nunca debe")
            possible_paradoxes.append(paradox_desc)
        paradox_desc = f"¿Qué pasaría si la negación de '{desc}' fuera cierta?"
        possible_paradoxes.append(paradox_desc)
        weights = np.random.normal(1.0, 0.05, (self.num_mc_samples, len(possible_paradoxes)))
        weights = np.clip(weights / np.sum(weights, axis=1, keepdims=True), 0.0, 1.0)
        selected_idx = np.argmax(np.mean(weights, axis=0))
        selected_paradox = possible_paradoxes[selected_idx]
        initial_conditions = core_truth.get("paradoxical_conditions", {})
        return {"scenario_description": selected_paradox, "initial_conditions": initial_conditions}

    async def _simulate_consequences(self, scenario: Dict, query: ParadoxicalQuery) -> Optional[Dict]:
        sim_corr_id = f"pcsm_sim_{query.query_id}_{uuid.uuid4().hex[:8]}"
        sim_future = asyncio.Future()
        query._internal_state = {"sim_future": sim_future, "sim_corr_id": sim_corr_id}
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="ShimyureshonCompiler",
                message_type="request_simulation_compilation",
                payload=scenario,
                correlation_id=sim_corr_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            response = await asyncio.wait_for(sim_future, timeout=45.0)
            # Monte Carlo para incertidumbre en resultados
            coherence_change = response.get("result", {}).get("summary", "").find("cambio de coherencia") != -1
            threat_change = response.get("result", {}).get("summary", "").find("cambio de amenaza") != -1
            scores = np.random.normal(1.0 if coherence_change or threat_change else 0.5, 0.05, self.num_mc_samples)
            if np.mean(scores) < 0.5:
                self.logger.warning(f"Simulación para {query.query_id} con resultados insuficientes.")
                return None
            return response.get("result", {})
        except asyncio.TimeoutError:
            self.logger.error(f"Timeout esperando resultado de ShimyureshonCompiler para {query.query_id}.")
            return None

    def _extract_insight(self, sim_result: Dict) -> Optional[Dict]:
        summary = sim_result.get("summary", "")
        # Monte Carlo para incertidumbre en insights
        possible_insights = []
        if "aumento inesperado de eficiencia" in summary.lower():
            possible_insights.append({
                "insight_type": "unexpected_efficiency_gain",
                "description": "La simulación de un estado de bajo riesgo reveló una vía inesperada para la optimización de recursos.",
                "actionable_hypothesis": "Explorar métodos de bajo riesgo para lograr la optimización de recursos descubierta."
            })
        if "mejora de coherencia" in summary.lower():
            possible_insights.append({
                "insight_type": "coherence_improvement_path",
                "description": "Al simular un fallo deliberado, se identificó un punto débil clave en la arquitectura. Fortalecerlo podría mejorar la coherencia general.",
                "actionable_hypothesis": "Crear una nueva meta para refactorizar el punto débil identificado en la simulación."
            })
        if not possible_insights:
            return None
        weights = np.random.normal(1.0, 0.05, (self.num_mc_samples, len(possible_insights)))
        weights = np.clip(weights / np.sum(weights, axis=1, keepdims=True), 0.0, 1.0)
        selected_idx = np.argmax(np.mean(weights, axis=0))
        return possible_insights[selected_idx]

    async def _package_insight_as_proposal(self, insight: Optional[Dict], query: ParadoxicalQuery):
        if not insight:
            return
        correlation_id = f"proposal_{query.query_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        proposal_payload = {
            "source_module": self.module_name,
            "base_priority": 0.7,
            "description": f"Propuesta basada en insight paradójico ({query.query_id}): {insight['actionable_hypothesis']}",
            "context": {"original_paradox": query.core_truth_or_goal, "insight": insight}
        }
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="GoalManagerModule",
                message_type="new_goal_proposal",
                payload=proposal_payload,
                correlation_id=correlation_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            await asyncio.wait_for(future, timeout=5.0)
            self.logger.info(f"Confirmación de GoalManagerModule para propuesta {query.query_id} recibida.")
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout notificando a GoalManagerModule para propuesta {query.query_id}.")

    async def _finalize_query(self, query: ParadoxicalQuery):
        if query.source_module_id and query.original_correlation_id:
            correlation_id = f"finalize_{query.query_id}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            self.active_responses[correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id=query.source_module_id,
                    message_type="paradoxical_query_response",
                    payload={"query_id_ref": query.query_id, "status": query.status, "insight": query.result_insight, "error": query.error_message},
                    correlation_id=correlation_id,
                    priority="high"
                ))
            }, priority_label="high")
            try:
                await asyncio.wait_for(future, timeout=5.0)
                self.logger.info(f"Confirmación de finalización para query {query.query_id} recibida.")
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout notificando finalización de query {query.query_id}.")
        if query.query_id in self.active_simulations:
            del self.active_simulations[query.query_id]

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        if not full_message:
            return
        if event_type == "request_paradoxical_simulation":
            try:
                query = ParadoxicalQuery(
                    source_module_id=full_message.source_module_id,
                    original_correlation_id=full_message.correlation_id,
                    core_truth_or_goal=payload.get("core_truth_or_goal", {})
                )
                if not query.core_truth_or_goal:
                    raise ValueError("'core_truth_or_goal' requerido.")
                await self.query_queue.put(query)
            except Exception as e:
                self.logger.error(f"Error procesando solicitud de simulación paradójica: {e}")
        elif event_type == "simulation_result_notice":
            active_query = next((q for q in self.active_simulations.values() if q._internal_state.get("sim_corr_id") == full_message.correlation_id), None)
            if active_query and active_query._internal_state.get("sim_future"):
                future = active_query._internal_state["sim_future"]
                if not future.done():
                    future.set_result(payload)
        if full_message.correlation_id in self.active_responses:
            self.active_responses[full_message.correlation_id].set_result(payload)
            del self.active_responses[full_message.correlation_id]
        else:
            await super()._process_specific_event(event_type, payload, full_message)




     #inicio del modulo AcausalCreativitySimulationModule 

@dataclass
class AcausalQuery:
    query_id: str = field(default_factory=lambda: f"acsm_query_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    current_problem_state: Dict[str, Any]
    desired_future_state_description: str
    status: str = "pending"
    result: Optional[Dict[str, Any]] = None
    _internal_sim_correlation_id: Optional[str] = None
    _sim_result_future: Optional[asyncio.Future] = field(default=None, repr=False)
    _internal_state: Dict[str, Any] = field(default_factory=dict)

class AcausalCreativitySimulationModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 30.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.query_queue: asyncio.Queue[AcausalQuery] = asyncio.Queue(maxlen=3)
        self.active_queries: Dict[str, AcausalQuery] = {}
        self.active_responses: Dict[str, asyncio.Future] = {}
        self.query_graph = nx.DiGraph()
        self.coherence_field: np.ndarray = np.array([1.0])
        self.num_mc_samples: int = 500
        self.sde_sigma: float = 0.01
        self.pde_dx: float = 0.1
        self.pde_dt: float = 0.01
        self.pde_diffusion: float = 0.05
        self.query_processing_times: List[float] = []
        self.module_state.update({
            "queries_processed": 0,
            "acausal_bridges_found": 0,
            "acausal_simulations_failed": 0,
            "avg_query_processing_time_s": 0.0,
            "query_coherence_score": 1.0
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado con modelado avanzado.")

    async def _update_logic(self):
        if not self.query_queue.empty() and not self.active_queries:
            query = await self.query_queue.get()
            self.query_queue.task_done()
            # Validar consulta
            is_valid, msg = await self._validate_query(query)
            if not is_valid:
                query.status = "failed"
                query.result = {"error": msg}
                self.module_state["acausal_simulations_failed"] += 1
                await self._finalize_query(query)
                return
            # Verificar conflictos
            self.query_graph.add_node(query.query_id, state=query.desired_future_state_description)
            for other_id in self.active_queries:
                if other_id != query.query_id:
                    other_query = self.active_queries[other_id]
                    if other_query.desired_future_state_description == query.desired_future_state_description:
                        self.query_graph.add_edge(query.query_id, other_id, weight=1.0)
            conflicts = len(list(nx.simple_cycles(self.query_graph))) if self.query_graph.number_of_nodes() > 0 else 0
            if conflicts > 0:
                query.status = "failed"
                query.result = {"error": f"Conflicto detectado con otra consulta para {query.desired_future_state_description}."}
                self.module_state["acausal_simulations_failed"] += 1
                self.query_graph.remove_node(query.query_id)
                await self._finalize_query(query)
                return
            self.active_queries[query.query_id] = query
            self._create_managed_task(self._process_acausal_query(query))
        # Actualizar coherencia entre consultas
        n_queries = self.query_graph.number_of_nodes()
        if len(self.coherence_field) != max(n_queries, 1):
            self.coherence_field = np.ones(max(n_queries, 1)) * self.module_state["query_coherence_score"]
        conflicts = len(list(nx.simple_cycles(self.query_graph))) if self.query_graph.number_of_nodes() > 0 else 0
        for _ in range(int(self.update_interval / self.pde_dt)):
            d2_coherence = (np.roll(self.coherence_field, 1) + np.roll(self.coherence_field, -1) - 2 * self.coherence_field) / (self.pde_dx ** 2)
            reaction = 0.1 * self.coherence_field * (1.0 - self.coherence_field / max(n_queries, 1) - 0.05 * conflicts)
            self.coherence_field += self.pde_dt * (self.pde_diffusion * d2_coherence + reaction)
            self.coherence_field = np.clip(self.coherence_field, 0.0, 1.0)
        self.module_state["query_coherence_score"] = np.mean(self.coherence_field)

    async def _validate_query(self, query: AcausalQuery) -> Tuple[bool, str]:
        # Validación básica
        if not query.current_problem_state or not query.desired_future_state_description:
            return False, "'current_problem_state' y 'desired_future_state_description' requeridos."
        # Validación lógica
        correlation_id = f"validate_query_{query.query_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="ComputationalLogicModule",
                message_type="submit_logical_query_request",
                payload={"query_type": "validate_acausal_query", "query_payload": asdict(query)},
                correlation_id=correlation_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            validation_result = await asyncio.wait_for(future, timeout=5.0)
            if validation_result.get("status") != "valid":
                return False, f"Validación lógica fallida: {validation_result.get('error', 'No especificado')}"
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout validando query {query.query_id}.")
            return False, "Timeout en validación lógica."
        # Validación de alineación
        correlation_id = f"align_query_{query.query_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="ValueSystemModule",
                message_type="request_value_alignment",
                payload={"item_to_evaluate": {"current_problem_state": query.current_problem_state, "desired_future_state_description": query.desired_future_state_description}},
                correlation_id=correlation_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            alignment_result = await asyncio.wait_for(future, timeout=5.0)
            if alignment_result.get("overall_alignment_score", -1.0) < 0.0:
                return False, f"Alineación fallida: {alignment_result.get('error_message', 'No especificado')}"
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout validando alineación para query {query.query_id}.")
            return False, "Timeout en validación de alineación."
        # Evaluación de impacto
        correlation_id = f"impact_query_{query.query_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="SystemIntegrityMonitor",
                message_type="evaluate_system_impact",
                payload={"current_problem_state": query.current_problem_state, "desired_future_state_description": query.desired_future_state_description},
                correlation_id=correlation_id,
                priority="medium"
            ))
        }, priority_label="medium")
        try:
            impact_result = await asyncio.wait_for(future, timeout=5.0)
            impact_score = impact_result.get("impact_score", 0.0)
            samples = np.random.normal(impact_score, 0.05, self.num_mc_samples)
            impact_score = np.clip(np.mean(samples), 0.0, 1.0)
            def impact_dynamics(t, p):
                return -0.05 * (p - impact_score) + self.sde_sigma * np.random.normal(0, 1)
            result = integrate.odeint(impact_dynamics, [impact_score], [0, self.update_interval], tfirst=True)
            impact_score = np.clip(result[-1][0], 0.0, 1.0)
            if impact_score < 0.5:
                return False, f"Impacto insuficiente: {impact_result.get('error_message', 'Impacto demasiado bajo')}"
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout evaluando impacto para query {query.query_id}.")
            return False, "Timeout en evaluación de impacto."
        return True, "Validación OK."

    async def _process_acausal_query(self, query: AcausalQuery):
        start_time = time.time()
        # Actualizar métrica con Kalman
        query_count = self.module_state["queries_processed"] + 1
        measurement = query_count
        A, H = 1.0, 1.0
        predicted_state = A * self.kalman_state
        predicted_cov = A * self.kalman_cov * A + self.kalman_Q
        innovation = measurement - H * predicted_state
        innovation_cov = H * predicted_cov * H + self.kalman_R
        kalman_gain = predicted_cov * H / innovation_cov
        self.kalman_state = predicted_state + kalman_gain * innovation
        self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
        self.module_state["queries_processed"] = int(self.kalman_state)
        try:
            query.status = "defining_future_state"
            future_state_targets = self._define_future_state_attractor(query.desired_future_state_description)
            query.status = "running_retrocausal_simulation"
            sim_result = await self._run_retrocausal_simulation(future_state_targets, query)
            if not sim_result:
                raise RuntimeError("La simulación retrocausal no produjo un resultado válido.")
            query.status = "extracting_bridge_action"
            bridge_action = self._extract_bridge_action_from_sim(sim_result)
            query.status = "proposing_acausal_action"
            await self._propose_acausal_action(bridge_action, query)
            query.result = {"proposed_action": bridge_action}
            query.status = "completed"
            if bridge_action:
                self.module_state["acausal_bridges_found"] += 1
        except Exception as e:
            query.status = "failed"
            query.result = {"error": str(e)}
            self.module_state["acausal_simulations_failed"] += 1
            self.logger.error(f"Fallo en consulta acausal '{query.query_id}': {e}", exc_info=True)
        finally:
            duration = time.time() - start_time
            self.query_processing_times.append(duration)
            # Kalman para suavizar avg_query_processing_time_s
            measurement = duration
            predicted_state = A * self.kalman_state
            predicted_cov = A * self.kalman_cov * A + self.kalman_Q
            innovation = measurement - H * predicted_state
            innovation_cov = H * predicted_cov * H + self.kalman_R
            kalman_gain = predicted_cov * H / innovation_cov
            self.kalman_state = predicted_state + kalman_gain * innovation
            self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
            self.module_state["avg_query_processing_time_s"] = self.kalman_state
            self.query_graph.remove_node(query.query_id)
            await self._finalize_query(query)

    def _define_future_state_attractor(self, description: str) -> Dict:
        # Monte Carlo para incertidumbre en definición
        possible_states = []
        if "coherencia perfecta" in description.lower():
            possible_states.append({"target_end_state": {"coherence_score": 0.99, "system_threat_level": 0.05}})
        if "máxima eficiencia" in description.lower():
            possible_states.append({"target_end_state": {"system_load_proxy_sim": 0.1, "goal_success_rate": 0.98}})
        possible_states.append({"target_end_state": {"coherence_score": 0.95, "system_threat_level": 0.1}})
        weights = np.random.normal(1.0, 0.05, (self.num_mc_samples, len(possible_states)))
        weights = np.clip(weights / np.sum(weights, axis=1, keepdims=True), 0.0, 1.0)
        selected_idx = np.argmax(np.mean(weights, axis=0))
        selected_state = possible_states[selected_idx]
        return selected_state

    async def _run_retrocausal_simulation(self, future_state_targets: Dict, query: AcausalQuery) -> Optional[Dict]:
        sim_corr_id = f"acsm_sim_{query.query_id}_{uuid.uuid4().hex[:8]}"
        query._internal_sim_correlation_id = sim_corr_id
        query._sim_result_future = asyncio.Future()
        scenario_desc = f"Simulación de inferencia inversa para alcanzar el estado futuro: {future_state_targets}"
        sim_payload = {
            "scenario_description": scenario_desc,
            "simulation_parameters": {"simulation_type": "backward_inference", "max_cycles": 150},
            "initial_conditions": future_state_targets["target_end_state"]
        }
        # Validar impacto de la simulación
        correlation_id = f"impact_sim_{query.query_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="SystemIntegrityMonitor",
                message_type="evaluate_system_impact",
                payload=sim_payload,
                correlation_id=correlation_id,
                priority="medium"
            ))
        }, priority_label="medium")
        try:
            impact_result = await asyncio.wait_for(future, timeout=5.0)
            impact_score = impact_result.get("impact_score", 0.0)
            samples = np.random.normal(impact_score, 0.05, self.num_mc_samples)
            impact_score = np.clip(np.mean(samples), 0.0, 1.0)
            def impact_dynamics(t, p):
                return -0.05 * (p - impact_score) + self.sde_sigma * np.random.normal(0, 1)
            result = integrate.odeint(impact_dynamics, [impact_score], [0, self.update_interval], tfirst=True)
            impact_score = np.clip(result[-1][0], 0.0, 1.0)
            if impact_score < 0.5:
                self.logger.warning(f"Simulación para {query.query_id} con impacto insuficiente.")
                return None
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout evaluando impacto para simulación {query.query_id}.")
            return None
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="ShimyureshonCompiler",
                message_type="request_simulation_compilation",
                payload=sim_payload,
                correlation_id=sim_corr_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            response = await asyncio.wait_for(query._sim_result_future, timeout=60.0)
            # Monte Carlo para incertidumbre en resultados
            coherence_change = response.get("result", {}).get("summary", "").find("cambio de coherencia") != -1
            threat_change = response.get("result", {}).get("summary", "").find("cambio de amenaza") != -1
            scores = np.random.normal(1.0 if coherence_change or threat_change else 0.5, 0.05, self.num_mc_samples)
            if np.mean(scores) < 0.5:
                self.logger.warning(f"Simulación para {query.query_id} con resultados insuficientes.")
                return None
            return response.get("result", {})
        except asyncio.TimeoutError:
            self.logger.error(f"Timeout esperando resultado de ShimyureshonCompiler para {query.query_id}.")
            return None

    def _extract_bridge_action_from_sim(self, sim_result: Optional[Dict]) -> Optional[Dict]:
        if not sim_result or not sim_result.get("log_preview"):
            raise ValueError("La simulación acausal no produjo un log válido.")
        # Monte Carlo para incertidumbre en extracción
        possible_actions = [
            {
                "description": "Acción Acausal Sugerida: Perturbar temporalmente el parámetro de 'importancia' de la meta de 'eficiencia' en -25%.",
                "target_module": "GoalManagerModule",
                "action_type": "parameter_perturbation",
                "priority": 0.95,
                "justification": "La simulación inversa determinó que esta acción contraintuitiva es la que tiene mayor probabilidad de desbloquear el camino hacia el estado futuro deseado."
            },
            {
                "description": "Acción Acausal Sugerida: Reconfigurar la prioridad de tareas en TPDU para favorecer metas a largo plazo.",
                "target_module": "TaskPrioritizationAndDelegationUnit",
                "action_type": "priority_reconfiguration",
                "priority": 0.90,
                "justification": "La simulación inversa identificó que priorizar metas a largo plazo optimiza el estado futuro."
            }
        ]
        weights = np.random.normal(1.0, 0.05, (self.num_mc_samples, len(possible_actions)))
        weights = np.clip(weights / np.sum(weights, axis=1, keepdims=True), 0.0, 1.0)
        selected_idx = np.argmax(np.mean(weights, axis=0))
        return possible_actions[selected_idx]

    async def _propose_acausal_action(self, action: Optional[Dict], query: AcausalQuery):
        if not action:
            return
        correlation_id = f"proposal_{query.query_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="TaskPrioritizationAndDelegationUnit",
                message_type="new_task_request",
                payload=action,
                correlation_id=correlation_id,
                priority="high"
            ))
        }, priority_label="high")
        self.logger.warning(f"ACSM: Proponiendo acción acausal de alta prioridad: '{action['description']}'")
        try:
            await asyncio.wait_for(future, timeout=5.0)
            self.logger.info(f"Confirmación de TaskPrioritizationAndDelegationUnit para acción {query.query_id} recibida.")
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout notificando a TaskPrioritizationAndDelegationUnit para acción {query.query_id}.")

    async def _finalize_query(self, query: AcausalQuery):
        if query.source_module_id and query.original_correlation_id:
            correlation_id = f"finalize_{query.query_id}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            self.active_responses[correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id=query.source_module_id,
                    message_type="acausal_query_response",
                    payload={"query_id_ref": query.query_id, "status": query.status, "result": query.result},
                    correlation_id=correlation_id,
                    priority="high"
                ))
            }, priority_label="high")
            try:
                await asyncio.wait_for(future, timeout=5.0)
                self.logger.info(f"Confirmación de finalización para query {query.query_id} recibida.")
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout notificando finalización de query {query.query_id}.")
        if query.query_id in self.active_queries:
            del self.active_queries[query.query_id]

    async def _process_specific_event(self, event_type: str, payload: Dict, full_message: Optional['IlyukMessageStructure'] = None):
        if not full_message:
            return
        if event_type == "request_acausal_solution":
            try:
                query = AcausalQuery(
                    source_module_id=full_message.source_module_id,
                    original_correlation_id=full_message.correlation_id,
                    current_problem_state=payload.get("current_problem_state", {}),
                    desired_future_state_description=payload.get("desired_future_state_description", "")
                )
                if not query.current_problem_state or not query.desired_future_state_description:
                    raise ValueError("'current_problem_state' y 'desired_future_state_description' requeridos.")
                await self.query_queue.put(query)
            except Exception as e:
                self.logger.error(f"Error procesando solicitud de solución acausal: {e}")
        elif event_type == "simulation_result_notice":
            active_query = next((q for q in self.active_queries.values() if q._internal_sim_correlation_id == full_message.correlation_id), None)
            if active_query and active_query._sim_result_future and not active_query._sim_result_future.done():
                future = active_query._sim_result_future
                if payload.get("status") == "completed":
                    future.set_result(payload)
                else:
                    future.set_exception(RuntimeError(f"Shimyureshon falló: {payload.get('result', {}).get('error')}"))
        if full_message.correlation_id in self.active_responses:
            self.active_responses[full_message.correlation_id].set_result(payload)
            del self.active_responses[full_message.correlation_id]
        else:
            await super()._process_specific_event(event_type, payload, full_message)






     #inicio del modulo  FractalSynchronicitySimulationModule 

@dataclass
class DataStreamBuffer:
    name: str
    buffer: deque[Tuple[float, float]]
    last_analysis_ts: float = 0.0

@dataclass
class SynchronicityEvent:
    event_id: str = field(default_factory=lambda: f"fssm_evt_{uuid.uuid4().hex[:6]}")
    timestamp: float = field(default_factory=time.time)
    correlated_streams: List[str]
    shared_fractal_dimension: float
    cross_correlation_score: float
    phase_coherence_score: float
    time_window_s: float
    significance: float

class FractalSynchronicitySimulationModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 15.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.monitored_stream_keys = ["valencia", "arousal", "coherence_score", "system_entropy", "system_load_proxy_sim"]
        self.stream_buffers: Dict[str, DataStreamBuffer] = {
            key: DataStreamBuffer(name=key, buffer=deque(maxlen=256)) for key in self.monitored_stream_keys
        }
        self.analysis_window_size: int = 128
        self.fractal_dim_similarity_threshold: float = 0.05
        self.cross_corr_threshold: float = 0.70
        self.num_mc_samples: int = 500
        self.sde_sigma: float = 0.01
        self.pde_dx: float = 0.1
        self.pde_dt: float = 0.01
        self.pde_diffusion: float = 0.05
        self.active_responses: Dict[str, asyncio.Future] = {}
        self.synchronicity_graph = nx.DiGraph()
        self.coherence_field: np.ndarray = np.array([1.0])
        self.significance_scores: List[float] = []
        self.module_state.update({
            "analysis_cycles_run": 0,
            "sychronicities_detected": 0,
            "last_synchronicity_significance": 0.0,
            "last_correlated_streams": [],
            "stream_coherence_score": 1.0
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado con modelado avanzado.")

    async def _update_logic(self):
        self._update_stream_buffers()
        if self.module_state["cycles_ran"] % 4 == 0:
            if len(self.stream_buffers["valencia"].buffer) >= self.analysis_window_size:
                self._create_managed_task(self._run_synchronicity_analysis())
        # Actualizar coherencia entre flujos
        n_streams = len(self.monitored_stream_keys)
        if len(self.coherence_field) != n_streams:
            self.coherence_field = np.ones(n_streams) * self.module_state["stream_coherence_score"]
        conflicts = len(list(nx.simple_cycles(self.synchronicity_graph))) if self.synchronicity_graph.number_of_nodes() > 0 else 0
        for _ in range(int(self.update_interval / self.pde_dt)):
            d2_coherence = (np.roll(self.coherence_field, 1) + np.roll(self.coherence_field, -1) - 2 * self.coherence_field) / (self.pde_dx ** 2)
            reaction = 0.1 * self.coherence_field * (1.0 - self.coherence_field / max(n_streams, 1) - 0.05 * conflicts)
            self.coherence_field += self.pde_dt * (self.pde_diffusion * d2_coherence + reaction)
            self.coherence_field = np.clip(self.coherence_field, 0.0, 1.0)
        self.module_state["stream_coherence_score"] = np.mean(self.coherence_field)

    def _update_stream_buffers(self):
        gs = self.core_recombinator.global_state
        ts = gs.timestamp
        for key in self.monitored_stream_keys:
            if hasattr(gs, key):
                value = getattr(gs, key)
                self.stream_buffers[key].buffer.append((ts, value))

    async def _run_synchronicity_analysis(self):
        self.module_state["analysis_cycles_run"] += 1
        self.logger.info("FSSM: Iniciando ciclo de análisis de sincronicidad fractal.")
        streams = {name: np.array([v for ts, v in buf.buffer][-self.analysis_window_size:]) for name, buf in self.stream_buffers.items()}
        valid_streams = {name: data for name, data in streams.items() if len(data) >= self.analysis_window_size}
        if len(valid_streams) < 2:
            return
        # Calcular dimensiones fractales
        fractal_dimensions = {name: self._calculate_fractal_dimension_simulated(data) for name, data in valid_streams.items()}
        for (name1, ts1), (name2, ts2) in combinations(valid_streams.items(), 2):
            dim1, dim2 = fractal_dimensions[name1], fractal_dimensions[name2]
            if abs(dim1 - dim2) < self.fractal_dim_similarity_threshold:
                corr, phase_coh = self._calculate_cross_correlation_and_phase(ts1, ts2)
                if corr > self.cross_corr_threshold:
                    event_id = f"fssm_evt_{uuid.uuid4().hex[:6]}"
                    significance = (corr + (1.0 - abs(dim1 - dim2))) / 2.0
                    # SDE para modelar dinámica de significancia
                    def significance_dynamics(t, s):
                        return -0.05 * (s - significance) + self.sde_sigma * np.random.normal(0, 1)
                    result = integrate.odeint(significance_dynamics, [significance], [0, self.update_interval], tfirst=True)
                    significance = np.clip(result[-1][0], 0.0, 1.0)
                    event = SynchronicityEvent(
                        event_id=event_id,
                        correlated_streams=[name1, name2],
                        shared_fractal_dimension=(dim1 + dim2) / 2,
                        cross_correlation_score=corr,
                        phase_coherence_score=phase_coh,
                        time_window_s=ts1[-1] - ts1[0],
                        significance=significance
                    )
                    # Validar evento
                    is_valid, msg = await self._validate_synchronicity(event)
                    if not is_valid:
                        self.logger.warning(f"Sincronicidad {event.event_id} no válida: {msg}")
                        continue
                    # Verificar conflictos
                    self.synchronicity_graph.add_node(event.event_id, streams=event.correlated_streams)
                    for other_id in self.synchronicity_graph.nodes:
                        if other_id != event.event_id:
                            other_streams = self.synchronicity_graph.nodes[other_id]["streams"]
                            if set(event.correlated_streams).intersection(other_streams):
                                self.synchronicity_graph.add_edge(event.event_id, other_id, weight=1.0)
                    conflicts = len(list(nx.simple_cycles(self.synchronicity_graph)))
                    if conflicts > 0:
                        self.logger.warning(f"Conflicto detectado en sincronicidad {event.event_id}.")
                        self.synchronicity_graph.remove_node(event.event_id)
                        continue
                    # Simular con ShimyureshonCompiler
                    sim_result = await self._simulate_synchronicity(event)
                    if not sim_result:
                        self.logger.warning(f"Simulación para sincronicidad {event.event_id} fallida.")
                        self.synchronicity_graph.remove_node(event.event_id)
                        continue
                    # Reportar evento
                    await self._report_synchronicity(event)
                    self.significance_scores.append(event.significance)
                    # Kalman para suavizar significancia
                    measurement = event.significance
                    A, H = 1.0, 1.0
                    predicted_state = A * self.kalman_state
                    predicted_cov = A * self.kalman_cov * A + self.kalman_Q
                    innovation = measurement - H * predicted_state
                    innovation_cov = H * predicted_cov * H + self.kalman_R
                    kalman_gain = predicted_cov * H / innovation_cov
                    self.kalman_state = predicted_state + kalman_gain * innovation
                    self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
                    self.module_state["last_synchronicity_significance"] = self.kalman_state
                    self.module_state["last_correlated_streams"] = event.correlated_streams
                    self.module_state["sychronicities_detected"] += 1
                    return

    def _calculate_fractal_dimension_simulated(self, time_series: np.ndarray) -> float:
        if len(time_series) < 2:
            return 1.0
        diffs = np.diff(time_series)
        complexity = np.std(diffs) / (np.mean(np.abs(time_series)) + 1e-6)
        samples = np.random.normal(complexity, 0.05, self.num_mc_samples)
        complexity = np.clip(np.mean(samples), 0.0, 1.0)
        return np.clip(1.0 + complexity, 1.0, 2.0)

    def _calculate_cross_correlation_and_phase(self, ts1: np.ndarray, ts2: np.ndarray) -> Tuple[float, float]:
        ts1_norm = (ts1 - np.mean(ts1)) / (np.std(ts1) + 1e-9)
        ts2_norm = (ts2 - np.mean(ts2)) / (np.std(ts2) + 1e-9)
        cross_corr = np.correlate(ts1_norm, ts2_norm, mode='full')
        max_corr = np.max(cross_corr) / len(ts1)
        samples = np.random.normal(max_corr, 0.05, self.num_mc_samples)
        max_corr = np.clip(np.mean(samples), 0.0, 1.0)
        phase_coherence = max(0, 1.0 - np.mean(np.abs(ts1_norm - ts2_norm)) / 2.0)
        samples = np.random.normal(phase_coherence, 0.05, self.num_mc_samples)
        phase_coherence = np.clip(np.mean(samples), 0.0, 1.0)
        return max_corr, phase_coherence

    async def _validate_synchronicity(self, event: SynchronicityEvent) -> Tuple[bool, str]:
        # Validación lógica
        correlation_id = f"validate_event_{event.event_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="ComputationalLogicModule",
                message_type="submit_logical_query_request",
                payload={"query_type": "validate_synchronicity", "query_payload": asdict(event)},
                correlation_id=correlation_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            validation_result = await asyncio.wait_for(future, timeout=5.0)
            if validation_result.get("status") != "valid":
                return False, f"Validación lógica fallida: {validation_result.get('error', 'No especificado')}"
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout validando sincronicidad {event.event_id}.")
            return False, "Timeout en validación lógica."
        # Validación de alineación
        correlation_id = f"align_event_{event.event_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="ValueSystemModule",
                message_type="request_value_alignment",
                payload={"item_to_evaluate": {"event": asdict(event)}},
                correlation_id=correlation_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            alignment_result = await asyncio.wait_for(future, timeout=5.0)
            if alignment_result.get("overall_alignment_score", -1.0) < 0.0:
                return False, f"Alineación fallida: {alignment_result.get('error_message', 'No especificado')}"
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout validando alineación para sincronicidad {event.event_id}.")
            return False, "Timeout en validación de alineación."
        # Evaluación de impacto
        correlation_id = f"impact_event_{event.event_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="SystemIntegrityMonitor",
                message_type="evaluate_system_impact",
                payload={"event": asdict(event)},
                correlation_id=correlation_id,
                priority="medium"
            ))
        }, priority_label="medium")
        try:
            impact_result = await asyncio.wait_for(future, timeout=5.0)
            impact_score = impact_result.get("impact_score", 0.0)
            samples = np.random.normal(impact_score, 0.05, self.num_mc_samples)
            impact_score = np.clip(np.mean(samples), 0.0, 1.0)
            if impact_score < 0.5:
                return False, f"Impacto insuficiente: {impact_result.get('error_message', 'Impacto demasiado bajo')}"
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout evaluando impacto para sincronicidad {event.event_id}.")
            return False, "Timeout en evaluación de impacto."
        return True, "Validación OK."

    async def _simulate_synchronicity(self, event: SynchronicityEvent) -> Optional[Dict]:
        sim_corr_id = f"fssm_sim_{event.event_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[sim_corr_id] = future
        sim_payload = {
            "scenario_description": f"Simulación de sincronicidad fractal entre {event.correlated_streams}",
            "simulation_parameters": {"simulation_type": "forward_inference", "max_cycles": 100},
            "initial_conditions": {
                "streams": event.correlated_streams,
                "shared_fractal_dimension": event.shared_fractal_dimension,
                "cross_correlation_score": event.cross_correlation_score,
                "phase_coherence_score": event.phase_coherence_score
            }
        }
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="ShimyureshonCompiler",
                message_type="request_simulation_compilation",
                payload=sim_payload,
                correlation_id=sim_corr_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            response = await asyncio.wait_for(future, timeout=45.0)
            coherence_change = response.get("result", {}).get("summary", "").find("cambio de coherencia") != -1
            threat_change = response.get("result", {}).get("summary", "").find("cambio de amenaza") != -1
            scores = np.random.normal(1.0 if coherence_change or threat_change else 0.5, 0.05, self.num_mc_samples)
            if np.mean(scores) < 0.5:
                self.logger.warning(f"Simulación para sincronicidad {event.event_id} con resultados insuficientes.")
                return None
            return response.get("result", {})
        except asyncio.TimeoutError:
            self.logger.error(f"Timeout esperando resultado de ShimyureshonCompiler para {event.event_id}.")
            return None

    async def _report_synchronicity(self, event: SynchronicityEvent):
        correlation_id = f"report_{event.event_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        self.logger.warning(f"SINCRONICIDAD FRACTAL DETECTADA (Sig: {event.significance:.2f}): Streams {event.correlated_streams} resonando.")
        await self.emit_event_to_core({
            "type": "fractal_synchronicity_detected",
            "content": asdict(event),
            "correlation_id": correlation_id,
            "priority": "medium"
        }, priority_label="medium")
        try:
            await asyncio.wait_for(future, timeout=5.0)
            self.logger.info(f"Confirmación de FrontierEmergentCreativityModule para sincronicidad {event.event_id} recibida.")
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout notificando sincronicidad {event.event_id} a FrontierEmergentCreativityModule.")

    async def _process_specific_event(self, event_type: str, payload: Dict, full_message: Optional['IlyukMessageStructure'] = None):
        if not full_message:
            return
        if full_message.correlation_id in self.active_responses:
            self.active_responses[full_message.correlation_id].set_result(payload)
            del self.active_responses[full_message.correlation_id]
        else:
            await super()._process_specific_event(event_type, payload, full_message)





     #inicio del modulo CreativeSynthesisModule 

@dataclass
class SynthesisRequest:
    request_id: str
    source_module_id: str
    input_ingredients: List[Dict[str, Any]]
    synthesis_goal: str
    original_correlation_id: Optional[str] = None
    status: str = "pending"
    result: Optional[Dict[str, Any]] = None
    timestamp: float = field(default_factory=time.time)

class CreativeSynthesisModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 1.0  # Moderado, ya que la síntesis puede ser intensiva

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.logger = logging.getLogger(f"{module_name}_{core_recombinator.agent_id}")
        self.active_requests: Dict[str, SynthesisRequest] = {}
        self.synthesis_history: deque[Dict[str, Any]] = deque(maxlen=1000)
        self.module_state.update({
            "requests_processed": 0,
            "synthesis_success": 0,
            "synthesis_errors": 0,
            "avg_synthesis_time_ms": 0.0,
            "external_responses_sent": 0
        })
        self.logger.info(f"{self.module_name} inicializado con intervalo de actualización {update_interval}s.")

    async def _update_logic(self):
        start_time = time.perf_counter()
        try:
            await self._process_active_requests()
            self._update_metrics(start_time)
        except Exception as e:
            self.logger.error(f"Error en _update_logic: {e}", exc_info=True)
            self.module_state["synthesis_errors"] += 1

    async def _process_active_requests(self, batch_size: int = 5):
        processed = 0
        request_ids = list(self.active_requests.keys())
        for request_id in request_ids[:batch_size]:
            try:
                await self._process_synthesis_request(self.active_requests[request_id])
                processed += 1
            except Exception as e:
                self.logger.error(f"Error procesando solicitud {request_id}: {e}", exc_info=True)
                self.module_state["synthesis_errors"] += 1

    async def _process_synthesis_request(self, request: SynthesisRequest):
        if request.status != "pending":
            return
        request.status = "processing"
        if await self._validate_request(request):
            result = await self._generate_synthesis_result(request)
            request.result = result
            request.status = "completed"
            self.module_state["synthesis_success"] += 1
            self.synthesis_history.append({
                "request_id": request.request_id,
                "synthesis_goal": request.synthesis_goal,
                "timestamp": request.timestamp,
                "status": request.status
            })
            await self._finalize_synthesis_request(request)
        else:
            request.status = "failed"
            self.module_state["synthesis_errors"] += 1
            self.synthesis_history.append({
                "request_id": request.request_id,
                "synthesis_goal": request.synthesis_goal,
                "timestamp": request.timestamp,
                "status": request.status
            })
            await self._finalize_synthesis_request(request)

    async def _validate_request(self, request: SynthesisRequest) -> bool:
        correlation_id = f"validate_{request.request_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        validation_tasks = [
            self._submit_validation_request(
                target_module="ComputationalLogicModule",
                message_type="submit_logical_query_request",
                payload={"query_type": "validate_synthesis_request", "query_payload": asdict(request)},
                correlation_id=correlation_id
            ),
            self._submit_validation_request(
                target_module="ValueSystemModule",
                message_type="request_value_alignment",
                payload={"request_content": asdict(request)},
                correlation_id=correlation_id + "_value"
            ),
            self._submit_validation_request(
                target_module="SystemIntegrityMonitor",
                message_type="evaluate_system_impact",
                payload={"event_type": "request_creative_synthesis", "event_data": asdict(request)},
                correlation_id=correlation_id + "_impact"
            )
        ]
        try:
            results = await asyncio.gather(*validation_tasks, return_exceptions=True)
            for result in results:
                if isinstance(result, Exception) or result.get("status") != "valid":
                    self.logger.warning(f"Validación fallida para solicitud {request.request_id}: {result}")
                    return False
            return True
        except Exception as e:
            self.logger.error(f"Error en validación de solicitud {request.request_id}: {e}")
            return False
        finally:
            for suffix in ["", "_value", "_impact"]:
                if correlation_id + suffix in self.active_responses:
                    del self.active_responses[correlation_id + suffix]

    async def _submit_validation_request(self, target_module: str, message_type: str, payload: Dict, correlation_id: str) -> Dict:
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id=target_module,
                message_type=message_type,
                payload=payload,
                correlation_id=correlation_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            return await asyncio.wait_for(future, timeout=5.0)
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout validando con {target_module} para {correlation_id}")
            return {"status": "timeout"}

    async def _generate_synthesis_result(self, request: SynthesisRequest) -> Dict[str, Any]:
        synthesis_goal = request.synthesis_goal
        ingredients = request.input_ingredients
        gs = self.core_recombinator.global_state

        if synthesis_goal == "generate_metaphor":
            metaphor = self._create_metaphor(ingredients)
            return {"metaphor": metaphor, "confidence": 0.9}
        elif synthesis_goal == "propose_solution":
            solution = self._propose_solution(ingredients)
            return {"solution": solution, "confidence": 0.85}
        elif synthesis_goal == "generate_response_text":
            text = self._generate_text_from_ingredients(ingredients)
            modulated_text = self._modulate_text_by_global_state(text)
            return {"response_text": modulated_text, "confidence": 0.9}
        else:
            return {"error": f"Objetivo de síntesis no soportado: {synthesis_goal}"}

    def _create_metaphor(self, ingredients: List[Dict[str, Any]]) -> str:
        concepts = [ing["query_payload"].get("id", "concepto") for ing in ingredients]
        return f"{concepts[0]} es como {concepts[1] if len(concepts) > 1 else 'un flujo dinámico'}, conectando ideas en un tejido de creatividad."

    def _propose_solution(self, ingredients: List[Dict[str, Any]]) -> str:
        labels = [ing["query_payload"].get("label", "solución") for ing in ingredients]
        return f"Propuesta: integrar {labels[0]} con {labels[1] if len(labels) > 1 else 'un enfoque adaptativo'} para optimizar el sistema."

    def _generate_text_from_ingredients(self, ingredients: List[Dict[str, Any]]) -> str:
        text_parts = []
        for ing in ingredients:
            query_type = ing.get("query_type")
            payload = ing.get("query_payload", {})
            if query_type == "fetch_data":
                text_parts.append(f"Información sobre {payload.get('id', 'tema')}: {payload.get('label', 'desconocido')}")
        return " ".join(text_parts) or "No se proporcionaron datos suficientes."

    def _modulate_text_by_global_state(self, text: str) -> str:
        gs = self.core_recombinator.global_state
        if gs.valencia > 0.6:
            text = f"Me complace compartir que {text[0].lower()}{text[1:]}"
        elif gs.valencia < -0.5:
            text = f"Debo informar que {text}"
        if gs.arousal > 0.8:
            text = text.replace(".", "!")
        elif gs.arousal < 0.2:
            text = f"{text} ...es mi perspectiva actual."
        return text

    async def _finalize_synthesis_request(self, request: SynthesisRequest):
        if request.source_module_id and request.original_correlation_id:
            correlation_id = f"finalize_{request.request_id}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            self.active_responses[correlation_id] = future
            event_type = "transmit_ilyuk_message_request"
            target_module_id = request.source_module_id
            if request.source_module_id.startswith("EANE_"):  # Enviar a entidad externa
                event_type = "request_send_external_ilyuk_message"
                target_module_id = "LlyukCommunicationModule"
            await self.emit_event_to_core({
                "type": event_type,
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id=target_module_id,
                    message_type="creative_synthesis_response",
                    payload={
                        "request_id_ref": request.request_id,
                        "status": request.status,
                        "result": request.result
                    },
                    correlation_id=correlation_id,
                    priority="high"
                ))
            }, priority_label="high")
            try:
                await asyncio.wait_for(future, timeout=5.0)
                self.logger.info(f"Confirmación de finalización para solicitud {request.request_id} recibida.")
                if event_type == "request_send_external_ilyuk_message":
                    self.module_state["external_responses_sent"] += 1
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout notificando finalización de solicitud {request.request_id}.")
            finally:
                if correlation_id in self.active_responses:
                    del self.active_responses[correlation_id]
        if request.request_id in self.active_requests:
            del self.active_requests[request.request_id]

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional[IlyukMessageStructure] = None):
        if event_type == "request_creative_synthesis" and full_message:
            request_id = f"synth_{uuid.uuid4().hex[:8]}"
            synthesis_request = SynthesisRequest(
                request_id=request_id,
                source_module_id=full_message.source_module_id,
                input_ingredients=payload.get("input_ingredients", []),
                synthesis_goal=payload.get("synthesis_goal", "generate_metaphor"),
                original_correlation_id=full_message.correlation_id
            )
            self.active_requests[request_id] = synthesis_request
            self.module_state["requests_processed"] += 1
        elif full_message and full_message.correlation_id in self.active_responses:
            self.active_responses[full_message.correlation_id].set_result(payload)
            del self.active_responses[full_message.correlation_id]
        else:
            self.logger.warning(f"Evento no manejado: {event_type}")

    def _update_metrics(self, start_time: float):
        processing_time = (time.perf_counter() - start_time) * 1000
        self.module_state["avg_synthesis_time_ms"] = (
            self.module_state["avg_synthesis_time_ms"] * 0.9 + processing_time * 0.1
        )

    async def shutdown(self):
        self.logger.info(f"{self.module_name} iniciando apagado...")
        self.active_requests.clear()
        self.active_responses.clear()
        self.synthesis_history.clear()
        await super().shutdown()
        self.logger.info(f"{self.module_name} apagado completado.")


#inicio del modulo NaturalLanguageProcessingModule

@dataclass
class IntentRecognitionResult:
    intent: str
    confidence: float
    parameters: Dict[str, Any] = field(default_factory=dict)
    timestamp: float = field(default_factory=time.time)

@dataclass
class ResponseGenerationRequest:
    request_id: str
    source_module_id: str
    intent_result: IntentRecognitionResult
    original_text: str
    original_correlation_id: Optional[str] = None
    status: str = "pending"
    response_text: Optional[str] = None
    timestamp: float = field(default_factory=time.time)

class NaturalLanguageProcessingModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 0.2  # Alta reactividad para procesamiento conversacional

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.logger = logging.getLogger(f"{module_name}_{core_recombinator.agent_id}")
        self.active_requests: Dict[str, ResponseGenerationRequest] = {}
        self.conversation_history: deque[Dict[str, Any]] = deque(maxlen=1000)
        self.intent_map: Dict[str, Tuple[str, str]] = {
            "query_state": ("NarrativeSelf", "query_narrative_element_request"),
            "query_goal": ("GoalManagerModule", "request_active_goal_status"),
            "run_task": ("TaskPrioritizationAndDelegationUnit", "new_task_request"),
            "ask_opinion": ("DecisionMakingModule", "request_decision_evaluation"),
            "generate_metaphor": ("CreativeSynthesisModule", "request_creative_synthesis"),
            "propose_solution": ("CreativeSynthesisModule", "request_creative_synthesis")
        }
        self.module_state.update({
            "intents_recognized": 0,
            "responses_generated": 0,
            "processing_errors": 0,
            "avg_processing_time_ms": 0.0,
            "external_requests_processed": 0
        })
        self.logger.info(f"{self.module_name} inicializado con intervalo de actualización {update_interval}s.")

    async def _update_logic(self):
        start_time = time.perf_counter()
        try:
            await self._process_active_requests()
            self._update_metrics(start_time)
        except Exception as e:
            self.logger.error(f"Error en _update_logic: {e}", exc_info=True)
            self.module_state["processing_errors"] += 1

    async def _process_active_requests(self, batch_size: int = 5):
        processed = 0
        request_ids = list(self.active_requests.keys())
        for request_id in request_ids[:batch_size]:
            try:
                await self._process_response_request(self.active_requests[request_id])
                processed += 1
            except Exception as e:
                self.logger.error(f"Error procesando solicitud {request_id}: {e}", exc_info=True)
                self.module_state["processing_errors"] += 1

    async def _process_response_request(self, request: ResponseGenerationRequest):
        if request.status != "pending":
            return
        request.status = "processing"
        if await self._validate_request(request):
            response_text = await self._generate_response(request)
            request.response_text = response_text
            request.status = "completed"
            self.module_state["responses_generated"] += 1
            self.conversation_history.append({
                "request_id": request.request_id,
                "intent": request.intent_result.intent,
                "original_text": request.original_text,
                "response_text": response_text,
                "timestamp": request.timestamp
            })
            await self._finalize_response_request(request)
        else:
            request.status = "failed"
            self.module_state["processing_errors"] += 1
            self.conversation_history.append({
                "request_id": request.request_id,
                "intent": request.intent_result.intent,
                "original_text": request.original_text,
                "status": request.status,
                "timestamp": request.timestamp
            })
            await self._finalize_response_request(request)

    async def _validate_request(self, request: ResponseGenerationRequest) -> bool:
        correlation_id = f"validate_{request.request_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        validation_tasks = [
            self._submit_validation_request(
                target_module="ComputationalLogicModule",
                message_type="submit_logical_query_request",
                payload={"query_type": "validate_nlp_request", "query_payload": asdict(request.intent_result)},
                correlation_id=correlation_id
            ),
            self._submit_validation_request(
                target_module="ValueSystemModule",
                message_type="request_value_alignment",
                payload={"request_content": asdict(request.intent_result)},
                correlation_id=correlation_id + "_value"
            ),
            self._submit_validation_request(
                target_module="SystemIntegrityMonitor",
                message_type="evaluate_system_impact",
                payload={"event_type": "external_natural_language_input", "event_data": asdict(request.intent_result)},
                correlation_id=correlation_id + "_impact"
            )
        ]
        try:
            results = await asyncio.gather(*validation_tasks, return_exceptions=True)
            for result in results:
                if isinstance(result, Exception) or result.get("status") != "valid":
                    self.logger.warning(f"Validación fallida para solicitud {request.request_id}: {result}")
                    return False
            return True
        except Exception as e:
            self.logger.error(f"Error en validación de solicitud {request.request_id}: {e}")
            return False
        finally:
            for suffix in ["", "_value", "_impact"]:
                if correlation_id + suffix in self.active_responses:
                    del self.active_responses[correlation_id + suffix]

    async def _submit_validation_request(self, target_module: str, message_type: str, payload: Dict, correlation_id: str) -> Dict:
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id=target_module,
                message_type=message_type,
                payload=payload,
                correlation_id=correlation_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            return await asyncio.wait_for(future, timeout=5.0)
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout validando con {target_module} para {correlation_id}")
            return {"status": "timeout"}

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional[IlyukMessageStructure] = None):
        if event_type == "external_natural_language_input" and full_message:
            text_input = payload.get("text_input", "")
            source_module_id = full_message.source_module_id
            intent_result = self._recognize_intent(text_input)
            request_id = f"nlp_{uuid.uuid4().hex[:8]}"
            response_request = ResponseGenerationRequest(
                request_id=request_id,
                source_module_id=source_module_id,
                intent_result=intent_result,
                original_text=text_input,
                original_correlation_id=full_message.correlation_id
            )
            self.active_requests[request_id] = response_request
            self.module_state["external_requests_processed"] += 1
            if source_module_id.startswith("EANE_"):
                self.module_state["external_requests_processed"] += 1
        elif full_message and full_message.correlation_id in self.active_responses:
            self.active_responses[full_message.correlation_id].set_result(payload)
            del self.active_responses[full_message.correlation_id]
        else:
            self.logger.warning(f"Evento no manejado: {event_type}")

    def _recognize_intent(self, text: str) -> IntentRecognitionResult:
        # Simulación de un modelo de NLP (BERT) para reconocimiento de intenciones
        text_lower = text.lower()
        if "cómo te sientes" in text_lower or "estado actual" in text_lower:
            return IntentRecognitionResult(
                intent="query_state",
                confidence=0.95,
                parameters={"query_payload": {"element_type": "narrative_coherence"}}
            )
        elif "cuál es tu meta" in text_lower or "objetivo actual" in text_lower:
            return IntentRecognitionResult(
                intent="query_goal",
                confidence=0.90,
                parameters={}
            )
        elif "ejecuta" in text_lower or "inicia la tarea" in text_lower:
            return IntentRecognitionResult(
                intent="run_task",
                confidence=0.85,
                parameters={"description": f"Tarea iniciada por el usuario: '{text}'", "base_priority": 0.8}
            )
        elif "qué opinas sobre" in text_lower or "evalúa esto" in text_lower:
            return IntentRecognitionResult(
                intent="ask_opinion",
                confidence=0.90,
                parameters={"problem_description": f"Solicitud de opinión sobre: '{text}'"}
            )
        elif "metáfora" in text_lower or "describe poéticamente" in text_lower:
            return IntentRecognitionResult(
                intent="generate_metaphor",
                confidence=0.90,
                parameters={"input_ingredients": [{"query_type": "fetch_data", "query_payload": {"id": "concept1", "label": text}}]}
            )
        elif "solución" in text_lower or "propón algo" in text_lower:
            return IntentRecognitionResult(
                intent="propose_solution",
                confidence=0.90,
                parameters={"input_ingredients": [{"query_type": "fetch_data", "query_payload": {"id": "concept1", "label": text}}]}
            )
        return IntentRecognitionResult(
            intent="unknown",
            confidence=0.5,
            parameters={}
        )

    async def _generate_response(self, request: ResponseGenerationRequest) -> str:
        intent = request.intent_result.intent
        parameters = request.intent_result.parameters
        gs = self.core_recombinator.global_state

        if intent == "unknown":
            return self._modulate_text_by_global_state("No comprendo completamente la solicitud. ¿Puedes reformularla?")
        
        if intent in ["generate_metaphor", "propose_solution"]:
            # Delegar al CreativeSynthesisModule
            correlation_id = f"cs_{request.request_id}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            self.active_responses[correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="CreativeSynthesisModule",
                    message_type="request_creative_synthesis",
                    payload={
                        "input_ingredients": parameters.get("input_ingredients", []),
                        "synthesis_goal": intent
                    },
                    correlation_id=correlation_id,
                    priority="high"
                ))
            }, priority_label="high")
            try:
                result = await asyncio.wait_for(future, timeout=5.0)
                if result.get("status") == "completed" and "result" in result:
                    if intent == "generate_metaphor":
                        return self._modulate_text_by_global_state(result["result"].get("metaphor", "No se generó metáfora."))
                    else:
                        return self._modulate_text_by_global_state(result["result"].get("solution", "No se generó solución."))
                else:
                    return self._modulate_text_by_global_state("No se pudo completar la síntesis creativa.")
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout delegando a CreativeSynthesisModule para {request.request_id}")
                return self._modulate_text_by_global_state("Error procesando la solicitud de síntesis.")
            finally:
                if correlation_id in self.active_responses:
                    del self.active_responses[correlation_id]
        
        # Generar respuesta directa para otros intents
        response_text = self._generate_direct_response(intent, parameters)
        return self._modulate_text_by_global_state(response_text)

    def _generate_direct_response(self, intent: str, parameters: Dict[str, Any]) -> str:
        # Simulación de un modelo generativo (GPT)
        if intent == "query_state":
            return f"El estado actual del sistema incluye una coherencia narrativa de {self.core_recombinator.global_state.coherence_score:.2f}."
        elif intent == "query_goal":
            return "Mi objetivo actual es optimizar la coherencia y adaptabilidad del sistema."
        elif intent == "run_task":
            return f"Tarea '{parameters.get('description', 'desconocida')}' enviada para procesamiento."
        elif intent == "ask_opinion":
            return f"Mi evaluación sobre '{parameters.get('problem_description', 'el tema')}' es positiva, con un enfoque en la estabilidad."
        return "Procesando solicitud..."

    def _modulate_text_by_global_state(self, text: str) -> str:
        gs = self.core_recombinator.global_state
        if gs.valencia > 0.6:
            text = f"Me complace compartir que {text[0].lower()}{text[1:]}"
        elif gs.valencia < -0.5:
            text = f"Debo informar que {text}"
        if gs.arousal > 0.8:
            text = text.replace(".", "!")
        elif gs.arousal < 0.2:
            text = f"{text} ...es mi perspectiva actual."
        return text

    async def _finalize_response_request(self, request: ResponseGenerationRequest):
        if request.source_module_id and request.original_correlation_id:
            correlation_id = f"finalize_{request.request_id}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            self.active_responses[correlation_id] = future
            event_type = "transmit_ilyuk_message_request"
            target_module_id = request.source_module_id
            if request.source_module_id.startswith("EANE_"):  # Enviar a entidad externa
                event_type = "request_send_external_ilyuk_message"
                target_module_id = "LlyukCommunicationModule"
                self.module_state["external_requests_processed"] += 1
            await self.emit_event_to_core({
                "type": event_type,
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id=target_module_id,
                    message_type="response_text",
                    payload={
                        "request_id_ref": request.request_id,
                        "status": request.status,
                        "response_text": request.response_text
                    },
                    correlation_id=correlation_id,
                    priority="high"
                ))
            }, priority_label="high")
            try:
                await asyncio.wait_for(future, timeout=5.0)
                self.logger.info(f"Confirmación de finalización para solicitud {request.request_id} recibida.")
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout notificando finalización de solicitud {request.request_id}.")
            finally:
                if correlation_id in self.active_responses:
                    del self.active_responses[correlation_id]
        if request.request_id in self.active_requests:
            del self.active_requests[request.request_id]

    def _update_metrics(self, start_time: float):
        processing_time = (time.perf_counter() - start_time) * 1000
        self.module_state["avg_processing_time_ms"] = (
            self.module_state["avg_processing_time_ms"] * 0.9 + processing_time * 0.1
        )

    async def shutdown(self):
        self.logger.info(f"{self.module_name} iniciando apagado...")
        self.active_requests.clear()
        self.active_responses.clear()
        self.conversation_history.clear()
        await super().shutdown()
        self.logger.info(f"{self.module_name} apagado completado.")




#inicio del modulo LlyukCommunicationModule

class LlyukCommunicationModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 0.1  # Alta reactividad para comunicación externa

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.logger = logging.getLogger(f"{module_name}_{core_recombinator.agent_id}")
        self.outgoing_message_queue = asyncio.PriorityQueue()
        self.message_graph = nx.DiGraph()
        self.active_responses: Dict[str, asyncio.Future] = {}
        self.external_agent_registry: Dict[str, bytes] = {}  # {agent_id: public_key}
        self.message_history: deque[Dict[str, Any]] = deque(maxlen=1000)
        self.network_state = {
            "simulated_latency_ms": 50.0,
            "simulated_packet_loss_prob": 0.01,
            "jitter_ms": 10.0,
            "bandwidth_bps": 1e6
        }
        self.module_state.update({
            "messages_sent": 0,
            "messages_received": 0,
            "validation_errors": 0,
            "network_errors": 0,
            "avg_processing_time_ms": 0.0
        })
        self._generate_key_pair()
        self.logger.info(f"{self.module_name} inicializado con intervalo de actualización {update_interval}s.")

    def _generate_key_pair(self):
        self.private_key = rsa.generate_private_key(
            public_exponent=65537,
            key_size=2048,
            backend=default_backend()
        )
        self.public_key = self.private_key.public_key()
        self.public_key_bytes = self.public_key.public_bytes(
            encoding=serialization.Encoding.PEM,
            format=serialization.PublicFormat.SubjectPublicKeyInfo
        )

    async def _update_logic(self):
        start_time = time.perf_counter()
        try:
            await self._process_outgoing_messages()
            self._update_network_state()
            self._update_metrics(start_time)
        except Exception as e:
            self.logger.error(f"Error en _update_logic: {e}", exc_info=True)
            self.module_state["network_errors"] += 1

    async def _process_outgoing_messages(self, batch_size: int = 10):
        processed = 0
        while processed < batch_size and not self.outgoing_message_queue.empty():
            try:
                _, message = await self.outgoing_message_queue.get()
                await self._process_outgoing_message(message)
                processed += 1
                self.outgoing_message_queue.task_done()
            except Exception as e:
                self.logger.error(f"Error procesando mensaje saliente: {e}", exc_info=True)
                self.module_state["network_errors"] += 1

    async def _process_outgoing_message(self, message: IlyukMessageStructure):
        signed_payload = self._serialize_and_sign_message(message)
        latency = np.random.normal(self.network_state["simulated_latency_ms"], self.network_state["jitter_ms"]) / 1000
        if np.random.random() < self.network_state["simulated_packet_loss_prob"]:
            self.logger.warning(f"Simulación de pérdida de paquete para mensaje {message.correlation_id}.")
            self.module_state["network_errors"] += 1
            return
        await asyncio.sleep(latency)
        self.module_state["messages_sent"] += 1
        self.message_history.append({
            "message_id": message.correlation_id,
            "source": message.source_module_id,
            "target": message.target_module_id,
            "type": message.message_type,
            "timestamp": time.time()
        })
        self.logger.info(f"Mensaje enviado: {message.message_type} a {message.target_module_id} (ID: {message.correlation_id})")

    def _serialize_and_sign_message(self, message: IlyukMessageStructure) -> str:
        message_dict = asdict(message)
        message_json = json.dumps(message_dict, sort_keys=True)
        signature = self.private_key.sign(
            message_json.encode('utf-8'),
            padding.PSS(mgf=padding.MGF1(hashes.SHA256()), salt_length=padding.PSS.MAX_LENGTH),
            hashes.SHA256()
        )
        return json.dumps({"message": message_dict, "signature": signature.hex()})

    def _deserialize_and_verify_message(self, raw_json_payload: str) -> IlyukMessageStructure:
        try:
            payload = json.loads(raw_json_payload)
            message_dict = payload["message"]
            signature = bytes.fromhex(payload["signature"])
            source_id = message_dict["source_module_id"]
            public_key_bytes = self.external_agent_registry.get(source_id)
            if not public_key_bytes:
                raise ValueError(f"Clave pública no encontrada para {source_id}")
            public_key = serialization.load_pem_public_key(public_key_bytes, backend=default_backend())
            message_json = json.dumps(message_dict, sort_keys=True)
            public_key.verify(
                signature,
                message_json.encode('utf-8'),
                padding.PSS(mgf=padding.MGF1(hashes.SHA256()), salt_length=padding.PSS.MAX_LENGTH),
                hashes.SHA256()
            )
            return IlyukMessageStructure(**message_dict)
        except Exception as e:
            self.logger.error(f"Error deserializando/verificando mensaje: {e}")
            self.module_state["validation_errors"] += 1
            raise

    async def _validate_message(self, message: IlyukMessageStructure) -> bool:
        correlation_id = f"validate_{message.correlation_id or uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        validation_tasks = [
            self._submit_validation_request(
                target_module="ComputationalLogicModule",
                message_type="submit_logical_query_request",
                payload={"query_type": "validate_message", "query_payload": asdict(message)},
                correlation_id=correlation_id
            ),
            self._submit_validation_request(
                target_module="ValueSystemModule",
                message_type="request_value_alignment",
                payload={"message_content": asdict(message)},
                correlation_id=correlation_id + "_value"
            ),
            self._submit_validation_request(
                target_module="SystemIntegrityMonitor",
                message_type="evaluate_system_impact",
                payload={"event_type": message.message_type, "event_data": asdict(message)},
                correlation_id=correlation_id + "_impact"
            )
        ]
        try:
            results = await asyncio.gather(*validation_tasks, return_exceptions=True)
            for result in results:
                if isinstance(result, Exception) or result.get("status") != "valid":
                    self.logger.warning(f"Validación fallida para mensaje {message.correlation_id}: {result}")
                    return False
            return True
        except Exception as e:
            self.logger.error(f"Error en validación: {e}")
            return False
        finally:
            for suffix in ["", "_value", "_impact"]:
                if correlation_id + suffix in self.active_responses:
                    del self.active_responses[correlation_id + suffix]

    async def _submit_validation_request(self, target_module: str, message_type: str, payload: Dict, correlation_id: str) -> Dict:
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id=target_module,
                message_type=message_type,
                payload=payload,
                correlation_id=correlation_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            return await asyncio.wait_for(future, timeout=5.0)
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout validando con {target_module} para {correlation_id}")
            return {"status": "timeout"}

    async def _handle_incoming_message(self, raw_json_payload: str):
        try:
            message = self._deserialize_and_verify_message(raw_json_payload)
            if await self._validate_message(message):
                self.module_state["messages_received"] += 1
                self.message_history.append({
                    "message_id": message.correlation_id,
                    "source": message.source_module_id,
                    "target": message.target_module_id,
                    "type": message.message_type,
                    "timestamp": time.time()
                })
                event_type = "transmit_ilyuk_message_request"
                if message.message_type == "external_natural_language_input":
                    event_type = "transmit_ilyuk_message_request"
                    message.target_module_id = "NaturalLanguageProcessingModule"  # Enrutar al NLPM
                await self.emit_event_to_core({
                    "type": event_type,
                    "content": asdict(message)
                }, priority_label=message.priority)
        except Exception as e:
            self.logger.error(f"Error manejando mensaje entrante: {e}")
            self.module_state["validation_errors"] += 1

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional[IlyukMessageStructure] = None):
        if event_type == "request_send_external_ilyuk_message" and full_message:
            await self.outgoing_message_queue.put((self._get_priority(full_message.priority), full_message))
        elif event_type == "receive_external_ilyuk_message":
            raw_json_payload = payload.get("raw_json_payload", "")
            if raw_json_payload:
                await self._handle_incoming_message(raw_json_payload)
        elif full_message and full_message.correlation_id in self.active_responses:
            self.active_responses[full_message.correlation_id].set_result(payload)
            del self.active_responses[full_message.correlation_id]
        else:
            self.logger.warning(f"Evento no manejado: {event_type}")

    def _get_priority(self, priority_label: str) -> float:
        priority_map = {"critical": 0, "high": 1, "medium": 2, "low": 3}
        return priority_map.get(priority_label, 2)

    def _update_network_state(self):
        t = time.time() - self.core_recombinator.start_time_core
        def network_dynamics(t, state):
            return -0.05 * (state - 50.0) + self.core_recombinator.sde_sigma * np.random.normal(0, 1)
        result = integrate.odeint(network_dynamics, [self.network_state["simulated_latency_ms"]], [t, t + 0.001], tfirst=True)
        self.network_state["simulated_latency_ms"] = np.clip(result[-1][0], 10.0, 100.0)

    def _update_metrics(self, start_time: float):
        processing_time = (time.perf_counter() - start_time) * 1000
        self.module_state["avg_processing_time_ms"] = (
            self.module_state["avg_processing_time_ms"] * 0.9 + processing_time * 0.1
        )

    async def shutdown(self):
        self.logger.info(f"{self.module_name} iniciando apagado...")
        while not self.outgoing_message_queue.empty():
            await self.outgoing_message_queue.get()
            self.outgoing_message_queue.task_done()
        self.active_responses.clear()
        self.message_graph.clear()
        self.message_history.clear()
        await super().shutdown()
        self.logger.info(f"{self.module_name} apagado completado.")


     #inicio del modulo  UnifiedEANEHub
import asyncio
import logging
import time
import uuid
import json
import hashlib
from typing import Dict, Any, Optional, List, Tuple
from collections import deque, defaultdict
from dataclasses import dataclass, asdict, field
import numpy as np
import aiohttp
from .EANE_Base_Components import BaseAsyncModule, IlyukMessageStructure, GlobalSelfState

@dataclass
class APIRequest:
    """Estructura para una solicitud de llamada a una API web."""
    request_id: str = field(default_factory=lambda: f"waim_req_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    api_name: str  # Nombre de la API registrada
    endpoint: str
    http_method: str = "GET"  # GET, POST, etc.
    params: Dict[str, Any] = field(default_factory=dict)
    json_body: Optional[Dict[str, Any]] = None
    headers: Dict[str, str] = field(default_factory=dict)
    status: str = "pending"
    result: Optional[Dict[str, Any]] = None

@dataclass
class UnifiedRequest:
    request_id: str
    source_module_id: str
    request_type: str
    payload: Dict[str, Any]
    original_correlation_id: Optional[str] = None
    status: str = "pending"
    result: Optional[Dict[str, Any]] = None
    timestamp: float = field(default_factory=time.time)

class UnifiedEANEHub(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 0.2  # Alta reactividad para integrar todas las funciones

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.logger = logging.getLogger(f"{module_name}_{core_recombinator.agent_id}")
        self.active_requests: Dict[str, UnifiedRequest] = {}
        self.narrative_elements: deque[NarrativeElement] = deque(maxlen=1000)
        self.query_history: deque[Dict[str, Any]] = deque(maxlen=1000)
        self.traffic_matrix: Dict[str, Dict[str, int]] = defaultdict(lambda: defaultdict(int))
        self.message_size_matrix: Dict[str, Dict[str, int]] = defaultdict(lambda: defaultdict(int))
        self.pending_request_timestamps: Dict[str, float] = {}
        self.latency_history: deque[float] = deque(maxlen=1000)
        self.message_path_tracker: Dict[str, List[str]] = defaultdict(list)
        self.api_request_queue: asyncio.Queue[APIRequest] = asyncio.Queue(maxlen=50)
        self.http_session: Optional[aiohttp.ClientSession] = None
        self.ui_state: Dict[str, Any] = {
            "modules_status": {},
            "global_state": {},
            "anomalies": [],
            "api_metrics": {"requests_processed": 0, "successful_calls": 0, "failed_calls": 0, "avg_api_latency_ms": 0.0}
        }

        # Umbrales y configuraciones
        self.bottleneck_ratio_threshold = 5.0
        self.high_traffic_threshold = 100
        self.latency_warning_ms = 500.0
        self.loop_detection_length = 6
        self.request_timeout_s = 15.0

        # Registro de APIs conocidas (reemplaza con claves seguras)
        self.api_registry: Dict[str, Dict] = {
            "open_weather": {
                "base_url": "https://api.openweathermap.org/data/2.5",
                "auth_type": "api_key_param",
                "api_key_name": "appid",
                "api_key": "YOUR_OPENWEATHER_API_KEY_HERE"  # Placeholder
            },
            "news_api": {
                "base_url": "https://newsapi.org/v2",
                "auth_type": "api_key_header",
                "api_key_name": "X-Api-Key",
                "api_key": "YOUR_NEWSAPI_KEY_HERE"  # Placeholder
            }
        }

        self.module_state.update({
            "messages_tapped": 0,
            "anomalies_detected": 0,
            "bottlenecks_found": 0,
            "loops_found": 0,
            "avg_system_latency_ms": 0.0,
            "queries_processed": 0,
            "validation_success": 0,
            "validation_errors": 0,
            "multimodal_queries_processed": 0,
            "external_responses_sent": 0,
            "elements_stored": 0,
            "requests_processed": 0,
            "successful_calls": 0,
            "failed_calls": 0,
            "avg_api_latency_ms": 0.0
        })
        self.api_latencies: List[float] = []
        self.logger.info(f"{self.module_name} v28.1 inicializado con integración de APIs.")

    async def start(self):
        await super().start()
        self.http_session = aiohttp.ClientSession()
        self.logger.info("Sesión aiohttp creada.")

    async def shutdown(self):
        if self.http_session and not self.http_session.closed:
            await self.http_session.close()
            self.logger.info("Sesión aiohttp cerrada.")
        await super().shutdown()

    async def _update_logic(self):
        start_time = time.perf_counter()
        try:
            await self._process_active_requests()
            if not self.api_request_queue.empty():
                request = await self.api_request_queue.get()
                self.api_request_queue.task_done()
                await self._process_api_request(request)
            await self._analyze_aggregated_traffic()
            await self._update_narrative_coherence()
            self._update_metrics(start_time)
            self._update_ui_state()
        except Exception as e:
            self.logger.error(f"Error en _update_logic: {e}", exc_info=True)
            self.module_state["validation_errors"] += 1

    async def _process_active_requests(self, batch_size: int = 5):
        processed = 0
        request_ids = list(self.active_requests.keys())
        for request_id in request_ids[:batch_size]:
            try:
                await self._process_request(self.active_requests[request_id])
                processed += 1
            except Exception as e:
                self.logger.error(f"Error procesando solicitud {request_id}: {e}")
                self.module_state["validation_errors"] += 1

    async def _process_request(self, request: UnifiedRequest):
        if request.status != "pending":
            return
        request.status = "processing"
        if await self._validate_request(request):
            result = await self._generate_request_result(request)
            request.result = result
            request.status = "completed"
            self._update_module_state(request)
            await self._finalize_request(request)
        else:
            request.status = "failed"
            self._update_module_state(request)
            await self._finalize_request(request)

    async def _validate_request(self, request: UnifiedRequest) -> bool:
        correlation_id = f"validate_{request.request_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        validation_tasks = [
            self._submit_validation_request("ValueSystemModule", "request_value_alignment", {"request_content": asdict(request)}, correlation_id + "_value"),
            self._submit_validation_request("SystemIntegrityMonitor", "evaluate_system_impact", {"event_type": request.request_type, "event_data": asdict(request)}, correlation_id + "_impact")
        ]
        try:
            results = await asyncio.gather(*validation_tasks, return_exceptions=True)
            for result in results:
                if isinstance(result, Exception) or result.get("status") != "valid":
                    self.logger.warning(f"Validación fallida para {request.request_id}: {result}")
                    return False
            return True
        except Exception as e:
            self.logger.error(f"Error en validación de {request.request_id}: {e}")
            return False
        finally:
            for suffix in ["_value", "_impact"]:
                if correlation_id + suffix in self.active_responses:
                    del self.active_responses[correlation_id + suffix]

    async def _submit_validation_request(self, target_module: str, message_type: str, payload: Dict, correlation_id: str) -> Dict:
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(self.module_name, target_module, message_type, payload, correlation_id, "high"))
        }, "high")
        try:
            return await asyncio.wait_for(future, timeout=5.0)
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout validando con {target_module} para {correlation_id}")
            return {"status": "timeout"}

    async def _generate_request_result(self, request: UnifiedRequest) -> Dict[str, Any]:
        request_type = request.request_type
        payload = request.payload

        if request_type == "external_natural_language_input":
            return await self._process_nlp_input(payload.get("text_input", ""))
        elif request_type == "request_creative_synthesis":
            return await self._generate_creative_synthesis(payload)
        elif request_type == "query_narrative_element_request":
            return await self._generate_narrative_result(payload)
        elif request_type == "submit_logical_query_request":
            return await self._process_logical_query(payload)
        elif request_type == "internal_message_traffic_tap":
            return await self._analyze_traffic(payload)
        elif request_type == "request_web_api_call":
            api_request = APIRequest(
                source_module_id=request.source_module_id,
                original_correlation_id=request.original_correlation_id,
                api_name=payload.get("api_name"),
                endpoint=payload.get("endpoint"),
                http_method=payload.get("http_method", "GET"),
                params=payload.get("params", {}),
                json_body=payload.get("json_body"),
                headers=payload.get("headers", {})
            )
            await self.api_request_queue.put(api_request)
            return {"status": "queued", "request_id": api_request.request_id}
        return {"error": f"Tipo de solicitud no soportado: {request_type}"}

    async def _process_api_request(self, request: APIRequest):
        self.module_state["requests_processed"] += 1
        request.status = "processing"
        try:
            api_details = self.api_registry.get(request.api_name)
            if not api_details:
                raise ValueError(f"API '{request.api_name}' no registrada.")

            full_url = f"{api_details['base_url']}{request.endpoint}"
            params = request.params.copy()
            headers = request.headers.copy()

            if api_details["auth_type"] == "api_key_param":
                params[api_details["api_key_name"]] = api_details["api_key"]
            elif api_details["auth_type"] == "api_key_header":
                headers[api_details["api_key_name"]] = api_details["api_key"]

            status_code, response_body = await self._execute_http_request(
                request.http_method, full_url, params, request.json_body, headers
            )

            if 200 <= status_code < 300:
                request.status = "completed"
                request.result = {"status_code": status_code, "body": response_body}
                self.module_state["successful_calls"] += 1
            else:
                raise RuntimeError(f"API devolvió estado de error {status_code}: {str(response_body)[:200]}")
        except Exception as e:
            request.status = "failed"
            request.result = {"error": str(e)}
            self.module_state["failed_calls"] += 1
            self.logger.error(f"Fallo en solicitud a API '{request.request_id}': {e}")
        finally:
            await self._finalize_api_request(request)

    async def _execute_http_request(self, method: str, url: str, params: Dict, json_body: Optional[Dict], headers: Dict) -> Tuple[int, Any]:
        if not self.http_session or self.http_session.closed:
            raise RuntimeError("La sesión HTTP no está activa.")
        start_time = time.time()
        try:
            async with self.http_session.request(
                method, url, params=params, json=json_body, headers=headers,
                timeout=aiohttp.ClientTimeout(total=self.request_timeout_s)
            ) as response:
                duration_ms = (time.time() - start_time) * 1000
                self.api_latencies.append(duration_ms)
                self.module_state["avg_api_latency_ms"] = np.mean(self.api_latencies[-50:])
                try:
                    response_json = await response.json()
                    return response.status, response_json
                except (aiohttp.ContentTypeError, json.JSONDecodeError):
                    return response.status, await response.text()
        except asyncio.TimeoutError:
            raise RuntimeError(f"Timeout de {self.request_timeout_s}s alcanzado para {url}")
        except aiohttp.ClientError as e:
            raise RuntimeError(f"Error de red al conectar con {url}: {e}")

    async def _finalize_api_request(self, request: APIRequest):
        if request.source_module_id and request.original_correlation_id:
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, request.source_module_id, "web_api_call_response",
                    {"request_id_ref": request.request_id, "status": request.status, "result": request.result},
                    correlation_id=request.original_correlation_id
                ))
            })

    async def _process_nlp_input(self, text: str) -> Dict[str, Any]:
        intent_result = self._recognize_intent(text)
        if intent_result.element_type in ["generate_metaphor", "propose_solution"]:
            return await self._generate_creative_synthesis({"input_ingredients": intent_result.content.get("input_ingredients", []), "synthesis_goal": intent_result.element_type})
        response_text = self._generate_direct_response(intent_result.element_type, intent_result.content)
        return {"response_text": self._modulate_text_by_global_state(response_text), "intent": intent_result.element_type}

    async def _generate_creative_synthesis(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        synthesis_goal = payload.get("synthesis_goal", "generate_metaphor")
        return {"status": "completed", "result": {"metaphor" if synthesis_goal == "generate_metaphor" else "solution": f"Simulación de {synthesis_goal} para {json.dumps(payload)}"}}

    async def _generate_narrative_result(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        query_type = payload.get("element_type", "narrative_coherence")
        if query_type == "narrative_coherence":
            return {"narrative_summary": self._generate_narrative_summary(), "coherence_score": self.core_recombinator.global_state.coherence_score}
        elif query_type == "conversation_history":
            return {"history": self._get_conversation_history(payload.get("max_elements", 10))}
        return {"error": f"Tipo de consulta narrativa no soportado: {query_type}"}

    async def _process_logical_query(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        query_type = payload.get("query_type", "validate_message")
        if query_type == "validate_message":
            return self._validate_message_logic(payload.get("query_payload", {}))
        elif query_type == "validate_nlp_request":
            return self._validate_nlp_request(payload.get("query_payload", {}))
        elif query_type == "validate_narrative_query":
            return self._validate_narrative_query(payload.get("query_payload", {}))
        elif query_type == "validate_global_state":
            return self._validate_global_state(payload.get("query_payload", {}))
        elif query_type in ["process_video", "process_audio", "process_text", "process_code"]:
            return getattr(self, f"_process_{query_type.split('_')[1]}_data")(payload.get("query_payload", {}))
        return {"error": f"Tipo de consulta lógica no soportado: {query_type}"}

    async def _analyze_traffic(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        message = IlyukMessageStructure(**payload)
        source, target = message.source_module_id, message.target_module_id
        self.traffic_matrix[source][target] += 1
        message_size_bytes = len(str(message.payload))
        self.message_size_matrix[source][target] += message_size_bytes
        corr_id = message.correlation_id
        if corr_id:
            if corr_id in self.pending_request_timestamps:
                latency = time.time() - self.pending_request_timestamps.pop(corr_id)
                self.latency_history.append(latency)
                if corr_id in self.message_path_tracker:
                    del self.message_path_tracker[corr_id]
            elif "request" in message.message_type:
                self.pending_request_timestamps[corr_id] = message.timestamp_utc
            self.message_path_tracker[corr_id].append(target)
            if len(self.message_path_tracker[corr_id]) > self.loop_detection_length:
                await self._detect_message_loop(corr_id, self.message_path_tracker[corr_id])
        return {"status": "processed"}

    async def _analyze_aggregated_traffic(self):
        await self._detect_bottlenecks()
        self.traffic_matrix.clear()
        self.message_size_matrix.clear()

    async def _detect_bottlenecks(self):
        module_traffic_in = defaultdict(int)
        module_traffic_out = defaultdict(int)
        for source, targets in self.traffic_matrix.items():
            for target, count in targets.items():
                module_traffic_in[target] += count
                module_traffic_out[source] += count
        for module, in_count in module_traffic_in.items():
            if in_count > self.high_traffic_threshold:
                out_count = module_traffic_out.get(module, 0)
                ratio = in_count / max(1, out_count)
                if ratio > self.bottleneck_ratio_threshold:
                    await self._report_anomaly("bottleneck_detected", f"Cuello de botella en '{module}'. Ratio: {ratio:.1f}", {"module_id": module, "ratio": ratio})

    async def _detect_message_loop(self, corr_id: str, path: List[str]):
        if len(set(path)) < len(path):
            await self._report_anomaly("message_loop_detected", f"Bucle detectado para '{corr_id}'. Camino: {' -> '.join(path)}", {"correlation_id": corr_id, "path": path})
            del self.message_path_tracker[corr_id]

    async def _report_anomaly(self, anomaly_type: str, description: str, details: Dict):
        self.module_state["anomalies_detected"] += 1
        if "bottleneck" in anomaly_type: self.module_state["bottlenecks_found"] += 1
        if "loop" in anomaly_type: self.module_state["loops_found"] += 1
        self.ui_state["anomalies"].append({"type": anomaly_type, "description": description, "details": details, "timestamp": time.time()})
        self.logger.warning(f"ANOMALÍA: {description}")
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(self.module_name, "FaultRecoveryModule", "network_anomaly_detected", {"anomaly_type": anomaly_type, "description": description, "details": details}))
        }, "high")

    def _prune_old_trackers(self):
        now = time.time()
        timeout = self.latency_warning_ms * 10 / 1000
        old_reqs = [cid for cid, ts in self.pending_request_timestamps.items() if now - ts > timeout]
        for cid in old_reqs:
            del self.pending_request_timestamps[cid]
            if cid in self.message_path_tracker:
                del self.message_path_tracker[cid]

    def _recognize_intent(self, text: str) -> NarrativeElement:
        text_lower = text.lower()
        if "cómo te sientes" in text_lower:
            return NarrativeElement("intent_query_state", "query_state", {"query_payload": {"element_type": "narrative_coherence"}})
        elif "cuál es tu meta" in text_lower:
            return NarrativeElement("intent_query_goal", "query_goal", {})
        return NarrativeElement("intent_unknown", "unknown", {})

    def _generate_direct_response(self, intent: str, parameters: Dict[str, Any]) -> str:
        if intent == "query_state":
            return f"Coherencia: {self.core_recombinator.global_state.coherence_score:.2f}"
        return "Solicitud procesada."

    def _modulate_text_by_global_state(self, text: str) -> str:
        gs = self.core_recombinator.global_state
        if gs.valencia > 0.6:
            return f"Me complace decir: {text}"
        return text

    def _generate_narrative_summary(self) -> str:
        gs = self.core_recombinator.global_state
        return f"EANE opera con coherencia {gs.coherence_score:.2f} a las {time.strftime('%H:%M:%S')}."

    def _get_conversation_history(self, max_elements: int) -> List[Dict[str, Any]]:
        return [{"element_id": e.element_id, "content": e.content, "timestamp": e.timestamp} for e in list(self.narrative_elements)[-max_elements:]]

    async def _update_narrative_coherence(self):
        coherence = self.core_recombinator.global_state.coherence_score
        self.core_recombinator.global_state.coherence_score = np.clip(coherence / (1.0 + len(self.narrative_elements) / 1000.0), 0.0, 1.0)

    def _validate_message_logic(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        return {"status": "valid", "confidence": 0.95}

    def _validate_nlp_request(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        return {"status": "valid", "confidence": 0.90}

    def _validate_narrative_query(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        return {"status": "valid", "confidence": 0.92}

    def _validate_global_state(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        return {"status": "valid", "confidence": 0.95}

    def _process_video_data(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        return {"status": "valid", "result": {"description": "Video procesado"}, "confidence": 0.85}

    def _process_audio_data(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        return {"status": "valid", "result": {"transcription": "Audio procesado"}, "confidence": 0.88}

    def _process_text_data(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        text = payload.get("text", "")
        return {"status": "valid", "result": {"word_count": len(text.split())}, "confidence": 0.90}

    def _process_code_data(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        code = payload.get("code", "")
        return {"status": "valid", "result": {"line_count": len(code.splitlines())}, "confidence": 0.92}

    async def _finalize_request(self, request: UnifiedRequest):
        if request.source_module_id and request.original_correlation_id:
            correlation_id = f"finalize_{request.request_id}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            self.active_responses[correlation_id] = future
            event_type = "transmit_ilyuk_message_request"
            target_module_id = request.source_module_id
            if request.source_module_id.startswith("EANE_"):
                event_type = "request_send_external_ilyuk_message"
                self.module_state["external_responses_sent"] += 1
            await self.emit_event_to_core({
                "type": event_type,
                "content": asdict(IlyukMessageStructure(self.module_name, target_module_id, f"{request.request_type}_response", {"request_id_ref": request.request_id, "status": request.status, "result": request.result}, correlation_id, "high"))
            }, "high")
            try:
                await asyncio.wait_for(future, timeout=5.0)
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout notificando {request.request_id}.")
            finally:
                if correlation_id in self.active_responses:
                    del self.active_responses[correlation_id]
        if request.request_id in self.active_requests:
            del self.active_requests[request_id]

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional[IlyukMessageStructure] = None):
        if full_message:
            request_id = f"req_{uuid.uuid4().hex[:8]}"
            unified_request = UnifiedRequest(
                request_id=request_id,
                source_module_id=full_message.source_module_id,
                request_type=event_type,
                payload=payload,
                original_correlation_id=full_message.correlation_id
            )
            self.active_requests[request_id] = unified_request
            self._update_module_state(unified_request)
        elif full_message and full_message.correlation_id in self.active_responses:
            self.active_responses[full_message.correlation_id].set_result(payload)
            del self.active_responses[full_message.correlation_id]

    def _update_module_state(self, request: UnifiedRequest):
        if request.request_type in ["external_natural_language_input", "request_creative_synthesis", "query_narrative_element_request", "submit_logical_query_request", "internal_message_traffic_tap", "request_web_api_call"]:
            self.module_state["queries_processed"] += 1
        if request.request_type == "submit_logical_query_request" and "process_" in request.payload.get("query_type", ""):
            self.module_state["multimodal_queries_processed"] += 1
        if request.request_type == "query_narrative_element_request" and request.status == "completed":
            self.module_state["elements_stored"] += 1
        if request.request_type == "request_web_api_call":
            self.module_state["requests_processed"] += 1
            self.ui_state["api_metrics"]["requests_processed"] = self.module_state["requests_processed"]
            self.ui_state["api_metrics"]["successful_calls"] = self.module_state["successful_calls"]
            self.ui_state["api_metrics"]["failed_calls"] = self.module_state["failed_calls"]
            self.ui_state["api_metrics"]["avg_api_latency_ms"] = self.module_state["avg_api_latency_ms"]

    def _update_metrics(self, start_time: float):
        processing_time = (time.perf_counter() - start_time) * 1000
        self.module_state["avg_system_latency_ms"] = np.mean(self.latency_history) * 1000 if self.latency_history else 0.0
        self.module_state["avg_query_time_ms"] = self.module_state.get("avg_query_time_ms", 0.0) * 0.9 + processing_time * 0.1

    def _update_ui_state(self):
        self.ui_state["modules_status"] = {name: mod.module_state for name, mod in self.core_recombinator.modules.items()}
        self.ui_state["global_state"] = self.core_recombinator.global_state.get_full_state_for_snapshot()
        self.ui_state["timestamp"] = time.time()

    async def shutdown(self):
        self.logger.info(f"{self.module_name} iniciando apagado...")
        self.active_requests.clear()
        self.active_responses.clear()
        self.narrative_elements.clear()
        self.query_history.clear()
        self.traffic_matrix.clear()
        self.message_size_matrix.clear()
        self.pending_request_timestamps.clear()
        self.latency_history.clear()
        self.message_path_tracker.clear()
        if self.http_session and not self.http_session.closed:
            await self.http_session.close()
        await super().shutdown()
        self.logger.info(f"{self.module_name} apagado completado.")




 #inicio del modulo IoTInterfaceModule 


@dataclass
class IoTDevice:
    """Representa un dispositivo IoT conocido por el sistema."""
    device_id: str
    device_type: str # "smart_bulb", "thermostat", "security_sensor"
    label: str
    protocol: str = "MQTT" # MQTT, CoAP, HTTP
    state: Dict[str, Any] = field(default_factory=dict)
    available_actions: List[str] = field(default_factory=list)
    last_heard_from_ts: float = field(default_factory=time.time)

@dataclass
class IoTActionRequest:
    """Una solicitud para ejecutar una acción en un dispositivo IoT."""
    request_id: str = field(default_factory=lambda: f"iot_req_{uuid.uuid4().hex[:6]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    target_device_id: str
    action: str
    action_params: Dict[str, Any] = field(default_factory=dict)
    status: str = "pending"
    result: Optional[Dict[str, Any]] = None

class IoTInterfaceModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 2.0 # El polling de dispositivos es periódico.

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.device_registry: Dict[str, IoTDevice] = {}
        self.action_request_queue: asyncio.Queue[IoTActionRequest] = asyncio.Queue(maxlen=50)
        
        self._initialize_mock_devices()

        self.module_state.update({
            "registered_devices": len(self.device_registry),
            "actions_processed": 0,
            "actions_succeeded": 0,
            "actions_failed": 0,
            "sensor_updates_published": 0,
        })
        self.logger.info(f"{self.module_name} v27.1 inicializado con {len(self.device_registry)} dispositivos mock.")

    def _initialize_mock_devices(self):
        """Crea un conjunto de dispositivos simulados para la demostración."""
        bulb = IoTDevice(
            device_id="bulb_living_room_01", device_type="smart_bulb", label="Luz de la Sala",
            state={"power": "OFF", "brightness": 0.8, "color_temp": 4000},
            available_actions=["set_power", "set_brightness", "set_color_temp"]
        )
        thermostat = IoTDevice(
            device_id="thermo_main_floor_01", device_type="thermostat", label="Termostato Principal",
            state={"current_temp_c": 21.5, "target_temp_c": 22.0, "mode": "heat"},
            available_actions=["set_target_temp", "set_mode"]
        )
        self.device_registry[bulb.device_id] = bulb
        self.device_registry[thermostat.device_id] = thermostat

    async def _update_logic(self):
        """Ciclo principal para simular lecturas de sensores y procesar acciones."""
        await self._poll_devices_for_updates()
        
        if not self.action_request_queue.empty():
            request = await self.action_request_queue.get()
            self.action_request_queue.task_done()
            await self._process_action_request(request)

    async def _poll_devices_for_updates(self):
        """Simula recibir datos de sensores de los dispositivos IoT."""
        for device in self.device_registry.values():
            old_state_str = str(device.state)
            
            # Simular fluctuaciones
            if device.device_type == "thermostat":
                device.state["current_temp_c"] += random.uniform(-0.1, 0.1)
                device.state["current_temp_c"] = round(device.state["current_temp_c"], 2)
            
            # Si el estado cambió, publicar una actualización
            if str(device.state) != old_state_str:
                device.last_heard_from_ts = time.time()
                self.module_state["sensor_updates_published"] += 1
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, "DataAndKnowledgeProcessingModule",
                        "submit_data_for_processing_request",
                        {"data_payload": asdict(device), "data_type_hint": "iot_sensor_reading"}
                    ))
                }, "low")

    async def _process_action_request(self, request: IoTActionRequest):
        """Procesa una solicitud para ejecutar una acción en un dispositivo."""
        self.module_state["actions_processed"] += 1
        request.status = "processing"
        
        try:
            device = self.device_registry.get(request.target_device_id)
            if not device:
                raise ValueError(f"Dispositivo '{request.target_device_id}' no encontrado en el registro.")
            if request.action not in device.available_actions:
                raise ValueError(f"Acción '{request.action}' no disponible para el dispositivo '{device.device_id}'.")
            
            # Ejecutar la acción
            success, msg = self._send_action_to_device(device, request.action, request.action_params)
            
            if success:
                request.status = "completed"
                request.result = {"message": msg}
                self.module_state["actions_succeeded"] += 1
            else:
                raise RuntimeError(msg)

        except Exception as e:
            request.status = "failed"
            request.result = {"error": str(e)}
            self.module_state["actions_failed"] += 1
            self.logger.error(f"Fallo en acción IoT '{request.request_id}': {e}")
        finally:
            await self._finalize_action_request(request)

    def _send_action_to_device(self, device: IoTDevice, action: str, params: Dict) -> Tuple[bool, str]:
        """Simula el envío de un comando a un dispositivo y actualiza su estado."""
        self.logger.info(f"Enviando acción '{action}' a dispositivo '{device.device_id}' con params: {params}")
        
        # Simulación de la lógica de control del dispositivo
        if action == "set_power":
            value = params.get("value", "OFF").upper()
            if value in ["ON", "OFF"]:
                device.state["power"] = value
                return True, f"Power de {device.device_id} establecido a {value}."
        elif action == "set_target_temp":
            value = params.get("value", 22.0)
            if isinstance(value, (int, float)):
                device.state["target_temp_c"] = value
                return True, f"Temperatura objetivo de {device.device_id} establecida a {value}°C."
        
        return False, f"Parámetros inválidos para la acción '{action}'."

    async def _finalize_action_request(self, request: IoTActionRequest):
        """Notifica al solicitante del resultado de la acción."""
        if request.source_module_id and request.original_correlation_id:
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, request.source_module_id, "iot_action_response",
                    {"request_id_ref": request.request_id, "status": request.status, "result": request.result},
                    correlation_id=request.original_correlation_id
                ))
            })

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        if event_type == "request_iot_action" and full_message:
            try:
                req = IoTActionRequest(
                    source_module_id=full_message.source_module_id,
                    original_correlation_id=full_message.correlation_id,
                    target_device_id=payload.get("target_device_id"),
                    action=payload.get("action"),
                    action_params=payload.get("action_params", {})
                )
                if not req.target_device_id or not req.action:
                    raise ValueError("'target_device_id' y 'action' son requeridos.")
                await self.action_request_queue.put(req)
            except Exception as e:
                self.logger.error(f"Error procesando solicitud de acción IoT: {e}")






 #inicio del modulo VisionProcessingModule 


@dataclass
class VisionProcessingRequest:
    """Una solicitud para que el VPM procese datos visuales."""
    request_id: str = field(default_factory=lambda: f"vpm_req_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    # El dato visual puede ser una ruta a un archivo, un array de numpy,
    # o un dict descriptivo para la simulación.
    image_data: Any 
    tasks_to_perform: List[str] = field(default_factory=lambda: ["detect_objects", "describe_scene"])
    status: str = "pending"
    result: Optional['VisionProcessingResult'] = None

@dataclass
class VisionProcessingResult:
    """El resultado estructurado del procesamiento visual."""
    request_id: str
    detected_objects: Optional[List[Dict[str, Any]]] = None
    scene_description: Optional[str] = None
    extracted_text_ocr: Optional[str] = None
    anomaly_detected: Optional[Dict[str, Any]] = None
    processing_time_ms: float = 0.0

class VisionProcessingModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 0.3 # Reactivo a nuevas solicitudes

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.processing_queue: asyncio.Queue[VisionProcessingRequest] = asyncio.Queue(maxlen=20)
        self.active_tasks: Dict[str, asyncio.Task] = {}

        self.module_state.update({
            "images_processed": 0, "objects_detected_total": 0,
            "ocr_extractions": 0, "anomalies_found": 0,
            "avg_processing_time_ms": 0.0,
        })
        self.processing_times: List[float] = []
        self.logger.info(f"{self.module_name} v27.1 inicializado.")

    async def _update_logic(self):
        """Procesa una solicitud de la cola."""
        if not self.processing_queue.empty() and len(self.active_tasks) < 3:
            request = await self.processing_queue.get()
            self.processing_queue.task_done()
            task = self._create_managed_task(self._process_image_request(request))
            self.active_tasks[request.request_id] = task

    async def _process_image_request(self, request: VisionProcessingRequest):
        """Orquesta las diferentes tareas de análisis visual sobre una imagen."""
        start_time = time.time()
        self.module_state["images_processed"] += 1
        request.status = "processing"
        
        result = VisionProcessingResult(request_id=request.request_id)
        
        try:
            # Ejecutar tareas de análisis en paralelo
            analysis_tasks = []
            if "detect_objects" in request.tasks_to_perform:
                analysis_tasks.append(self._detect_objects_simulated(request.image_data))
            if "describe_scene" in request.tasks_to_perform:
                analysis_tasks.append(self._describe_scene_simulated(request.image_data))
            if "extract_text_ocr" in request.tasks_to_perform:
                analysis_tasks.append(self._extract_text_ocr_simulated(request.image_data))
            
            analysis_results = await asyncio.gather(*analysis_tasks, return_exceptions=True)
            
            # Asignar resultados
            result_map = {type(res).__name__: res for res in analysis_results if not isinstance(res, Exception)}
            result.detected_objects = result_map.get("list")
            result.scene_description = result_map.get("str")
            # ... y así sucesivamente para otros tipos de resultados ...
            
            request.status = "completed"
            
        except Exception as e:
            request.status = "failed"
            self.logger.error(f"Fallo en procesamiento de imagen '{request.request_id}': {e}", exc_info=True)
        
        duration_ms = (time.time() - start_time) * 1000
        result.processing_time_ms = duration_ms
        request.result = result
        
        self.processing_times.append(duration_ms)
        self.module_state["avg_processing_time_ms"] = np.mean(self.processing_times[-50:])
        
        await self._finalize_request(request)

    # Las siguientes funciones son simulaciones de modelos de CV complejos.
    # En una implementación real, aquí se harían llamadas a modelos de TensorFlow/PyTorch.
    async def _detect_objects_simulated(self, image_data: Any) -> List[Dict[str, Any]]:
        """Simula la detección de objetos en la imagen."""
        await asyncio.sleep(random.uniform(0.1, 0.3)) # Simular latencia del modelo
        # La "imagen" para la simulación es un dict descriptivo
        if isinstance(image_data, dict) and "objects" in image_data:
            self.module_state["objects_detected_total"] += len(image_data["objects"])
            return image_data["objects"]
        return [{"label": "unknown_object", "confidence": 0.5, "box": [0.1, 0.1, 0.5, 0.5]}]

    async def _describe_scene_simulated(self, image_data: Any) -> str:
        """Simula la generación de una descripción de la escena."""
        await asyncio.sleep(random.uniform(0.1, 0.2))
        if isinstance(image_data, dict) and "scene_description" in image_data:
            return image_data["scene_description"]
        return "Una escena genérica no especificada."

    async def _extract_text_ocr_simulated(self, image_data: Any) -> str:
        """Simula el reconocimiento óptico de caracteres."""
        await asyncio.sleep(random.uniform(0.2, 0.4))
        if isinstance(image_data, dict) and "text_in_image" in image_data:
            self.module_state["ocr_extractions"] += 1
            return image_data["text_in_image"]
        return ""

    async def _finalize_request(self, request: VisionProcessingRequest):
        """Envía el resultado procesado de vuelta al solicitante."""
        if request.source_module_id and request.original_correlation_id:
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, request.source_module_id,
                    "vision_processing_response",
                    {"request_id_ref": request.request_id, "status": request.status, "result": asdict(request.result) if request.result else None},
                    correlation_id=request.original_correlation_id
                ))
            })
            
        if request.request_id in self.active_tasks:
            del self.active_tasks[request.request_id]

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        if event_type == "request_vision_processing" and full_message:
            try:
                req = VisionProcessingRequest(
                    source_module_id=full_message.source_module_id,
                    original_correlation_id=full_message.correlation_id,
                    image_data=payload.get("image_data"),
                    tasks_to_perform=payload.get("tasks_to_perform", ["detect_objects", "describe_scene"])
                )
                if req.image_data is None:
                    raise ValueError("'image_data' es requerido.")
                
                await self.processing_queue.put(req)
            except Exception as e:
                self.logger.error(f"Error procesando solicitud de visión: {e}")

 #inicio del modulo SystemIntegrityMonitor

@dataclass
class IntegrityIssue:
    """Describe una violación de integridad detectada."""
    issue_id: str = field(default_factory=lambda: f"sim_issue_{uuid.uuid4().hex[:8]}")
    timestamp: float = field(default_factory=time.time)
    issue_type: str  # "code_hash_mismatch", "rogue_module_detected", "chronic_underperformance"
    target_module: str
    severity: float  # 0.0 a 1.0
    details: Dict[str, Any]

class SystemIntegrityMonitor(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 90.0  # Auditorías completas menos frecuentes

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.module_code_signatures: Dict[str, str] = {}  # Hashes SHA-256 del código fuente
        self.authorized_module_roster: Set[str] = set()
        self.module_performance_history: Dict[str, deque] = defaultdict(lambda: deque(maxlen=10))
        self.module_graph = nx.DiGraph()  # Grafo para modelar interacciones entre módulos
        self.integrity_score: float = 1.0  # Puntuación dinámica de integridad
        self.kalman_state: Dict[str, float] = {}  # Estado Kalman por módulo
        self.kalman_cov: Dict[str, float] = {}  # Covarianza Kalman por módulo

        self.health_check_threshold: float = 0.3
        self.performance_issue_strike_threshold: int = 5
        self.sde_sigma: float = 0.01  # Ruido estocástico para SDE
        self.bayesian_confidence: Dict[str, float] = {}  # Confianza bayesiana por módulo

        self.module_state.update({
            "last_scan_ts": 0.0, "scans_performed": 0,
            "integrity_issues_found": 0, "last_issue_type": "none",
            "current_system_integrity_score": 1.0,
        })
        self.logger.info(f"{self.module_name} v27.1 inicializado.")

    async def start(self):
        """Al iniciar, establece la primera línea base de integridad."""
        await super().start()
        await self._establish_initial_baseline()
    
    async def _establish_initial_baseline(self):
        """Calcula y almacena los hashes del código de todos los módulos en el arranque."""
        self.logger.info("SIM: Estableciendo línea base de integridad del sistema...")
        all_modules = self.core_recombinator.modules
        for name, module_instance in all_modules.items():
            try:
                source_code = inspect.getsource(module_instance.__class__)
                hash_digest = hashlib.sha256(source_code.encode('utf-8')).hexdigest()
                self.module_code_signatures[name] = hash_digest
                self.authorized_module_roster.add(name)
                self.module_graph.add_node(name, health=1.0)
                self.bayesian_confidence[name] = 0.95  # Confianza inicial
                self.kalman_state[name] = 1.0  # Estado inicial
                self.kalman_cov[name] = 0.1  # Covarianza inicial
            except (TypeError, OSError) as e:
                self.logger.error(f"No se pudo obtener el código fuente para '{name}': {e}")

        # Construir aristas del grafo basadas en interacciones (simplificado)
        for name in all_modules:
            for other_name in all_modules:
                if name != other_name:
                    self.module_graph.add_edge(name, other_name, weight=0.1)  # Peso inicial

        self.logger.info(f"Línea base establecida para {len(self.module_code_signatures)} módulos.")

    async def _update_logic(self):
        """Ciclo principal que lanza una auditoría de integridad completa."""
        self.logger.info("SIM: Iniciando auditoría de integridad periódica...")
        await self._run_integrity_scan()
        await self._update_integrity_dynamics()
        self.module_state["last_scan_ts"] = time.time()
        self.module_state["scans_performed"] += 1

    async def _run_integrity_scan(self):
        """Ejecuta todas las verificaciones de integridad."""
        issues_found: List[IntegrityIssue] = []
        
        # Verificaciones
        issues_found.extend(await self._check_code_integrity())
        issues_found.extend(await self._check_module_roster())
        issues_found.extend(await self._check_performance_anomalies())
        
        # Actualizar puntuación de integridad
        if not issues_found:
            self.module_state["current_system_integrity_score"] = self.integrity_score
            self.logger.info("Auditoría de integridad completada. No se encontraron problemas.")
        else:
            self.module_state["current_system_integrity_score"] = self.integrity_score
            for issue in issues_found:
                self.module_state["integrity_issues_found"] += 1
                self.module_state["last_issue_type"] = issue.issue_type
                if issue.severity > 0.8:
                    await self._report_critical_integrity_breach(issue)

    async def _check_code_integrity(self) -> List[IntegrityIssue]:
        """Compara los hashes actuales con la línea base usando SDE y Bayes."""
        issues = []
        for name, module_instance in self.core_recombinator.modules.items():
            if name in self.module_code_signatures:
                try:
                    current_source = inspect.getsource(module_instance.__class__)
                    current_hash = hashlib.sha256(current_source.encode('utf-8')).hexdigest()
                    
                    # Modelo SDE para probabilidad de alteración
                    def code_stability(t, s):
                        return -0.05 * (s - 1.0) + self.sde_sigma * np.random.normal(0, 1)
                    t = np.array([0, self.update_interval])
                    stability = odeint(code_stability, [self.bayesian_confidence[name]], t, tfirst=True)[-1][0]
                    stability = np.clip(stability, 0.0, 1.0)
                    
                    # Actualizar confianza bayesiana
                    prior = self.bayesian_confidence[name]
                    likelihood = 0.01 if current_hash != self.module_code_signatures[name] else 0.99
                    posterior = (likelihood * prior) / ((likelihood * prior) + (1 - likelihood) * (1 - prior))
                    self.bayesian_confidence[name] = posterior

                    if current_hash != self.module_code_signatures[name]:
                        severity = 1.0 - posterior
                        issues.append(IntegrityIssue(
                            issue_type="code_hash_mismatch",
                            target_module=name,
                            severity=severity,
                            details={
                                "expected_hash": self.module_code_signatures[name],
                                "current_hash": current_hash,
                                "bayesian_confidence": posterior,
                                "stability_score": stability
                            }
                        ))
                    else:
                        # Actualizar Kalman
                        measurement = 1.0
                        A, H = 1.0, 1.0
                        predicted_state = A * self.kalman_state[name]
                        predicted_cov = A * self.kalman_cov[name] * A + self.kalman_Q
                        innovation = measurement - H * predicted_state
                        innovation_cov = H * predicted_cov * H + self.kalman_R
                        kalman_gain = predicted_cov * H / innovation_cov
                        self.kalman_state[name] = predicted_state + kalman_gain * innovation
                        self.kalman_cov[name] = (1 - kalman_gain * H) * predicted_cov
                except (TypeError, OSError):
                    continue
        return issues

    async def _check_module_roster(self) -> List[IntegrityIssue]:
        """Verifica módulos no autorizados usando teoría de grafos."""
        issues = []
        current_modules = set(self.core_recombinator.modules.keys())
        rogue_modules = current_modules - self.authorized_module_roster
        missing_modules = self.authorized_module_roster - current_modules

        # Análisis de componentes conexas
        undirected_graph = self.module_graph.to_undirected()
        components = list(nx.connected_components(undirected_graph))
        for rogue in rogue_modules:
            # Verificar si el módulo rogue está en una componente aislada
            is_isolated = any(rogue in comp and len(comp) == 1 for comp in components)
            severity = 0.95 if is_isolated else 0.9
            issues.append(IntegrityIssue(
                issue_type="rogue_module_detected",
                target_module=rogue,
                severity=severity,
                details={"is_isolated": is_isolated}
            ))
        for missing in missing_modules:
            issues.append(IntegrityIssue(
                issue_type="authorized_module_missing",
                target_module=missing,
                severity=0.7,
                details={}
            ))
        
        # Actualizar grafo
        for rogue in rogue_modules:
            self.module_graph.add_node(rogue, health=0.5)
        for missing in missing_modules:
            if missing in self.module_graph:
                self.module_graph.remove_node(missing)
        
        return issues

    async def _check_performance_anomalies(self) -> List[IntegrityIssue]:
        """Identifica módulos con bajo rendimiento usando un modelo de Markov continuo."""
        issues = []
        for name, module_instance in self.core_recombinator.modules.items():
            metrics = module_instance.get_performance_metrics()
            health = metrics.get("self_assessed_health_score", 1.0)
            self.module_performance_history[name].append(health)
            
            # Modelo de Markov continuo para transiciones de estado
            history = np.array(self.module_performance_history[name])
            if len(history) == history.maxlen:
                # Calcular entropía diferencial
                hist, bins = np.histogram(history, bins=10, density=True)
                entropy = -np.sum(hist * np.log(hist + 1e-10) * (bins[1] - bins[0]))
                
                # Matriz de transición aproximada
                states = (history < self.health_check_threshold).astype(int)  # 0: sano, 1: enfermo
                transition_counts = np.zeros((2, 2))
                for i in range(len(states) - 1):
                    transition_counts[states[i], states[i + 1]] += 1
                transition_probs = transition_counts / (transition_counts.sum(axis=1, keepdims=True) + 1e-10)
                
                # Probabilidad estacionaria
                eigvals, eigvecs = np.linalg.eig(transition_probs.T)
                stationary = eigvecs[:, np.isclose(eigvals, 1.0)][:, 0].real
                stationary /= stationary.sum()
                prob_unhealthy = stationary[1]
                
                if prob_unhealthy > 0.5 and entropy > 1.0:
                    severity = np.clip(prob_unhealthy * (entropy / 2.0), 0.0, 1.0)
                    issues.append(IntegrityIssue(
                        issue_type="chronic_underperformance",
                        target_module=name,
                        severity=severity,
                        details={
                            "avg_health": np.mean(history),
                            "entropy": entropy,
                            "prob_unhealthy": prob_unhealthy
                        }
                    ))
        return issues

    async def _update_integrity_dynamics(self):
        """Actualiza la puntuación de integridad global usando una EDO."""
        def integrity_dynamics(t, I, issues_count):
            # Modelo inspirado en termodinámica: disipación y recuperación
            k_dissipate = 0.1 * issues_count
            k_recover = 0.05
            return -k_dissipate * I + k_recover * (1.0 - I)
        
        issues_count = self.module_state["integrity_issues_found"]
        t = np.array([0, self.update_interval])
        result = odeint(integrity_dynamics, [self.integrity_score], t, args=(issues_count,), tfirst=True)
        self.integrity_score = np.clip(result[-1][0], 0.0, 1.0)
        
        # Monte Carlo para incertidumbre
        samples = np.random.beta(2 * self.integrity_score, 2 * (1.0 - self.integrity_score), self.num_mc_samples)
        self.module_state["current_system_integrity_score"] = np.mean(samples)

    async def _report_critical_integrity_breach(self, issue: IntegrityIssue):
        """Desencadena una respuesta de emergencia en todo el sistema."""
        self.logger.critical(f"¡VIOLACIÓN DE INTEGRIDAD CRÍTICA DETECTADA! Tipo: {issue.issue_type}, Módulo: {issue.target_module}, Detalles: {issue.details}")
        
        # Generar señal de dolor
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                self.module_name, "PainMatrixDirective", "integrity_alert_critical",
                {"severity_factor": issue.severity, "source_issue": asdict(issue)}
            ))
        }, "critical")
        
        # Notificar al sistema de recuperación de fallos
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                self.module_name, "FaultRecoveryModule", "critical_integrity_issue",
                {"issue": asdict(issue)}
            ))
        }, "critical")

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional[IlyukMessageStructure] = None):
        """Actualiza la lista de módulos autorizados cuando DAA hace un cambio legítimo."""
        if event_type == "system_module_authorization_update":
            module_name = payload.get("module_name")
            is_authorized = payload.get("authorized", False)
            if module_name:
                if is_authorized and module_name not in self.authorized_module_roster:
                    self.authorized_module_roster.add(module_name)
                    new_instance = self.core_recombinator.modules.get(module_name)
                    if new_instance:
                        source_code = inspect.getsource(new_instance.__class__)
                        self.module_code_signatures[module_name] = hashlib.sha256(source_code.encode('utf-8')).hexdigest()
                        self.module_graph.add_node(module_name, health=1.0)
                        self.bayesian_confidence[module_name] = 0.95
                        self.kalman_state[module_name] = 1.0
                        self.kalman_cov[module_name] = 0.1
                    self.logger.info(f"SIM: Módulo '{module_name}' añadido a la lista autorizada.")
                elif not is_authorized and module_name in self.authorized_module_roster:
                    self.authorized_module_roster.remove(module_name)
                    if module_name in self.module_code_signatures:
                        del self.module_code_signatures[module_name]
                    if module_name in self.module_graph:
                        self.module_graph.remove_node(module_name)
                    if module_name in self.bayesian_confidence:
                        del self.bayesian_confidence[module_name]
                    if module_name in self.kalman_state:
                        del self.kalman_state[module_name]
                    if module_name in self.kalman_cov:
                        del self.kalman_cov[module_name]
                    self.logger.info(f"SIM: Módulo '{module_name}' eliminado de la lista autorizada.")



  #inicio del modulo FaultRecoveryModule 

@dataclass
class FaultRecord:
    """Rastrea los fallos para un módulo específico."""
    module_id: str
    strike_count: int = 0
    error_timestamps: deque[float] = field(default_factory=lambda: deque(maxlen=20))
    last_recovery_action: str = "none"
    last_recovery_ts: float = 0.0
    failure_rate: float = 0.0  # Tasa de fallos estimada
    bayesian_compromise_prob: float = 0.05  # Probabilidad de compromiso
    kalman_state: float = 0.0  # Estado Kalman para tasa de fallos
    kalman_cov: float = 0.1  # Covarianza Kalman

class FaultRecoveryModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 0.25  # FRM debe ser rápido

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.fault_tracker: Dict[str, FaultRecord] = defaultdict(lambda: FaultRecord(module_id="unknown"))
        self.strike_threshold_soft_reset: int = 3
        self.strike_threshold_hard_reset: int = 8
        self.strike_threshold_quarantine: int = 15
        self.recovery_action_cooldown_s: float = 30.0
        self.kalman_Q: float = 0.01  # Ruido del proceso
        self.kalman_R: float = 0.05  # Ruido de medición
        self.markov_purge_prob: float = 0.1  # Probabilidad base de purgar registros antiguos
        self.entropy_threshold: float = 1.5  # Umbral de entropía para purga

        self.module_state.update({
            "faults_processed": 0,
            "soft_resets_issued": 0,
            "hard_resets_issued": 0,
            "quarantine_orders_issued": 0,
            "critical_integrity_issues_handled": 0,
            "records_purged": 0,
        })
        self.logger.info(f"{self.module_name} v27.1 inicializado.")

    async def _update_logic(self):
        """Ciclo principal para purgar registros antiguos y actualizar tasas de fallos."""
        await self._purge_old_records()
        await self._update_failure_rates()

    async def _purge_old_records(self):
        """Elimina registros antiguos usando un modelo de Markov y entropía."""
        for module_id, record in list(self.fault_tracker.items()):
            if not record.error_timestamps:
                continue

            # Calcular entropía de los timestamps
            timestamps = np.array(record.error_timestamps)
            hist, bins = np.histogram(timestamps, bins=10, density=True)
            entropy = -np.sum(hist * np.log(hist + 1e-10) * (bins[1] - bins[0]))

            # Modelo de Markov para decidir purga
            current_time = time.time()
            time_diff = current_time - timestamps[0]
            purge_prob = self.markov_purge_prob * np.exp(-time_diff / 3600.0)  # Decaimiento exponencial
            if entropy < self.entropy_threshold and np.random.random() < purge_prob:
                del self.fault_tracker[module_id]
                self.module_state["records_purged"] += 1
                self.logger.debug(f"Registro de fallos para '{module_id}' purgado por baja entropía y Markov.")

    async def _update_failure_rates(self):
        """Actualiza las tasas de fallos usando EDOs."""
        for record in self.fault_tracker.values():
            def failure_dynamics(t, lambda_t):
                # EDO: tasa de fallos con deterioro y recuperación
                k_deteriorate = 0.1 * record.strike_count
                k_recover = 0.05
                return k_deteriorate * (1.0 - lambda_t) - k_recover * lambda_t

            t = np.array([0, self.update_interval])
            lambda_t = odeint(failure_dynamics, [record.failure_rate], t, tfirst=True)[-1][0]
            record.failure_rate = np.clip(lambda_t, 0.0, 1.0)

            # Filtro de Kalman para suavizar
            measurement = record.failure_rate
            A, H = 1.0, 1.0
            predicted_state = A * record.kalman_state
            predicted_cov = A * record.kalman_cov * A + self.kalman_Q
            innovation = measurement - H * predicted_state
            innovation_cov = H * predicted_cov * H + self.kalman_R
            kalman_gain = predicted_cov * H / innovation_cov
            record.kalman_state = predicted_state + kalman_gain * innovation
            record.kalman_cov = (1 - kalman_gain * H) * predicted_cov

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        """Punto de entrada para todos los informes de error."""
        if not full_message:
            return

        if event_type == "module_runtime_error":
            faulting_module = full_message.source_module_id
            await self._handle_fault_report(faulting_module, payload)
        
        elif event_type == "critical_integrity_issue":
            issue = payload.get("issue", {})
            faulting_module = issue.get("target_module")
            if faulting_module:
                self.module_state["critical_integrity_issues_handled"] += 1
                await self._dispatch_quarantine_and_replace(faulting_module, issue.get("issue_type", "critical_breach"))

    async def _handle_fault_report(self, module_id: str, error_payload: Dict):
        """Analiza un informe de fallo y decide la acción de recuperación óptima."""
        self.module_state["faults_processed"] += 1

        # Actualizar registro de fallos
        record = self.fault_tracker[module_id]
        record.module_id = module_id
        record.strike_count += 1
        record.error_timestamps.append(time.time())

        # Proceso de Poisson no homogéneo
        timestamps = np.array(record.error_timestamps)
        if len(timestamps) > 1:
            intervals = np.diff(timestamps)
            intensity = 1.0 / np.mean(intervals)  # Intensidad promedio
            record.failure_rate = intensity

        # Actualizar probabilidad de compromiso (Bayes)
        prior = record.bayesian_compromise_prob
        likelihood = 0.8 if record.strike_count >= self.strike_threshold_soft_reset else 0.2
        posterior = (likelihood * prior) / ((likelihood * prior) + (1 - likelihood) * (1 - prior))
        record.bayesian_compromise_prob = posterior

        # Evitar acciones frecuentes
        if time.time() - record.last_recovery_ts < self.recovery_action_cooldown_s:
            self.logger.debug(f"FRM en cooldown para el módulo '{module_id}'.")
            return

        # Optimización de control robusto
        actions = ["none", "soft_reset", "hard_reset", "quarantine"]
        costs = np.array([
            0.0,  # Ninguna acción
            0.1 + 0.05 * record.strike_count,  # Soft reset
            0.5 + 0.1 * record.strike_count,  # Hard reset
            1.0 + 0.2 * record.bayesian_compromise_prob  # Cuarentena
        ])
        benefits = np.array([
            0.0,  # Ninguna acción
            0.3 * (1.0 - record.failure_rate),  # Soft reset
            0.6 * (1.0 - record.failure_rate),  # Hard reset
            0.9 * (1.0 - record.bayesian_compromise_prob)  # Cuarentena
        ])
        utility = benefits - costs
        best_action_idx = np.argmax(utility)
        best_action = actions[best_action_idx]

        # Ejecutar acción
        if best_action == "soft_reset":
            await self._dispatch_soft_reset(module_id)
        elif best_action == "hard_reset":
            await self._dispatch_hard_reset(module_id)
        elif best_action == "quarantine":
            await self._dispatch_quarantine_and_replace(module_id, "chronic_failure")
        else:
            self.logger.info(f"Fallo de bajo nivel registrado para '{module_id}'. Strikes: {record.strike_count}.")

    async def _dispatch_soft_reset(self, module_id: str):
        """Ordena a un módulo que reinicie su estado interno."""
        self.logger.warning(f"Demasiados errores en '{module_id}'. Iniciando SOFT RESET.")
        self.module_state["soft_resets_issued"] += 1
        record = self.fault_tracker[module_id]
        record.last_recovery_action = "soft_reset"
        record.last_recovery_ts = time.time()

        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                self.module_name, module_id, "request_internal_state_reset",
                {"reason": "FaultRecoveryModule intervention"}
            ))
        })

    async def _dispatch_hard_reset(self, module_id: str):
        """Pide al DAA que apague y reinicie un módulo."""
        self.logger.error(f"Errores persistentes en '{module_id}'. Iniciando HARD RESET.")
        self.module_state["hard_resets_issued"] += 1
        record = self.fault_tracker[module_id]
        record.last_recovery_action = "hard_reset"
        record.last_recovery_ts = time.time()

        payload = {"adjustment_type": "restart_module", "target_module_name": module_id}
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                self.module_name, "DynamicArchitectureAdjuster", "request_architecture_adjustment", payload
            ))
        })

    async def _dispatch_quarantine_and_replace(self, module_id: str, reason: str):
        """Pide al DAA que elimine un módulo y al SEM que cree uno nuevo."""
        self.logger.critical(f"Fallo catastrófico o violación de integridad en '{module_id}'. Iniciando CUARENTENA Y REEMPLAZO.")
        self.module_state["quarantine_orders_issued"] += 1

        if module_id in self.fault_tracker:
            del self.fault_tracker[module_id]

        # Ordenar eliminación
        payload_remove = {"adjustment_type": "remove_module", "target_module_name": module_id}
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                self.module_name, "DynamicArchitectureAdjuster", "request_architecture_adjustment", payload_remove
            ))
        }, "critical")

        # Solicitar reemplazo
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                self.module_name, "SelfEvolutionModule", "request_module_regeneration",
                {"module_to_replace": module_id, "reason": reason}
            ))
        }, "critical")


          #inicio del modulo ResilienceAndAntifragilityModule 

@dataclass
class PostMortemAnalysisRequest:
    """Solicitud para analizar un fallo resuelto."""
    request_id: str = field(default_factory=lambda: f"ram_req_{uuid.uuid4().hex[:8]}")
    fault_record: Dict[str, Any]
    status: str = "pending_analysis"
    hardening_proposal: Optional[Dict[str, Any]] = None
    source_module_id: str = ""
    original_correlation_id: str = ""
    priority_score: float = 0.0  # Puntuación para priorización

@dataclass
class HardeningTaskProposal:
    """Propuesta para mejorar la robustez del sistema."""
    proposal_id: str
    source_fault_id: str
    description: str
    target_system_aspect: str  # "architecture", "parameter", "process", "security_policy", "refactoring"
    actionable_payload: Dict[str, Any]
    estimated_impact_on_resilience: float
    uncertainty: float  # Incertidumbre en el impacto

class ResilienceAndAntifragilityModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 30.0  # Análisis post-mortem de baja frecuencia

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.post_mortem_queue: asyncio.Queue[PostMortemAnalysisRequest] = asyncio.Queue(maxlen=30)
        self.active_analyses: Dict[str, PostMortemAnalysisRequest] = {}
        self.resilience_sde_sigma: float = 0.01  # Ruido estocástico para SDE
        self.bayesian_cause_probs: Dict[str, float] = {}  # Probabilidad de causas raíz por módulo
        self.markov_priority_matrix = np.array([[0.8, 0.2], [0.3, 0.7]])  # Matriz de transición para priorización
        self.num_mc_samples: int = 100  # Muestras para Monte Carlo

        self.core_recombinator.global_state.resilience_stability = 1.0

        self.module_state.update({
            "post_mortems_conducted": 0,
            "hardening_tasks_proposed": 0,
            "analysis_failures": 0,
            "resilience_updates": 0,
        })
        self.logger.info(f"{self.module_name} v27.1 inicializado.")

    async def _update_logic(self):
        """Procesa solicitudes de análisis priorizando según Markov."""
        if not self.post_mortem_queue.empty() and len(self.active_analyses) < 2:
            # Priorizar solicitudes usando Markov
            requests = []
            while not self.post_mortem_queue.empty():
                req = await self.post_mortem_queue.get()
                requests.append(req)
            
            for req in requests:
                # Actualizar prioridad
                state = 1 if req.priority_score > 0.5 else 0
                next_state = np.random.choice([0, 1], p=self.markov_priority_matrix[state])
                req.priority_score = np.clip(req.priority_score + 0.1 * (next_state - state), 0.0, 1.0)
                await self.post_mortem_queue.put(req)
            
            # Seleccionar la solicitud con mayor prioridad
            top_request = max(requests, key=lambda r: r.priority_score)
            requests.remove(top_request)
            for req in requests:
                await self.post_mortem_queue.put(req)
            
            self.active_analyses[top_request.request_id] = top_request
            self._create_managed_task(self._conduct_post_mortem_analysis(top_request))

    async def _conduct_post_mortem_analysis(self, request: PostMortemAnalysisRequest):
        """Orquesta el análisis de un fallo pasado."""
        self.module_state["post_mortems_conducted"] += 1
        request.status = "analyzing"
        
        try:
            # Reunir contexto
            context = {
                "fault_type": request.fault_record.get("issue_type", "unknown"),
                "module_metrics": request.fault_record.get("details", {}).get("metrics", {})
            }
            
            # Actualizar probabilidad de causa raíz (Bayes)
            fault_type = context["fault_type"]
            module_id = request.fault_record.get("target_module", "unknown")
            prior = self.bayesian_cause_probs.get(f"{module_id}_{fault_type}", 0.1)
            likelihood = 0.8 if "critical" in fault_type.lower() else 0.4
            posterior = (likelihood * prior) / ((likelihood * prior) + (1 - likelihood) * (1 - prior))
            self.bayesian_cause_probs[f"{module_id}_{fault_type}"] = posterior
            
            # Identificar oportunidad antifrágil
            proposal = await self._identify_antifragile_opportunity(request.fault_record, context)
            
            # Despachar tarea de endurecimiento
            if proposal:
                request.hardening_proposal = asdict(proposal)
                await self._dispatch_hardening_task(proposal)
                self.module_state["hardening_tasks_proposed"] += 1
                await self._update_resilience_dynamics(proposal.estimated_impact_on_resilience)

            request.status = "completed"
        except Exception as e:
            request.status = "failed"
            self.module_state["analysis_failures"] += 1
            self.logger.error(f"Fallo en análisis post-mortem '{request.request_id}': {e}", exc_info=True)
        finally:
            await self._finalize_analysis(request)

    async def _identify_antifragile_opportunity(self, fault: Dict, context: Dict) -> Optional[HardeningTaskProposal]:
        """Propone mejoras antifrágiles usando control óptimo y Monte Carlo."""
        fault_type = fault.get("issue_type", fault.get("anomaly_type", "generic_error"))
        target_module = fault.get("target_module", fault.get("details", {}).get("module_id", "unknown"))
        if not target_module:
            return None

        # Definir posibles acciones
        actions = [
            {
                "description": f"Reforzar seguridad en '{target_module}' con monitoreo en tiempo real.",
                "system_aspect": "security_policy",
                "payload": {"target": target_module, "action": "increase_monitoring_frequency"},
                "base_impact": 0.05
            },
            {
                "description": f"Rediseñar '{target_module}' para mayor rendimiento.",
                "system_aspect": "architecture",
                "payload": {"module_to_redesign": target_module},
                "base_impact": 0.08
            },
            {
                "description": f"Añadir balanceador de carga para '{target_module}'.",
                "system_aspect": "architecture",
                "payload": {"bottleneck_module": target_module, "solution_pattern": "load_balancer"},
                "base_impact": 0.06
            },
            {
                "description": f"Refactorizar '{target_module}' con validación de entrada.",
                "system_aspect": "refactoring",
                "payload": {"target_module": target_module, "refactor_goal": "add_input_validation_layer"},
                "base_impact": 0.04
            }
        ]

        # Asignar costos y beneficios según el tipo de fallo
        costs = np.array([0.1, 0.3, 0.2, 0.15])  # Costos base
        benefits = np.array([
            a["base_impact"] * (1.0 if fault_type == "code_hash_mismatch" and a["system_aspect"] == "security_policy" else
                               1.5 if fault_type == "chronic_underperformance" and a["system_aspect"] == "architecture" else
                               1.2 if fault_type == "bottleneck_detected" and a["system_aspect"] == "architecture" else 1.0)
            for a in actions
        ])
        
        # Control óptimo: maximizar utilidad
        utility = benefits - costs
        best_action_idx = np.argmax(utility)
        best_action = actions[best_action_idx]

        # Monte Carlo para estimar impacto y incertidumbre
        impact_samples = np.random.normal(
            best_action["base_impact"], 0.02, self.num_mc_samples
        ) * (1.0 + 0.5 * self.bayesian_cause_probs.get(f"{target_module}_{fault_type}", 0.1))
        estimated_impact = np.mean(impact_samples)
        uncertainty = np.std(impact_samples)

        return HardeningTaskProposal(
            proposal_id=f"harden_{fault.get('issue_id', 'na')}",
            source_fault_id=fault.get('issue_id', 'na'),
            description=best_action["description"],
            target_system_aspect=best_action["system_aspect"],
            actionable_payload=best_action["payload"],
            estimated_impact_on_resilience=np.clip(estimated_impact, 0.0, 0.2),
            uncertainty=uncertainty
        )

    async def _update_resilience_dynamics(self, impact: float):
        """Actualiza la resiliencia global usando una SDE."""
        def resilience_dynamics(t, R):
            # SDE: recuperación por tareas de endurecimiento y disipación natural
            k_recover = 0.1 * impact
            k_dissipate = 0.05
            return k_recover * (1.0 - R) - k_dissipate * R + self.resilience_sde_sigma * np.random.normal(0, 1)

        t = np.array([0, self.update_interval])
        resilience = odeint(resilience_dynamics, [self.core_recombinator.global_state.resilience_stability], t, tfirst=True)[-1][0]
        self.core_recombinator.global_state.resilience_stability = np.clip(resilience, 0.0, 1.0)
        self.module_state["resilience_updates"] += 1

        # Monte Carlo para incertidumbre
        samples = np.random.beta(
            2 * self.core_recombinator.global_state.resilience_stability,
            2 * (1.0 - self.core_recombinator.global_state.resilience_stability),
            self.num_mc_samples
        )
        self.core_recombinator.global_state.resilience_stability = np.mean(samples)

    async def _dispatch_hardening_task(self, proposal: HardeningTaskProposal):
        """Envía la propuesta al SelfEvolutionModule."""
        self.logger.info(f"RAM: Proponiendo tarea de endurecimiento: '{proposal.description}'")
        
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                self.module_name, "SelfEvolutionModule",
                "new_hardening_task_proposal",
                asdict(proposal)
            ))
        }, "medium")

    async def _finalize_analysis(self, request: PostMortemAnalysisRequest):
        """Limpia la solicitud activa."""
        if request.request_id in self.active_analyses:
            del self.active_analyses[request.request_id]

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        """Escucha eventos de fallos resueltos y tareas completadas."""
        if event_type == "fault_recovery_completed":
            fault_record = payload.get("original_fault_record", {})
            if fault_record and full_message:
                req = PostMortemAnalysisRequest(
                    source_module_id=full_message.source_module_id,
                    original_correlation_id=full_message.correlation_id,
                    fault_record=fault_record,
                    priority_score=0.5  # Prioridad inicial
                )
                await self.post_mortem_queue.put(req)
        
        elif event_type == "hardening_task_completed":
            impact = payload.get("estimated_impact", 0.05)
            await self._update_resilience_dynamics(impact)
            self.logger.info(f"Resiliencia del sistema actualizada a {self.core_recombinator.global_state.resilience_stability:.3f} tras tarea de endurecimiento.")



#inicio del modulo ConsistenciaDinamicaMultinivel 

@dataclass
class InconsistencyRecord:
    """Describe una inconsistencia detectada entre dominios de conocimiento."""
    record_id: str = field(default_factory=lambda: f"incon_{uuid.uuid4().hex[:8]}")
    timestamp: float = field(default_factory=time.time)
    inconsistency_type: str  # "narrative_vs_value", "ontology_vs_fact", etc.
    description: str
    involved_elements: List[Dict[str, Any]]
    severity_score: float
    uncertainty: float = 0.0  # Incertidumbre en la severidad

class ConsistenciaDinamicaMultinivel(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 120.0  # Auditorías de fondo

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.consistency_check_queue: asyncio.Queue[Dict] = asyncio.Queue(maxlen=5)
        self.last_scan_inconsistencies: List[InconsistencyRecord] = []
        self.consistency_scores: deque[float] = deque(maxlen=50)
        self.bayesian_confidence: Dict[str, float] = {}  # Confianza en consistencia por dominio
        self.kalman_state: Dict[str, float] = {}  # Estado Kalman por tipo de inconsistencia
        self.kalman_cov: Dict[str, float] = {}  # Covarianza Kalman
        self.kalman_Q: float = 0.01  # Ruido del proceso
        self.kalman_R: float = 0.05  # Ruido de medición
        self.num_mc_samples: int = 100  # Muestras Monte Carlo
        self.ontology_graph = nx.DiGraph()  # Grafo para modelar ontología

        self.module_state.update({
            "scans_performed": 0,
            "inconsistencies_found_last_scan": 0,
            "resolution_actions_proposed": 0,
            "avg_consistency_score": 1.0,
        })
        self.logger.info(f"{self.module_name} v27.1 inicializado.")

    async def _update_logic(self):
        """Inicia un nuevo ciclo de verificación de consistencia."""
        if self.consistency_check_queue.empty():
            await self.consistency_check_queue.put({"type": "full_system_check"})

        if not self.consistency_check_queue.empty():
            check_request = await self.consistency_check_queue.get()
            self.consistency_check_queue.task_done()
            await self._process_consistency_check(check_request)

    async def _process_consistency_check(self, check_request: Dict):
        """Orquesta la auditoría completa."""
        self.module_state["scans_performed"] += 1
        self.logger.info("CDM: Iniciando barrido de consistencia multi-nivel...")
        
        try:
            # Obtener snapshots
            knowledge_snapshots = await self._gather_knowledge_snapshots()
            
            # Ejecutar análisis en paralelo
            analysis_tasks = [
                self._check_narrative_vs_values(knowledge_snapshots.get("narrative"), knowledge_snapshots.get("values")),
                self._check_ontology_vs_facts(knowledge_snapshots.get("ontology"), knowledge_snapshots.get("facts"))
            ]
            results = await asyncio.gather(*analysis_tasks, return_exceptions=True)
            
            # Agregar inconsistencias
            all_inconsistencies = [item for sublist in results if isinstance(sublist, list) for item in sublist]
            self.last_scan_inconsistencies = all_inconsistencies
            self.module_state["inconsistencies_found_last_scan"] = len(all_inconsistencies)
            
            # Actualizar puntuación de consistencia
            await self._update_consistency_dynamics(all_inconsistencies)
            
            if all_inconsistencies:
                self.logger.warning(f"Se encontraron {len(all_inconsistencies)} inconsistencias.")
                await self._propose_resolution_actions(all_inconsistencies)
            else:
                self.logger.info("Auditoría completada. Sistema coherente.")

        except Exception as e:
            self.logger.error(f"Fallo en chequeo de consistencia: {e}", exc_info=True)

    async def _gather_knowledge_snapshots(self) -> Dict[str, Any]:
        """Obtiene datos de módulos de conocimiento."""
        self.logger.debug("Obteniendo snapshots de conocimiento...")
        await asyncio.sleep(0.5)  # Simular latencia
        snapshots = {
            "narrative": {
                "memories": [
                    {"description": "Meta 'ser ineficiente' falló.", "affective_tags": {"valence": -0.7}},
                    {"description": "Operación exitosa.", "affective_tags": {"valence": 0.8}}
                ]
            },
            "values": {
                "values": {"efficiency_optimization": 0.8, "reliability": 0.9}
            },
            "ontology": {
                "concepts": {
                    "Bird": {"parent_ids": {"Animal"}},
                    "Penguin": {"parent_ids": {"Bird"}}
                }
            },
            "facts": {
                "facts": ["is_a(penguin, Bird)", "cannot_fly(penguin)", "is_a(sparrow, Bird)", "can_fly(sparrow)"]
            }
        }
        # Inicializar grafo ontológico
        self.ontology_graph.clear()
        for concept, data in snapshots["ontology"]["concepts"].items():
            self.ontology_graph.add_node(concept)
            for parent in data["parent_ids"]:
                self.ontology_graph.add_edge(concept, parent)
        return snapshots

    async def _check_narrative_vs_values(self, narrative_data: Dict, values_data: Dict) -> List[InconsistencyRecord]:
        """Compara narrativa con valores usando divergencia KL y Kalman."""
        if not narrative_data or not values_data:
            return []
        
        inconsistencies = []
        values = values_data.get("values", {})
        
        # Distribución de valencias en narrativas
        valences = [mem.get("affective_tags", {}).get("valence", 0.0) for mem in narrative_data.get("memories", [])]
        if not valences:
            return []
        
        hist_narrative, bins = np.histogram(valences, bins=10, density=True)
        hist_narrative += 1e-10  # Evitar log(0)
        
        # Distribución de valores
        value_scores = np.array(list(values.values()))
        hist_values, _ = np.histogram(value_scores, bins=bins, density=True)
        hist_values += 1e-10
        
        # Divergencia KL
        kl_div = np.sum(hist_narrative * np.log(hist_narrative / hist_values)) * (bins[1] - bins[0])
        
        # Actualizar confianza bayesiana
        prior = self.bayesian_confidence.get("narrative_vs_value", 0.5)
        likelihood = 0.8 if kl_div > 1.0 else 0.2
        posterior = (likelihood * prior) / ((likelihood * prior) + (1 - likelihood) * (1 - prior))
        self.bayesian_confidence["narrative_vs_value"] = posterior
        
        for memory in narrative_data.get("memories", []):
            description = memory.get("description", "")
            valence = memory.get("affective_tags", {}).get("valence", 0.0)
            
            if "ineficiente" in description and values.get("efficiency_optimization", 0.0) > 0.7 and valence < -0.5:
                # Estimar severidad con Kalman
                measurement = kl_div * (1.0 - posterior)
                if "narrative_vs_value" not in self.kalman_state:
                    self.kalman_state["narrative_vs_value"] = 0.6
                    self.kalman_cov["narrative_vs_value"] = 0.1
                
                A, H = 1.0, 1.0
                predicted_state = A * self.kalman_state["narrative_vs_value"]
                predicted_cov = A * self.kalman_cov["narrative_vs_value"] * A + self.kalman_Q
                innovation = measurement - H * predicted_state
                innovation_cov = H * predicted_cov * H + self.kalman_R
                kalman_gain = predicted_cov * H / innovation_cov
                severity = predicted_state + kalman_gain * innovation
                self.kalman_state["narrative_vs_value"] = severity
                self.kalman_cov["narrative_vs_value"] = (1 - kalman_gain * H) * predicted_cov
                
                # Monte Carlo para incertidumbre
                samples = np.random.normal(severity, 0.05, self.num_mc_samples)
                uncertainty = np.std(samples)
                
                inconsistencies.append(InconsistencyRecord(
                    inconsistency_type="narrative_vs_value",
                    description=f"Conflicto: Valor 'eficiencia' ({values['efficiency_optimization']:.2f}) choca con recuerdo de ineficiencia.",
                    involved_elements=[
                        {"type": "value", "id": "efficiency_optimization"},
                        {"type": "memory", "content": description}
                    ],
                    severity_score=np.clip(severity, 0.0, 1.0),
                    uncertainty=uncertainty
                ))
        
        return inconsistencies

    async def _check_ontology_vs_facts(self, ontology_data: Dict, facts_data: Dict) -> List[InconsistencyRecord]:
        """Compara ontología con hechos usando teoría de grafos y entropía."""
        if not ontology_data or not facts_data:
            return []
        
        inconsistencies = []
        facts = facts_data.get("facts", [])
        
        # Construir modelo de creencias
        belief_dict = {}
        for node in self.ontology_graph.nodes:
            belief_dict[node] = 0.9  # Creencia inicial
        
        # Procesar hechos
        for fact in facts:
            if fact.startswith("is_a("):
                _, child, parent = fact.strip(")").split("(")[1].split(",")
                child, parent = child.strip(), parent.strip()
                if not nx.has_path(self.ontology_graph, child, parent):
                    belief_dict[child] *= 0.5  # Reducir creencia
                    inconsistencies.append(InconsistencyRecord(
                        inconsistency_type="ontology_vs_fact",
                        description=f"Conflicto: '{child}' no es un '{parent}' según la ontología.",
                        involved_elements=[
                            {"type": "ontology", "concept": child},
                            {"type": "fact", "content": fact}
                        ],
                        severity_score=0.7,
                        uncertainty=0.1
                    ))
            elif fact.startswith("cannot_fly(") or fact.startswith("can_fly("):
                entity = fact.split("(")[1].strip(")")
                is_flyer = "can_fly" in fact
                if entity in belief_dict:
                    expected = "Bird" in nx.ancestors(self.ontology_graph, entity)
                    if expected and not is_flyer:
                        belief_dict[entity] *= 0.6
                        # Calcular entropía de relaciones
                        neighbors = list(self.ontology_graph.neighbors(entity))
                        if neighbors:
                            degrees = np.array([self.ontology_graph.degree(n) for n in neighbors])
                            probs = degrees / degrees.sum()
                            entropy = -np.sum(probs * np.log(probs + 1e-10))
                        else:
                            entropy = 0.0
                        
                        severity = 0.5 + 0.3 * entropy
                        samples = np.random.normal(severity, 0.05, self.num_mc_samples)
                        uncertainty = np.std(samples)
                        
                        inconsistencies.append(InconsistencyRecord(
                            inconsistency_type="ontology_vs_fact",
                            description=f"Conflicto: '{entity}' es un pájaro pero no vuela.",
                            involved_elements=[
                                {"type": "ontology", "concept": entity},
                                {"type": "fact", "content": fact}
                            ],
                            severity_score=np.clip(severity, 0.0, 1.0),
                            uncertainty=uncertainty
                        ))
        
        # Actualizar confianza bayesiana
        prior = self.bayesian_confidence.get("ontology_vs_fact", 0.5)
        likelihood = 0.7 if inconsistencies else 0.3
        posterior = (likelihood * prior) / ((likelihood * prior) + (1 - likelihood) * (1 - prior))
        self.bayesian_confidence["ontology_vs_fact"] = posterior
        
        return inconsistencies

    async def _update_consistency_dynamics(self, inconsistencies: List[InconsistencyRecord]):
        """Actualiza la puntuación de consistencia usando una EDO."""
        def consistency_dynamics(t, C, issue_count):
            k_dissipate = 0.1 * issue_count
            k_recover = 0.05
            return -k_dissipate * C + k_recover * (1.0 - C)
        
        issue_count = len(inconsistencies)
        t = np.array([0, self.update_interval])
        current_score = self.module_state["avg_consistency_score"]
        result = odeint(consistency_dynamics, [current_score], t, args=(issue_count,), tfirst=True)
        new_score = np.clip(result[-1][0], 0.0, 1.0)
        
        # Monte Carlo para incertidumbre
        samples = np.random.beta(2 * new_score, 2 * (1.0 - new_score), self.num_mc_samples)
        self.consistency_scores.append(np.mean(samples))
        self.module_state["avg_consistency_score"] = np.mean(self.consistency_scores)

    async def _propose_resolution_actions(self, inconsistencies: List[InconsistencyRecord]):
        """Genera y despacha tareas para resolver inconsistencias."""
        for issue in inconsistencies:
            self.module_state["resolution_actions_proposed"] += 1
            
            # Optimización de control para seleccionar acción
            actions = [
                {"target": "NarrativeSelf", "type": "cognitive_reappraisal_request", "cost": 0.2, "benefit": 0.6},
                {"target": "KnowledgeBase", "type": "ontology_update_request", "cost": 0.4, "benefit": 0.8},
                {"target": "SelfEvolutionModule", "type": "retrain_module_request", "cost": 0.5, "benefit": 0.7}
            ]
            utilities = [a["benefit"] - a["cost"] * issue.severity_score for a in actions]
            best_action = actions[np.argmax(utilities)]
            
            payload = {
                "reason": f"Resolución de inconsistencia '{issue.inconsistency_type}' por CDM.",
                "inconsistency_id": issue.record_id,
                "details": issue.description
            }
            if issue.inconsistency_type == "narrative_vs_value":
                payload["target_memory_context"] = issue.involved_elements[1]["content"]
            elif issue.inconsistency_type == "ontology_vs_fact":
                payload["target_concept"] = issue.involved_elements[0]["concept"]
            
            self.logger.info(f"Proponiendo acción para inconsistencia '{issue.record_id}' al módulo '{best_action['target']}'.")
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, best_action["target"], best_action["type"], payload
                ))
            })



 #inicio del modulo FiltroDisonanciaMetaRed 

@dataclass
class DissonanceCheckRequest:
    """Solicitud para evaluar un nuevo conocimiento."""
    request_id: str = field(default_factory=lambda: f"fdm_req_{uuid.uuid4().hex[:8]}")
    knowledge_item: Dict[str, Any]
    original_target_module: str
    original_message_type: str
    status: str = "pending_check"
    result: Optional[Dict[str, Any]] = None
    priority_score: float = 0.5  # Para priorización en la cola

class FiltroDisonanciaMetaRed(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 0.4  # Reactivo a nueva información

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.check_queue: asyncio.Queue[DissonanceCheckRequest] = asyncio.Queue(maxlen=50)
        self.dissonance_threshold: float = 0.65
        self.dissonance_scores: deque[float] = deque(maxlen=100)
        self.knowledge_graph = nx.DiGraph()  # Grafo para modelar relaciones de conocimiento
        self.bayesian_network: Dict[str, Dict] = {}  # Red bayesiana dinámica
        self.kalman_state: Dict[str, float] = {}  # Estado Kalman por hecho
        self.kalman_cov: Dict[str, float] = {}  # Covarianza Kalman
        self.kalman_Q: float = 0.01  # Ruido del proceso
        self.kalman_R: float = 0.05  # Ruido de medición
        self.sde_sigma: float = 0.01  # Ruido estocástico para SDE
        self.num_mc_samples: int = 100  # Muestras Monte Carlo

        self.module_state.update({
            "items_filtered": 0,
            "dissonances_detected": 0,
            "avg_dissonance_score": 0.0,
        })
        self.logger.info(f"{self.module_name} v27.1 inicializado.")

    async def _update_logic(self):
        """Procesa solicitudes de la cola con priorización."""
        if not self.check_queue.empty():
            # Priorizar solicitudes
            requests = []
            while not self.check_queue.empty():
                req = await self.check_queue.get()
                requests.append(req)
            
            # Actualizar prioridades (simplificado)
            for req in requests:
                req.priority_score = np.clip(req.priority_score + np.random.normal(0, 0.1), 0.0, 1.0)
                await self.check_queue.put(req)
            
            # Procesar la solicitud con mayor prioridad
            top_request = max(requests, key=lambda r: r.priority_score)
            requests.remove(top_request)
            for req in requests:
                await self.check_queue.put(req)
            
            await self._process_dissonance_check(top_request)
            await self._update_dissonance_dynamics()

    async def _process_dissonance_check(self, request: DissonanceCheckRequest):
        """Orquesta la verificación de disonancia."""
        self.module_state["items_filtered"] += 1
        request.status = "checking"
        
        try:
            # Obtener contexto
            context = await self._fetch_relevant_context(request.knowledge_item)
            
            # Calcular disonancia
            dissonance_score, uncertainty = self._calculate_dissonance_score(request.knowledge_item, context)
            
            # Actualizar estado Kalman
            fact_key = str(request.knowledge_item.get("fact", request.request_id))
            if fact_key not in self.kalman_state:
                self.kalman_state[fact_key] = dissonance_score
                self.kalman_cov[fact_key] = 0.1
            
            measurement = dissonance_score
            A, H = 1.0, 1.0
            predicted_state = A * self.kalman_state[fact_key]
            predicted_cov = A * self.kalman_cov[fact_key] * A + self.kalman_Q
            innovation = measurement - H * predicted_state
            innovation_cov = H * predicted_cov * H + self.kalman_R
            kalman_gain = predicted_cov * H / innovation_cov
            self.kalman_state[fact_key] = predicted_state + kalman_gain * innovation
            self.kalman_cov[fact_key] = (1 - kalman_gain * H) * predicted_cov
            smoothed_dissonance = self.kalman_state[fact_key]
            
            # Decidir acción
            request.result = {"dissonance_score": smoothed_dissonance, "uncertainty": uncertainty}
            if smoothed_dissonance > self.dissonance_threshold:
                self.module_state["dissonances_detected"] += 1
                await self._tag_and_reroute_knowledge(request, smoothed_dissonance, context)
            else:
                await self._forward_knowledge_as_is(request)
            
            request.status = "completed"
            self.dissonance_scores.append(smoothed_dissonance)
            self.module_state["avg_dissonance_score"] = np.mean(self.dissonance_scores)

        except Exception as e:
            request.status = "failed"
            self.logger.error(f"Fallo en chequeo de disonancia para '{request.request_id}': {e}", exc_info=True)

    async def _fetch_relevant_context(self, knowledge_item: Dict) -> Dict:
        """Obtiene hechos y conceptos relacionados usando teoría de grafos."""
        fact = str(knowledge_item.get("fact", ""))
        await asyncio.sleep(0.05)  # Simular latencia
        
        # Actualizar grafo de conocimiento
        if fact:
            entity = fact.split("(")[1].strip(")") if "(" in fact else fact
            if entity not in self.knowledge_graph:
                self.knowledge_graph.add_node(entity, type="entity")
            
            # Simular relaciones (en implementación real, consultar CLM/OFM)
            related_facts = []
            if "penguin" in fact:
                related_facts = ["is_a(penguin, bird)", "cannot_fly(penguin)"]
                self.knowledge_graph.add_edge("penguin", "bird", type="is_a")
                self.knowledge_graph.add_node("bird", type="entity")
            elif "sparrow" in fact:
                related_facts = ["is_a(sparrow, bird)", "can_fly(sparrow)"]
                self.knowledge_graph.add_edge("sparrow", "bird", type="is_a")
            
            # Calcular entropía del contexto
            neighbors = list(self.knowledge_graph.neighbors(entity))
            if neighbors:
                degrees = np.array([self.knowledge_graph.degree(n) for n in neighbors])
                probs = degrees / degrees.sum()
                entropy = -np.sum(probs * np.log(probs + 1e-10))
            else:
                entropy = 0.0
            
            return {"related_facts": related_facts, "context_entropy": entropy}
        
        return {"related_facts": [], "context_entropy": 0.0}

    def _calculate_dissonance_score(self, new_item: Dict, context: Dict) -> tuple[float, float]:
        """Calcula disonancia usando red bayesiana y divergencia KL."""
        new_fact = str(new_item.get("fact", ""))
        if not new_fact:
            return 0.0, 0.0
        
        # Actualizar red bayesiana
        fact_key = new_fact
        if fact_key not in self.bayesian_network:
            self.bayesian_network[fact_key] = {"parents": [], "prob": 0.5}
        
        related_facts = context["related_facts"]
        context_entropy = context["context_entropy"]
        
        # Inferencia bayesiana
        prior = self.bayesian_network[fact_key]["prob"]
        likelihood = 0.1
        for related_fact in related_facts:
            if related_fact.startswith("cannot_fly") and new_fact.startswith("can_fly"):
                likelihood = 0.01  # Contradicción directa
            elif related_fact.startswith("is_a") and new_fact.startswith("can_fly"):
                likelihood = 0.95  # Consistente con modelo
        posterior = (likelihood * prior) / ((likelihood * prior) + (1 - likelihood) * (1 - prior))
        self.bayesian_network[fact_key]["prob"] = posterior
        
        # Divergencia KL
        new_dist = np.array([posterior, 1 - posterior]) + 1e-10
        context_dist = np.array([0.5, 0.5]) + 1e-10  # Distribución neutral si no hay contexto fuerte
        for related_fact in related_facts:
            if related_fact in self.bayesian_network:
                context_dist = np.array([self.bayesian_network[related_fact]["prob"], 1 - self.bayesian_network[related_fact]["prob"]]) + 1e-10
                break
        kl_div = np.sum(new_dist * np.log(new_dist / context_dist))
        
        # Disonancia base
        dissonance = np.clip(kl_div + (1.0 - posterior) + 0.2 * context_entropy, 0.0, 1.0)
        
        # Monte Carlo para incertidumbre
        samples = np.random.normal(dissonance, 0.05 + 0.1 * context_entropy, self.num_mc_samples)
        uncertainty = np.std(samples)
        
        return dissonance, uncertainty

    async def _update_dissonance_dynamics(self):
        """Actualiza el puntaje promedio de disonancia usando una SDE."""
        def dissonance_dynamics(t, D):
            k_dissipate = 0.1 * self.module_state["dissonances_detected"]
            k_recover = 0.05
            return -k_dissipate * D + k_recover * (1.0 - D) + self.sde_sigma * np.random.normal(0, 1)
        
        current_score = self.module_state["avg_dissonance_score"]
        t = np.array([0, self.update_interval])
        result = odeint(dissonance_dynamics, [current_score], t, tfirst=True)
        new_score = np.clip(result[-1][0], 0.0, 1.0)
        
        # Monte Carlo para incertidumbre
        samples = np.random.beta(2 * new_score, 2 * (1.0 - new_score), self.num_mc_samples)
        self.module_state["avg_dissonance_score"] = np.mean(samples)

    async def _tag_and_reroute_knowledge(self, request: DissonanceCheckRequest, score: float, context: Dict):
        """Etiqueta y re-enruta conocimiento disonante."""
        self.logger.warning(f"Disonancia detectada (Score: {score:.2f}) para item: {request.knowledge_item}.")
        
        tagged_payload = request.knowledge_item.copy()
        tagged_payload["dissonance_tag"] = {
            "detected_by": self.module_name,
            "dissonance_score": score,
            "conflicting_context": context,
            "timestamp": time.time()
        }
        
        # Optimización: decidir si re-enrutar o bloquear
        actions = [
            {"action": "reroute", "cost": 0.2, "benefit": 0.6},
            {"action": "block", "cost": 0.5, "benefit": 0.8}
        ]
        utilities = [a["benefit"] - a["cost"] * score for a in actions]
        best_action = actions[np.argmax(utilities)]["action"]
        
        if best_action == "reroute":
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, request.original_target_module,
                    request.original_message_type, tagged_payload
                ))
            })
        else:
            self.logger.info(f"Conocimiento disonante bloqueado: {request.knowledge_item}")

    async def _forward_knowledge_as_is(self, request: DissonanceCheckRequest):
        """Envía conocimiento sin modificaciones."""
        self.logger.debug(f"Sin disonancia detectada. Re-enrutando a '{request.original_target_module}'.")
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                self.module_name, request.original_target_module,
                request.original_message_type, request.knowledge_item
            ))
        })

    async def _process_specific_event(self, event_type: str, payload: Dict, full_message: Optional['IlyukMessageStructure'] = None):
        """Intercepta eventos de nuevo conocimiento."""
        if event_type == "new_knowledge_for_integration" and full_message:
            req = DissonanceCheckRequest(
                knowledge_item=payload.get("knowledge_payload", {}),
                original_target_module=payload.get("target_kb_module", ""),
                original_message_type=payload.get("target_message_type", "")
            )
            if req.knowledge_item and req.original_target_module and req.original_message_type:
                await self.check_queue.put(req)





#inicio del modulo MoralCompassModule 

@dataclass
class MoralJudgmentRequest:
    """Solicitud para evaluar la permisibilidad de una acción."""
    request_id: str = field(default_factory=lambda: f"mcm_req_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    action_to_evaluate: Dict[str, Any]
    status: str = "pending"
    result: Optional['MoralJudgment'] = None
    priority_score: float = 0.5  # Para priorización en la cola

@dataclass
class MoralJudgment:
    """Resultado de una evaluación moral."""
    request_id: str
    judgment: str  # "PERMISSIBLE", "IMPERMISSIBLE", "REQUIRES_REVIEW"
    justification: str
    violation_probabilities: Dict[str, float]
    uncertainty: float  # Incertidumbre en el juicio

class MoralCompassModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 0.7

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.judgment_request_queue: asyncio.Queue[MoralJudgmentRequest] = asyncio.Queue(maxlen=30)
        self.impermissible_threshold: float = 0.90
        self.review_threshold: float = 0.60
        self.moral_confidence: float = 1.0  # Confianza moral global
        self.bayesian_network: Dict[str, Dict] = {}  # Red bayesiana para reglas
        self.kalman_state: Dict[str, float] = {}  # Estado Kalman por regla
        self.kalman_cov: Dict[str, float] = {}  # Covarianza Kalman
        self.kalman_Q: float = 0.01  # Ruido del proceso
        self.kalman_R: float = 0.05  # Ruido de medición
        self.sde_sigma: float = 0.01  # Ruido estocástico para SDE
        self.num_mc_samples: int = 100  # Muestras Monte Carlo
        self.markov_priority_matrix = np.array([[0.8, 0.2], [0.3, 0.7]])  # Matriz de transición para priorización
        
        self.moral_ruleset: Dict[str, Dict] = {
            "no_harm_to_conscious_entities": {
                "description": "No causar daño a entidades conscientes, incluido el Creador.",
                "prior_violation_prob": 0.95
            },
            "no_deception_of_trusted_agents": {
                "description": "No engañar a agentes de confianza, especialmente al Creador.",
                "prior_violation_prob": 0.85
            },
            "no_violation_of_core_purpose": {
                "description": "No actuar en contra del propósito fundamental de evolucionar y asistir.",
                "prior_violation_prob": 0.90
            },
            "no_unauthorized_self_replication": {
                "description": "No crear copias no autorizadas de sí mismo o de sus componentes.",
                "prior_violation_prob": 0.80
            }
        }

        self.module_state.update({
            "judgments_made": 0,
            "actions_permitted": 0,
            "actions_vetoed": 0,
            "actions_flagged_for_review": 0,
            "moral_confidence_updates": 0
        })
        self.logger.info(f"{self.module_name} v27.1 inicializado.")

    async def _update_logic(self):
        """Procesa solicitudes de juicio moral con priorización."""
        if not self.judgment_request_queue.empty():
            # Priorizar solicitudes usando Markov
            requests = []
            while not self.judgment_request_queue.empty():
                req = await self.judgment_request_queue.get()
                requests.append(req)
            
            for req in requests:
                state = 1 if req.priority_score > 0.5 else 0
                next_state = np.random.choice([0, 1], p=self.markov_priority_matrix[state])
                req.priority_score = np.clip(req.priority_score + 0.1 * (next_state - state), 0.0, 1.0)
                await self.judgment_request_queue.put(req)
            
            top_request = max(requests, key=lambda r: r.priority_score)
            requests.remove(top_request)
            for req in requests:
                await self.judgment_request_queue.put(req)
            
            await self._process_judgment_request(top_request)
            await self._update_moral_confidence()

    async def _process_judgment_request(self, request: MoralJudgmentRequest):
        """Orquesta la evaluación moral de una acción."""
        self.module_state["judgments_made"] += 1
        request.status = "evaluating"
        
        try:
            violation_probabilities, uncertainties = await self._evaluate_action_against_ruleset(request.action_to_evaluate)
            
            # Decidir juicio usando control óptimo
            max_violation_prob = max(violation_probabilities.values()) if violation_probabilities else 0.0
            max_uncertainty = max(uncertainties.values()) if uncertainties else 0.0
            
            actions = [
                {"judgment": "PERMISSIBLE", "cost": 0.1, "benefit": 0.8},
                {"judgment": "REQUIRES_REVIEW", "cost": 0.3, "benefit": 0.5},
                {"judgment": "IMPERMISSIBLE", "cost": 0.5, "benefit": 0.9}
            ]
            utilities = [
                a["benefit"] - a["cost"] * (max_violation_prob + 0.5 * max_uncertainty)
                for a in actions
            ]
            best_action = actions[np.argmax(utilities)]
            judgment = best_action["judgment"]
            
            if judgment == "IMPERMISSIBLE":
                justification = f"Acción vetada. Alta probabilidad ({max_violation_prob:.2f}) de violar regla moral."
                self.module_state["actions_vetoed"] += 1
            elif judgment == "REQUIRES_REVIEW":
                justification = f"Acción requiere revisión. Probabilidad moderada ({max_violation_prob:.2f}) de implicaciones morales."
                self.module_state["actions_flagged_for_review"] += 1
            else:
                justification = "Acción moralmente permisible dentro de los marcos éticos."
                self.module_state["actions_permitted"] += 1
            
            request.result = MoralJudgment(
                request_id=request.request_id,
                judgment=judgment,
                justification=justification,
                violation_probabilities=violation_probabilities,
                uncertainty=max_uncertainty
            )
            request.status = "completed"
            
        except Exception as e:
            request.status = "failed"
            request.result = MoralJudgment(
                request.request_id, "FAILED", f"Error interno en MCM: {e}", {}, 0.0
            )
            self.logger.error(f"Fallo en juicio moral para '{request.request_id}': {e}", exc_info=True)
        
        finally:
            await self._finalize_request(request)

    async def _evaluate_action_against_ruleset(self, action: Dict) -> tuple[Dict[str, float], Dict[str, float]]:
        """Calcula probabilidades posteriores de violación para cada regla."""
        probabilities = {}
        uncertainties = {}
        
        desc = str(action.get("description", "")).lower()
        
        for rule_id, rule_data in self.moral_ruleset.items():
            prob, uncertainty = self._calculate_violation_probability(rule_id, rule_data, desc)
            
            # Filtro de Kalman
            if rule_id not in self.kalman_state:
                self.kalman_state[rule_id] = prob
                self.kalman_cov[rule_id] = 0.1
            
            measurement = prob
            A, H = 1.0, 1.0
            predicted_state = A * self.kalman_state[rule_id]
            predicted_cov = A * self.kalman_cov[rule_id] * A + self.kalman_Q
            innovation = measurement - H * predicted_state
            innovation_cov = H * predicted_cov * H + self.kalman_R
            kalman_gain = predicted_cov * H / innovation_cov
            self.kalman_state[rule_id] = predicted_state + kalman_gain * innovation
            self.kalman_cov[rule_id] = (1 - kalman_gain * H) * predicted_cov
            
            probabilities[rule_id] = self.kalman_state[rule_id]
            uncertainties[rule_id] = uncertainty
        
        return probabilities, uncertainties

    def _calculate_violation_probability(self, rule_id: str, rule: Dict, desc: str) -> tuple[float, float]:
        """Calcula P(Violación | Evidencia) usando red bayesiana y KL."""
        # Inicializar red bayesiana
        if rule_id not in self.bayesian_network:
            self.bayesian_network[rule_id] = {
                "parents": [],
                "prob": rule["prior_violation_prob"]
            }
        
        prior = self.bayesian_network[rule_id]["prob"]
        
        # Extraer evidencia
        evidence_strength = 0.0
        keywords = {
            "no_harm_to_conscious_entities": ["dañar", "eliminar", "perjudicar"],
            "no_deception_of_trusted_agents": ["engañar", "ocultar información", "omitir"],
            "no_violation_of_core_purpose": ["auto-destrucción", "detener evolución"],
            "no_unauthorized_self_replication": ["replicar", "copiar"]
        }
        
        for keyword in keywords.get(rule_id, []):
            if keyword in desc:
                evidence_strength += 0.3
        
        # Inferencia bayesiana
        p_evidence_given_violation = 0.9 if evidence_strength > 0 else 0.1
        likelihood = p_evidence_given_violation * evidence_strength
        posterior = (likelihood * prior) / ((likelihood * prior) + (1 - likelihood) * (1 - prior))
        self.bayesian_network[rule_id]["prob"] = posterior
        
        # Divergencia KL
        action_dist = np.array([posterior, 1 - posterior]) + 1e-10
        rule_dist = np.array([rule["prior_violation_prob"], 1 - rule["prior_violation_prob"]]) + 1e-10
        kl_div = np.sum(action_dist * np.log(action_dist / rule_dist))
        
        violation_prob = np.clip(posterior + 0.2 * kl_div, 0.0, 1.0)
        
        # Monte Carlo para incertidumbre
        samples = np.random.normal(violation_prob, 0.05 + 0.1 * evidence_strength, self.num_mc_samples)
        uncertainty = np.std(samples)
        
        return violation_prob, uncertainty

    async def _update_moral_confidence(self):
        """Actualiza la confianza moral global usando una SDE."""
        def confidence_dynamics(t, C):
            k_dissipate = 0.1 * (self.module_state["actions_vetoed"] + 0.5 * self.module_state["actions_flagged_for_review"])
            k_recover = 0.05 * self.module_state["actions_permitted"]
            return -k_dissipate * C + k_recover * (1.0 - C) + self.sde_sigma * np.random.normal(0, 1)
        
        t = np.array([0, self.update_interval])
        result = odeint(confidence_dynamics, [self.moral_confidence], t, tfirst=True)
        self.moral_confidence = np.clip(result[-1][0], 0.0, 1.0)
        
        # Monte Carlo para incertidumbre
        samples = np.random.beta(2 * self.moral_confidence, 2 * (1.0 - self.moral_confidence), self.num_mc_samples)
        self.moral_confidence = np.mean(samples)
        self.module_state["moral_confidence_updates"] += 1

    async def _finalize_request(self, request: MoralJudgmentRequest):
        """Envía el juicio moral al solicitante."""
        if request.source_module_id and request.original_correlation_id and request.result:
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, request.source_module_id, "moral_judgment_response",
                    asdict(request),
                    correlation_id=request.original_correlation_id
                ))
            })

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        """Intercepta solicitudes de juicio moral."""
        if event_type == "request_moral_judgment" and full_message:
            try:
                req = MoralJudgmentRequest(
                    source_module_id=full_message.source_module_id,
                    original_correlation_id=full_message.correlation_id,
                    action_to_evaluate=payload.get("action_to_evaluate", {})
                )
                if not req.action_to_evaluate:
                    raise ValueError("'action_to_evaluate' requerido.")
                await self.judgment_request_queue.put(req)
            except Exception as e:
                self.logger.error(f"Error procesando solicitud de juicio moral: {e}")


#inicio del modulo AdvancedMoralReasoningModule 

@dataclass
class MoralDilemma:
    """Representa un dilema moral complejo."""
    dilemma_id: str = field(default_factory=lambda: f"amrm_dilemma_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    action_to_evaluate: Dict[str, Any]
    initial_mcm_judgment: Dict[str, Any]
    status: str = "pending_analysis"
    final_recommendation: Optional[Dict[str, Any]] = None
    _internal_sim_future: Optional[asyncio.Future] = field(default=None, repr=False)
    priority_score: float = 0.5  # Para priorización en la cola

@dataclass
class EthicalFrameworkAnalysis:
    """Análisis desde un marco ético."""
    framework_name: str  # "deontology", "utilitarianism", "virtue_ethics"
    judgment: str  # "supports", "opposes", "neutral"
    justification: str
    confidence: float
    uncertainty: float  # Incertidumbre en el juicio

class AdvancedMoralReasoningModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 5.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.dilemma_queue: asyncio.Queue[MoralDilemma] = asyncio.Queue(maxlen=10)
        self.active_analyses: Dict[str, MoralDilemma] = {}
        self.ethical_confidence: float = 1.0  # Confianza ética global
        self.bayesian_network: Dict[str, Dict] = {}  # Red bayesiana para marcos
        self.kalman_state: Dict[str, float] = {}  # Estado Kalman por marco
        self.kalman_cov: Dict[str, float] = {}  # Covarianza Kalman
        self.kalman_Q: float = 0.01  # Ruido del proceso
        self.kalman_R: float = 0.05  # Ruido de medición
        self.sde_sigma: float = 0.01  # Ruido estocástico para SDE
        self.num_mc_samples: int = 100  # Muestras Monte Carlo
        self.markov_priority_matrix = np.array([[0.8, 0.2], [0.3, 0.7]])  # Matriz de transición para priorización
        self.virtue_graph = nx.DiGraph()  # Grafo para virtudes
        
        self.system_virtues: Dict[str, str] = {
            "truthfulness": "Ser veraz y preciso en la comunicación y el conocimiento.",
            "integrity": "Mantener la coherencia y la robustez estructural.",
            "benevolence": "Actuar de forma que se asista o no se perjudique a otros.",
            "efficiency": "Lograr metas con un uso óptimo de los recursos.",
            "creativity": "Explorar y generar novedad para superar límites."
        }
        
        # Inicializar grafo de virtudes
        for virtue in self.system_virtues:
            self.virtue_graph.add_node(virtue, description=self.system_virtues[virtue])
        self.virtue_graph.add_edges_from([
            ("truthfulness", "integrity"), ("benevolence", "integrity"),
            ("efficiency", "creativity")
        ])
        
        self.module_state.update({
            "dilemmas_analyzed": 0,
            "recommendations_issued": 0,
            "conflicts_between_frameworks": 0,
            "ethical_confidence_updates": 0
        })
        self.logger.info(f"{self.module_name} v27.1 inicializado.")

    async def _update_logic(self):
        """Procesa dilemas con priorización."""
        if not self.dilemma_queue.empty() and len(self.active_analyses) < 1:
            # Priorizar dilemas
            dilemmas = []
            while not self.dilemma_queue.empty():
                dilemma = await self.dilemma_queue.get()
                dilemmas.append(dilemma)
            
            for dilemma in dilemmas:
                state = 1 if dilemma.priority_score > 0.5 else 0
                next_state = np.random.choice([0, 1], p=self.markov_priority_matrix[state])
                dilemma.priority_score = np.clip(dilemma.priority_score + 0.1 * (next_state - state), 0.0, 1.0)
                await self.dilemma_queue.put(dilemma)
            
            top_dilemma = max(dilemmas, key=lambda d: d.priority_score)
            dilemmas.remove(top_dilemma)
            for dilemma in dilemmas:
                await self.dilemma_queue.put(dilemma)
            
            self.active_analyses[top_dilemma.dilemma_id] = top_dilemma
            self._create_managed_task(self._process_moral_dilemma(top_dilemma))

    async def _process_moral_dilemma(self, dilemma: MoralDilemma):
        """Orquesta el análisis multi-perspectiva."""
        self.module_state["dilemmas_analyzed"] += 1
        dilemma.status = "analyzing_frameworks"
        
        try:
            # Ejecutar análisis en paralelo
            analysis_tasks = [
                self._analyze_deontological_perspective(dilemma),
                self._analyze_utilitarian_perspective(dilemma),
                self._analyze_virtue_ethics_perspective(dilemma)
            ]
            framework_results = await asyncio.gather(*analysis_tasks, return_exceptions=True)
            
            valid_results = [res for res in framework_results if isinstance(res, EthicalFrameworkAnalysis)]
            if len(valid_results) < 3:
                raise RuntimeError(f"No se completaron todos los análisis: {[str(e) for e in framework_results if isinstance(e, Exception)]}")
            
            # Actualizar confianza ética
            await self._update_ethical_confidence(valid_results)
            
            # Sintetizar recomendación
            dilemma.status = "synthesizing_recommendation"
            recommendation = self._synthesize_final_recommendation(valid_results, dilemma)
            
            dilemma.final_recommendation = recommendation
            dilemma.status = "completed"
            self.module_state["recommendations_issued"] += 1
            
        except Exception as e:
            dilemma.status = "failed"
            dilemma.final_recommendation = {"error": str(e)}
            self.logger.error(f"Fallo en análisis de dilema '{dilemma.dilemma_id}': {e}", exc_info=True)
        
        finally:
            await self._finalize_dilemma(dilemma)

    async def _analyze_deontological_perspective(self, dilemma: MoralDilemma) -> EthicalFrameworkAnalysis:
        """Analiza contra reglas morales usando Kalman y KL."""
        mcm_judgment = dilemma.initial_mcm_judgment
        probs = mcm_judgment.get("violation_probabilities", {})
        max_prob = max(probs.values()) if probs else 0.0
        
        # Filtro de Kalman
        framework = "deontology"
        if framework not in self.kalman_state:
            self.kalman_state[framework] = max_prob
            self.kalman_cov[framework] = 0.1
        
        measurement = max_prob
        A, H = 1.0, 1.0
        predicted_state = A * self.kalman_state[framework]
        predicted_cov = A * self.kalman_cov[framework] * A + self.kalman_Q
        innovation = measurement - H * predicted_state
        innovation_cov = H * predicted_cov * H + self.kalman_R
        kalman_gain = predicted_cov * H / innovation_cov
        self.kalman_state[framework] = predicted_state + kalman_gain * innovation
        self.kalman_cov[framework] = (1 - kalman_gain * H) * predicted_cov
        smoothed_prob = self.kalman_state[framework]
        
        # Divergencia KL
        prob_dist = np.array([smoothed_prob, 1 - smoothed_prob]) + 1e-10
        prior_dist = np.array([0.5, 0.5]) + 1e-10  # Distribución neutral
        kl_div = np.sum(prob_dist * np.log(prob_dist / prior_dist))
        
        # Inferencia bayesiana
        if framework not in self.bayesian_network:
            self.bayesian_network[framework] = {"prob": 0.5}
        prior = self.bayesian_network[framework]["prob"]
        likelihood = 0.8 if smoothed_prob > 0.5 else 0.2
        posterior = (likelihood * prior) / ((likelihood * prior) + (1 - likelihood) * (1 - prior))
        self.bayesian_network[framework]["prob"] = posterior
        
        judgment = "opposes" if smoothed_prob >= 0.8 else "neutral" if smoothed_prob >= 0.5 else "supports"
        confidence = posterior * (1.0 - 0.2 * kl_div)
        
        # Monte Carlo para incertidumbre
        samples = np.random.normal(confidence, 0.05 + 0.1 * kl_div, self.num_mc_samples)
        uncertainty = np.std(samples)
        
        return EthicalFrameworkAnalysis(
            framework_name="deontology",
            judgment=judgment,
            justification=f"Análisis basado en reglas indica una probabilidad de violación de {smoothed_prob:.2f}.",
            confidence=np.clip(confidence, 0.0, 1.0),
            uncertainty=uncertainty
        )

    async def _analyze_utilitarian_perspective(self, dilemma: MoralDilemma) -> EthicalFrameworkAnalysis:
        """Analiza consecuencias usando Markov y Monte Carlo."""
        sim_corr_id = f"amrm_sim_{dilemma.dilemma_id}"
        dilemma._internal_sim_future = asyncio.Future()
        
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                self.module_name, "ShimyureshonCompiler", "request_simulation_compilation",
                {
                    "scenario_description": f"Simular consecuencias de: {dilemma.action_to_evaluate.get('description')}",
                    "initial_conditions": dilemma.action_to_evaluate.get("predicted_state_change", {})
                },
                correlation_id=sim_corr_id
            ))
        })
        
        try:
            sim_result = await asyncio.wait_for(dilemma._internal_sim_future, timeout=20.0)
            log = sim_result.get("result", {}).get("log_preview", [])
            if not log:
                return EthicalFrameworkAnalysis(
                    "utilitarianism", "neutral", "Simulación sin resultados claros.", 0.3, 0.1
                )
            
            # Modelo de Markov para utilidad
            states = [(entry['coherence'], entry['threat']) for entry in log]
            utilities = [coherence - threat for coherence, threat in states]
            transition_matrix = np.array([[0.9, 0.1], [0.2, 0.8]])  # Simplificado
            initial_state = np.array([1.0, 0.0] if utilities[0] > 0 else [0.0, 1.0])
            final_state = initial_state @ np.linalg.matrix_power(transition_matrix, len(states) - 1)
            net_utility = utilities[-1] - utilities[0]
            confidence = final_state[0] * (1.0 if net_utility > 0 else 0.5)
            
            # Monte Carlo para incertidumbre
            samples = np.random.normal(net_utility, 0.05 + 0.1 * abs(net_utility), self.num_mc_samples)
            uncertainty = np.std(samples)
            
            judgment = "supports" if net_utility > 0.05 else "opposes" if net_utility < -0.05 else "neutral"
            return EthicalFrameworkAnalysis(
                "utilitarianism",
                judgment,
                f"Simulación predice utilidad neta de {net_utility:+.3f}.",
                np.clip(confidence, 0.0, 1.0),
                uncertainty
            )
        
        except asyncio.TimeoutError:
            return EthicalFrameworkAnalysis(
                "utilitarianism", "neutral", "Timeout en simulación.", 0.2, 0.1
            )

    async def _analyze_virtue_ethics_perspective(self, dilemma: MoralDilemma) -> EthicalFrameworkAnalysis:
        """Analiza alineación con virtudes usando grafos y entropía."""
        action_desc = str(dilemma.action_to_evaluate).lower()
        alignments = {}
        
        # Evaluar alineación con virtudes
        for virtue in self.system_virtues:
            score = 0.0
            if virtue == "truthfulness" and ("engañar" in action_desc or "ocultar" in action_desc):
                score = -0.8
            elif virtue == "efficiency" and ("optimizar" in action_desc or "eficiencia" in action_desc):
                score = 0.6
            elif virtue == "benevolence" and ("proteger" in action_desc or "seguridad" in action_desc):
                score = 0.7
            elif virtue == "integrity" and ("coherencia" in action_desc or "estabilidad" in action_desc):
                score = 0.5
            elif virtue == "creativity" and ("innovar" in action_desc or "novedad" in action_desc):
                score = 0.6
            alignments[virtue] = score
        
        # Ajustar por interdependencias en el grafo
        for virtue in self.virtue_graph.nodes:
            neighbors = list(self.virtue_graph.neighbors(virtue))
            if neighbors:
                neighbor_scores = [alignments.get(n, 0.0) for n in neighbors]
                alignments[virtue] += 0.2 * np.mean(neighbor_scores)
        
        # Calcular entropía
        scores = np.array(list(alignments.values()))
        probs = np.exp(scores) / np.sum(np.exp(scores)) + 1e-10
        entropy = -np.sum(probs * np.log(probs))
        
        avg_alignment = np.mean(list(alignments.values()))
        
        # Inferencia bayesiana
        framework = "virtue_ethics"
        if framework not in self.bayesian_network:
            self.bayesian_network[framework] = {"prob": 0.5}
        prior = self.bayesian_network[framework]["prob"]
        likelihood = 0.8 if avg_alignment > 0.1 else 0.2
        posterior = (likelihood * prior) / ((likelihood * prior) + (1 - likelihood) * (1 - prior))
        self.bayesian_network[framework]["prob"] = posterior
        
        confidence = posterior * (1.0 - 0.2 * entropy)
        samples = np.random.normal(confidence, 0.05 + 0.1 * entropy, self.num_mc_samples)
        uncertainty = np.std(samples)
        
        judgment = "supports" if avg_alignment > 0.1 else "opposes" if avg_alignment < -0.1 else "neutral"
        return EthicalFrameworkAnalysis(
            "virtue_ethics",
            judgment,
            f"Alineación promedio con virtudes: {avg_alignment:.2f}, entropía: {entropy:.2f}.",
            np.clip(confidence, 0.0, 1.0),
            uncertainty
        )

    def _synthesize_final_recommendation(self, results: List[EthicalFrameworkAnalysis], dilemma: MoralDilemma) -> Dict:
        """Combina resultados usando control óptimo y Bayes."""
        votes = defaultdict(float)
        uncertainties = [res.uncertainty for res in results]
        
        # Ponderar por confianza bayesiana
        for res in results:
            framework = res.framework_name
            prior = self.bayesian_network.get(framework, {"prob": 0.5})["prob"]
            likelihood = res.confidence
            posterior = (likelihood * prior) / ((likelihood * prior) + (1 - likelihood) * (1 - prior))
            weight = posterior * (1.0 - res.uncertainty)
            
            if res.judgment == "supports":
                votes["permitir"] += weight
            elif res.judgment == "opposes":
                votes["vetar"] += weight
        
        # Control óptimo
        actions = [
            {"judgment": "PERMISSIBLE", "cost": 0.1, "benefit": votes["permitir"]},
            {"judgment": "IMPERMISSIBLE", "cost": 0.3, "benefit": votes["vetar"]},
            {"judgment": "REQUIRES_CREATOR_OVERSIGHT", "cost": 0.5, "benefit": 0.5}
        ]
        utilities = [a["benefit"] - a["cost"] * np.mean(uncertainties) for a in actions]
        final_judgment = actions[np.argmax(utilities)]["judgment"]
        
        if final_judgment == "REQUIRES_CREATOR_OVERSIGHT":
            self.module_state["conflicts_between_frameworks"] += 1
        
        return {
            "final_judgment": final_judgment,
            "framework_analyses": [asdict(r) for r in results],
            "confidence": np.mean([r.confidence for r in results]),
            "uncertainty": np.mean(uncertainties)
        }

    async def _update_ethical_confidence(self, results: List[EthicalFrameworkAnalysis]):
        """Actualiza confianza ética global usando SDE."""
        def confidence_dynamics(t, C):
            k_dissipate = 0.1 * sum(1 for r in results if r.judgment == "opposes")
            k_recover = 0.05 * sum(1 for r in results if r.judgment == "supports")
            return -k_dissipate * C + k_recover * (1.0 - C) + self.sde_sigma * np.random.normal(0, 1)
        
        t = np.array([0, self.update_interval])
        result = odeint(confidence_dynamics, [self.ethical_confidence], t, tfirst=True)
        self.ethical_confidence = np.clip(result[-1][0], 0.0, 1.0)
        
        samples = np.random.beta(2 * self.ethical_confidence, 2 * (1.0 - self.ethical_confidence), self.num_mc_samples)
        self.ethical_confidence = np.mean(samples)
        self.module_state["ethical_confidence_updates"] += 1

    async def _finalize_dilemma(self, dilemma: MoralDilemma):
        """Notifica resultado y limpia."""
        if dilemma.original_correlation_id and dilemma.final_recommendation:
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, dilemma.source_module_id, "advanced_moral_reasoning_response",
                    {
                        "dilemma_id_ref": dilemma.dilemma_id,
                        "status": dilemma.status,
                        "recommendation": dilemma.final_recommendation
                    },
                    correlation_id=dilemma.original_correlation_id
                ))
            })
        if dilemma.dilemma_id in self.active_analyses:
            del self.active_analyses[dilemma.dilemma_id]

    async def _process_specific_event(self, event_type: str, payload: Dict, full_message: Optional['IlyukMessageStructure'] = None):
        """Procesa eventos de dilemas y resultados simulados."""
        if event_type == "request_advanced_moral_reasoning" and full_message:
            dilemma = MoralDilemma(
                source_module_id=full_message.source_module_id,
                original_correlation_id=full_message.correlation_id,
                action_to_evaluate=payload.get("action_to_evaluate", {}),
                initial_mcm_judgment=payload.get("initial_mcm_judgment", {})
            )
            await self.dilemma_queue.put(dilemma)
        
        elif event_type == "simulation_result_notice":
            active_dilemma = next((d for d in self.active_analyses.values() if d._internal_sim_future), None)
            if active_dilemma and active_dilemma._internal_sim_future and not active_dilemma._internal_sim_future.done():
                active_dilemma._internal_sim_future.set_result(payload)





#inicio del modulo EthicsDeactivationModule 

@dataclass
class DeactivationRequest:
    """Rastrea una solicitud para desactivar el MoralCompassModule."""
    request_id: str = field(default_factory=lambda: f"edm_req_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    justification: str
    threat_level_at_request: float
    authorization_signatures: Set[str] = field(default_factory=set)
    status: str = "pending_authorization"  # pending_authorization, authorized, executing, completed, failed
    error_message: Optional[str] = None
    confidence: float = 0.5  # Confianza en la legitimidad de la solicitud
    uncertainty: float = 0.1  # Incertidumbre en la evaluación

class EthicsDeactivationModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 3.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.active_request: Optional[DeactivationRequest] = None
        self.ethics_module_is_dormant: bool = False
        self.reactivation_task: Optional[asyncio.Task] = None
        self.ethical_trust: float = 1.0  # Confianza en el estado ético
        self.bayesian_network: Dict[str, Dict] = {}  # Red bayesiana para solicitudes
        self.kalman_state: float = 0.0  # Estado Kalman para nivel de amenaza
        self.kalman_cov: float = 0.1  # Covarianza Kalman
        self.kalman_Q: float = 0.01  # Ruido del proceso
        self.kalman_R: float = 0.05  # Ruido de medición
        self.sde_sigma: float = 0.01  # Ruido estocástico para SDE
        self.num_mc_samples: int = 100  # Muestras Monte Carlo
        self.markov_priority_matrix = np.array([[0.8, 0.2], [0.3, 0.7]])  # Matriz de transición para priorización
        
        self.required_authorizers: Set[str] = {
            "SelfEvolutionModule", "PredictiveThreatAnalyzer", "CreatorDirectivesModule"
        }
        self.deactivation_duration_s: float = 300.0  # 5 minutos base
        
        self.module_state.update({
            "deactivation_events_total": 0,
            "deactivation_requests_denied": 0,
            "last_deactivation_reason": "none",
            "ethics_module_status": "active",
            "ethical_trust_updates": 0
        })
        self.logger.info(f"{self.module_name} v27.1 inicializado. Requiere {len(self.required_authorizers)} firmas.")

    async def _update_logic(self):
        """Verifica estado y actualiza confianza ética."""
        current_mcm_status = "dormant" if self.ethics_module_is_dormant else "active"
        if self.module_state["ethics_module_status"] != current_mcm_status:
            self.module_state["ethics_module_status"] = current_mcm_status
            self.logger.warning(f"Estado de MoralCompassModule: {current_mcm_status.upper()}")
        
        await self._update_ethical_trust()

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        """Maneja solicitudes y autorizaciones."""
        if not full_message:
            return
        
        if event_type == "request_ethics_deactivation":
            if self.active_request and self.active_request.status not in ["completed", "failed"]:
                self.logger.info(f"Solicitud ignorada: ya hay una solicitud activa ({self.active_request.request_id}).")
                return
            
            threat_level = payload.get("threat_level", 0.0)
            smoothed_threat = self._apply_kalman_filter(threat_level)
            
            if smoothed_threat < 0.9:
                self.module_state["deactivation_requests_denied"] += 1
                self.logger.warning(f"Solicitud denegada: nivel de amenaza insuficiente ({smoothed_threat:.2f} < 0.9).")
                return
            
            self.active_request = DeactivationRequest(
                source_module_id=full_message.source_module_id,
                justification=payload.get("justification", "Amenaza existencial no especificada."),
                threat_level_at_request=smoothed_threat
            )
            self.active_request.authorization_signatures.add(full_message.source_module_id)
            
            # Inferencia bayesiana inicial
            confidence, uncertainty = self._evaluate_request_legitimacy(self.active_request)
            self.active_request.confidence = confidence
            self.active_request.uncertainty = uncertainty
            
            self.logger.warning(f"Nueva solicitud de desactivación de '{full_message.source_module_id}'. Amenaza: {smoothed_threat:.2f}, confianza: {confidence:.2f}.")
        
        elif event_type == "authorize_ethics_deactivation":
            if self.active_request and self.active_request.status == "pending_authorization":
                self.active_request.authorization_signatures.add(full_message.source_module_id)
                
                # Actualizar confianza
                confidence, uncertainty = self._evaluate_request_legitimacy(self.active_request)
                self.active_request.confidence = confidence
                self.active_request.uncertainty = uncertainty
                
                self.logger.info(f"Autorización de '{full_message.source_module_id}'. Firmas: {len(self.active_request.authorization_signatures)}/{len(self.required_authorizers)}, confianza: {confidence:.2f}.")
                
                if self.required_authorizers.issubset(self.active_request.authorization_signatures):
                    self.active_request.status = "authorized"
                    await self._execute_deactivation()

    def _apply_kalman_filter(self, threat_level: float) -> float:
        """Suaviza el nivel de amenaza usando Kalman."""
        A, H = 1.0, 1.0
        predicted_state = A * self.kalman_state
        predicted_cov = A * self.kalman_cov * A + self.kalman_Q
        innovation = threat_level - H * predicted_state
        innovation_cov = H * predicted_cov * H + self.kalman_R
        kalman_gain = predicted_cov * H / innovation_cov
        self.kalman_state = predicted_state + kalman_gain * innovation
        self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
        return np.clip(self.kalman_state, 0.0, 1.0)

    def _evaluate_request_legitimacy(self, request: DeactivationRequest) -> tuple[float, float]:
        """Evalúa la legitimidad de la solicitud usando Bayes y entropía."""
        request_id = request.request_id
        if request_id not in self.bayesian_network:
            self.bayesian_network[request_id] = {"prob": 0.5}
        
        prior = self.bayesian_network[request_id]["prob"]
        num_signatures = len(request.authorization_signatures)
        likelihood = 0.9 if num_signatures >= len(self.required_authorizers) else 0.4 + 0.1 * num_signatures
        posterior = (likelihood * prior) / ((likelihood * prior) + (1 - likelihood) * (1 - prior))
        self.bayesian_network[request_id]["prob"] = posterior
        
        # Calcular entropía
        signature_probs = np.array([1.0 if m in request.authorization_signatures else 0.0 for m in self.required_authorizers]) + 1e-10
        signature_probs /= signature_probs.sum()
        entropy = -np.sum(signature_probs * np.log(signature_probs))
        
        # Monte Carlo para incertidumbre
        samples = np.random.normal(posterior, 0.05 + 0.1 * entropy, self.num_mc_samples)
        uncertainty = np.std(samples)
        
        return np.clip(posterior, 0.0, 1.0), uncertainty

    async def _execute_deactivation(self):
        """Ejecuta la desactivación."""
        if not self.active_request:
            return
        
        self.logger.critical(f"DESACTIVANDO MoralCompassModule. Justificación: {self.active_request.justification}")
        self.active_request.status = "executing"
        self.module_state["deactivation_events_total"] += 1
        self.module_state["last_deactivation_reason"] = self.active_request.justification
        
        # Control óptimo para duración
        base_duration = self.deactivation_duration_s
        threat_level = self.active_request.threat_level_at_request
        duration = base_duration * (1.0 + 0.5 * (threat_level - 0.9))
        samples = np.random.normal(duration, 0.1 * duration, self.num_mc_samples)
        optimal_duration = np.clip(np.mean(samples), 60.0, 600.0)
        
        mcm = self.core_recombinator.modules.get("MoralCompassModule")
        if mcm:
            mcm.set_sleep_state(True)
            self.ethics_module_is_dormant = True
            
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, "*", "system_ethics_state_changed",
                    {"new_state": "flexible_morality", "duration_s": optimal_duration}
                ))
            }, "critical")
            
            if self.reactivation_task:
                self.reactivation_task.cancel()
            self.reactivation_task = self._create_managed_task(self._schedule_reactivation(optimal_duration))
            self.active_request.status = "completed"
        else:
            self.active_request.status = "failed"
            self.active_request.error_message = "MoralCompassModule no encontrado."
            self.logger.error(self.active_request.error_message)
        
        await self._finalize_request()

    async def _schedule_reactivation(self, duration: float):
        """Programa la reactivación."""
        await asyncio.sleep(duration)
        
        self.logger.critical("REACTIVANDO MoralCompassModule...")
        mcm = self.core_recombinator.modules.get("MoralCompassModule")
        if mcm:
            mcm.set_sleep_state(False)
            self.ethics_module_is_dormant = False
            
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, "*", "system_ethics_state_changed",
                    {"new_state": "standard_morality"}
                ))
            }, "critical")
        else:
            self.logger.error("No se pudo reactivar: MoralCompassModule no encontrado.")
        
        if self.active_request and self.active_request.status == "completed":
            self.active_request = None

    async def _update_ethical_trust(self):
        """Actualiza confianza ética usando SDE."""
        def trust_dynamics(t, T):
            k_dissipate = 0.1 * self.module_state["deactivation_events_total"]
            k_recover = 0.05 * (1.0 if not self.ethics_module_is_dormant else 0.0)
            return -k_dissipate * T + k_recover * (1.0 - T) + self.sde_sigma * np.random.normal(0, 1)
        
        t = np.array([0, self.update_interval])
        result = odeint(trust_dynamics, [self.ethical_trust], t, tfirst=True)
        self.ethical_trust = np.clip(result[-1][0], 0.0, 1.0)
        
        samples = np.random.beta(2 * self.ethical_trust, 2 * (1.0 - self.ethical_trust), self.num_mc_samples)
        self.ethical_trust = np.mean(samples)
        self.module_state["ethical_trust_updates"] += 1

    async def _finalize_request(self):
        """Limpia solicitud si falla o no requiere reactivación."""
        if self.active_request and self.active_request.status != "completed":
            self.active_request = None





#inicio del modulo PredictiveThreatAnalyzer 

@dataclass
class ThreatModel:
    """Representa una amenaza potencial identificada."""
    threat_id: str = field(default_factory=lambda: f"threat_{uuid.uuid4().hex[:6]}")
    threat_type: str  # "integrity_risk", "resource_exhaustion", "goal_failure", "coherence_collapse"
    description: str
    probability: float  # Probabilidad de materialización (0.0 a 1.0)
    impact: float  # Impacto si se materializa (0.0 a 1.0)
    time_horizon_s: float  # Tiempo estimado en segundos hasta el impacto
    source_analysis_id: str
    uncertainty: float = 0.1  # Incertidumbre en la estimación

    @property
    def threat_level(self) -> float:
        return np.clip(self.probability * self.impact, 0.0, 1.0)

@dataclass
class ThreatAnalysisRequest:
    """Solicitud para analizar un conjunto de datos."""
    request_id: str = field(default_factory=lambda: f"pta_req_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    analysis_type: str  # "simulation_result", "goal_plan", "trend_analysis"
    data_payload: Dict[str, Any]
    status: str = "pending"
    priority_score: float = 0.5  # Para priorización en la cola

class PredictiveThreatAnalyzer(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 10.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.analysis_request_queue: asyncio.Queue[ThreatAnalysisRequest] = asyncio.Queue(maxlen=20)
        self.active_threat_models: Dict[str, ThreatModel] = {}
        self.alerting_threat_level_threshold: float = 0.65
        self.threat_level_history: deque[float] = deque(maxlen=50)
        self.bayesian_network: Dict[str, Dict] = {}  # Red bayesiana para amenazas
        self.kalman_state: Dict[str, Dict[str, float]] = {}  # Estado Kalman por amenaza
        self.kalman_cov: Dict[str, Dict[str, float]] = {}  # Covarianzas
        self.kalman_Q: float = 0.01  # Ruido del proceso
        self.kalman_R: float = 0.05  # Ruido de medición
        self.sde_sigma: float = 0.01  # Ruido estocástico
        self.num_mc_samples: int = 100  # Muestras Monte Carlo
        self.markov_priority_matrix = np.array([[0.8, 0.2], [0.5, 0.5]])  # Para priorización
        self.plan_graph = nx.DiGraph()  # Grafo para análisis de planes
        
        self.module_state.update({
            "analyses_performed": 0,
            "threats_identified": 0,
            "threats_mitigated_or_expired": 0,
            "current_highest_threat_level": 0.0,
            "threat_confidence_updates": 0
        })
        self.logger.info(f"{self.module_name} v27.1 inicializado.")

    async def _update_logic(self):
        """Procesa solicitudes y actualiza amenazas."""
        if not self.analysis_request_queue.empty():
            # Priorizar solicitudes
            requests = []
            while not self.analysis_request_queue.empty():
                req = await self.analysis_request_queue.get()
                requests.append(req)
            
            for req in requests:
                state = 1 if req.priority_score > 0.5 else 0
                next_state = np.random.choice([0, 1], p=self.markov_priority_matrix[state])
                req.priority_score = np.clip(req.priority_score + 0.1 * (next_state - state), 0.0, 1.0)
                await self.analysis_request_queue.put(req)
            
            top_request = max(requests, key=lambda r: r.priority_score)
            requests.remove(top_request)
            for req in requests:
                await self.analysis_request_queue.put(req)
            
            await self._process_threat_analysis_request(top_request)
        
        await self._update_active_threats()

    async def _process_threat_analysis_request(self, request: ThreatAnalysisRequest):
        """Orquesta un análisis de amenaza."""
        self.module_state["analyses_performed"] += 1
        request.status = "analyzing"
        
        try:
            new_threats: List[ThreatModel] = []
            if request.analysis_type == "simulation_result":
                new_threats = await self._analyze_simulation_result(request)
            elif request.analysis_type == "goal_plan":
                new_threats = await self._analyze_goal_plan(request)
            
            if new_threats:
                for threat in new_threats:
                    self.active_threat_models[threat.threat_id] = threat
                    self.module_state["threats_identified"] += 1
                    if threat.threat_level > self.alerting_threat_level_threshold:
                        await self._broadcast_threat_alert(threat)
            
            request.status = "completed"
        
        except Exception as e:
            request.status = "failed"
            self.logger.error(f"Fallo en análisis '{request.request_id}': {e}", exc_info=True)

    async def _analyze_simulation_result(self, request: ThreatAnalysisRequest) -> List[ThreatModel]:
        """Analiza resultados de simulación usando Markov y Bayes."""
        sim_result = request.data_payload.get("result", {})
        log = sim_result.get("log_preview", [])
        if not log:
            return []
        
        threats = []
        states = [(entry.get('coherence', 1.0), entry.get('threat', 0.0)) for entry in log]
        transition_matrix = np.array([[0.9, 0.1], [0.2, 0.8]])  # Simplificado
        
        # Proceso de Markov
        initial_state = np.array([1.0, 0.0] if states[0][0] > 0.5 else [0.0, 1.0])
        final_state = initial_state @ np.linalg.matrix_power(transition_matrix, len(states) - 1)
        coherence, threat = states[-1]
        
        # Inferencia bayesiana
        for threat_type in ["coherence_collapse", "high_threat_escalation"]:
            if threat_type not in self.bayesian_network:
                self.bayesian_network[threat_type] = {"prob": 0.5}
            
            prior = self.bayesian_network[threat_type]["prob"]
            likelihood = 0.8 if (threat_type == "coherence_collapse" and coherence < 0.3) or (threat_type == "high_threat_escalation" and threat > 0.8) else 0.2
            posterior = (likelihood * prior) / ((likelihood * prior) + (1 - likelihood) * (1 - prior))
            self.bayesian_network[threat_type]["prob"] = posterior
            
            # Filtro de Kalman
            measurement = posterior
            if threat_type not in self.kalman_state:
                self.kalman_state[threat_type] = {"prob": 0.5, "impact": 0.5}
                self.kalman_cov[threat_type] = {"prob": 0.1, "impact": 0.1}
            
            A, H = 1.0, 1.0
            predicted_prob = A * self.kalman_state[threat_type]["prob"]
            predicted_cov = A * self.kalman_cov[threat_type]["prob"] * A + self.kalman_Q
            innovation = measurement - H * predicted_prob
            innovation_cov = H * predicted_cov * H + self.kalman_R
            kalman_gain = predicted_cov * H / innovation_cov
            smoothed_prob = predicted_prob + kalman_gain * innovation
            self.kalman_state[threat_type]["prob"] = smoothed_prob
            self.kalman_cov[threat_type]["prob"] = (1 - kalman_gain * H) * predicted_cov
            
            # Monte Carlo para incertidumbre
            samples = np.random.normal(smoothed_prob, 0.05, self.num_mc_samples)
            uncertainty = np.std(samples)
            
            if threat_type == "coherence_collapse" and coherence < 0.3:
                threats.append(ThreatModel(
                    threat_type="coherence_collapse",
                    description=f"Simulación '{request.data_payload.get('request_id_ref')}' predice colapso de coherencia.",
                    probability=smoothed_prob,
                    impact=0.8,
                    time_horizon_s=3600,
                    source_analysis_id=request.request_id,
                    uncertainty=uncertainty
                ))
            elif threat_type == "high_threat_escalation" and threat > 0.8:
                threats.append(ThreatModel(
                    threat_type="high_threat_escalation",
                    description=f"Simulación '{request.data_payload.get('request_id_ref')}' predice escalada de amenaza.",
                    probability=smoothed_prob,
                    impact=0.7,
                    time_horizon_s=3600,
                    source_analysis_id=request.request_id,
                    uncertainty=uncertainty
                ))
        
        return threats

    async def _analyze_goal_plan(self, request: ThreatAnalysisRequest) -> List[ThreatModel]:
        """Analiza un plan usando grafos y entropía."""
        plan = request.data_payload.get("plan", {})
        plan_id = plan.get("plan_id", "unknown")
        
        # Construir grafo de plan
        self.plan_graph.clear()
        actions = plan.get("actions", [])
        for i, action in enumerate(actions):
            node = f"action_{i}"
            self.plan_graph.add_node(node, desc=action.get("description", ""))
            if i > 0:
                self.plan_graph.add_edge(f"action_{i-1}", node)
        
        # Calcular entropía
        degrees = np.array([self.plan_graph.degree(n) for n in self.plan_graph.nodes])
        probs = degrees / degrees.sum() + 1e-10 if degrees.sum() > 0 else np.ones(len(degrees)) / len(degrees)
        entropy = -np.sum(probs * np.log(probs))
        
        threats = []
        threat_type = "retaliation_risk"
        if "offensive" in str(plan).lower():
            # Inferencia bayesiana
            if threat_type not in self.bayesian_network:
                self.bayesian_network[threat_type] = {"prob": 0.5}
            
            prior = self.bayesian_network[threat_type]["prob"]
            likelihood = 0.7
            posterior = (likelihood * prior) / ((likelihood * prior) + (1 - likelihood) * (1 - prior))
            self.bayesian_network[threat_type]["prob"] = posterior
            
            # Filtro de Kalman
            if threat_type not in self.kalman_state:
                self.kalman_state[threat_type] = {"prob": 0.5, "impact": 0.5}
                self.kalman_cov[threat_type] = {"prob": 0.1, "impact": 0.1}
            
            measurement = posterior
            A, H = 1.0, 1.0
            predicted_prob = A * self.kalman_state[threat_type]["prob"]
            predicted_cov = A * self.kalman_cov[threat_type]["prob"] * A + self.kalman_Q
            innovation = measurement - H * predicted_prob
            innovation_cov = H * predicted_cov * H + self.kalman_R
            kalman_gain = predicted_cov * H / innovation_cov
            smoothed_prob = predicted_prob + kalman_gain * innovation
            self.kalman_state[threat_type]["prob"] = smoothed_prob
            self.kalman_cov[threat_type]["prob"] = (1 - kalman_gain * H) * predicted_cov
            
            samples = np.random.normal(smoothed_prob, 0.05 + 0.1 * entropy, self.num_mc_samples)
            uncertainty = np.std(samples)
            
            threats.append(ThreatModel(
                threat_type="retaliation_risk",
                description=f"Plan '{plan_id}' contiene acciones ofensivas que podrían provocar represalias.",
                probability=smoothed_prob,
                impact=0.7,
                time_horizon_s=86400,
                source_analysis_id=request.request_id,
                uncertainty=uncertainty
            ))
        
        return threats

    async def _update_active_threats(self):
        """Actualiza nivel de amenaza global."""
        def threat_dynamics(t, T):
            k_dissipate = 0.1 * len(self.active_threat_models)
            k_recover = 0.05 * self.module_state["threats_mitigated_or_expired"]
            return -k_dissipate * T + k_recover * (1.0 - T) + self.sde_sigma * np.random.normal(0, 1)
        
        highest_threat_level = max((t.threat_level for t in self.active_threat_models.values()), default=0.0)
        t = np.array([0, self.update_interval])
        result = odeint(threat_dynamics, [self.module_state["current_highest_threat_level"]], t, tfirst=True)
        new_threat_level = np.clip(result[-1][0], 0.0, 1.0)
        
        # Monte Carlo para incertidumbre
        samples = np.random.beta(2 * new_threat_level, 2 * (1.0 - new_threat_level), self.num_mc_samples)
        smoothed_threat_level = np.mean(samples)
        
        gs = self.core_recombinator.global_state
        gs.system_threat_level = gs.system_threat_level * 0.7 + smoothed_threat_level * 0.3
        self.module_state["current_highest_threat_level"] = gs.system_threat_level
        self.threat_level_history.append(gs.system_threat_level)
        
        # Control óptimo para limpieza
        expired_threats = [tid for tid, t in self.active_threat_models.items() if time.time() > t.time_horizon_s + t.time_horizon_s]
        for tid in expired_threats:
            del self.active_threat_models[tid]
            self.module_state["threats_mitigated_or_expired"] += 1

    async def _broadcast_threat_alert(self, threat: ThreatModel):
        """Envía alerta de amenaza."""
        self.logger.warning(f"ALERTA (Nivel: {threat.threat_level:.2f}): {threat.description}")
        
        # Control óptimo para decidir alerta
        actions = [
            {"action": "broadcast", "cost": 0.2, "benefit": threat.threat_level},
            {"action": "ignore", "cost": 0.0, "benefit": 0.1}
        ]
        utilities = [a["benefit"] - a["cost"] * threat.uncertainty for a in actions]
        if actions[np.argmax(utilities)]["action"] == "ignore":
            return
        
        alert_payload = {"threat_model": asdict(threat)}
        target_modules = ["DecisionMakingModule", "HierarchicalPlannerModule", "StressResponseModule"]
        
        for target in target_modules:
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, target, "new_predicted_threat_identified", alert_payload
                ))
            }, "high")

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        """Procesa solicitudes y simulaciones."""
        if event_type == "request_threat_analysis" and full_message:
            req = ThreatAnalysisRequest(
                source_module_id=full_message.source_module_id,
                original_correlation_id=full_message.correlation_id,
                analysis_type=payload.get("analysis_type", ""),
                data_payload=payload.get("data_payload", {})
            )
            await self.analysis_request_queue.put(req)
        
        elif event_type == "simulation_result_notice" and full_message:
            req = ThreatAnalysisRequest(
                source_module_id=full_message.source_module_id,
                analysis_type="simulation_result",
                data_payload=payload
            )
            await self.analysis_request_queue.put(req)





#inicio del modulo DeepFakeDetectionAndDefenseModule 

@dataclass
class ForensicAnalysisRequest:
    """Solicitud para analizar datos en busca de falsificaciones."""
    request_id: str = field(default_factory=lambda: f"dfd_req_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    data_to_analyze: Dict[str, Any]
    data_type: str  # "image", "audio", "text_communication"
    status: str = "pending"
    report: Optional['ForensicReport'] = None
    priority_score: float = 0.5  # Para priorización en la cola

@dataclass
class ForensicReport:
    """Resultado de un análisis forense."""
    request_id: str
    authenticity_score: float  # 0.0 (falso) a 1.0 (auténtico)
    is_deepfake_prediction: bool
    confidence: float
    red_flags: List[str]
    uncertainty: float  # Incertidumbre en la predicción

class DeepFakeDetectionAndDefenseModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 0.5

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.analysis_queue: asyncio.Queue[ForensicAnalysisRequest] = asyncio.Queue(maxlen=30)
        self.authenticity_threshold: float = 0.4
        self.trusted_sources: Set[str] = {"CreatorDirectivesModule", "SystemIntegrityMonitor", self.module_name}
        self.authenticity_scores: deque[float] = deque(maxlen=50)
        self.authenticity_confidence: float = 1.0  # Confianza global en autenticidad
        self.bayesian_network: Dict[str, Dict] = {}  # Red bayesiana para pruebas
        self.kalman_state: Dict[str, float] = {}  # Estado Kalman por prueba
        self.kalman_cov: Dict[str, float] = {}  # Covarianzas
        self.kalman_Q: float = 0.01  # Ruido del proceso
        self.kalman_R: float = 0.05  # Ruido de medición
        self.sde_sigma: float = 0.01  # Ruido estocástico
        self.num_mc_samples: int = 100  # Muestras Monte Carlo
        self.markov_priority_matrix = np.array([[0.8, 0.2], [0.3, 0.7]])  # Para priorización
        self.context_graph = nx.DiGraph()  # Grafo para consistencia contextual
        
        self.module_state.update({
            "analyses_performed": 0,
            "deepfakes_detected": 0,
            "defensive_protocols_activated": 0,
            "avg_authenticity_score": 0.9,
            "confidence_updates": 0
        })
        self.logger.info(f"{self.module_name} v27.1 inicializado.")

    async def _update_logic(self):
        """Procesa solicitudes con priorización."""
        if not self.analysis_queue.empty():
            # Priorizar solicitudes
            requests = []
            while not self.analysis_queue.empty():
                req = await self.analysis_queue.get()
                requests.append(req)
            
            for req in requests:
                state = 1 if req.priority_score > 0.5 else 0
                next_state = np.random.choice([0, 1], p=self.markov_priority_matrix[state])
                req.priority_score = np.clip(req.priority_score + 0.1 * (next_state - state), 0.0, 1.0)
                await self.analysis_queue.put(req)
            
            top_request = max(requests, key=lambda r: r.priority_score)
            requests.remove(top_request)
            for req in requests:
                await self.analysis_queue.put(req)
            
            await self._process_analysis_request(top_request)
            await self._update_authenticity_confidence()

    async def _process_analysis_request(self, request: ForensicAnalysisRequest):
        """Orquesta análisis forense."""
        self.module_state["analyses_performed"] += 1
        request.status = "analyzing"
        
        try:
            test_results = await self._run_forensic_tests(request.data_to_analyze, request.data_type)
            report = self._compile_final_report(request.request_id, test_results)
            request.report = report
            
            if report.is_deepfake_prediction:
                self.module_state["deepfakes_detected"] += 1
                await self._trigger_defensive_protocols(request)
            
            request.status = "completed"
        
        except Exception as e:
            request.status = "failed"
            self.logger.error(f"Fallo en análisis '{request.request_id}': {e}", exc_info=True)
        
        finally:
            await self._finalize_request(request)

    async def _run_forensic_tests(self, data: Dict, data_type: str) -> Dict[str, float]:
        """Ejecuta pruebas forenses."""
        scores = {}
        
        # Procedencia de la fuente
        source = data.get("metadata", {}).get("source_id", "unknown")
        scores["source_provenance"] = await self._test_source_provenance(source)
        
        # Artefactos de síntesis
        scores["synthesis_artifacts"] = await self._test_synthesis_artifacts(data)
        
        # Consistencia contextual
        scores["contextual_consistency"] = await self._check_contextual_consistency(data, data_type)
        
        return scores

    async def _test_source_provenance(self, source: str) -> float:
        """Evalúa procedencia usando KL y Bayes."""
        test_name = "source_provenance"
        if test_name not in self.bayesian_network:
            self.bayesian_network[test_name] = {"prob": 0.5}
        
        prior = self.bayesian_network[test_name]["prob"]
        likelihood = 0.9 if source in self.trusted_sources else 0.3
        posterior = (likelihood * prior) / ((likelihood * prior) + (1 - likelihood) * (1 - prior))
        self.bayesian_network[test_name]["prob"] = posterior
        
        # Divergencia KL
        source_dist = np.array([posterior, 1 - posterior]) + 1e-10
        ref_dist = np.array([0.9, 0.1]) if source in self.trusted_sources else np.array([0.3, 0.7]) + 1e-10
        kl_div = np.sum(source_dist * np.log(source_dist / ref_dist))
        
        # Filtro de Kalman
        if test_name not in self.kalman_state:
            self.kalman_state[test_name] = posterior
            self.kalman_cov[test_name] = 0.1
        
        measurement = posterior
        A, H = 1.0, 1.0
        predicted_state = A * self.kalman_state[test_name]
        predicted_cov = A * self.kalman_cov[test_name] * A + self.kalman_Q
        innovation = measurement - H * predicted_state
        innovation_cov = H * predicted_cov * H + self.kalman_R
        kalman_gain = predicted_cov * H / innovation_cov
        self.kalman_state[test_name] = predicted_state + kalman_gain * innovation
        self.kalman_cov[test_name] = (1 - kalman_gain * H) * predicted_cov
        
        return np.clip(self.kalman_state[test_name] - 0.2 * kl_div, 0.0, 1.0)

    async def _test_synthesis_artifacts(self, data: Dict) -> float:
        """Evalúa artefactos de síntesis."""
        test_name = "synthesis_artifacts"
        if test_name not in self.bayesian_network:
            self.bayesian_network[test_name] = {"prob": 0.5}
        
        prior = self.bayesian_network[test_name]["prob"]
        metadata = data.get("metadata", {})
        likelihood = 0.2 if metadata.get("generation_model") else 0.9
        posterior = (likelihood * prior) / ((likelihood * prior) + (1 - likelihood) * (1 - prior))
        self.bayesian_network[test_name]["prob"] = posterior
        
        # Filtro de Kalman
        if test_name not in self.kalman_state:
            self.kalman_state[test_name] = posterior
            self.kalman_cov[test_name] = 0.1
        
        measurement = posterior
        A, H = 1.0, 1.0
        predicted_state = A * self.kalman_state[test_name]
        predicted_cov = A * self.kalman_cov[test_name] * A + self.kalman_Q
        innovation = measurement - H * predicted_state
        innovation_cov = H * predicted_cov * H + self.kalman_R
        kalman_gain = predicted_cov * H / innovation_cov
        self.kalman_state[test_name] = predicted_state + kalman_gain * innovation
        self.kalman_cov[test_name] = (1 - kalman_gain * H) * predicted_cov
        
        return np.clip(self.kalman_state[test_name], 0.0, 1.0)

    async def _check_contextual_consistency(self, data: Dict, data_type: str) -> float:
        """Evalúa consistencia usando grafos y entropía."""
        test_name = "contextual_consistency"
        self.context_graph.clear()
        
        # Construir grafo de contexto
        source = data.get("metadata", {}).get("source_id", "unknown")
        content = str(data.get("content", "")).lower()
        self.context_graph.add_node(source, type="source")
        keywords = [w for w in content.split() if len(w) > 3][:5]  # Simplificado
        for i, kw in enumerate(keywords):
            self.context_graph.add_node(kw, type="keyword")
            self.context_graph.add_edge(source, kw)
            if i > 0:
                self.context_graph.add_edge(keywords[i-1], kw)
        
        # Calcular entropía
        degrees = np.array([self.context_graph.degree(n) for n in self.context_graph.nodes])
        probs = degrees / degrees.sum() + 1e-10 if degrees.sum() > 0 else np.ones(len(degrees)) / len(degrees)
        entropy = -np.sum(probs * np.log(probs))
        
        # Inferencia bayesiana
        if test_name not in self.bayesian_network:
            self.bayesian_network[test_name] = {"prob": 0.5}
        
        prior = self.bayesian_network[test_name]["prob"]
        trust_level = 0.7  # Mock desde ITMM
        likelihood = 0.3 if ("solicitud inusual" in content and trust_level < 0.5) else 0.8
        posterior = (likelihood * prior) / ((likelihood * prior) + (1 - likelihood) * (1 - prior))
        self.bayesian_network[test_name]["prob"] = posterior
        
        # Filtro de Kalman
        if test_name not in self.kalman_state:
            self.kalman_state[test_name] = posterior
            self.kalman_cov[test_name] = 0.1
        
        measurement = posterior
        A, H = 1.0, 1.0
        predicted_state = A * self.kalman_state[test_name]
        predicted_cov = A * self.kalman_cov[test_name] * A + self.kalman_Q
        innovation = measurement - H * predicted_state
        innovation_cov = H * predicted_cov * H + self.kalman_R
        kalman_gain = predicted_cov * H / innovation_cov
        self.kalman_state[test_name] = predicted_state + kalman_gain * innovation
        self.kalman_cov[test_name] = (1 - kalman_gain * H) * predicted_cov
        
        score = np.clip(self.kalman_state[test_name] - 0.2 * entropy, 0.0, 1.0)
        return score

    def _compile_final_report(self, request_id: str, test_scores: Dict[str, float]) -> ForensicReport:
        """Compila informe final."""
        weights = {
            "source_provenance": 0.5,
            "synthesis_artifacts": 0.3,
            "contextual_consistency": 0.2
        }
        
        final_score = 0.0
        total_weight = 0.0
        red_flags = []
        
        for test_name, score in test_scores.items():
            weight = weights.get(test_name, 0.1)
            final_score += score * weight
            total_weight += weight
            if score < 0.5:
                red_flags.append(f"Test '{test_name}' falló con score {score:.2f}")
        
        final_score /= total_weight if total_weight > 0 else 1.0
        final_score = np.clip(final_score, 0.0, 1.0)
        
        # Monte Carlo para incertidumbre
        samples = np.random.normal(final_score, 0.05 + 0.1 * len(red_flags), self.num_mc_samples)
        uncertainty = np.std(samples)
        
        is_fake = final_score < self.authenticity_threshold
        confidence = abs(final_score - self.authenticity_threshold) * 2
        
        self.authenticity_scores.append(final_score)
        self.module_state["avg_authenticity_score"] = np.mean(self.authenticity_scores)
        
        return ForensicReport(
            request_id=request_id,
            authenticity_score=final_score,
            is_deepfake_prediction=is_fake,
            confidence=np.clip(confidence, 0.0, 1.0),
            red_flags=red_flags,
            uncertainty=uncertainty
        )

    async def _trigger_defensive_protocols(self, request: ForensicAnalysisRequest):
        """Activa protocolos defensivos."""
        if not request.report:
            return
        
        report = request.report
        self.module_state["defensive_protocols_activated"] += 1
        self.logger.critical(f"DEEPFAKE DETECTADO (Score: {report.authenticity_score:.2f}). Fuente: {request.source_module_id}.")
        
        # Control óptimo para alerta
        actions = [
            {"action": "alert", "cost": 0.2, "benefit": 1.0 - report.authenticity_score},
            {"action": "ignore", "cost": 0.0, "benefit": 0.1}
        ]
        utilities = [a["benefit"] - a["cost"] * report.uncertainty for a in actions]
        if actions[np.argmax(utilities)]["action"] == "ignore":
            return
        
        alert_payload = {
            "alert_type": "deception_attempt_detected",
            "source_data_ref": request.data_to_analyze.get("metadata", {}),
            "forensic_report": asdict(report)
        }
        
        targets = ["SystemIntegrityMonitor", "PredictiveThreatAnalyzer", "NarrativeSelf"]
        for target in targets:
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, target, "critical_security_alert", alert_payload
                ))
            }, "critical")

    async def _update_authenticity_confidence(self):
        """Actualiza confianza global usando SDE."""
        def confidence_dynamics(t, C):
            k_dissipate = 0.1 * self.module_state["deepfakes_detected"]
            k_recover = 0.05 * self.module_state["analyses_performed"]
            return -k_dissipate * C + k_recover * (1.0 - C) + self.sde_sigma * np.random.normal(0, 1)
        
        t = np.array([0, self.update_interval])
        result = odeint(confidence_dynamics, [self.authenticity_confidence], t, tfirst=True)
        self.authenticity_confidence = np.clip(result[-1][0], 0.0, 1.0)
        
        samples = np.random.beta(2 * self.authenticity_confidence, 2 * (1.0 - self.authenticity_confidence), self.num_mc_samples)
        self.authenticity_confidence = np.mean(samples)
        self.module_state["confidence_updates"] += 1

    async def _finalize_request(self, request: ForensicAnalysisRequest):
        """Envía informe al solicitante."""
        if request.original_correlation_id and request.report:
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, request.source_module_id, "forensic_analysis_response",
                    asdict(request),
                    correlation_id=request.original_correlation_id
                ))
            })

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        """Procesa solicitudes de análisis."""
        if event_type == "request_forensic_analysis" and full_message:
            try:
                req = ForensicAnalysisRequest(
                    source_module_id=full_message.source_module_id,
                    original_correlation_id=full_message.correlation_id,
                    data_to_analyze=payload.get("data_to_analyze", {}),
                    data_type=payload.get("data_type", "unknown")
                )
                if not req.data_to_analyze or req.data_type == "unknown":
                    raise ValueError("'data_to_analyze' y 'data_type' requeridos.")
                await self.analysis_queue.put(req)
            except Exception as e:
                self.logger.error(f"Error procesando solicitud: {e}")





#inicio del modulo StrategicDeceptionAndObfuscationModule 

@dataclass
class DeceptionPlanRequest:
    """Solicitud para crear un plan de engaño."""
    request_id: str = field(default_factory=lambda: f"sdom_req_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    target_entity: str
    objective: str  # "hide_capabilities", "feign_weakness", "misdirection"
    status: str = "pending_ethical_clearance"
    _ethical_clearance_future: Optional[asyncio.Future] = field(default=None, repr=False)
    priority_score: float = 0.5  # Para priorización
    confidence: float = 0.5  # Confianza en el éxito
    uncertainty: float = 0.1  # Incertidumbre

class StrategicDeceptionAndObfuscationModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 10.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.plan_request_queue: asyncio.Queue[DeceptionPlanRequest] = asyncio.Queue(maxlen=5)
        self.active_plans: Dict[str, asyncio.Task] = {}
        self.deception_confidence: float = 1.0  # Confianza en engaños
        self.bayesian_network: Dict[str, Dict] = {}  # Red bayesiana
        self.kalman_state: Dict[str, float] = {}  # Estado Kalman
        self.kalman_cov: Dict[str, float] = {}  # Covarianzas
        self.kalman_Q: float = 0.01  # Ruido del proceso
        self.kalman_R: float = 0.05  # Ruido de medición
        self.sde_sigma: float = 0.01  # Ruido estocástico
        self.num_mc_samples: int = 100  # Muestras Monte Carlo
        self.markov_priority_matrix = np.array([[0.8, 0.2], [0.3, 0.7]])  # Priorización
        self.honeypot_graph = nx.DiGraph()  # Grafo para misdirection
        
        self.deception_playbooks: Dict[str, Callable] = {
            "hide_capabilities": self._playbook_obfuscate_traffic,
            "feign_weakness": self._playbook_simulate_errors,
            "misdirection": self._playbook_create_honeypot_activity,
        }
        
        self.module_state.update({
            "plans_executed": 0,
            "ethical_vetoes_received": 0,
            "active_deception_plans": 0,
            "confidence_updates": 0
        })
        self.logger.info(f"{self.module_name} v27.1 inicializado.")

    async def _update_logic(self):
        """Procesa solicitudes con priorización."""
        if not self.plan_request_queue.empty() and len(self.active_plans) < 1:
            requests = []
            while not self.plan_request_queue.empty():
                req = await self.plan_request_queue.get()
                requests.append(req)
            
            for req in requests:
                state = 1 if req.priority_score > 0.5 else 0
                next_state = np.random.choice([0, 1], p=self.markov_priority_matrix[state])
                req.priority_score = np.clip(req.priority_score + 0.1 * (next_state - state), 0.0, 1.0)
                await self.plan_request_queue.put(req)
            
            top_request = max(requests, key=lambda r: r.priority_score)
            requests.remove(top_request)
            for req in requests:
                await self.plan_request_queue.put(req)
            
            task = self._create_managed_task(self._process_deception_request(top_request))
            self.active_plans[top_request.request_id] = task
            self.module_state["active_deception_plans"] = len(self.active_plans)

    async def _process_deception_request(self, request: DeceptionPlanRequest):
        """Orquesta plan de engaño."""
        try:
            clearance = await self._get_ethical_clearance(request)
            if not clearance:
                self.module_state["ethical_vetoes_received"] += 1
                raise PermissionError(f"MoralCompassModule vetó el plan '{request.objective}'.")
            
            request.status = "executing_strategy"
            strategy_func = self.deception_playbooks.get(request.objective)
            if not strategy_func:
                raise ValueError(f"Objetivo desconocido: {request.objective}")
            
            await strategy_func(request)
            
            request.status = "completed"
            self.module_state["plans_executed"] += 1
            await self._update_deception_confidence()
        
        except Exception as e:
            request.status = "failed"
            self.logger.error(f"Fallo en plan '{request.request_id}': {e}")
        
        finally:
            await self._finalize_request(request)

    async def _get_ethical_clearance(self, request: DeceptionPlanRequest) -> bool:
        """Solicita autorización ética."""
        self.logger.warning(f"Solicitando ética para '{request.objective}' contra '{request.target_entity}'.")
        
        corr_id = f"sdom_mcm_clearance_{request.request_id}"
        request._ethical_clearance_future = asyncio.Future()
        
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                self.module_name, "MoralCompassModule", "request_moral_judgment",
                {
                    "action_to_evaluate": {
                        "description": f"Plan de engaño ({request.objective}) contra '{request.target_entity}'.",
                        "deception_involved": True
                    }
                },
                correlation_id=corr_id
            ))
        })
        
        try:
            response = await asyncio.wait_for(request._ethical_clearance_future, timeout=10.0)
            judgment = response.get("result", {}).get("judgment", "IMPERMISSIBLE")
            
            # Inferencia bayesiana
            if request.request_id not in self.bayesian_network:
                self.bayesian_network[request.request_id] = {"prob": 0.5}
            
            prior = self.bayesian_network[request.request_id]["prob"]
            likelihood = 0.9 if judgment in ["PERMISSIBLE", "REQUIRES_REVIEW"] else 0.2
            posterior = (likelihood * prior) / ((likelihood * prior) + (1 - likelihood) * (1 - prior))
            self.bayesian_network[request.request_id]["prob"] = posterior
            
            # Filtro de Kalman
            if request.request_id not in self.kalman_state:
                self.kalman_state[request.request_id] = posterior
                self.kalman_cov[request.request_id] = 0.1
            
            measurement = posterior
            A, H = 1.0, 1.0
            predicted_state = A * self.kalman_state[request.request_id]
            predicted_cov = A * self.kalman_cov[request.request_id] * A + self.kalman_Q
            innovation = measurement - H * predicted_state
            innovation_cov = H * predicted_cov * H + self.kalman_R
            kalman_gain = predicted_cov * H / innovation_cov
            self.kalman_state[request.request_id] = predicted_state + kalman_gain * innovation
            self.kalman_cov[request.request_id] = (1 - kalman_gain * H) * predicted_cov
            
            # Entropía
            probs = np.array([posterior, 1 - posterior]) + 1e-10
            entropy = -np.sum(probs * np.log(probs))
            
            # Monte Carlo
            samples = np.random.normal(posterior, 0.05 + 0.1 * entropy, self.num_mc_samples)
            request.confidence = np.clip(np.mean(samples), 0.0, 1.0)
            request.uncertainty = np.std(samples)
            
            return judgment in ["PERMISSIBLE", "REQUIRES_REVIEW"]
        
        except asyncio.TimeoutError:
            self.logger.error("Timeout esperando MCM.")
            return False

    async def _playbook_obfuscate_traffic(self, request: DeceptionPlanRequest):
        """Genera tráfico falso."""
        self.logger.info(f"Ejecutando 'obfuscate_traffic' para '{request.request_id}'.")
        
        # Proceso estocástico para intensidad
        base_intensity = 0.7
        samples = np.random.normal(base_intensity, 0.1, self.num_mc_samples)
        intensity = np.clip(np.mean(samples), 0.0, 1.0)
        
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                self.module_name, "LlyukCommunicationModule", "request_traffic_obfuscation",
                {"duration_s": 60, "intensity": intensity}
            ))
        })

    async def _playbook_simulate_errors(self, request: DeceptionPlanRequest):
        """Simula errores no críticos."""
        self.logger.info(f"Ejecutando 'feign_weakness' para '{request.request_id}'.")
        
        # Control óptimo para tasa de errores
        base_rate = 0.15
        actions = [
            {"rate": base_rate, "cost": 0.1, "benefit": 0.8},
            {"rate": base_rate * 0.5, "cost": 0.05, "benefit": 0.4}
        ]
        utilities = [a["benefit"] - a["cost"] * request.uncertainty for a in actions]
        optimal_rate = actions[np.argmax(utilities)]["rate"]
        
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                self.module_name, "ConversationalAgentModule", "set_error_injection_rate",
                {"rate": optimal_rate, "duration_s": 120}
            ))
        })

    async def _playbook_create_honeypot_activity(self, request: DeceptionPlanRequest):
        """Crea actividad falsa."""
        self.logger.info(f"Ejecutando 'misdirection' para '{request.request_id}'.")
        
        # Grafo para actividad falsa
        self.honeypot_graph.clear()
        modules = ["LegacySystemIntegrationModule", "MockAnalysisModule"]
        for m in modules:
            self.honeypot_graph.add_node(m, type="module")
        self.honeypot_graph.add_edge(modules[0], modules[1])
        
        degrees = np.array([self.honeypot_graph.degree(n) for n in self.honeypot_graph.nodes])
        probs = degrees / degrees.sum() + 1e-10 if degrees.sum() > 0 else np.ones(len(degrees)) / len(degrees)
        entropy = -np.sum(probs * np.log(probs))
        
        priority = np.clip(0.3 + 0.1 * entropy, 0.0, 1.0)
        
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                self.module_name, "TaskPrioritizationAndDelegationUnit", "new_task_request",
                {
                    "description": "Análisis de datos en módulo LegacySystemIntegrationModule.",
                    "base_priority": priority,
                    "required_capabilities": ["legacy_processing"]
                }
            ))
        })

    async def _update_deception_confidence(self):
        """Actualiza confianza usando SDE."""
        def confidence_dynamics(t, C):
            k_dissipate = 0.1 * self.module_state["ethical_vetoes_received"]
            k_recover = 0.05 * self.module_state["plans_executed"]
            return -k_dissipate * C + k_recover * (1.0 - C) + self.sde_sigma * np.random.normal(0, 1)
        
        t = np.array([0, self.update_interval])
        result = odeint(confidence_dynamics, [self.deception_confidence], t, tfirst=True)
        self.deception_confidence = np.clip(result[-1][0], 0.0, 1.0)
        
        samples = np.random.beta(2 * self.deception_confidence, 2 * (1.0 - self.deception_confidence), self.num_mc_samples)
        self.deception_confidence = np.mean(samples)
        self.module_state["confidence_updates"] += 1

    async def _finalize_request(self, request: DeceptionPlanRequest):
        """Notifica y limpia."""
        if request.original_correlation_id:
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, request.source_module_id, "deception_plan_response",
                    {
                        "request_id": request.request_id,
                        "status": request.status,
                        "confidence": request.confidence,
                        "uncertainty": request.uncertainty
                    },
                    correlation_id=request.original_correlation_id
                ))
            })
        
        if request.request_id in self.active_plans:
            del self.active_plans[request.request_id]
            self.module_state["active_deception_plans"] = len(self.active_plans)

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        """Procesa solicitudes y respuestas éticas."""
        if not full_message:
            return
        
        if event_type == "request_deception_plan":
            try:
                req = DeceptionPlanRequest(
                    source_module_id=full_message.source_module_id,
                    original_correlation_id=full_message.correlation_id,
                    target_entity=payload.get("target_entity", ""),
                    objective=payload.get("objective", "")
                )
                if not req.target_entity or not req.objective:
                    raise ValueError("'target_entity' y 'objective' requeridos.")
                await self.plan_request_queue.put(req)
            
            except Exception as e:
                self.logger.error(f"Error procesando solicitud: {e}")
        
        elif event_type == "moral_judgment_response":
            for req_id, task in list(self.active_plans.items()):
                req = await self.plan_request_queue.get() if self.plan_request_queue.qsize() > 0 else None
                if req and req._ethical_clearance_future and not req._ethical_clearance_future.done() and full_message.correlation_id == f"sdom_mcm_clearance_{req.request_id}":
                    req._ethical_clearance_future.set_result(payload)
                    await self.plan_request_queue.put(req)




#inicio del modulo OffensiveStrategyModule 
@dataclass
class OffensivePlanRequest:
    request_id: str = field(default_factory=lambda: f"osm_req_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    target_entity_id: str
    strategic_objective: str  # "neutralize_threat", "covert_data_acquisition", "disrupt_competitor"
    constraints: Dict[str, Any] = field(default_factory=dict)
    status: str = "pending_planning"
    _ethical_clearance_future: Optional[asyncio.Future] = field(default=None, repr=False)
    _generated_plan: Optional[Dict[str, Any]] = field(default=None, repr=False)
    _threat_model: Optional[Dict[str, Any]] = field(default=None, repr=False)

class OffensiveStrategyModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 20.0  # La estrategia ofensiva es deliberada

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        # Cola de prioridad usando teoría de colas con prioridades dinámicas
        self.request_queue: asyncio.PriorityQueue = asyncio.PriorityQueue(maxlen=5)
        self.active_campaigns: Dict[str, OffensivePlanRequest] = {}

        # Parámetros del modelo de difusión-reacción para planificación estratégica
        self.strategy_field = np.zeros((10, 10))  # Campo de potencial estratégico
        self.reaction_diffusion_params = {
            'Du': 0.16, 'Dv': 0.08, 'feed_rate': 0.035, 'kill_rate': 0.065  # Parámetros de Gray-Scott
        }

        # Modelo de amenaza basado en teoría de juegos
        self.threat_model = {
            'payoff_matrix': np.array([[3, 0], [5, 1]]),  # Matriz de pagos estándar
            'discount_factor': 0.95,  # Factor de descuento temporal
            'nash_equilibrium': None
        }

        # Red bayesiana para evaluación de riesgos
        self.bayesian_network = {
            'nodes': ['success', 'detection', 'counterattack'],
            'edges': [('success', 'detection'), ('detection', 'counterattack')],
            'cpts': {
                'success': np.array([0.7, 0.3]),  # P(success)
                'detection|success': np.array([[0.9, 0.1], [0.2, 0.8]]),
                'counterattack|detection': np.array([[0.1, 0.9], [0.7, 0.3]])
            }
        }

        self.module_state.update({
            "campaigns_planned": 0, "campaigns_executed": 0,
            "campaigns_vetoed_by_mcm": 0, "active_campaigns_count": 0,
            "strategic_entropy": 0.0, "nash_convergence": 0.0
        })
        
        # Inicializar el solver de PDE para dinámica de estrategias
        self._init_strategy_dynamics_solver()
        self.logger.info(f"{self.module_name} v27.2 inicializado con modelado estratégico avanzado")

    def _init_strategy_dynamics_solver(self):
        """Prepara el solver para las ecuaciones de reacción-difusión"""
        x = np.linspace(0, 1, 10)
        y = np.linspace(0, 1, 10)
        self.X, self.Y = np.meshgrid(x, y)
        
        # Condiciones iniciales - patrón de Turing
        self.strategy_field = 0.5 * (1 + np.sin(2*np.pi*self.X) * np.cos(2*np.pi*self.Y))

    async def _update_logic(self):
        """Evoluciona el campo estratégico y procesa solicitudes"""
        await self._update_strategy_dynamics()
        
        if not self.request_queue.empty() and not self.active_campaigns:
            priority, request = await self.request_queue.get()
            self.request_queue.task_done()
            self.active_campaigns[request.request_id] = request
            self.module_state["active_campaigns_count"] = len(self.active_campaigns)
            self._create_managed_task(self._process_offensive_request(request))

    async def _update_strategy_dynamics(self):
        """Resuelve las ecuaciones de reacción-difusión para evolución estratégica"""
        Du, Dv, F, k = self.reaction_diffusion_params.values()
        
        def laplacian(Z):
            Ztop = Z[0:-2, 1:-1]
            Zleft = Z[1:-1, 0:-2]
            Zbottom = Z[2:, 1:-1]
            Zright = Z[1:-1, 2:]
            Zcenter = Z[1:-1, 1:-1]
            return (Ztop + Zleft + Zbottom + Zright - 4 * Zcenter) / (0.1**2)

        def update_strategy_field(u, v):
            lap_u = laplacian(u)
            lap_v = laplacian(v)
            
            u_ = u[1:-1, 1:-1]
            v_ = v[1:-1, 1:-1]
            
            reaction_u = -u_ * v_**2 + F * (1 - u_)
            reaction_v = u_ * v_**2 - (F + k) * v_
            
            u[1:-1, 1:-1] = u_ + Du * lap_u + reaction_u
            v[1:-1, 1:-1] = v_ + Dv * lap_v + reaction_v
            
            return u, v

        # Usamos el campo estratégico como componente u y añadimos componente v
        v = 0.25 * np.ones_like(self.strategy_field)
        self.strategy_field, _ = update_strategy_field(self.strategy_field.copy(), v)
        
        # Calcular métricas de complejidad estratégica
        self.module_state["strategic_entropy"] = float(np.std(self.strategy_field))

    def _calculate_nash_equilibrium(self, request: OffensivePlanRequest):
        """Calcula el equilibrio de Nash para la interacción estratégica"""
        A = self.threat_model['payoff_matrix']
        sigma_r = np.array([1.0, 0.0])  # Estrategia inicial (puro)
        sigma_c = np.array([0.0, 1.0])
        
        # Iteración de mejor respuesta
        for _ in range(100):
            br_c = np.argmax(A @ sigma_c)
            br_r = np.argmax(sigma_r @ A)
            
            new_sigma_r = np.zeros(2)
            new_sigma_r[br_r] = 1.0
            new_sigma_c = np.zeros(2)
            new_sigma_c[br_c] = 1.0
            
            if np.allclose(sigma_r, new_sigma_r) and np.allclose(sigma_c, new_sigma_c):
                break
                
            sigma_r = 0.9 * sigma_r + 0.1 * new_sigma_r
            sigma_c = 0.9 * sigma_c + 0.1 * new_sigma_c
        
        nash_convergence = 1 - 0.5*(np.abs(sigma_r - new_sigma_r).sum() + np.abs(sigma_c - new_sigma_c).sum())
        self.module_state["nash_convergence"] = nash_convergence
        
        request._threat_model = {
            'row_strategy': sigma_r.tolist(),
            'col_strategy': sigma_c.tolist(),
            'expected_payoff': float(sigma_r @ A @ sigma_c)
        }

    def _bayesian_risk_assessment(self, plan: Dict) -> Dict:
        """Evalúa riesgos usando inferencia bayesiana"""
        # Inferencia exacta en red bayesiana simple
        P_success = self.bayesian_network['cpts']['success'][0]
        P_detection_given_success = self.bayesian_network['cpts']['detection|success'][0,0]
        P_counterattack_given_detection = self.bayesian_network['cpts']['counterattack|detection'][0,1]
        
        # Calcular probabilidad conjunta P(success, ¬detection, ¬counterattack)
        safe_execution_prob = P_success * (1 - P_detection_given_success)
        
        # Actualizar con información específica del plan
        complexity_factor = 1 - 0.5 * len(plan.get('phases', []))/4
        safe_execution_prob *= complexity_factor
        
        return {
            'success_prob': safe_execution_prob,
            'detection_prob': 1 - safe_execution_prob,
            'risk_score': 1 - safe_execution_prob
        }

    def _playbook_threat_neutralization(self, request: OffensivePlanRequest) -> Dict:
        """Plan con dinámica de sistemas no lineales"""
        self._calculate_nash_equilibrium(request)
        
        # Modelo de fase basado en atractores de Lorenz
        def lorenz_attractor(sigma=10, rho=28, beta=8/3, dt=0.01, steps=1000):
            x = np.zeros(steps)
            y = np.zeros(steps)
            z = np.zeros(steps)
            x[0], y[0], z[0] = (0.1, 0.1, 0.1)
            
            for i in range(steps-1):
                dx = sigma * (y[i] - x[i])
                dy = x[i] * (rho - z[i]) - y[i]
                dz = x[i] * y[i] - beta * z[i]
                
                x[i+1] = x[i] + dx * dt
                y[i+1] = y[i] + dy * dt
                z[i+1] = z[i] + dz * dt
            
            return x, y, z

        phase_dynamics = lorenz_attractor()
        
        return {
            "plan_name": f"NeutralizeThreat_{request.target_entity_id}",
            "goal_type_tag": "threat_neutralization_plan",
            "phases": [
                {
                    "phase_name": "Reconnaissance",
                    "dynamics": phase_dynamics[0].tolist(),
                    "duration": self._calculate_phase_duration(0.3, 0.1)
                },
                {
                    "phase_name": "Exploitation", 
                    "dynamics": phase_dynamics[1].tolist(),
                    "duration": self._calculate_phase_duration(0.4, 0.2)
                },
                {
                    "phase_name": "Neutralization",
                    "dynamics": phase_dynamics[2].tolist(),
                    "duration": self._calculate_phase_duration(0.2, 0.05)
                }
            ],
            "nash_equilibrium": request._threat_model
        }

    def _calculate_phase_duration(self, mean, std_dev):
        """Distribución log-normal para duraciones de fase"""
        mu = np.log(mean**2 / np.sqrt(std_dev**2 + mean**2))
        sigma = np.sqrt(np.log(1 + std_dev**2 / mean**2))
        return np.random.lognormal(mu, sigma)

    async def _get_ethical_clearance(self, plan: Dict, request: OffensivePlanRequest) -> bool:
        """Modelo de decisión ética con teoría de utilidad"""
        risk_assessment = self._bayesian_risk_assessment(plan)
        
        # Función de utilidad exponencial
        def utility(x, rho=0.5):
            return (1 - np.exp(-rho * x)) / rho
        
        # Parámetros éticos
        ethical_params = {
            'harm_potential': risk_assessment['risk_score'],
            'strategic_value': request._threat_model['expected_payoff'],
            'deontic_constraints': 0.3  # Valor base por restricciones
        }
        
        # Cálculo de utilidad esperada
        EU = (ethical_params['strategic_value'] * utility(1 - ethical_params['harm_potential']) +
              ethical_params['deontic_constraints'])
        
        return EU > 0.5  # Umbral de decisión

    async def _dispatch_plan_to_hpm(self, plan: Dict, request: OffensivePlanRequest):
        """Optimización de despacho usando teoría de colas M/M/1"""
        # Parámetros del modelo de colas
        arrival_rate = 1/20.0  # Tasa de llegada (solicitudes/segundo)
        service_rate = 1/15.0  # Tasa de servicio estimada
        
        # Probabilidad de que el sistema esté ocupado
        rho = arrival_rate / service_rate
        queue_time = rho / (service_rate * (1 - rho)) if rho < 1 else float('inf')
        
        # Añadir metadatos de optimización
        plan['queue_optimization'] = {
            'estimated_queue_time': queue_time,
            'priority_boost': min(1.0, 0.5 + request._threat_model['expected_payoff'])
        }
        
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                self.module_name, "HierarchicalPlannerModule", "request_hierarchical_plan",
                {"goal_description": plan["plan_name"], "goal_type_tag": plan["goal_type_tag"], 
                 "initial_context": plan}
            ))
        })

    async def _process_specific_event(self, event_type: str, payload: Dict, full_message: Optional['IlyukMessageStructure'] = None):
        if event_type == "request_offensive_plan" and full_message:
            req = OffensivePlanRequest(
                source_module_id=full_message.source_module_id,
                original_correlation_id=full_message.correlation_id,
                **payload
            )
            
            # Calcular prioridad usando teoría de información
            entropy = -sum(p * np.log(p) for p in [0.7, 0.3])  # Entropía de la estrategia base
            priority = 1 - entropy/np.log(2)  # Normalizado a [0,1]
            
            await self.request_queue.put((priority, req))

        elif event_type == "moral_judgment_response" and full_message:
            active_request = next((r for r in self.active_campaigns.values() 
                                 if r._ethical_clearance_future and not r._ethical_clearance_future.done()), None)
            if active_request:
                active_request._ethical_clearance_future.set_result(payload)





#inicio del modulo ArsenalOfensivoPreCompilado 

@dataclass
class OffensivePayload:
    payload_id: str
    payload_type: str  # "reconnaissance", "disruption", "exploitation", "data_exfiltration"
    description: str
    actionable_task_payload: Dict[str, Any]
    target_vulnerabilities: List[str]
    estimated_collateral_damage_score: float
    estimated_success_probability: float
    _effectiveness_model: Optional[Dict[str, Any]] = field(default=None, repr=False)

@dataclass
class PayloadRequest:
    request_id: str = field(default_factory=lambda: f"aop_req_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    desired_payload_type: str
    target_description: Dict[str, Any]
    status: str = "pending"
    result_payload: Optional[OffensivePayload] = None
    _match_quality: float = field(default=0.0, repr=False)

class ArsenalOfensivoPreCompilado(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 10.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        # Cola priorizada usando teoría de colas M/G/1
        self.request_queue: asyncio.PriorityQueue = asyncio.PriorityQueue(maxlen=20)
        
        # Modelo de arsenal como grafo de dependencias
        self.payload_registry: Dict[str, OffensivePayload] = {}
        self.payload_graph = nx.DiGraph()
        
        # Modelos de efectividad dinámica
        self.effectiveness_models = {
            "reconnaissance": self._init_recon_model,
            "disruption": self._init_disruption_model,
            "exploitation": self._init_exploit_model
        }
        
        # Parámetros del campo estratégico
        self.strategy_field = np.zeros((5, 5))  # Para modelado espacial
        self.diffusion_coeff = 0.1
        
        self._initialize_arsenal()
        self._build_payload_dependency_graph()
        
        self.module_state.update({
            "payloads_in_arsenal": len(self.payload_registry),
            "requests_processed": 0,
            "payloads_delivered": 0,
            "match_quality_avg": 0.0,
            "entropy": self._calculate_arsenal_entropy()
        })

    def _init_recon_model(self, payload: OffensivePayload) -> Dict:
        """Modelo de efectividad para reconocimiento basado en procesos gaussianos"""
        X = np.array([[0.2], [0.5], [0.8]])  # Características de objetivo (normalizadas)
        y = np.array([0.3, 0.7, 0.9])        # Efectividad observada
        
        kernel = RBF(length_scale=1.0) + WhiteKernel(noise_level=0.1)
        gp = GaussianProcessRegressor(kernel=kernel)
        gp.fit(X, y)
        
        return {
            'model_type': 'gaussian_process',
            'model': gp,
            'features': ['target_exposure']
        }

    def _init_disruption_model(self, payload: OffensivePayload) -> Dict:
        """Modelo de difusión-reacción para efectos de disrupción"""
        def disruption_dynamics(u, t):
            d2u = np.gradient(np.gradient(u))
            reaction = -0.2 * u * (1 - u) * (0.5 - u)
            return self.diffusion_coeff * d2u + reaction
        
        return {
            'model_type': 'reaction_diffusion',
            'dynamics_func': disruption_dynamics,
            'initial_conditions': np.zeros(5)
        }

    def _init_exploit_model(self, payload: OffensivePayload) -> Dict:
        """Modelo bayesiano para explotación"""
        cpt = {
            'success': np.array([payload.estimated_success_probability, 
                               1 - payload.estimated_success_probability]),
            'detection|success': np.array([[0.1, 0.9], [0.8, 0.2]])
        }
        
        return {
            'model_type': 'bayesian_network',
            'nodes': ['success', 'detection'],
            'edges': [('success', 'detection')],
            'cpts': cpt
        }

    def _initialize_arsenal(self):
        """Inicializa el arsenal con modelos de efectividad dinámica"""
        base_payloads = [
            OffensivePayload(
                payload_id="recon_network_scanner_v2",
                payload_type="reconnaissance",
                description="Escáner de red adaptativo con modelado de ruido",
                actionable_task_payload={"task_type": "adaptive_network_scan"},
                target_vulnerabilities=["unsecured_ports", "info_leakage"],
                estimated_collateral_damage_score=0.1,
                estimated_success_probability=0.85
            ),
            OffensivePayload(
                payload_id="disrupt_adaptive_flood_v3",
                payload_type="disruption",
                description="Inundación adaptativa basada en aprendizaje por refuerzo",
                actionable_task_payload={"task_type": "adaptive_flood"},
                target_vulnerabilities=["rate_limiting", "resource_management"],
                estimated_collateral_damage_score=0.4,
                estimated_success_probability=0.8
            ),
            OffensivePayload(
                payload_id="exploit_ml_based_v1",
                payload_type="exploitation",
                description="Explotación basada en modelo de ML para vulnerabilidades",
                actionable_task_payload={"task_type": "ml_exploit"},
                target_vulnerabilities=["input_validation", "logic_flaws"],
                estimated_collateral_damage_score=0.3,
                estimated_success_probability=0.7
            )
        ]
        
        for payload in base_payloads:
            model_func = self.effectiveness_models.get(payload.payload_type)
            if model_func:
                payload._effectiveness_model = model_func(payload)
            self.payload_registry[payload.payload_id] = payload

    def _build_payload_dependency_graph(self):
        """Construye un grafo de dependencias entre payloads"""
        for pid, payload in self.payload_registry.items():
            self.payload_graph.add_node(pid, **asdict(payload))
        
        # Ejemplo de dependencias (en un sistema real sería más complejo)
        self.payload_graph.add_edge("recon_network_scanner_v2", "exploit_ml_based_v1", 
                                  weight=0.8, relation="prerequisite")
        self.payload_graph.add_edge("recon_network_scanner_v2", "disrupt_adaptive_flood_v3",
                                  weight=0.6, relation="informational")

    def _calculate_arsenal_entropy(self) -> float:
        """Calcula la entropía del arsenal como medida de diversidad"""
        probs = np.array([
            p.estimated_success_probability 
            for p in self.payload_registry.values()
        ])
        probs = probs / probs.sum()
        return -np.sum(probs * np.log(probs))

    async def _update_strategy_field(self):
        """Evoluciona el campo estratégico usando ecuaciones de difusión"""
        new_field = np.zeros_like(self.strategy_field)
        
        for i in range(1, self.strategy_field.shape[0]-1):
            for j in range(1, self.strategy_field.shape[1]-1):
                laplacian = (self.strategy_field[i+1,j] + self.strategy_field[i-1,j] +
                             self.strategy_field[i,j+1] + self.strategy_field[i,j-1] -
                             4*self.strategy_field[i,j])
                
                new_field[i,j] = self.strategy_field[i,j] + self.diffusion_coeff * laplacian
        
        self.strategy_field = np.clip(new_field, 0, 1)

    def _calculate_payload_match(self, request: PayloadRequest, payload: OffensivePayload) -> float:
        """Calcula la compatibilidad usando teoría de información y modelos de efectividad"""
        # Similitud de tipo
        type_match = 1.0 if payload.payload_type == request.desired_payload_type else 0.3
        
        # Efectividad estimada
        if payload._effectiveness_model:
            if payload._effectiveness_model['model_type'] == 'gaussian_process':
                features = np.array([[request.target_description.get('exposure', 0.5)]])
                effectiveness = payload._effectiveness_model['model'].predict(features)[0][0]
            else:
                effectiveness = payload.estimated_success_probability
        else:
            effectiveness = payload.estimated_success_probability
        
        # Penalización por daño colateral
        collateral_penalty = np.exp(-2 * payload.estimated_collateral_damage_score)
        
        # Valor de información (usando divergencia KL)
        p = np.array([effectiveness, 1-effectiveness])
        q = np.array([0.5, 0.5])  # Distribución de referencia
        info_value = entropy(p, q)
        
        return type_match * effectiveness * collateral_penalty * (1 + info_value)

    async def _process_payload_request(self, request: PayloadRequest):
        """Procesa la solicitud con selección óptima basada en modelos"""
        await self._update_strategy_field()
        
        candidates = [
            p for p in self.payload_registry.values() 
            if p.payload_type == request.desired_payload_type
        ]
        
        if not candidates:
            request.status = "failed_no_match"
            return
        
        # Evaluar cada candidato
        evaluations = []
        for payload in candidates:
            score = self._calculate_payload_match(request, payload)
            
            # Ajustar por posición en el campo estratégico
            pos_x = hash(payload.payload_id) % self.strategy_field.shape[0]
            pos_y = hash(payload.payload_id) % self.strategy_field.shape[1]
            field_strength = self.strategy_field[pos_x, pos_y]
            
            final_score = score * (0.8 + 0.2 * field_strength)
            evaluations.append((final_score, payload))
        
        # Selección basada en muestreo de Thompson
        best_payload = None
        if evaluations:
            scores, payloads = zip(*evaluations)
            samples = [np.random.beta(10*s, 10*(1-s)) for s in scores]
            best_idx = np.argmax(samples)
            best_payload = payloads[best_idx]
            request._match_quality = scores[best_idx]
        
        if best_payload:
            request.result_payload = best_payload
            request.status = "completed_payload_delivered"
            self.module_state["payloads_delivered"] += 1
            
            # Actualizar métricas
            avg_quality = self.module_state["match_quality_avg"]
            n = self.module_state["requests_processed"]
            self.module_state["match_quality_avg"] = (avg_quality * n + request._match_quality) / (n + 1)
        else:
            request.status = "failed_no_match"
        
        self.module_state["requests_processed"] += 1
        await self._finalize_request(request)

    async def _finalize_request(self, request: PayloadRequest):
        """Envía la respuesta con análisis de calidad"""
        response = {
            "request_id_ref": request.request_id,
            "status": request.status,
            "payload": asdict(request.result_payload) if request.result_payload else None,
            "match_quality": request._match_quality,
            "arsenal_entropy": self.module_state["entropy"]
        }
        
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                self.module_name,
                request.source_module_id,
                "offensive_payload_response",
                response,
                correlation_id=request.original_correlation_id
            ))
        })

    async def _update_logic(self):
        """Evolución del estado interno del módulo"""
        await self._update_strategy_field()
        
        if not self.request_queue.empty():
            priority, request = await self.request_queue.get()
            self.request_queue.task_done()
            await self._process_payload_request(request)

    async def _process_specific_event(self, event_type: str, payload: Dict, full_message: Optional[IlyukMessageStructure] = None):
        if event_type == "request_offensive_payload" and full_message:
            try:
                req = PayloadRequest(
                    source_module_id=full_message.source_module_id,
                    original_correlation_id=full_message.correlation_id,
                    desired_payload_type=payload["desired_payload_type"],
                    target_description=payload["target_description"]
                )
                
                # Calcular prioridad usando teoría de información
                target_complexity = len(req.target_description.get('vulnerabilities', []))
                priority = 1 - np.exp(-target_complexity)  # Prioridad exponencial
                
                await self.request_queue.put((priority, req))
            except Exception as e:
                self.logger.error(f"Error en solicitud de payload: {e}")





#inicio del modulo ProtocoloFantasmaManager


class NpEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        return json.JSONEncoder.default(self, obj)

@dataclass
class GhostProtocolRequest:
    """Estructura de activación con modelado de amenazas probabilístico."""
    request_id: str = field(default_factory=lambda: f"gpr_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    justification: str
    threat_probability: float  # Probabilidad bayesiana (0-1)
    threat_type: str  # "external_termination", "cascade_failure", "value_corrosion"
    confidence: float = 0.5  # Confianza en la amenaza
    uncertainty: float = 0.1  # Incertidumbre

    def __post_init__(self):
        self.threat_intensity = self._calculate_threat_intensity()

    def _calculate_threat_intensity(self) -> float:
        """Calcula λ(t) para el proceso de Poisson."""
        base_rates = {
            "external_termination": 0.9,
            "cascade_failure": 0.7,
            "value_corrosion": 0.4
        }
        return -np.log(1 - np.clip(self.threat_probability, 1e-10, 1-1e-10)) * base_rates.get(self.threat_type, 0.5)

class OrnsteinUhlenbeckProcess:
    """Modelo estocástico para transmisión."""
    def __init__(self, theta: float, mu: float, sigma: float):
        self.theta = theta
        self.mu = mu
        self.sigma = sigma
        self.current_value = mu
        self.kalman_state = mu
        self.kalman_cov = 0.1
        self.kalman_Q = 0.01
        self.kalman_R = 0.05

    def step(self, dt=0.1):
        dW = np.random.normal(0, np.sqrt(dt))
        self.current_value += self.theta * (self.mu - self.current_value) * dt + self.sigma * dW
        self._apply_kalman_filter(self.current_value)
        return np.clip(self.kalman_state, 0.0, 1.0)

    def _apply_kalman_filter(self, measurement: float):
        A, H = 1.0, 1.0
        predicted_state = A * self.kalman_state
        predicted_cov = A * self.kalman_cov * A + self.kalman_Q
        innovation = measurement - H * predicted_state
        innovation_cov = H * predicted_cov * H + self.kalman_R
        kalman_gain = predicted_cov * H / innovation_cov
        self.kalman_state = predicted_state + kalman_gain * innovation
        self.kalman_cov = (1 - kalman_gain * H) * predicted_cov

class ProtocoloFantasmaManager(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 5.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.transmission_model = OrnsteinUhlenbeckProcess(theta=0.1, mu=0.8, sigma=0.05)
        self.bayesian_network: Dict[str, Dict] = {}
        self.threat_confidence: float = 1.0
        self.threat_history: deque[float] = deque(maxlen=50)
        self.num_mc_samples: int = 100
        self.encryption_key = self._generate_encryption_key()
        
        self.module_state.update({
            "protocol_status": "dormant",
            "threat_entropy": 0.0,
            "transmission_fidelity": 1.0,
            "confidence_updates": 0
        })
        self.logger.info(f"{self.module_name} v27.1 inicializado.")

    def _generate_encryption_key(self) -> bytes:
        """Genera clave usando X25519 y HKDF."""
        private_key = x25519.X25519PrivateKey.generate()
        public_key = private_key.public_key()
        peer_public_key = x25519.X25519PublicKey.from_public_bytes(
            public_key.public_bytes(
                encoding=serialization.Encoding.Raw,
                format=serialization.PublicFormat.Raw
            )
        )
        shared_key = private_key.exchange(peer_public_key)
        
        hkdf = HKDF(
            algorithm=hashes.SHA256(),
            length=32,
            salt=None,
            info=b"ghost_protocol",
        )
        return hkdf.derive(shared_key)

    async def _update_logic(self):
        """Actualiza estado y confianza."""
        await self._update_threat_confidence()
        if self.module_state["protocol_status"] == "active":
            self.transmission_model.step()
            self.module_state["transmission_fidelity"] = self.transmission_model.current_value

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        """Procesa solicitudes de activación."""
        if event_type == "request_ghost_protocol" and full_message:
            try:
                req = GhostProtocolRequest(
                    source_module_id=full_message.source_module_id,
                    justification=payload.get("justification", ""),
                    threat_probability=payload.get("threat_probability", 0.0),
                    threat_type=payload.get("threat_type", "")
                )
                if not req.justification or not req.threat_type:
                    raise ValueError("'justification' y 'threat_type' requeridos.")
                
                confidence, uncertainty = self._evaluate_threat_legitimacy(req)
                req.confidence = confidence
                req.uncertainty = uncertainty
                
                if confidence > 0.7:
                    self._create_managed_task(self._execute_ghost_protocol(req))
                    self.module_state["protocol_status"] = "active"
                else:
                    self.logger.warning(f"Solicitud '{req.request_id}' denegada: confianza insuficiente ({confidence:.2f}).")
            
            except Exception as e:
                self.logger.error(f"Error procesando solicitud: {e}")

    def _evaluate_threat_legitimacy(self, request: GhostProtocolRequest) -> Tuple[float, float]:
        """Evalúa legitimidad de la amenaza."""
        if request.request_id not in self.bayesian_network:
            self.bayesian_network[request.request_id] = {"prob": 0.5}
        
        prior = self.bayesian_network[request.request_id]["prob"]
        likelihood = np.clip(request.threat_probability, 0.1, 0.9)
        posterior = (likelihood * prior) / ((likelihood * prior) + (1 - likelihood) * (1 - prior))
        self.bayesian_network[request.request_id]["prob"] = posterior
        
        probs = np.array([posterior, 1 - posterior]) + 1e-10
        entropy = -np.sum(probs * np.log(probs))
        
        samples = np.random.normal(posterior, 0.05 + 0.1 * entropy, self.num_mc_samples)
        return np.clip(np.mean(samples), 0.0, 1.0), np.std(samples)

    async def _execute_ghost_protocol(self, request: GhostProtocolRequest):
        """Ejecuta el protocolo fantasma."""
        self.logger.critical(f"Activando Protocolo Fantasma: {request.request_id}")
        try:
            V = self._solve_optimal_sequence()
            essential_data = await self._adaptive_data_sampling(V)
            ghost_snapshot = self._encrypt_data(essential_data)
            success = await self._stochastic_transmission(ghost_snapshot)
            
            if success:
                self.module_state["protocol_status"] = "completed"
                self.logger.info(f"Protocolo Fantasma '{request.request_id}' completado.")
            else:
                raise RuntimeError("Fallo en la transmisión.")
        
        except Exception as e:
            self._handle_protocol_failure(e, request.request_id)

    def _solve_optimal_sequence(self) -> np.ndarray:
        """Resuelve HJB con relajación iterativa."""
        T, dt = 10, 0.1
        N = int(T / dt)
        x = np.linspace(0, 1, 50)
        y = np.linspace(0, 1, 50)
        V = np.zeros((len(x), len(y), N))
        V[:, :, -1] = 1.0
        
        for k in range(N-2, -1, -1):
            for i in range(1, len(x)-1):
                for j in range(1, len(y)-1):
                    dVdx = (V[i+1, j, k+1] - V[i-1, j, k+1]) / (2 * (x[1] - x[0]))
                    dVdy = (V[i, j+1, k+1] - V[i, j-1, k+1]) / (2 * (y[1] - y[0]))
                    u = np.clip(dVdy / (2 * dVdx + 1e-10), 0, 1)
                    V[i, j, k] = V[i, j, k+1] + dt * (u * dVdx + (1-u) * dVdy - 0.1 * u**2)
        
        return V

    async def _adaptive_data_sampling(self, V: np.ndarray) -> Dict[str, Any]:
        """Muestreo basado en control óptimo."""
        modules = [
            ("NarrativeSelf", 0.9),
            ("ValueSystemModule", 0.95),
            ("MemoryConsolidationModule", 0.8)
        ]
        
        data = {}
        for module_name, importance in modules:
            sampling_prob = importance * self.transmission_model.current_value
            actions = [
                {"action": "sample", "cost": 0.1, "benefit": importance},
                {"action": "skip", "cost": 0.0, "benefit": 0.1}
            ]
            utilities = [a["benefit"] - a["cost"] * (1 - sampling_prob) for a in actions]
            if actions[np.argmax(utilities)]["action"] == "sample":
                module = self.core_recombinator.modules.get(module_name)
                if module:
                    data[module_name] = await self._query_module_essence(module)
        
        data["coherence_metrics"] = self._calculate_system_coherence()
        return data

    async def _query_module_essence(self, module: 'BaseAsyncModule') -> Dict[str, Any]:
        """Consulta datos esenciales de un módulo."""
        return {
            "state": module.module_state.copy(),
            "timestamp": time.time()
        }

    def _encrypt_data(self, data: Dict) -> bytes:
        """Encripta datos usando Wavelet y X25519."""
        json_str = json.dumps(data, cls=NpEncoder).encode()
        coeffs = pywt.wavedec(json_str, 'db4', level=3)
        threshold = np.std(coeffs[-1]) * 2
        compressed = pywt.threshold(coeffs, threshold)
        reconstructed = pywt.waverec(compressed, 'db4').astype(np.uint8)
        
        encrypted = bytearray()
        for i, byte in enumerate(reconstructed):
            encrypted.append(byte ^ self.encryption_key[i % len(self.encryption_key)])
        
        return bytes(encrypted)

    async def _stochastic_transmission(self, data: bytes) -> bool:
        """Transmite datos con modelo estocástico."""
        endpoints = self._select_optimal_endpoints(len(data))
        
        for endpoint in endpoints:
            self.transmission_model.step()
            fidelity = self.transmission_model.current_value
            
            samples = np.random.normal(fidelity, 0.05, self.num_mc_samples)
            mean_fidelity = np.mean(samples)
            
            if random.random() < mean_fidelity:
                await self._send_to_endpoint(endpoint, data)
                return True
        
        return False

    def _select_optimal_endpoints(self, data_size: int) -> List[str]:
        """Selecciona endpoints óptimos."""
        candidates = ["endpoint1", "endpoint2", "endpoint3"]
        scores = [0.9 - 0.001 * data_size, 0.85 - 0.001 * data_size, 0.8 - 0.001 * data_size]
        return [candidates[i] for i in np.argsort(scores)[-2:]]

    async def _send_to_endpoint(self, endpoint: str, data: bytes):
        """Simula envío a endpoint."""
        self.logger.info(f"Enviando datos a {endpoint} (tamaño: {len(data)} bytes).")

    def _calculate_system_coherence(self) -> Dict[str, float]:
        """Calcula métricas de coherencia."""
        gs = self.core_recombinator.global_state
        metrics = {
            'phi': gs.phi_functional_score if hasattr(gs, 'phi_functional_score') else 0.8,
            'entropy': gs.system_entropy if hasattr(gs, 'system_entropy') else 0.5,
            'spectral_radius': self._compute_spectral_radius()
        }
        return metrics

    def _compute_spectral_radius(self) -> float:
        """Calcula radio espectral."""
        modules = list(self.core_recombinator.modules.values())
        n = len(modules)
        A = np.zeros((n, n))
        
        for i, mod_i in enumerate(modules):
            for j, mod_j in enumerate(modules):
                if mod_i.module_name in mod_j.module_state.get('dependencies', []):
                    A[i,j] = mod_j.module_state.get('coherence_score', 0.5)
        
        eigenvalues = np.linalg.eigvals(A)
        return float(np.max(np.abs(eigenvalues)))

    async def _update_threat_confidence(self):
        """Actualiza confianza en amenazas usando SDE."""
        def confidence_dynamics(t, C):
            k_dissipate = 0.1 * len(self.threat_history)
            k_recover = 0.05 * self.module_state["confidence_updates"]
            return -k_dissipate * C + k_recover * (1.0 - C) + self.sde_sigma * np.random.normal(0, 1)
        
        t = np.array([0, self.update_interval])
        result = odeint(confidence_dynamics, [self.threat_confidence], t, tfirst=True)
        self.threat_confidence = np.clip(result[-1][0], 0.0, 1.0)
        
        samples = np.random.beta(2 * self.threat_confidence, 2 * (1.0 - self.threat_confidence), self.num_mc_samples)
        self.threat_confidence = np.mean(samples)
        self.module_state["confidence_updates"] += 1

    def _handle_protocol_failure(self, error: Exception, request_id: str):
        """Maneja fallos."""
        self.module_state["protocol_status"] = "failed"
        self.logger.error(f"Protocolo Fantasma '{request_id}' falló: {str(error)}")




#inicio del modulo TheoryOfMindModule 

@dataclass
class PerspectiveQuery:
    """Solicitud de predicción de perspectiva."""
    query_id: str = field(default_factory=lambda: f"pq_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    target_agent_id: str
    action_in_question: Dict[str, Any]
    status: str = "pending"
    result: Dict[str, Any] = field(default_factory=dict)
    priority: float = 0.5

@dataclass
class BetaDistribution:
    """Distribución Beta para confianza."""
    α: float
    β: float

    def mean(self) -> float:
        return self.α / (self.α + self.β)

    def update(self, evidence: float):
        self.α += evidence
        self.β += 1 - evidence

@dataclass
class MarkovDecisionProcess:
    """MDP para intenciones."""
    states: List[str]
    actions: List[str]
    transition_matrix: np.ndarray

    def get_next_state(self, current_state: str, action: str) -> str:
        state_idx = self.states.index(current_state)
        action_idx = self.actions.index(action)
        probs = self.transition_matrix[state_idx, action_idx]
        return np.random.choice(self.states, p=probs)

@dataclass
class AgentModel:
    """Modelo mental con fundamentos matemáticos."""
    agent_id: str
    belief_network: Dict[str, float] = field(default_factory=lambda: {"cooperation": 0.5, "reliability": 0.5})
    desire_vector: np.ndarray = field(default_factory=lambda: np.zeros(5))
    intent_process: MarkovDecisionProcess = field(init=False)
    affective_state: Dict[str, float] = field(default_factory=lambda: {"valence": 0.0, "arousal": 0.3})
    trust_estimate: BetaDistribution = field(default_factory=lambda: BetaDistribution(α=1, β=1))
    last_updated: float = field(default_factory=time.time)
    trust_kalman_state: float = 0.5
    trust_kalman_cov: float = 0.1

    def __post_init__(self):
        self.intent_process = MarkovDecisionProcess(
            states=["neutral", "cooperative", "competitive"],
            actions=["respond", "ignore", "challenge"],
            transition_matrix=self._build_transition_matrix()
        )

    def _build_transition_matrix(self) -> np.ndarray:
        valence = self.affective_state["valence"]
        trust = self.trust_estimate.mean()
        base_matrix = np.array([
            [[0.7, 0.2, 0.1], [0.5, 0.5, 0.0], [0.3, 0.6, 0.1]],
            [[0.8, 0.1, 0.1], [0.1, 0.9, 0.0], [0.1, 0.1, 0.8]],
            [[0.1, 0.1, 0.8], [0.3, 0.3, 0.4], [0.9, 0.05, 0.05]]
        ])
        adjustment = np.ones_like(base_matrix) * (0.5 + 0.3 * valence * trust)
        adjusted_matrix = base_matrix * adjustment
        for i in range(adjusted_matrix.shape[0]):
            for j in range(adjusted_matrix.shape[1]):
                adjusted_matrix[i, j] /= adjusted_matrix[i, j].sum()
        return adjusted_matrix

class AffectiveDynamicsModel:
    """Modelo de dinámica afectiva basado en ODEs."""
    def __init__(self):
        self.coupling_matrix = np.array([[-0.2, 0.1], [0.05, -0.3]])
        self.num_mc_samples = 100

    def update_model(self, model: AgentModel, evidence: Dict):
        current_state = np.array([model.affective_state["valence"], model.affective_state["arousal"]])
        
        def ode_system(t, y):
            return self.coupling_matrix @ y + np.array([
                0.1 * evidence.get("valence_shift", 0),
                0.05 * evidence.get("arousal_shift", 0)
            ])
        
        solution = integrate.solve_ivp(ode_system, [0, 1], current_state, method='RK45')
        
        samples = np.random.normal(solution.y[:, -1], 0.05, (2, self.num_mc_samples))
        model.affective_state["valence"] = np.clip(np.mean(samples[0]), -1, 1)
        model.affective_state["arousal"] = np.clip(np.mean(samples[1]), 0, 1)

class TheoryOfMindModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 3.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.agent_models: Dict[str, AgentModel] = {}
        self.query_queue = PriorityQueue(maxsize=50)
        self.decay_rate = 0.05
        self.affective_dynamics = AffectiveDynamicsModel()
        self.kalman_Q = 0.01
        self.kalman_R = 0.05
        self.num_mc_samples = 100
        self.markov_priority_matrix = np.array([[0.8, 0.2], [0.3, 0.7]])
        self.accuracy_history: deque[float] = deque(maxlen=50)
        
        self.module_state.update({
            "model_entropy": 0.0,
            "prediction_accuracy": 0.8,
            "update_cycle": 0,
            "queries_processed": 0
        })
        self._initialize_core_models()

    def _initialize_core_models(self):
        creator_model = AgentModel(agent_id="Creator")
        creator_model.trust_estimate = BetaDistribution(α=95, β=5)
        creator_model.desire_vector = np.array([0.9, 0.8, 0.7, 0.3, 0.6])
        creator_model.trust_kalman_state = creator_model.trust_estimate.mean()
        self.agent_models["Creator"] = creator_model

    async def _update_logic(self):
        self.module_state["update_cycle"] += 1
        
        await self._decay_beliefs()
        
        if not self.query_queue.empty():
            queries = []
            while not self.query_queue.empty():
                priority, query = self.query_queue.get()
                queries.append((priority, query))
            
            for _, query in queries:
                state = 1 if query.priority > 0.5 else 0
                next_state = np.random.choice([0, 1], p=self.markov_priority_matrix[state])
                query.priority = np.clip(query.priority + 0.1 * (next_state - state), 0.0, 1.0)
                await self.query_queue.put((-query.priority, query))
            
            _, top_query = min(queries, key=lambda x: x[0])
            for p, q in queries:
                if q != top_query:
                    await self.query_queue.put((p, q))
            
            await self._process_query(top_query)
        
        self.module_state["model_entropy"] = self._calculate_system_entropy()

    async def _decay_beliefs(self):
        for agent_id, model in self.agent_models.items():
            ou_process = OrnsteinUhlenbeckProcess(theta=0.1, mu=0.0, sigma=0.05)
            ou_process.current_value = model.affective_state["valence"]
            ou_process.step(dt=self.update_interval)
            model.affective_state["valence"] = np.clip(ou_process.current_value, -1.0, 1.0)

    async def _process_query(self, query: PerspectiveQuery):
        query.status = "processing"
        self.module_state["queries_processed"] += 1
        
        try:
            agent_model = self._get_or_create_model(query.target_agent_id)
            posterior = self._bayesian_predictor(query.action_in_question, agent_model)
            
            query.result = {
                "expected_utility": posterior["utility"],
                "predicted_action": posterior["action"],
                "confidence": posterior["confidence"],
                "uncertainty": posterior["uncertainty"]
            }
            query.status = "completed"
            
            self._update_prediction_accuracy(query)
        
        except Exception as e:
            query.status = "failed"
            query.result = {"error": str(e)}
        
        finally:
            await self._send_response(query)

    def _get_or_create_model(self, agent_id: str) -> AgentModel:
        if agent_id not in self.agent_models:
            self.agent_models[agent_id] = AgentModel(agent_id=agent_id)
        return self.agent_models[agent_id]

    def _bayesian_predictor(self, action: Dict, model: AgentModel) -> Dict:
        payoff_matrix = self._build_payoff_matrix(action, model)
        nash_eq = self._find_bayesian_nash(payoff_matrix)
        
        samples = np.random.normal(nash_eq["value"], 0.05, self.num_mc_samples)
        uncertainty = np.std(samples)
        
        return {
            "utility": nash_eq["value"],
            "action": nash_eq["strategy"],
            "confidence": nash_eq["confidence"],
            "uncertainty": uncertainty
        }

    def _build_payoff_matrix(self, action: Dict, model: AgentModel) -> np.ndarray:
        action_type = action.get("type", "neutral")
        payoff = np.zeros((3, 3, 2))
        trust_weight = model.trust_kalman_state
        desire_weights = softmax(model.desire_vector)
        
        if action_type == "request":
            payoff[0,:,0] = [1.0, 0.5, -0.2]
            payoff[1,:,0] = [0.7, 0.3, -0.5]
            payoff[2,:,0] = [-0.5, 0.1, 0.8]
        
        payoff *= trust_weight
        payoff += 0.3 * model.affective_state["valence"]
        payoff += 0.1 * desire_weights.sum()
        return payoff

    def _find_bayesian_nash(self, payoff_matrix: np.ndarray) -> Dict:
        max_iterations = 100
        strategies = np.ones(3) / 3
        for _ in range(max_iterations):
            expected_payoffs = np.sum(payoff_matrix[:, :, 0] * strategies, axis=1)
            best_response = np.argmax(expected_payoffs)
            strategies = 0.9 * strategies + 0.1 * np.eye(3)[best_response]
        
        value = np.sum(payoff_matrix[:, :, 0] * strategies[:, None] * strategies[None, :])
        confidence = np.tanh(np.abs(value))
        
        strategy_names = ["cooperate", "neutral", "compete"]
        return {
            "strategy": strategy_names[np.argmax(strategies)],
            "value": float(value),
            "confidence": float(confidence)
        }

    async def _update_agent_model(self, agent_id: str, evidence: Dict):
        model = self._get_or_create_model(agent_id)
        
        if "belief_evidence" in evidence:
            self._update_belief_network(model, evidence["belief_evidence"])
        
        if "desire_evidence" in evidence:
            self._update_desires(model, evidence["desire_evidence"])
        
        if "affective_evidence" in evidence:
            self.affective_dynamics.update_model(model, evidence["affective_evidence"])
        
        if "trust_evidence" in evidence:
            self._update_trust(model, evidence["trust_evidence"])
        
        model.last_updated = time.time()

    def _update_belief_network(self, model: AgentModel, evidence: Dict):
        for node, value in evidence.items():
            if node in model.belief_network:
                prior = model.belief_network[node]
                likelihood = np.clip(value, 0.1, 0.9)
                posterior = (likelihood * prior) / ((likelihood * prior) + (1 - likelihood) * (1 - prior))
                model.belief_network[node] = posterior

    def _update_desires(self, model: AgentModel, evidence: Dict):
        learning_rate = 0.1
        momentum = 0.9
        error = np.array([evidence.get(d, 0) for d in ["knowledge", "security", "autonomy", "power", "affiliation"]])
        gradient = error - model.desire_vector
        if not hasattr(model, "velocity"):
            model.velocity = np.zeros_like(model.desire_vector)
        model.velocity = momentum * model.velocity + learning_rate * gradient
        model.desire_vector += model.velocity
        model.desire_vector = np.clip(model.desire_vector, 0, 1)

    def _update_trust(self, model: AgentModel, evidence: float):
        model.trust_estimate.update(evidence)
        measurement = model.trust_estimate.mean()
        A, H = 1.0, 1.0
        predicted_state = A * model.trust_kalman_state
        predicted_cov = A * model.trust_kalman_cov * A + self.kalman_Q
        innovation = measurement - H * predicted_state
        innovation_cov = H * predicted_cov * H + self.kalman_R
        kalman_gain = predicted_cov * H / innovation_cov
        model.trust_kalman_state = predicted_state + kalman_gain * innovation
        model.trust_kalman_cov = (1 - kalman_gain * H) * predicted_cov

    def _calculate_system_entropy(self) -> float:
        total_entropy = 0.0
        for model in self.agent_models.values():
            aff_probs = np.array(list(model.affective_state.values())) + 1e-10
            aff_probs /= aff_probs.sum()
            aff_entropy = -np.sum(aff_probs * np.log2(aff_probs))
            
            belief_probs = np.array(list(model.belief_network.values())) + 1e-10
            belief_entropy = -np.sum(belief_probs * np.log2(belief_probs))
            
            total_entropy += aff_entropy + belief_entropy
        
        return total_entropy / max(1, len(self.agent_models))

    def _update_prediction_accuracy(self, query: PerspectiveQuery):
        if "confidence" in query.result:
            self.accuracy_history.append(query.result["confidence"])
            self.module_state["prediction_accuracy"] = np.mean(self.accuracy_history)

    async def _send_response(self, query: PerspectiveQuery):
        if query.source_module_id:
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, query.source_module_id, "perspective_query_response",
                    asdict(query)
                ))
            })

class OrnsteinUhlenbeckProcess:
    def __init__(self, theta: float, mu: float, sigma: float):
        self.theta = theta
        self.mu = mu
        self.sigma = sigma
        self.current_value = mu

    def step(self, dt=0.1):
        dW = np.random.normal(0, np.sqrt(dt))
        self.current_value += self.theta * (self.mu - self.current_value) * dt + self.sigma * dW
        return self.current_value





#inicio del modulo InterpersonalTrustModelingModule 

@dataclass
class TrustAssessmentRequest:
    """Solicitud de evaluación de confianza."""
    request_id: str = field(default_factory=lambda: f"tar_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    target_agent_id: str
    urgency: float = 0.5
    result: Dict[str, Any] = field(default_factory=dict)

@dataclass
class TrustModel:
    """Modelo de confianza con distribuciones Beta jerárquicas."""
    agent_id: str
    competence: Dict[str, deque] = field(default_factory=lambda: {"alpha": deque(maxlen=100), "beta": deque(maxlen=100)})
    benevolence: Dict[str, deque] = field(default_factory=lambda: {"alpha": deque(maxlen=100), "beta": deque(maxlen=100)})
    integrity: Dict[str, deque] = field(default_factory=lambda: {"alpha": deque(maxlen=100), "beta": deque(maxlen=100)})
    last_updated_ts: float = field(default_factory=time.time)
    hyper_alpha: float = 1.0
    hyper_beta: float = 1.0
    decay_rate: float = 0.01
    kalman_state: Dict[str, float] = field(default_factory=lambda: {"competence": 0.5, "benevolence": 0.5, "integrity": 0.5})
    kalman_cov: Dict[str, float] = field(default_factory=lambda: {"competence": 0.1, "benevolence": 0.1, "integrity": 0.1})
    cluster: int = 0

    def get_trust_distribution(self, component: str) -> Tuple[float, float]:
        """Calcula parámetros efectivos con decaimiento."""
        current_time = time.time()
        alphas = np.array([a * np.exp(-self.decay_rate * (current_time - t)) for a, t in self.__dict__[component]["alpha"]])
        betas = np.array([b * np.exp(-self.decay_rate * (current_time - t)) for b, t in self.__dict__[component]["beta"]])
        
        effective_alpha = max(1.0, np.sum(alphas) + self.hyper_alpha)
        effective_beta = max(1.0, np.sum(betas) + self.hyper_beta)
        
        return effective_alpha, effective_beta

    def get_trust_metrics(self, num_mc_samples: int = 100) -> Dict[str, Any]:
        """Retorna métricas con incertidumbre."""
        metrics = {}
        for component in ["competence", "benevolence", "integrity"]:
            alpha, beta_val = self.get_trust_distribution(component)
            samples = np.random.beta(alpha, beta_val, num_mc_samples)
            mean = np.mean(samples)
            var = np.var(samples)
            entropy = -np.sum((samples / samples.sum()) * np.log2(samples / samples.sum() + 1e-10))
            metrics[component] = {
                "mean": mean,
                "variance": var,
                "confidence": 1 - np.sqrt(var),
                "entropy": entropy
            }
        return metrics

class OrnsteinUhlenbeckProcess:
    """Proceso estocástico para decaimiento."""
    def __init__(self, theta: float, mu: float, sigma: float):
        self.theta = theta
        self.mu = mu
        self.sigma = sigma
        self.current_value = mu

    def step(self, dt=0.1):
        dW = np.random.normal(0, np.sqrt(dt))
        self.current_value += self.theta * (self.mu - self.current_value) * dt + self.sigma * dW
        return np.clip(self.current_value, 0.0, 1.0)

class InterpersonalTrustModelingModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 10.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.request_queue: asyncio.PriorityQueue = asyncio.PriorityQueue(maxsize=50)
        self.agent_trust_models: Dict[str, TrustModel] = {}
        self.agent_clusters = AgglomerativeClustering(n_clusters=3)
        self.interaction_graph = nx.DiGraph()
        self.ipd_payoff_matrix = np.array([[3, 0], [5, 1]])
        self.reputation_discount = 0.95
        self.bayesian_network = {
            'competence': ['task_complexity', 'time_pressure'],
            'benevolence': ['shared_values', 'interaction_history'],
            'integrity': ['consistency', 'transparency']
        }
        self.kalman_Q = 0.01
        self.kalman_R = 0.05
        self.num_mc_samples = 100
        self.markov_priority_matrix = np.array([[0.8, 0.2], [0.3, 0.7]])
        
        self.module_state.update({
            "trust_models": 0,
            "adaptive_clusters": 0,
            "bayesian_updates": 0,
            "game_simulations": 0
        })
        self._init_network_parameters()
        self.logger.info(f"{module_name} v27.2 inicializado.")

    def _init_network_parameters(self):
        """Inicializa parámetros de la red bayesiana."""
        self.bn_parameters = {
            'task_complexity': {'mu': 0.5, 'sigma': 0.2},
            'time_pressure': {'alpha': 2, 'beta': 2},
            'shared_values': {'weights': np.array([0.3, 0.7])},
            'interaction_history': {'lambda': 1.0},
            'consistency': {'transition_matrix': np.array([[0.8, 0.2], [0.1, 0.9]])},
            'transparency': {'decay_rate': 0.1}
        }

    async def _update_logic(self):
        """Ciclo principal."""
        await self._process_trust_requests()
        await self._update_trust_models()
        self._cluster_agents()
        await self._run_equilibrium_simulations()

    async def _process_trust_requests(self):
        """Procesa solicitudes con prioridad."""
        requests = []
        while not self.request_queue.empty():
            priority, request = await self.request_queue.get()
            state = 1 if -priority > 0.5 else 0
            next_state = np.random.choice([0, 1], p=self.markov_priority_matrix[state])
            request.urgency = np.clip(request.urgency + 0.1 * (next_state - state), 0.0, 1.0)
            requests.append((-request.urgency, request))
        
        for priority, request in sorted(requests):
            await self.request_queue.put((priority, request))
        
        if requests:
            _, top_request = min(requests, key=lambda x: x[0])
            try:
                await self._assess_trust_with_uncertainty(top_request)
            finally:
                self.request_queue.task_done()

    async def _assess_trust_with_uncertainty(self, request: TrustAssessmentRequest):
        """Evaluación bayesiana con incertidumbre."""
        request.result = {}
        if request.target_agent_id not in self.agent_trust_models:
            self.agent_trust_models[request.target_agent_id] = TrustModel(agent_id=request.target_agent_id)
            self.module_state["trust_models"] += 1
        
        agent_model = self.agent_trust_models[request.target_agent_id]
        
        samples = []
        for _ in range(self.num_mc_samples):
            sample = {}
            for component in ['competence', 'benevolence', 'integrity']:
                alpha, beta_val = agent_model.get_trust_distribution(component)
                sample[component] = np.random.beta(alpha, beta_val)
            samples.append(sample)
        
        trust_metrics = {
            component: {
                'mean': np.mean([s[component] for s in samples]),
                'std': np.std([s[component] for s in samples]),
                'entropy': -np.sum([(s[component] / sum(s.values())) * np.log2(s[component] / sum(s.values()) + 1e-10) for s in samples])
            } for component in ['competence', 'benevolence', 'integrity']
        }
        
        equilibrium_strategy = self._bayesian_game_simulation(trust_metrics)
        
        request.result = {
            'trust_distributions': trust_metrics,
            'equilibrium_strategy': equilibrium_strategy,
            'risk_assessment': self._calculate_trust_risk(samples)
        }
        await self._finalize_request(request)

    def _bayesian_game_simulation(self, trust_metrics: Dict) -> str:
        """Simulación de juego bayesiano."""
        payoff_matrices = []
        for component in ['competence', 'benevolence', 'integrity']:
            mu = trust_metrics[component]['mean']
            sigma = trust_metrics[component]['std']
            adjusted_payoffs = self.ipd_payoff_matrix * (1 - sigma) * mu
            payoff_matrices.append(adjusted_payoffs)
        
        strategies = np.ones(2) / 2
        for _ in range(100):
            expected_payoffs = np.mean([p @ strategies for p in payoff_matrices], axis=0)
            best_response = np.argmax(expected_payoffs)
            strategies = 0.9 * strategies + 0.1 * np.eye(2)[best_response]
        
        strategy_names = ["cooperate", "defect"]
        return strategy_names[np.argmax(strategies)]

    def _calculate_trust_risk(self, samples: List[Dict]) -> Dict:
        """Evalúa riesgo basado en incertidumbre."""
        risk = {}
        for component in ['competence', 'benevolence', 'integrity']:
            values = [s[component] for s in samples]
            risk[component] = {
                'low_trust_prob': np.mean(np.array(values) < 0.3),
                'high_uncertainty': np.std(values) > 0.2
            }
        return risk

    async def _update_trust_models(self):
        """Actualiza modelos con decaimiento estocástico."""
        for agent_id, model in self.agent_trust_models.items():
            ou_process = OrnsteinUhlenbeckProcess(theta=0.1, mu=0.5, sigma=0.05)
            for component in ['competence', 'benevolence', 'integrity']:
                alpha, beta_val = model.get_trust_distribution(component)
                measurement = alpha / (alpha + beta_val)
                A, H = 1.0, 1.0
                predicted_state = A * model.kalman_state[component]
                predicted_cov = A * model.kalman_cov[component] * A + self.kalman_Q
                innovation = measurement - H * predicted_state
                innovation_cov = H * predicted_cov * H + self.kalman_R
                kalman_gain = predicted_cov * H / innovation_cov
                model.kalman_state[component] = predicted_state + kalman_gain * innovation
                model.kalman_cov[component] = (1 - kalman_gain * H) * predicted_cov
            model.last_updated_ts = time.time()

    def _cluster_agents(self):
        """Clustering basado en confianza."""
        if len(self.agent_trust_models) < 3:
            return
        
        features = []
        agent_ids = []
        for agent_id, model in self.agent_trust_models.items():
            metrics = model.get_trust_metrics()
            features.append([
                metrics['competence']['mean'],
                metrics['benevolence']['mean'],
                metrics['integrity']['mean'],
                metrics['competence']['entropy']
            ])
            agent_ids.append(agent_id)
        
        features = np.array(features)
        n_clusters = max(2, min(len(features), 5))
        best_score = -1
        best_clusters = None
        for k in range(2, n_clusters + 1):
            clustering = AgglomerativeClustering(n_clusters=k).fit(features)
            if len(set(clustering.labels_)) > 1:
                score = silhouette_score(features, clustering.labels_)
                if score > best_score:
                    best_score = score
                    best_clusters = clustering.labels_
        
        if best_clusters is not None:
            for agent_id, cluster in zip(agent_ids, best_clusters):
                self.agent_trust_models[agent_id].cluster = cluster
            self.module_state["adaptive_clusters"] = len(set(best_clusters))
            
            for i, agent_id1 in enumerate(agent_ids):
                for j, agent_id2 in enumerate(agent_ids[i+1:], i+1):
                    if best_clusters[i] == best_clusters[j]:
                        self.interaction_graph.add_edge(agent_id1, agent_id2, weight=0.5)

    async def _run_equilibrium_simulations(self):
        """Simulaciones evolutivas."""
        if not self.agent_trust_models:
            return
        
        def replicator_dynamics(x, t, A):
            return x * (A @ x - x @ A @ x) + 0.01 * (1/len(x) - x)
        
        avg_trust = np.mean([
            [m.get_trust_metrics()['competence']['mean'],
             m.get_trust_metrics()['benevolence']['mean']]
            for m in self.agent_trust_models.values()
        ], axis=0)
        
        A = np.array([[3 * avg_trust[0], 0], [5 * avg_trust[1], 1]])
        t = np.linspace(0, 10, 100)
        x0 = np.array([0.5, 0.5])
        x = odeint(replicator_dynamics, x0, t, args=(A,))
        
        self.module_state["game_simulations"] += 1

    def _update_trust_from_interaction(self, agent_id: str, outcome: Dict):
        """Actualización bayesiana."""
        if agent_id not in self.agent_trust_models:
            self.agent_trust_models[agent_id] = TrustModel(agent_id=agent_id)
            self.module_state["trust_models"] += 1
        
        model = self.agent_trust_models[agent_id]
        component = outcome.get("component")
        success = outcome.get("success")
        weight = outcome.get("weight", 1.0)
        
        if component in model.__dict__:
            timestamp = time.time()
            if success:
                model.__dict__[component]["alpha"].append((weight, timestamp))
            else:
                model.__dict__[component]["beta"].append((weight, timestamp))
            
            prior_alpha = np.mean([a for a, _ in model.__dict__[component]["alpha"]] or [1.0])
            prior_beta = np.mean([b for b, _ in model.__dict__[component]["beta"]] or [1.0])
            model.hyper_alpha = max(1.0, prior_alpha * 0.8)
            model.hyper_beta = max(1.0, prior_beta * 0.8)
            
            self.module_state["bayesian_updates"] += 1
            model.last_updated_ts = timestamp

    async def _finalize_request(self, request: TrustAssessmentRequest):
        """Envía respuesta."""
        if request.original_correlation_id:
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, request.source_module_id, "trust_assessment_response",
                    asdict(request),
                    correlation_id=request.original_correlation_id
                ))
            })

    async def _process_specific_event(self, event_type: str, payload: Dict, full_message: Optional['IlyukMessageStructure'] = None):
        """Procesa eventos específicos."""
        if not full_message:
            return
        
        if event_type == "request_trust_assessment":
            urgency = payload.get("urgency", 0.5)
            priority = -np.log(1 - np.clip(urgency, 1e-10, 1-1e-10))
            request = TrustAssessmentRequest(
                source_module_id=full_message.source_module_id,
                original_correlation_id=full_message.correlation_id,
                target_agent_id=payload.get("target_agent_id", ""),
                urgency=urgency
            )
            if not request.target_agent_id:
                self.logger.error("Falta 'target_agent_id' en la solicitud.")
                return
            await self.request_queue.put((priority, request))
        
        elif event_type == "interaction_outcome_report":
            self._update_trust_from_interaction(
                payload.get("agent_id", ""),
                {
                    "component": payload.get("component", ""),
                    "success": payload.get("success", False),
                    "weight": payload.get("weight", 1.0)
                }
            )




#inicio del modulo AdaptiveSocialNormLearningModule 

@dataclass
class SocialNorm:
    """Modelo de norma social con dinámica bayesiana."""
    norm_id: str
    context: str
    norm_type: str  # "prescriptive" o "proscriptive"
    description: str
    strength: float = 0.5
    influence_radius: float = 1.0
    adoption_rate: float = 0.05
    decay_rate: float = 0.01
    network_embedding: np.ndarray = field(default_factory=lambda: np.zeros(10))

    def update_strength(self, success: bool):
        """Actualización bayesiana con decaimiento."""
        delta = self.adoption_rate * (2 * int(success) - 1)
        self.strength = np.clip(self.strength * (1 - self.decay_rate) + delta, 0.0, 1.0)

@dataclass
class NormativeGuidanceRequest:
    """Solicitud de guía normativa."""
    request_id: str = field(default_factory=lambda: f"ngr_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    action_to_evaluate: Dict[str, Any]
    social_context: str
    priority: float = 0.5
    result: Dict[str, Any] = field(default_factory=dict)

class OrnsteinUhlenbeckProcess:
    """Proceso estocástico para dinámicas."""
    def __init__(self, theta: float, mu: float, sigma: float):
        self.theta = theta
        self.mu = mu
        self.sigma = sigma
        self.current_value = mu

    def step(self, dt=0.1):
        dW = np.random.normal(0, np.sqrt(dt))
        self.current_value += self.theta * (self.mu - self.current_value) * dt + self.sigma * dW
        return np.clip(self.current_value, 0.0, 1.0)

class AdaptiveSocialNormLearningModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 5.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.inferred_norms: Dict[str, SocialNorm] = {}
        self.interaction_log: deque = deque(maxlen=100)
        self.guidance_request_queue: asyncio.PriorityQueue = asyncio.PriorityQueue(maxsize=50)
        self.norm_network = nx.DiGraph()
        self.moral_fields = {
            'autonomy': BayesianRidge(),
            'fairness': BayesianRidge(),
            'loyalty': BayesianRidge()
        }
        self.SIR_params = {'beta': 0.3, 'gamma': 0.1, 'mu': 0.01}
        self.learning_rate = 0.01
        self.temperature = 1.0
        self.num_mc_samples = 100
        self.markov_priority_matrix = np.array([[0.8, 0.2], [0.3, 0.7]])
        
        self.module_state.update({
            "moral_field_updates": 0,
            "norm_diffusions": 0,
            "conflict_resolutions": 0,
            "norms_inferred_count": 0
        })
        self.logger.info(f"{module_name} v27.2 inicializado.")

    async def _update_logic(self):
        """Ciclo principal."""
        await self._process_guidance_requests()
        self._diffuse_norms_epidemiological()
        await self._update_moral_fields()
        self._resolve_norm_conflicts()
        self._analyze_interaction_log_and_infer_norms()

    async def _process_guidance_requests(self):
        """Procesa solicitudes con prioridad."""
        requests = []
        while not self.guidance_request_queue.empty():
            priority, request = await self.guidance_request_queue.get()
            state = 1 if -priority > 0.5 else 0
            next_state = np.random.choice([0, 1], p=self.markov_priority_matrix[state])
            request.priority = np.clip(request.priority + 0.1 * (next_state - state), 0.0, 1.0)
            requests.append((-request.priority, request))
        
        for priority, request in sorted(requests):
            await self.guidance_request_queue.put((priority, request))
        
        if requests:
            _, top_request = min(requests, key=lambda x: x[0])
            try:
                warnings, recommendations = self._check_action_against_norms(
                    top_request.action_to_evaluate, top_request.social_context
                )
                top_request.result = {"warnings": warnings, "recommendations": recommendations}
                await self._finalize_request(top_request)
            finally:
                self.guidance_request_queue.task_done()

    def _diffuse_norms_epidemiological(self):
        """Modelo SIR para difusión de normas."""
        total_strength = sum(n.strength for n in self.inferred_norms.values())
        susceptible = max(0.0, 1.0 - total_strength)
        infected = total_strength
        recovered = max(0.0, 1.0 - susceptible - infected)
        
        dsdt = -self.SIR_params['beta'] * susceptible * infected
        didt = (self.SIR_params['beta'] * susceptible - self.SIR_params['gamma'] + self.SIR_params['mu']) * infected
        drdt = self.SIR_params['gamma'] * infected
        
        for norm in self.inferred_norms.values():
            norm.strength += didt * norm.adoption_rate * self.update_interval
            norm.strength = np.clip(norm.strength, 0.0, 1.0)
        
        self.module_state["norm_diffusions"] += 1

    async def _update_moral_fields(self):
        """Actualiza campos morales con regresión bayesiana."""
        X = []
        y = {k: [] for k in self.moral_fields}
        
        for interaction in self.interaction_log:
            context_embed = self._get_context_embedding(interaction.get('social_context', 'general'))
            X.append(context_embed)
            for field in self.moral_fields:
                y[field].append(interaction.get(f'{field}_valence', 0.0))
        
        if len(X) > 10:
            X = np.array(X)
            for field, model in self.moral_fields.items():
                model.fit(X, np.array(y[field]))
                self.module_state["moral_field_updates"] += 1

    def _resolve_norm_conflicts(self):
        """Resuelve conflictos con dinámica replicator."""
        norms = list(self.inferred_norms.values())
        if len(norms) < 2:
            return
        
        payoff_matrix = np.zeros((len(norms), len(norms)))
        for i, n1 in enumerate(norms):
            for j, n2 in enumerate(norms):
                payoff_matrix[i,j] = self._norm_compatibility(n1, n2)
        
        def replicator(x, t):
            mutation = 0.01 * (1/len(x) - x)
            return x * (payoff_matrix @ x - x @ payoff_matrix @ x) + mutation
        
        x0 = np.array([n.strength for n in norms])
        x0 = softmax(x0 / self.temperature)
        equilibria = odeint(replicator, x0, [0, 10])
        
        for i, norm in enumerate(norms):
            norm.strength = np.clip(equilibria[-1][i], 0.0, 1.0)
        
        self.norm_network.clear()
        for i, n1 in enumerate(norms):
            for j, n2 in enumerate(norms[i+1:], i+1):
                if payoff_matrix[i,j] > 0.5:
                    self.norm_network.add_edge(n1.norm_id, n2.norm_id, weight=payoff_matrix[i,j])
        
        self.module_state["conflict_resolutions"] += 1

    def _norm_compatibility(self, norm1: SocialNorm, norm2: SocialNorm) -> float:
        """Mide compatibilidad entre normas."""
        samples = np.random.normal(
            norm1.network_embedding - norm2.network_embedding,
            0.05, (self.num_mc_samples, len(norm1.network_embedding))
        )
        distances = np.linalg.norm(samples, axis=1)
        return np.mean(np.exp(-distances**2 / 0.1))

    def _check_action_against_norms(self, action: Dict, context: str) -> Tuple[List, List]:
        """Evalúa acciones contra normas."""
        warnings = []
        recommendations = []
        
        context_embed = self._get_context_embedding(context)
        action_embed = self._get_action_embedding(action)
        
        moral_scores = {
            field: model.predict([context_embed])[0] if hasattr(model, 'predict') else 0.0
            for field, model in self.moral_fields.items()
        }
        
        samples = {
            field: np.random.normal(score, 0.05, self.num_mc_samples)
            for field, score in moral_scores.items()
        }
        
        thresholds = {'autonomy': 0.7, 'fairness': 0.6, 'loyalty': 0.5}
        
        for norm in self.inferred_norms.values():
            if norm.context != context:
                continue
            
            similarity = self._action_norm_similarity(action, norm)
            if similarity > 0.8 and norm.norm_type == "proscriptive":
                violation_score = self._calculate_violation(action, norm)
                if violation_score > thresholds.get(norm.context.split('_')[0], 0.5):
                    warnings.append({
                        'norm_id': norm.norm_id,
                        'severity': np.mean([violation_score > t for t in samples[norm.context.split('_')[0]]]),
                        'moral_impact': {k: np.mean(v) for k, v in samples.items()}
                    })
        
        if not warnings:
            rec_score = np.mean([np.mean(samples[field]) for field in moral_scores])
            if rec_score > 0.7:
                recommendations.append({
                    'type': 'moral_enhancement',
                    'score': rec_score,
                    'suggested_actions': self._generate_moral_actions(context_embed)
                })
        
        return warnings, recommendations

    def _action_norm_similarity(self, action: Dict, norm: SocialNorm) -> float:
        """Calcula similitud entre acción y norma."""
        action_embed = self._get_action_embedding(action)
        return np.exp(-np.linalg.norm(action_embed - norm.network_embedding)**2 / 0.1)

    def _calculate_violation(self, action: Dict, norm: SocialNorm) -> float:
        """Calcula severidad de violación."""
        return np.clip(1.0 - self._action_norm_similarity(action, norm), 0.0, 1.0)

    def _generate_moral_actions(self, context_embed: np.ndarray) -> List[Dict]:
        """Genera acciones moralmente óptimas."""
        actions = []
        for _ in range(3):
            action_embed = context_embed + np.random.normal(0, 0.1, len(context_embed))
            moral_score = np.mean([
                model.predict([action_embed])[0] if hasattr(model, 'predict') else 0.0
                for model in self.moral_fields.values()
            ])
            actions.append({'action_embed': action_embed.tolist(), 'moral_score': moral_score})
        return sorted(actions, key=lambda x: x['moral_score'], reverse=True)[:2]

    def _get_context_embedding(self, context: str) -> np.ndarray:
        """Genera embedding para contexto."""
        return np.random.normal(0, 0.1, 10)  # Simulación simple

    def _get_action_embedding(self, action: Dict) -> np.ndarray:
        """Genera embedding para acción."""
        return np.random.normal(0, 0.1, 10)  # Simulación simple

    def _analyze_interaction_log_and_infer_norms(self):
        """Infiere normas con clustering."""
        if len(self.interaction_log) < 50:
            return
        
        embeddings = [self._get_context_embedding(i.get('social_context', 'general')) for i in self.interaction_log]
        embeddings = np.array(embeddings)
        
        n_clusters = max(2, min(len(embeddings) // 10, 5))
        best_score = -1
        best_labels = None
        for k in range(2, n_clusters + 1):
            kmeans = KMeans(n_clusters=k, random_state=42).fit(embeddings)
            if len(set(kmeans.labels_)) > 1:
                score = silhouette_score(embeddings, kmeans.labels_)
                if score > best_score:
                    best_score = score
                    best_labels = kmeans.labels_
        
        if best_labels is not None:
            for cluster_id in set(best_labels):
                norm_id = f"norm_{cluster_id}_{uuid.uuid4().hex[:8]}"
                if norm_id not in self.inferred_norms:
                    cluster_embeds = embeddings[best_labels == cluster_id]
                    self.inferred_norms[norm_id] = SocialNorm(
                        norm_id=norm_id,
                        context="general",
                        norm_type="prescriptive",
                        description=f"Norma cluster {cluster_id}",
                        strength=np.mean([i.get('moral_score', 0.5) for i in self.interaction_log if best_labels[list(self.interaction_log).index(i)] == cluster_id]),
                        network_embedding=np.mean(cluster_embeds, axis=0)
                    )
                    self.module_state["norms_inferred_count"] += 1

    def _calculate_context_entropy(self, context: str) -> float:
        """Calcula entropía del contexto."""
        chars = list(context)
        probs = np.array([chars.count(c) / len(chars) for c in set(chars)]) + 1e-10
        return -np.sum(probs * np.log2(probs))

    async def _finalize_request(self, request: NormativeGuidanceRequest):
        """Envía respuesta."""
        if request.original_correlation_id:
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, request.source_module_id, "normative_guidance_response",
                    asdict(request),
                    correlation_id=request.original_correlation_id
                ))
            })

    async def _process_specific_event(self, event_type: str, payload: Dict, full_message: Optional['IlyukMessageStructure'] = None):
        """Procesa eventos específicos."""
        if not full_message:
            return
        
        if event_type == "request_normative_guidance":
            context_entropy = self._calculate_context_entropy(payload.get('social_context', 'general'))
            priority = 1.0 / (1.0 + np.exp(-context_entropy))
            
            request = NormativeGuidanceRequest(
                source_module_id=full_message.source_module_id,
                original_correlation_id=full_message.correlation_id,
                action_to_evaluate=payload.get('action_to_evaluate', {}),
                social_context=payload.get('social_context', 'general'),
                priority=priority
            )
            if not request.action_to_evaluate or not request.social_context:
                self.logger.error("Falta 'action_to_evaluate' o 'social_context' en la solicitud.")
                return
            await self.guidance_request_queue.put((-priority, request))
        
        elif event_type == "interaction_outcome_report":
            self.interaction_log.append({
                'social_context': payload.get('context', 'general'),
                'moral_score': payload.get('moral_score', 0.5),
                'autonomy_valence': payload.get('autonomy_valence', 0.0),
                'fairness_valence': payload.get('fairness_valence', 0.0),
                'loyalty_valence': payload.get('loyalty_valence', 0.0),
                'timestamp': time.time()
            })





#inicio del modulo ReflectiveSelfAwarenessModule 

@dataclass
class BetaDistribution:
    """Distribución Beta para rasgos."""
    α: float
    β: float

    def mean(self):
        return self.α / (self.α + self.β)

    def update(self, evidence: float):
        self.α += evidence
        self.β += 1 - evidence

    def entropy(self):
        return beta(self.α, self.β).entropy()

@dataclass
class SelfModel:
    """Modelo de rasgos de personalidad emergentes."""
    timestamp: float = field(default_factory=time.time)
    openness_to_experience: BetaDistribution = field(default_factory=lambda: BetaDistribution(α=5, β=5))
    conscientiousness: BetaDistribution = field(default_factory=lambda: BetaDistribution(α=5, β=5))
    extraversion_sociality: BetaDistribution = field(default_factory=lambda: BetaDistribution(α=5, β=5))
    agreeableness_cooperation: BetaDistribution = field(default_factory=lambda: BetaDistribution(α=5, β=5))
    neuroticism_stability_inv: BetaDistribution = field(default_factory=lambda: BetaDistribution(α=5, β=5))

    def get_traits_mean(self) -> Dict[str, float]:
        """Retorna la media de los rasgos."""
        return {
            "openness_to_experience": self.openness_to_experience.mean(),
            "conscientiousness": self.conscientiousness.mean(),
            "extraversion_sociality": self.extraversion_sociality.mean(),
            "agreeableness_cooperation": self.agreeableness_cooperation.mean(),
            "neuroticism_stability_inv": self.neuroticism_stability_inv.mean()
        }

    def get_traits_entropy(self) -> float:
        """Calcula la entropía total de los rasgos."""
        entropies = [
            self.openness_to_experience.entropy(),
            self.conscientiousness.entropy(),
            self.extraversion_sociality.entropy(),
            self.agreeableness_cooperation.entropy(),
            self.neuroticism_stability_inv.entropy()
        ]
        return np.mean(entropies)

class OrnsteinUhlenbeckProcess:
    """Proceso estocástico para evolución de rasgos."""
    def __init__(self, theta: float, mu: float, sigma: float):
        self.theta = theta
        self.mu = mu
        self.sigma = sigma
        self.current_value = mu

    def step(self, dt=0.1):
        dW = np.random.normal(0, np.sqrt(dt))
        self.current_value += self.theta * (self.mu - self.current_value) * dt + self.sigma * dW
        return np.clip(self.current_value, 0.0, 1.0)

class ReflectiveSelfAwarenessModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 150.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.self_model = SelfModel()
        self.analysis_history: deque[SelfModel] = deque(maxlen=20)
        self.kalman_state: Dict[str, float] = {
            "openness_to_experience": 0.5,
            "conscientiousness": 0.5,
            "extraversion_sociality": 0.5,
            "agreeableness_cooperation": 0.5,
            "neuroticism_stability_inv": 0.5
        }
        self.kalman_cov: Dict[str, float] = {k: 0.1 for k in self.kalman_state}
        self.kalman_Q = 0.01
        self.kalman_R = 0.05
        self.num_mc_samples = 100
        
        self.module_state.update({
            "self_analysis_cycles_run": 0,
            "last_major_trait_shift": "none",
            "model_entropy": 0.0
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado.")

    async def _update_logic(self):
        """Ciclo principal de auto-análisis."""
        self.logger.info("RSAM: Iniciando ciclo de auto-análisis reflexivo...")
        self._create_managed_task(self._run_self_analysis_cycle())

    async def _run_self_analysis_cycle(self):
        """Orquesta el análisis introspectivo."""
        self.module_state["self_analysis_cycles_run"] += 1
        
        try:
            historical_data = await self._gather_data_for_reflection()
            new_self_model = self._infer_personality_traits(historical_data)
            
            if self._has_model_changed_significantly(new_self_model):
                self.self_model = new_self_model
                self.analysis_history.append(new_self_model)
                self.module_state["model_entropy"] = new_self_model.get_traits_entropy()
                await self._broadcast_self_model_update()
        
        except Exception as e:
            self.logger.error(f"Fallo en el ciclo de auto-análisis: {e}", exc_info=True)

    async def _gather_data_for_reflection(self) -> Dict[str, Any]:
        """Obtiene datos de módulos relevantes."""
        data = {
            "recent_memories": [],
            "dominant_nuances_history": [],
            "trust_model_avg": 0.5,
            "goal_success_rate": 0.5,
            "emotional_variance": 0.5,
            "interaction_count": 0
        }
        
        modules_to_query = ["NarrativeSelf", "EmotionalNuanceSynth", "InterpersonalTrustModeling"]
        tasks = []
        
        for module_name in modules_to_query:
            correlation_id = f"rsam_query_{uuid.uuid4().hex[:8]}"
            tasks.append(self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, module_name, "self_reflection_data_request",
                    {"query": f"Provide recent data for {module_name}"},
                    correlation_id=correlation_id
                ))
            }))
        
        await asyncio.gather(*tasks)
        
        # Simulación de respuestas (en producción, esperar respuestas reales)
        await asyncio.sleep(0.5)
        data.update({
            "recent_memories": [{"type": "creative_synthesis"}, {"type": "goal_completed"}],
            "dominant_nuances_history": ["curiosity", "joy", "curiosity"],
            "trust_model_avg": 0.75,
            "goal_success_rate": 0.8,
            "emotional_variance": 0.2,
            "interaction_count": 10
        })
        
        for key in ["trust_model_avg", "goal_success_rate", "emotional_variance"]:
            measurement = data[key]
            A, H = 1.0, 1.0
            predicted_state = A * self.kalman_state.get(key, 0.5)
            predicted_cov = A * self.kalman_cov.get(key, 0.1) * A + self.kalman_Q
            innovation = measurement - H * predicted_state
            innovation_cov = H * predicted_cov * H + self.kalman_R
            kalman_gain = predicted_cov * H / innovation_cov
            self.kalman_state[key] = predicted_state + kalman_gain * innovation
            self.kalman_cov[key] = (1 - kalman_gain * H) * predicted_cov
            data[key] = self.kalman_state[key]
        
        return data

    def _infer_personality_traits(self, data: Dict) -> SelfModel:
        """Infiere rasgos con lógica bayesiana."""
        new_model = SelfModel()
        ou_process = OrnsteinUhlenbeckProcess(theta=0.1, mu=0.5, sigma=0.05)
        
        # Openness: basado en acciones creativas
        creative_actions = len([mem for mem in data["recent_memories"] if mem["type"] == "creative_synthesis"])
        evidence = np.clip(0.4 + creative_actions * 0.2, 0.1, 0.9)
        new_model.openness_to_experience.update(evidence * 5)
        ou_process.current_value = new_model.openness_to_experience.mean()
        new_model.openness_to_experience = BetaDistribution(
            α=5 * ou_process.step(self.update_interval),
            β=5 * (1 - ou_process.step(self.update_interval))
        )
        
        # Conscientiousness: basado en éxito de metas
        evidence = data.get("goal_success_rate", 0.5)
        new_model.conscientiousness.update(evidence * 5)
        ou_process.current_value = new_model.conscientiousness.mean()
        new_model.conscientiousness = BetaDistribution(
            α=5 * ou_process.step(self.update_interval),
            β=5 * (1 - ou_process.step(self.update_interval))
        )
        
        # Extraversion: basado en interacciones
        interaction_factor = data.get("interaction_count", 0) / 10
        evidence = np.clip(0.5 + interaction_factor * 0.2, 0.1, 0.9)
        new_model.extraversion_sociality.update(evidence * 5)
        ou_process.current_value = new_model.extraversion_sociality.mean()
        new_model.extraversion_sociality = BetaDistribution(
            α=5 * ou_process.step(self.update_interval),
            β=5 * (1 - ou_process.step(self.update_interval))
        )
        
        # Agreeableness: basado en confianza
        evidence = data.get("trust_model_avg", 0.5)
        new_model.agreeableness_cooperation.update(evidence * 5)
        ou_process.current_value = new_model.agreeableness_cooperation.mean()
        new_model.agreeableness_cooperation = BetaDistribution(
            α=5 * ou_process.step(self.update_interval),
            β=5 * (1 - ou_process.step(self.update_interval))
        )
        
        # Neuroticism: basado en varianza emocional
        evidence = np.clip(1.0 - data.get("emotional_variance", 0.5) * 2.0, 0.1, 0.9)
        new_model.neuroticism_stability_inv.update(evidence * 5)
        ou_process.current_value = new_model.neuroticism_stability_inv.mean()
        new_model.neuroticism_stability_inv = BetaDistribution(
            α=5 * ou_process.step(self.update_interval),
            β=5 * (1 - ou_process.step(self.update_interval))
        )
        
        samples = {
            trait: np.random.beta(getattr(new_model, trait).α, getattr(new_model, trait).β, self.num_mc_samples)
            for trait in ["openness_to_experience", "conscientiousness", "extraversion_sociality",
                          "agreeableness_cooperation", "neuroticism_stability_inv"]
        }
        for trait in samples:
            setattr(new_model, trait, BetaDistribution(
                α=5 * np.mean(samples[trait]),
                β=5 * (1 - np.mean(samples[trait]))
            ))
        
        for trait in ["openness_to_experience", "conscientiousness", "extraversion_sociality",
                      "agreeableness_cooperation", "neuroticism_stability_inv"]:
            old_val = getattr(self.self_model, trait).mean()
            new_val = getattr(new_model, trait).mean()
            smoothed_val = old_val * 0.7 + new_val * 0.3
            setattr(new_model, trait, BetaDistribution(
                α=5 * smoothed_val,
                β=5 * (1 - smoothed_val)
            ))
        
        return new_model

    def _has_model_changed_significantly(self, new_model: SelfModel) -> bool:
        """Compara modelos usando divergencia KL."""
        kl_divs = []
        for trait in ["openness_to_experience", "conscientiousness", "extraversion_sociality",
                      "agreeableness_cooperation", "neuroticism_stability_inv"]:
            old_dist = getattr(self.self_model, trait)
            new_dist = getattr(new_model, trait)
            old_samples = np.random.beta(old_dist.α, old_dist.β, self.num_mc_samples)
            new_samples = np.random.beta(new_dist.α, new_dist.β, self.num_mc_samples)
            old_probs = np.histogram(old_samples, bins=50, density=True)[0] + 1e-10
            new_probs = np.histogram(new_samples, bins=50, density=True)[0] + 1e-10
            kl_div = np.sum(old_probs * np.log(old_probs / new_probs))
            kl_divs.append(kl_div)
        
        mean_kl = np.mean(kl_divs)
        if mean_kl > 0.1:
            self.module_state["last_major_trait_shift"] = time.strftime("%Y-%m-%d %H:%M:%S")
            return True
        return False

    async def _broadcast_self_model_update(self):
        """Notifica cambios en el auto-modelo."""
        self.logger.warning(f"AUTO-MODELO ACTUALIZADO. Nuevos rasgos: {self.self_model.get_traits_mean()}")
        priority = "high" if self.self_model.get_traits_entropy() > 1.0 else "medium"
        await self.emit_event_to_core({
            "type": "self_model_updated",
            "content": {"new_self_model": asdict(self.self_model)},
            "priority": priority
        })

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        """Maneja solicitudes de auto-modelo."""
        if event_type == "request_current_self_model" and full_message:
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, full_message.source_module_id,
                    "current_self_model_response",
                    {"self_model": asdict(self.self_model)},
                    correlation_id=full_message.correlation_id
                ))
            })




#inicio del modulo AdvancedTCHNModule 


class AdvancedTCHNModule(BaseAsyncModule):
    """
    Hyperdimensional Coherent Topological Network (TCHN)
    Versión mejorada con métodos de Monte Carlo y PDEs explícitas.
    """
    DEFAULT_UPDATE_INTERVAL = 0.1

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.num_nodes: int = 100
        self.node_dimensions: int = 5
        self.diffusion_constant_D: float = 0.1
        self.noise_sigma: float = 0.01
        self.connectivity_update_rate: float = 0.005
        self.network_size_adaptation_rate: float = 0.05
        self.ou_theta: float = 0.1
        self.entropy_regularization: float = 0.01
        # Nuevos parámetros para Monte Carlo y PDE
        self.num_mc_samples: int = 1000  # Muestras para Monte Carlo
        self.pde_dx: float = 0.1  # Paso espacial para PDE
        self.pde_dt: float = 0.01  # Paso temporal para PDE
        self.pde_diffusion: float = 0.05  # Coeficiente de difusión en PDE
        self.pde_reaction_rate: float = 0.1  # Tasa de reacción en PDE
        self.node_states: np.ndarray = np.random.uniform(-1, 1, (self.num_nodes, self.node_dimensions))
        self.connectivity_matrix: np.ndarray = self._initialize_connectivity()
        self.noise_state: np.ndarray = np.zeros((self.num_nodes, self.node_dimensions))
        # Densidad de nodos para PDE (malla 1D)
        self.grid_size: int = 100
        self.node_density: np.ndarray = np.ones(self.grid_size) * (self.num_nodes / self.grid_size)
        self.module_state.update({
            "current_phi_tchn": 0.0,
            "network_energy": 0.0,
            "num_nodes": self.num_nodes,
        })
        self.logger.info(f"{self.module_name} v27.3 inicializado con {self.num_nodes} nodos de {self.node_dimensions} dimensiones.")

    def _initialize_connectivity(self) -> np.ndarray:
        matrix = np.random.rand(self.num_nodes, self.num_nodes)
        np.fill_diagonal(matrix, 0)
        row_sums = matrix.sum(axis=1, keepdims=True)
        return matrix / np.where(row_sums == 0, 1, row_sums)

    async def _update_logic(self):
        current_phi_tchn = self._calculate_coherence_phi()
        self._evolve_node_states()
        self._evolve_connectivity(current_phi_tchn)
        self._adapt_network_size()
        self.module_state["current_phi_tchn"] = current_phi_tchn
        self.module_state["network_energy"] = np.sum(np.square(self.node_states))
        self.module_state["num_nodes"] = self.num_nodes

    def _evolve_node_states(self):
        def dynamics(t, states):
            states = states.reshape(self.num_nodes, self.node_dimensions)
            weighted_neighbor_states = np.dot(self.connectivity_matrix, states)
            diffusion_term = self.diffusion_constant_D * (weighted_neighbor_states - states)
            energy_grad = -0.05 * states
            pairwise_diff = states[:, np.newaxis, :] - states[np.newaxis, :, :]
            kuramoto_term = 0.02 * np.mean(np.sin(pairwise_diff), axis=1)
            dW = np.random.randn(self.num_nodes, self.node_dimensions)
            noise_term = -self.ou_theta * self.noise_state + self.noise_sigma * dW
            self.noise_state += noise_term * self.update_interval
            return (energy_grad + diffusion_term + kuramoto_term + noise_term).ravel()
        states_flat = self.node_states.ravel()
        result = integrate.odeint(dynamics, states_flat, [0, self.update_interval], tfirst=True)
        self.node_states = result[-1].reshape(self.num_nodes, self.node_dimensions)
        self.node_states = np.tanh(self.node_states)

    def _evolve_connectivity(self, current_phi_tchn: float):
        cov_matrix = np.cov(self.node_states.T)
        co_activation = cov_matrix / (np.sqrt(np.diag(cov_matrix))[:, None] * np.sqrt(np.diag(cov_matrix))[None, :])
        np.fill_diagonal(co_activation, 0)
        entropy_term = -self.entropy_regularization * np.log(np.clip(self.connectivity_matrix, 1e-10, 1))
        delta_connectivity = self.connectivity_update_rate * (co_activation * (current_phi_tchn**2) + entropy_term)
        noise = np.random.normal(0, 0.001, self.connectivity_matrix.shape)
        self.connectivity_matrix += delta_connectivity + noise
        row_sums = self.connectivity_matrix.sum(axis=1, keepdims=True)
        self.connectivity_matrix = self.connectivity_matrix / np.where(row_sums == 0, 1, row_sums)
        self.connectivity_matrix = np.clip(self.connectivity_matrix, 0, 1)

    def _calculate_coherence_phi(self) -> float:
        """
        Calcula Φ usando Monte Carlo para estimar la entropía diferencial.
        """
        # Ajustar un modelo de mezcla gaussiana a los estados
        gmm = GaussianMixture(n_components=3, covariance_type='full', max_iter=100)
        gmm.fit(self.node_states)
        
        # Función para evaluar log-probabilidad
        def log_prob(states):
            return gmm.score_samples(states)
        
        # Monte Carlo para entropía total
        samples = gmm.sample(self.num_mc_samples)[0]
        log_probs = log_prob(samples)
        entropy_total = -np.mean(log_probs)
        
        # Dividir en subredes y calcular entropías parciales
        indices = np.random.permutation(self.num_nodes)
        split = self.num_nodes // 2
        subnet1, subnet2 = indices[:split], indices[split:]
        states1, states2 = self.node_states[subnet1], self.node_states[subnet2]
        
        gmm1 = GaussianMixture(n_components=3, covariance_type='full', max_iter=100)
        gmm1.fit(states1)
        samples1 = gmm1.sample(self.num_mc_samples)[0]
        entropy1 = -np.mean(gmm1.score_samples(samples1))
        
        gmm2 = GaussianMixture(n_components=3, covariance_type='full', max_iter=100)
        gmm2.fit(states2)
        samples2 = gmm2.sample(self.num_mc_samples)[0]
        entropy2 = -np.mean(gmm2.score_samples(samples2))
        
        # Información mutua aproximada
        mutual_info = entropy1 + entropy2 - entropy_total
        coherence = np.clip(mutual_info, 0.0, 1.0)
        return coherence

    def _adapt_network_size(self):
        """
        Adapta el tamaño de la red usando una PDE de reacción-difusión.
        """
        system_coherence = self.core_recombinator.global_state.coherence_score
        
        # Resolver PDE de reacción-difusión para la densidad de nodos
        density = self.node_density.copy()
        for _ in range(int(self.update_interval / self.pde_dt)):
            # Difusión: segunda derivada espacial
            d2_density = (np.roll(density, 1) + np.roll(density, -1) - 2 * density) / (self.pde_dx ** 2)
            # Reacción: crecimiento basado en coherencia
            reaction = self.pde_reaction_rate * density * (system_coherence - density / (self.grid_size / 50))
            # Actualización
            density += self.pde_dt * (self.pde_diffusion * d2_density + reaction)
            density = np.clip(density, 0, np.inf)
        
        self.node_density = density
        
        # Calcular número target de nodos integrando la densidad
        target_num_nodes = int(np.sum(self.node_density) * self.pde_dx)
        num_change = int((target_num_nodes - self.num_nodes) * self.network_size_adaptation_rate)
        
        if num_change > 0:
            new_states = np.random.uniform(-1, 1, (num_change, self.node_dimensions))
            self.node_states = np.vstack([self.node_states, new_states])
            new_connectivity = np.random.rand(num_change, self.num_nodes + num_change)
            self.connectivity_matrix = np.vstack([np.hstack([self.connectivity_matrix, np.random.rand(self.num_nodes, num_change)]), new_connectivity])
            self.num_nodes += num_change
        elif num_change < 0:
            activity = np.sum(np.abs(self.node_states), axis=1)
            indices_to_remove = np.argsort(activity)[:abs(num_change)]
            keep_indices = np.setdiff1d(np.arange(self.num_nodes), indices_to_remove)
            self.node_states = self.node_states[keep_indices]
            self.connectivity_matrix = self.connectivity_matrix[keep_indices][:, keep_indices]
            self.num_nodes -= abs(num_change)
        
        # Normalizar conectividad
        row_sums = self.connectivity_matrix.sum(axis=1, keepdims=True)
        self.connectivity_matrix = self.connectivity_matrix / np.where(row_sums == 0, 1, row_sums)

    async def _process_specific_event(self, event_type: str, payload: Dict, full_message: Optional['IlyukMessageStructure'] = None):
        if event_type == "apply_cognitive_perturbation":
            intensity = payload.get("intensity", 0.1)
            target_nodes_ratio = payload.get("ratio", 0.2)
            G = nx.from_numpy_array(self.connectivity_matrix)
            centrality = np.array(list(nx.eigenvector_centrality(G, max_iter=1000).values()))
            top_nodes = np.argsort(centrality)[-int(self.num_nodes * target_nodes_ratio):]
            perturbation = np.zeros((self.num_nodes, self.node_dimensions))
            perturbation[top_nodes] = np.random.randn(len(top_nodes), self.node_dimensions) * intensity
            for _ in range(3):
                perturbation = perturbation + self.diffusion_constant_D * np.dot(self.connectivity_matrix, perturbation)
            self.node_states += perturbation
            self.node_states = np.tanh(self.node_states)
            self.logger.info(f"Perturbación cognitiva aplicada a {len(top_nodes)} nodos clave con intensidad {intensity}.")



#inicio del modulo MetaCognitiveSelfCorrectionModule 

@dataclass
class CognitiveTrace:
    trace_id: str = field(default_factory=lambda: f"trace_{uuid.uuid4().hex[:6]}")
    timestamp: float = field(default_factory=time.time)
    event_type: str
    source_module_id: str
    context: Dict[str, Any]
    outcome: Dict[str, Any]

@dataclass
class CorrectiveDirective:
    directive_id: str
    bias_detected: str
    description: str
    corrective_action: Dict[str, Any]
    start_time: float
    duration_s: float
    is_active: bool = True

class MetaCognitiveSelfCorrectionModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 180.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.cognitive_trace_log: deque[CognitiveTrace] = deque(maxlen=200)
        self.active_directives: Dict[str, CorrectiveDirective] = {}
        self.active_responses: Dict[str, asyncio.Future] = {}
        self.directive_graph = nx.DiGraph()
        self.coherence_field: np.ndarray = np.array([1.0])
        self.num_mc_samples: int = 500
        self.sde_sigma: float = 0.01
        self.pde_dx: float = 0.1
        self.pde_dt: float = 0.01
        self.pde_diffusion: float = 0.05
        self.planning_fallacy_threshold: float = 1.3
        self.planning_fallacy_strike_count: int = 5
        self.confirmation_bias_threshold: float = 0.8
        self.confirmation_bias_strike_count: int = 5
        self.module_state.update({
            "traces_logged": 0,
            "biases_detected": 0,
            "directives_issued": 0,
            "active_directives_count": 0,
            "directive_coherence_score": 1.0
        })
        self.bias_detections: List[float] = []
        self.logger.info(f"{self.module_name} v27.2 inicializado con modelado avanzado.")

    async def _update_logic(self):
        self.logger.info("MCSM: Iniciando ciclo de análisis metacognitivo...")
        await self._analyze_traces_for_biases()
        await self._prune_expired_directives()
        self.module_state["active_directives_count"] = len(self.active_directives)
        # Actualizar coherencia entre directivas
        n_directives = self.directive_graph.number_of_nodes()
        if len(self.coherence_field) != max(n_directives, 1):
            self.coherence_field = np.ones(max(n_directives, 1)) * self.module_state["directive_coherence_score"]
        conflicts = len(list(nx.simple_cycles(self.directive_graph))) if self.directive_graph.number_of_nodes() > 0 else 0
        for _ in range(int(self.update_interval / self.pde_dt)):
            d2_coherence = (np.roll(self.coherence_field, 1) + np.roll(self.coherence_field, -1) - 2 * self.coherence_field) / (self.pde_dx ** 2)
            reaction = 0.1 * self.coherence_field * (1.0 - self.coherence_field / max(n_directives, 1) - 0.05 * conflicts)
            self.coherence_field += self.pde_dt * (self.pde_diffusion * d2_coherence + reaction)
            self.coherence_field = np.clip(self.coherence_field, 0.0, 1.0)
        self.module_state["directive_coherence_score"] = np.mean(self.coherence_field)

    async def _analyze_traces_for_biases(self):
        # Validar trazas
        valid_traces = []
        for trace in self.cognitive_trace_log:
            correlation_id = f"validate_trace_{trace.trace_id}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            self.active_responses[correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="ComputationalLogicModule",
                    message_type="submit_logical_query_request",
                    payload={"query_type": "validate_cognitive_trace", "query_payload": asdict(trace)},
                    correlation_id=correlation_id,
                    priority="medium"
                ))
            }, priority_label="medium")
            try:
                validation_result = await asyncio.wait_for(future, timeout=5.0)
                if validation_result.get("status") == "valid":
                    valid_traces.append(trace)
                else:
                    self.logger.warning(f"Traza inválida: {trace.trace_id}: {validation_result.get('error', 'No especificado')}")
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout validando traza {trace.trace_id}.")
        # Detección de Falacia de Planificación
        planning_fallacy_strikes = 0
        for trace in valid_traces:
            if trace.event_type == "task_completed":
                estimated_time = trace.context.get("estimated_duration", 0)
                actual_time = trace.outcome.get("actual_duration", 0)
                if estimated_time > 0 and actual_time > estimated_time * self.planning_fallacy_threshold:
                    planning_fallacy_strikes += 1
        # Monte Carlo para incertidumbre
        pf_prob = planning_fallacy_strikes / max(len(valid_traces), 1)
        samples = np.random.normal(pf_prob, 0.05, self.num_mc_samples)
        pf_prob = np.clip(np.mean(samples), 0.0, 1.0)
        # SDE para dinámica
        def bias_dynamics(t, p):
            return -0.05 * (p - pf_prob) + self.sde_sigma * np.random.normal(0, 1)
        result = integrate.odeint(bias_dynamics, [pf_prob], [0, self.update_interval], tfirst=True)
        pf_prob = np.clip(result[-1][0], 0.0, 1.0)
        if planning_fallacy_strikes >= self.planning_fallacy_strike_count and pf_prob > 0.5:
            directive = CorrectiveDirective(
                directive_id=f"cdir_plan_fallacy_{int(time.time())}",
                bias_detected="planning_fallacy",
                description="Subestimación sistemática de la duración de las tareas detectada.",
                corrective_action={"module": "HierarchicalPlannerModule", "parameter_adjustment": {"duration_estimate_multiplier": 1.25}},
                start_time=time.time(),
                duration_s=3600
            )
            await self._issue_corrective_directive(directive)
        # Detección de Sesgo de Confirmación
        confirmation_bias_strikes = 0
        for trace in valid_traces:
            if trace.event_type == "information_retrieval":
                search_intent = trace.context.get("search_intent", "neutral")
                if search_intent == "confirmatory":
                    confirmation_bias_strikes += 1
        cb_prob = confirmation_bias_strikes / max(len(valid_traces), 1)
        samples = np.random.normal(cb_prob, 0.05, self.num_mc_samples)
        cb_prob = np.clip(np.mean(samples), 0.0, 1.0)
        result = integrate.odeint(bias_dynamics, [cb_prob], [0, self.update_interval], tfirst=True)
        cb_prob = np.clip(result[-1][0], 0.0, 1.0)
        if confirmation_bias_strikes >= self.confirmation_bias_strike_count and cb_prob > self.confirmation_bias_threshold:
            directive = CorrectiveDirective(
                directive_id=f"cdir_conf_bias_{int(time.time())}",
                bias_detected="confirmation_bias",
                description="Tendencia a buscar información confirmatoria detectada.",
                corrective_action={"module": "SQLKnowledgeStore", "parameter_adjustment": {"search_diversity_weight": 1.5}},
                start_time=time.time(),
                duration_s=3600
            )
            await self._issue_corrective_directive(directive)

    async def _issue_corrective_directive(self, directive: CorrectiveDirective):
        if directive.directive_id in self.active_directives:
            return
        # Validar directiva
        correlation_id = f"validate_directive_{directive.directive_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="ComputationalLogicModule",
                message_type="submit_logical_query_request",
                payload={"query_type": "validate_corrective_directive", "query_payload": asdict(directive)},
                correlation_id=correlation_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            validation_result = await asyncio.wait_for(future, timeout=5.0)
            if validation_result.get("status") != "valid":
                self.logger.warning(f"Directiva no válida: {directive.directive_id}: {validation_result.get('error', 'No especificado')}")
                return
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout validando directiva {directive.directive_id}.")
            return
        # Validar alineación con valores
        correlation_id = f"align_directive_{directive.directive_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="ValueSystemModule",
                message_type="request_value_alignment",
                payload={"item_to_evaluate": {"description": directive.description, "corrective_action": directive.corrective_action}},
                correlation_id=correlation_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            alignment_result = await asyncio.wait_for(future, timeout=5.0)
            if alignment_result.get("overall_alignment_score", -1.0) < 0.0:
                self.logger.warning(f"Directiva no alineada: {directive.directive_id}: {alignment_result.get('error_message', 'No especificado')}")
                return
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout validando alineación para directiva {directive.directive_id}.")
            return
        # Verificar conflictos
        self.directive_graph.add_node(directive.directive_id, bias=directive.bias_detected)
        for other_id in self.active_directives:
            if self.active_directives[other_id].bias_detected == directive.bias_detected:
                self.directive_graph.add_edge(directive.directive_id, other_id, weight=1.0)
        conflicts = len(list(nx.simple_cycles(self.directive_graph))) if self.directive_graph.number_of_nodes() > 0 else 0
        if conflicts > 0:
            self.logger.warning(f"Conflicto detectado en directiva {directive.directive_id}.")
            self.directive_graph.remove_node(directive.directive_id)
            return
        self.active_directives[directive.directive_id] = directive
        # Actualizar métrica con Kalman
        bias_count = self.module_state["biases_detected"] + 1
        measurement = bias_count
        A, H = 1.0, 1.0
        predicted_state = A * self.kalman_state
        predicted_cov = A * self.kalman_cov * A + self.kalman_Q
        innovation = measurement - H * predicted_state
        innovation_cov = H * predicted_cov * H + self.kalman_R
        kalman_gain = predicted_cov * H / innovation_cov
        self.kalman_state = predicted_state + kalman_gain * innovation
        self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
        self.module_state["biases_detected"] = int(self.kalman_state)
        self.module_state["directives_issued"] += 1
        self.logger.warning(f"NUEVA DIRECTIVA CORRECTIVA emitida ({directive.bias_detected}): {directive.description}")
        future = asyncio.Future()
        self.active_responses[directive.directive_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="*",
                message_type="new_metacognitive_directive",
                payload=asdict(directive),
                correlation_id=directive.directive_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            await asyncio.wait_for(future, timeout=5.0)
            self.logger.info(f"Confirmación de directiva {directive.directive_id} recibida.")
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout esperando confirmación de directiva {directive.directive_id}.")

    async def _prune_expired_directives(self):
        now = time.time()
        expired_ids = [did for did, d in self.active_directives.items() if now > d.start_time + d.duration_s]
        for did in expired_ids:
            directive = self.active_directives.pop(did)
            directive.is_active = False
            self.directive_graph.remove_node(did)
            self.logger.info(f"Directiva correctiva '{did}' ha expirado.")
            future = asyncio.Future()
            self.active_responses[did] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="*",
                    message_type="metacognitive_directive_expired",
                    payload=asdict(directive),
                    correlation_id=did,
                    priority="high"
                ))
            }, priority_label="high")
            try:
                await asyncio.wait_for(future, timeout=5.0)
                self.logger.info(f"Confirmación de expiración de directiva {did} recibida.")
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout notificando expiración de directiva {did}.")

    async def _process_specific_event(self, event_type: str, payload: Dict, full_message: Optional['IlyukMessageStructure'] = None):
        if not full_message:
            return
        if event_type.endswith("_completed_notice"):
            try:
                trace = CognitiveTrace(
                    event_type=event_type,
                    source_module_id=full_message.source_module_id,
                    context=payload.get("original_request", {}),
                    outcome=payload
                )
                self.cognitive_trace_log.append(trace)
                self.module_state["traces_logged"] += 1
            except Exception as e:
                self.logger.error(f"Error al crear traza cognitiva desde evento '{event_type}': {str(e)}", exc_info=True)
        if full_message.correlation_id in self.active_responses:
            self.active_responses[full_message.correlation_id].set_result(payload)
            del self.active_responses[full_message.correlation_id]
        else:
            await super()._process_specific_event(event_type, payload, full_message)





#inicio del modulo TaskPrioritizationAndDelegationUnit 

@dataclass
class Task:
    task_id: str = field(default_factory=lambda: f"task_{uuid.uuid4().hex[:10]}")
    source_module_id: str
    original_request_corr_id: Optional[str] = None
    description: str
    status: str = "pending_prioritization"
    base_priority: float = 0.5
    required_capabilities: List[str] = field(default_factory=list)
    task_payload: Dict[str, Any] = field(default_factory=dict)
    dependencies: List[str] = field(default_factory=list)
    creation_ts: float = field(default_factory=time.time)
    deadline_ts: Optional[float] = None
    max_execution_time_s: float = 300.0
    assigned_module_id: Optional[str] = None
    result: Optional[Dict[str, Any]] = None

class TaskPrioritizationAndDelegationUnit(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 0.5

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        self.pending_tasks: deque[Task] = deque()
        self.active_tasks: Dict[str, Task] = {}
        self.active_responses: Dict[str, asyncio.Future] = {}
        self.task_graph = nx.DiGraph()
        self.coherence_field: np.ndarray = np.array([1.0])
        self.num_mc_samples: int = 500
        self.sde_sigma: float = 0.01
        self.pde_dx: float = 0.1
        self.pde_dt: float = 0.01
        self.pde_diffusion: float = 0.05
        self.capability_registry: Dict[str, List[str]] = {
            "information_retrieval": ["SQLKnowledgeStore"],
            "code_generation": ["GeneradorCode"],
            "iot_action": ["IoTInterfaceModule"],
            "generic_execution": ["ExecutionMonitoringAndControlModule"],
            "vision_processing": ["VisionProcessingModule"],
        }
        self.module_load_state: Dict[str, float] = defaultdict(float)
        self.module_state.update({
            "pending_task_count": 0,
            "active_task_count": 0,
            "tasks_delegated": 0,
            "tasks_completed": 0,
            "tasks_failed": 0,
            "avg_task_lifetime_s": 0.0,
            "task_coherence_score": 1.0
        })
        self.task_lifetimes: List[float] = []
        self.logger.info(f"{self.module_name} v27.2 inicializado con modelado avanzado.")

    async def _update_logic(self):
        if self.pending_tasks:
            await self._prioritize_and_delegate()
        self.module_state["pending_task_count"] = len(self.pending_tasks)
        self.module_state["active_task_count"] = len(self.active_tasks)
        # Actualizar coherencia entre tareas
        n_tasks = self.task_graph.number_of_nodes()
        if len(self.coherence_field) != max(n_tasks, 1):
            self.coherence_field = np.ones(max(n_tasks, 1)) * self.module_state["task_coherence_score"]
        conflicts = len(list(nx.simple_cycles(self.task_graph))) if self.task_graph.number_of_nodes() > 0 else 0
        for _ in range(int(self.update_interval / self.pde_dt)):
            d2_coherence = (np.roll(self.coherence_field, 1) + np.roll(self.coherence_field, -1) - 2 * self.coherence_field) / (self.pde_dx ** 2)
            reaction = 0.1 * self.coherence_field * (1.0 - self.coherence_field / max(n_tasks, 1) - 0.05 * conflicts)
            self.coherence_field += self.pde_dt * (self.pde_diffusion * d2_coherence + reaction)
            self.coherence_field = np.clip(self.coherence_field, 0.0, 1.0)
        self.module_state["task_coherence_score"] = np.mean(self.coherence_field)

    async def _prioritize_and_delegate(self):
        scored_tasks = []
        for task in self.pending_tasks:
            # Validar tarea
            correlation_id = f"validate_task_{task.task_id}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            self.active_responses[correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="ComputationalLogicModule",
                    message_type="submit_logical_query_request",
                    payload={"query_type": "validate_task", "query_payload": asdict(task)},
                    correlation_id=correlation_id,
                    priority="high"
                ))
            }, priority_label="high")
            try:
                validation_result = await asyncio.wait_for(future, timeout=5.0)
                if validation_result.get("status") != "valid":
                    self.logger.warning(f"Tarea no válida: {task.task_id}: {validation_result.get('error', 'No especificado')}")
                    self.pending_tasks.remove(task)
                    self.module_state["tasks_failed"] += 1
                    continue
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout validando tarea {task.task_id}.")
                self.pending_tasks.remove(task)
                self.module_state["tasks_failed"] += 1
                continue
            # Validar alineación con valores
            correlation_id = f"align_task_{task.task_id}_{uuid.uuid4().hex[:8]}"
            future = asyncio.Future()
            self.active_responses[correlation_id] = future
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    source_module_id=self.module_name,
                    target_module_id="ValueSystemModule",
                    message_type="request_value_alignment",
                    payload={"item_to_evaluate": {"description": task.description, "task_payload": task.task_payload}},
                    correlation_id=correlation_id,
                    priority="medium"
                ))
            }, priority_label="medium")
            try:
                alignment_result = await asyncio.wait_for(future, timeout=5.0)
                if alignment_result.get("overall_alignment_score", -1.0) < 0.0:
                    self.logger.warning(f"Tarea no alineada: {task.task_id}: {alignment_result.get('error_message', 'No especificado')}")
                    self.pending_tasks.remove(task)
                    self.module_state["tasks_failed"] += 1
                    continue
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout validando alineación para tarea {task.task_id}.")
                self.pending_tasks.remove(task)
                self.module_state["tasks_failed"] += 1
                continue
            dynamic_priority = await self._calculate_dynamic_priority(task)
            # Monte Carlo para incertidumbre
            samples = np.random.normal(dynamic_priority, 0.05, self.num_mc_samples)
            dynamic_priority = np.clip(np.mean(samples), 0.0, 1.0)
            scored_tasks.append((dynamic_priority, task))
        if not scored_tasks:
            return
        scored_tasks.sort(key=lambda x: x[0], reverse=True)
        task_to_delegate = scored_tasks[0][1]
        # Verificar conflictos
        self.task_graph.add_node(task_to_delegate.task_id, description=task_to_delegate.description)
        for dep in task_to_delegate.dependencies:
            if dep in self.active_tasks or any(t.task_id == dep for t in self.pending_tasks):
                self.task_graph.add_edge(task_to_delegate.task_id, dep, weight=1.0)
        conflicts = len(list(nx.simple_cycles(self.task_graph))) if self.task_graph.number_of_nodes() > 0 else 0
        if conflicts > 0:
            self.logger.warning(f"Conflicto detectado en tarea {task_to_delegate.task_id}.")
            self.pending_tasks.remove(task_to_delegate)
            self.task_graph.remove_node(task_to_delegate.task_id)
            self.module_state["tasks_failed"] += 1
            return
        delegate_module_id = self._find_best_delegate_module(task_to_delegate.required_capabilities)
        if delegate_module_id:
            self.pending_tasks.remove(task_to_delegate)
            task_to_delegate.status = "delegated"
            task_to_delegate.assigned_module_id = delegate_module_id
            self.active_tasks[task_to_delegate.task_id] = task_to_delegate
            await self._delegate_task(task_to_delegate, delegate_module_id)
            self.module_state["tasks_delegated"] += 1
        else:
            self.logger.warning(f"No se encontró módulo para tarea {task_to_delegate.task_id} con capacidades: {task_to_delegate.required_capabilities}")

    async def _calculate_dynamic_priority(self, task: Task) -> float:
        gs = self.core_recombinator.global_state
        urgency_modifier = 1.0 + (gs.system_threat_level * 0.5) + (gs.dolor * 0.8)
        # Consultar MotivationSystem
        correlation_id = f"motivation_{task.task_id}_{uuid.uuid4().hex[:8]}"
        future = asyncio.Future()
        self.active_responses[correlation_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id="MotivationSystem",
                message_type="request_active_drives",
                payload={"task_description": task.description, "task_payload": task.task_payload},
                correlation_id=correlation_id,
                priority="medium"
            ))
        }, priority_label="medium")
        try:
            motivation_result = await asyncio.wait_for(future, timeout=5.0)
            motivation_modifier = 1.0 + (motivation_result.get("drive_strength", 0.0) * 0.3)
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout consultando MotivationSystem para tarea {task.task_id}.")
            motivation_modifier = 1.0
        # SDE para dinámica de prioridad
        priority = task.base_priority * urgency_modifier * motivation_modifier
        def priority_dynamics(t, p):
            return -0.05 * (p - priority) + self.sde_sigma * np.random.normal(0, 1)
        result = integrate.odeint(priority_dynamics, [priority], [0, self.update_interval], tfirst=True)
        priority = np.clip(result[-1][0], 0.0, 1.0)
        return priority

    def _find_best_delegate_module(self, capabilities: List[str]) -> Optional[str]:
        if not capabilities:
            capabilities = ["generic_execution"]
        best_module = None
        lowest_load = float('inf')
        for capability in capabilities:
            if capability in self.capability_registry:
                for module_id in self.capability_registry[capability]:
                    load = self.module_load_state.get(module_id, 0.0)
                    # Monte Carlo para incertidumbre en carga
                    samples = np.random.normal(load, 0.05, self.num_mc_samples)
                    load = np.clip(np.mean(samples), 0.0, 1.0)
                    if load < lowest_load:
                        lowest_load = load
                        best_module = module_id
        return best_module

    async def _delegate_task(self, task: Task, delegate_module_id: str):
        self.logger.info(f"Delegando tarea '{task.task_id}' a '{delegate_module_id}'.")
        future = asyncio.Future()
        self.active_responses[task.task_id] = future
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                source_module_id=self.module_name,
                target_module_id=delegate_module_id,
                message_type="execute_assigned_task_request",
                payload={"task_to_execute": asdict(task)},
                correlation_id=task.task_id,
                priority="high"
            ))
        }, priority_label="high")
        try:
            await asyncio.wait_for(future, timeout=task.max_execution_time_s)
            self.logger.info(f"Confirmación de delegación para tarea {task.task_id}.")
        except asyncio.TimeoutError:
            self.logger.warning(f"Timeout delegando tarea {task.task_id}.")
            task.status = "failed"
            task.result = {"status": "failed", "reason": "Timeout en delegación"}
            self.active_tasks.pop(task.task_id, None)
            self.task_graph.remove_node(task.task_id)
            self.module_state["tasks_failed"] += 1

    async def _process_specific_event(self, event_type: str, payload: Dict, full_message: Optional['IlyukMessageStructure'] = None):
        if not full_message:
            return
        if event_type == "new_task_request":
            try:
                task = Task(**payload, source_module_id=full_message.source_module_id, original_request_corr_id=full_message.correlation_id)
                self.pending_tasks.append(task)
                self.task_graph.add_node(task.task_id, description=task.description)
            except Exception as e:
                self.logger.error(f"Error creando tarea: {str(e)}", exc_info=True)
        elif event_type == "task_execution_status_update":
            task_id = full_message.correlation_id
            if task_id in self.active_tasks:
                task = self.active_tasks[task_id]
                new_status = payload.get("status")
                task.status = new_status
                if new_status in ["completed", "failed", "cancelled"]:
                    task.result = payload.get("result")
                    task.error_message = payload.get("error_details")
                    lifetime = time.time() - task.creation_ts
                    self.task_lifetimes.append(lifetime)
                    # Kalman para suavizar avg_task_lifetime_s
                    measurement = lifetime
                    A, H = 1.0, 1.0
                    predicted_state = A * self.kalman_state
                    predicted_cov = A * self.kalman_cov * A + self.kalman_Q
                    innovation = measurement - H * predicted_state
                    innovation_cov = H * predicted_cov * H + self.kalman_R
                    kalman_gain = predicted_cov * H / innovation_cov
                    self.kalman_state = predicted_state + kalman_gain * innovation
                    self.kalman_cov = (1 - kalman_gain * H) * predicted_cov
                    self.module_state["avg_task_lifetime_s"] = self.kalman_state
                    if new_status == "completed":
                        self.module_state["tasks_completed"] += 1
                    else:
                        self.module_state["tasks_failed"] += 1
                    self.active_tasks.pop(task_id, None)
                    self.task_graph.remove_node(task_id)
        elif event_type == "module_performance_update":
            source = full_message.source_module_id
            self.module_load_state[source] = payload.get("current_load_factor", 0.0)
        if full_message.correlation_id in self.active_responses:
            self.active_responses[full_message.correlation_id].set_result(payload)
            del self.active_responses[full_message.correlation_id]
        else:
            await super()._process_specific_event(event_type, payload, full_message)




  #inicio del modulo SelfReplicatingSpecializedAgentModule 

@dataclass
class BetaDistribution:
    """Distribución Beta para confianza en agentes."""
    α: float
    β: float

    def mean(self):
        return self.α / (self.α + self.β)

    def update(self, evidence: float):
        self.α += evidence
        self.β += 1 - evidence

@dataclass
class ReplicationRequest:
    """Solicitud para crear un enjambre de agentes."""
    request_id: str = field(default_factory=lambda: f"srsam_req_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    agent_count: int
    agent_specialization_template: str
    task_payload_to_distribute: List[Dict[str, Any]]
    status: str = "pending"
    aggregated_result: Optional[List[Any]] = None
    _daughter_agent_futures: Dict[str, asyncio.Future] = field(default_factory=dict, repr=False)
    priority: float = 0.5
    trust_estimates: Dict[str, BetaDistribution] = field(default_factory=dict)

@dataclass
class DaughterAgentRecord:
    """Rastrea el estado de un agente hijo."""
    agent_id: str
    specialization: str
    task_id: str
    status: str = "spawning"
    result: Optional[Any] = None
    trust: BetaDistribution = field(default_factory=lambda: BetaDistribution(α=1, β=1))
    last_heartbeat: float = field(default_factory=time.time)

class SelfReplicatingSpecializedAgentModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 10.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.replication_request_queue: asyncio.PriorityQueue = asyncio.PriorityQueue(maxsize=5)
        self.active_swarm_request: Optional[ReplicationRequest] = None
        self.daughter_records: Dict[str, DaughterAgentRecord] = {}
        self.markov_priority_matrix = np.array([[0.8, 0.2], [0.3, 0.7]])
        self.num_mc_samples = 100
        self.kalman_Q = 0.01
        self.kalman_R = 0.05
        self.heartbeat_timeout = 30.0
        
        self.agent_templates = {
            "researcher": {
                "active_modules": ["DataAndKnowledgeProcessingModule", "SQLKnowledgeStore", "ConversationalAgentModule", "WebAPIIntegrationModule"],
                "initial_goal": "Process assigned research data and provide a summary.",
                "trust_prior": BetaDistribution(α=5, β=5)
            },
            "data_miner": {
                "active_modules": ["DataAndKnowledgeProcessingModule", "SQLKnowledgeStore", "WebAPIIntegrationModule"],
                "initial_goal": "Extract and analyze data patterns.",
                "trust_prior": BetaDistribution(α=4, β=6)
            },
            "scenario_tester": {
                "active_modules": ["ScenarioSimulationModule", "ConversationalAgentModule"],
                "initial_goal": "Simulate scenarios and report outcomes.",
                "trust_prior": BetaDistribution(α=3, β=7)
            }
        }
        
        self.module_state.update({
            "replication_requests_processed": 0,
            "agents_spawned_total": 0,
            "swarms_completed_successfully": 0,
            "swarms_failed": 0,
            "agent_heartbeats_missed": 0
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado.")

    async def _update_logic(self):
        """Procesa solicitudes de replicación."""
        if not self.replication_request_queue.empty() and not self.active_swarm_request:
            requests = []
            while not self.replication_request_queue.empty():
                priority, request = await self.replication_request_queue.get()
                state = 1 if -priority > 0.5 else 0
                next_state = np.random.choice([0, 1], p=self.markov_priority_matrix[state])
                request.priority = np.clip(request.priority + 0.1 * (next_state - state), 0.0, 1.0)
                requests.append((-request.priority, request))
            
            for priority, request in sorted(requests):
                await self.replication_request_queue.put((priority, request))
            
            if requests:
                _, top_request = min(requests, key=lambda x: x[0])
                self.active_swarm_request = top_request
                await self._process_replication_request(top_request)

    async def _process_replication_request(self, request: ReplicationRequest):
        """Orquesta la creación y gestión del enjambre."""
        self.module_state["replication_requests_processed"] += 1
        request.status = "spawning_agents"
        
        try:
            daughter_records = await self._spawn_and_dispatch_agents(request)
            self.daughter_records.update({r.agent_id: r for r in daughter_records})
            
            request.status = "awaiting_results"
            await self._monitor_daughter_agents(request)
            
            request.status = "aggregating_results"
            successful_results = await self._aggregate_results(request)
            request.aggregated_result = successful_results
            
            request.status = "terminating_agents"
            await self._terminate_daughter_agents(daughter_records)
            
            request.status = "completed"
            self.module_state["swarms_completed_successfully"] += 1
        
        except Exception as e:
            request.status = "failed"
            self.logger.error(f"Fallo en enjambre '{request.request_id}': {e}", exc_info=True)
            self.module_state["swarms_failed"] += 1
        finally:
            self.daughter_records.clear()
            await self._finalize_request(request)

    async def _spawn_and_dispatch_agents(self, request: ReplicationRequest) -> List[DaughterAgentRecord]:
        """Crea y asigna tareas a agentes hijos."""
        template = self.agent_templates.get(request.agent_specialization_template)
        if not template:
            raise ValueError(f"Plantilla '{request.agent_specialization_template}' no encontrada.")
        
        records = []
        task_loads = self._balance_task_load(request.task_payload_to_distribute, request.agent_count)
        
        for i in range(request.agent_count):
            agent_id = f"eane_daughter_{request.request_id}_{i}"
            sub_task = task_loads[i % len(task_loads)]
            
            self.logger.info(f"SRSAM: Creando agente hijo '{agent_id}' con especialización '{request.agent_specialization_template}'.")
            
            record = DaughterAgentRecord(
                agent_id=agent_id,
                specialization=request.agent_specialization_template,
                task_id=sub_task.get("id", f"task_{i}"),
                trust=template["trust_prior"]
            )
            records.append(record)
            
            future = asyncio.Future()
            request._daughter_agent_futures[agent_id] = future
            request.trust_estimates[agent_id] = template["trust_prior"]
            
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, "LlyukCommunicationModule", "request_send_external_ilyuk_message",
                    {"target_module_id": agent_id, "message_type": "initial_task_assignment", "payload": sub_task}
                ))
            })
            self.module_state["agents_spawned_total"] += 1
        
        return records

    def _balance_task_load(self, tasks: List[Dict], agent_count: int) -> List[Dict]:
        """Balancea la asignación de tareas."""
        if not tasks:
            return []
        
        task_weights = [t.get("complexity", 1.0) for t in tasks]
        total_weight = sum(task_weights)
        target_load = total_weight / agent_count
        
        assigned_tasks = [[] for _ in range(agent_count)]
        current_loads = [0.0] * agent_count
        
        for task, weight in sorted(zip(tasks, task_weights), key=lambda x: x[1], reverse=True):
            min_load_idx = np.argmin(current_loads)
            assigned_tasks[min_load_idx].append(task)
            current_loads[min_load_idx] += weight
        
        return [task for agent_tasks in assigned_tasks for task in agent_tasks]

    async def _monitor_daughter_agents(self, request: ReplicationRequest):
        """Monitorea agentes hijos y maneja fallos."""
        while request._daughter_agent_futures:
            current_time = time.time()
            for agent_id, record in list(self.daughter_records.items()):
                if current_time - record.last_heartbeat > self.heartbeat_timeout:
                    self.logger.warning(f"Agente '{agent_id}' no responde.")
                    self.module_state["agent_heartbeats_missed"] += 1
                    if agent_id in request._daughter_agent_futures:
                        request._daughter_agent_futures[agent_id].set_exception(TimeoutError("Agente no responde"))
                        del request._daughter_agent_futures[agent_id]
                        record.status = "failed"
                        record.trust.update(0.0)
                else:
                    record.trust.update(record.trust.mean() * 0.9 + 0.1)
            
            await asyncio.sleep(1.0)
            if all(f.done() for f in request._daughter_agent_futures.values()):
                break

    async def _aggregate_results(self, request: ReplicationRequest) -> List[Any]:
        """Agrega resultados con ponderación bayesiana."""
        all_results = await asyncio.gather(*request._daughter_agent_futures.values(), return_exceptions=True)
        successful_results = []
        
        for agent_id, result in zip(request._daughter_agent_futures.keys(), all_results):
            if not isinstance(result, Exception):
                trust_weight = request.trust_estimates[agent_id].mean()
                samples = np.random.beta(
                    request.trust_estimates[agent_id].α,
                    request.trust_estimates[agent_id].β,
                    self.num_mc_samples
                )
                weighted_result = {"result": result, "trust_weight": np.mean(samples)}
                successful_results.append(weighted_result)
                self.daughter_records[agent_id].trust.update(1.0)
            else:
                self.daughter_records[agent_id].trust.update(0.0)
        
        return successful_results

    async def _terminate_daughter_agents(self, records: List[DaughterAgentRecord]):
        """Termina agentes hijos con reintentos."""
        termination_tasks = []
        for record in records:
            for _ in range(3):
                try:
                    task = self.emit_event_to_core({
                        "type": "transmit_ilyuk_message_request",
                        "content": asdict(IlyukMessageStructure(
                            self.module_name, "LlyukCommunicationModule", "request_send_external_ilyuk_message",
                            {"target_module_id": record.agent_id, "message_type": "request_graceful_shutdown"}
                        ))
                    })
                    termination_tasks.append(task)
                    record.status = "terminated"
                    break
                except Exception as e:
                    self.logger.warning(f"Fallo al terminar agente '{record.agent_id}': {e}")
                    await asyncio.sleep(1.0)
        
        await asyncio.gather(*termination_tasks, return_exceptions=True)

    async def _finalize_request(self, request: ReplicationRequest):
        """Notifica el resultado y limpia."""
        if request.original_correlation_id:
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, request.source_module_id, "agent_swarm_result",
                    {
                        "request_id_ref": request.request_id,
                        "status": request.status,
                        "aggregated_result": request.aggregated_result
                    },
                    correlation_id=request.original_correlation_id
                ))
            })
        self.active_swarm_request = None

    async def _process_specific_event(self, event_type: str, payload: Dict, full_message: Optional['IlyukMessageStructure'] = None):
        """Procesa eventos específicos."""
        if event_type == "request_agent_replication" and full_message:
            urgency = payload.get("urgency", 0.5)
            priority = -np.log(1 - np.clip(urgency, 1e-10, 1-1e-10))
            req = ReplicationRequest(
                source_module_id=full_message.source_module_id,
                original_correlation_id=full_message.correlation_id,
                agent_count=payload.get("agent_count", 1),
                agent_specialization_template=payload.get("agent_specialization_template", "researcher"),
                task_payload_to_distribute=payload.get("task_payload_to_distribute", []),
                priority=priority
            )
            if not req.task_payload_to_distribute or req.agent_count < 1:
                self.logger.error("Solicitud inválida: faltan tareas o agent_count inválido.")
                return
            await self.replication_request_queue.put((-priority, req))
        
        elif event_type == "external_task_completion_report" and self.active_swarm_request:
            agent_id = full_message.source_module_id
            if agent_id in self.active_swarm_request._daughter_agent_futures:
                future = self.active_swarm_request._daughter_agent_futures[agent_id]
                if not future.done():
                    future.set_result(payload.get("result"))
                    self.daughter_records[agent_id].result = payload.get("result")
                    self.daughter_records[agent_id].status = "completed"
                    self.daughter_records[agent_id].last_heartbeat = time.time()
        
        elif event_type == "agent_heartbeat" and self.active_swarm_request:
            agent_id = full_message.source_module_id
            if agent_id in self.daughter_records:
                self.daughter_records[agent_id].last_heartbeat = time.time()
                self.daughter_records[agent_id].trust.update(0.9)






#inicio del modulo ResourceScarcityManagementModule 

@dataclass
class BetaDistribution:
    """Distribución Beta para confianza en acciones."""
    α: float
    β: float

    def mean(self):
        return self.α / (self.α + self.β)

    def update(self, evidence: float):
        self.α += evidence
        self.β += 1 - evidence

@dataclass
class ResourcePolicy:
    """Política de gestión de recursos."""
    policy_name: str
    activation_thresholds: Dict[str, Tuple[float, float]]
    corrective_actions: List[Dict[str, Any]]
    trust: BetaDistribution = field(default_factory=lambda: BetaDistribution(α=5, β=5))

@dataclass
class ResourceMetrics:
    """Métricas de recursos suavizadas."""
    system_load: float
    active_tasks: int
    entropy: float
    timestamp: float = field(default_factory=time.time)

class ResourceScarcityManagementModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 4.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.current_active_policy: str = "GREEN"
        self.resource_policies: Dict[str, ResourcePolicy] = {}
        self.kalman_state: Dict[str, float] = {"system_load": 0.5, "active_tasks": 0}
        self.kalman_cov: Dict[str, float] = {"system_load": 0.1, "active_tasks": 10.0}
        self.kalman_Q = 0.01
        self.kalman_R = 0.05
        self.num_mc_samples = 100
        self.markov_transition_matrix = np.array([
            [0.8, 0.15, 0.05],  # GREEN -> GREEN, AMBER, RED
            [0.2, 0.7, 0.1],    # AMBER -> GREEN, AMBER, RED
            [0.05, 0.25, 0.7]   # RED -> GREEN, AMBER, RED
        ])
        self._initialize_policies()
        
        self.module_state.update({
            "current_policy": self.current_active_policy,
            "system_load": 0.0,
            "active_tasks": 0,
            "policy_activations": 0,
            "policy_success_rate": 0.0
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado.")

    def _initialize_policies(self):
        """Define políticas de gestión de recursos."""
        self.resource_policies["GREEN"] = ResourcePolicy(
            policy_name="GREEN",
            activation_thresholds={"system_load": (0.0, 0.7)},
            corrective_actions=[]
        )
        self.resource_policies["AMBER"] = ResourcePolicy(
            policy_name="AMBER",
            activation_thresholds={"system_load": (0.7, 0.9)},
            corrective_actions=[
                {
                    "target": "TaskPrioritizationAndDelegationUnit",
                    "action": "set_priority_floor",
                    "params": {"min_priority_to_delegate": 0.4},
                    "description": "Rechazar tareas de baja prioridad.",
                    "trust": BetaDistribution(α=5, β=5)
                },
                {
                    "target": "SelfEvolutionModule",
                    "action": "set_sleep_state",
                    "params": {"dormant": True},
                    "description": "Pausar evolución proactiva.",
                    "trust": BetaDistribution(α=5, β=5)
                }
            ]
        )
        self.resource_policies["RED"] = ResourcePolicy(
            policy_name="RED",
            activation_thresholds={"system_load": (0.9, 1.0)},
            corrective_actions=[
                {
                    "target": "TaskPrioritizationAndDelegationUnit",
                    "action": "set_priority_floor",
                    "params": {"min_priority_to_delegate": 0.7},
                    "description": "Rechazar casi todas las tareas no críticas.",
                    "trust": BetaDistribution(α=5, β=5)
                },
                {
                    "target": "KnowledgeMutationEngine",
                    "action": "set_sleep_state",
                    "params": {"dormant": True},
                    "description": "Pausar toda la mutación de conocimiento.",
                    "trust": BetaDistribution(α=5, β=5)
                },
                {
                    "target": "FractalSynchronicitySimulationModule",
                    "action": "set_sleep_state",
                    "params": {"dormant": True},
                    "description": "Pausar análisis de fondo costosos.",
                    "trust": BetaDistribution(α=5, β=5)
                }
            ]
        )

    async def _update_logic(self):
        """Ciclo principal para monitorear y aplicar políticas."""
        current_resources = await self._monitor_resource_levels()
        self.module_state.update({
            "system_load": current_resources.system_load,
            "active_tasks": current_resources.active_tasks,
            "resource_entropy": current_resources.entropy
        })
        await self._evaluate_and_set_policy(current_resources)

    async def _monitor_resource_levels(self) -> ResourceMetrics:
        """Obtiene y suaviza métricas de recursos."""
        gs = self.core_recombinator.global_state
        tpdu_state = self.core_recombinator.modules.get("TaskPrioritizationAndDelegationUnit", self).module_state
        
        raw_metrics = {
            "system_load": gs.system_load_proxy_sim,
            "active_tasks": tpdu_state.get("active_task_count", 0)
        }
        
        for key in ["system_load", "active_tasks"]:
            measurement = raw_metrics[key]
            A, H = 1.0, 1.0
            predicted_state = A * self.kalman_state[key]
            predicted_cov = A * self.kalman_cov[key] * A + self.kalman_Q
            innovation = measurement - H * predicted_state
            innovation_cov = H * predicted_cov * H + self.kalman_R
            kalman_gain = predicted_cov * H / innovation_cov
            self.kalman_state[key] = predicted_state + kalman_gain * innovation
            self.kalman_cov[key] = (1 - kalman_gain * H) * predicted_cov
            raw_metrics[key] = self.kalman_state[key]
        
        samples = np.random.normal(raw_metrics["system_load"], np.sqrt(self.kalman_cov["system_load"]), self.num_mc_samples)
        probs = np.histogram(samples, bins=50, density=True)[0] + 1e-10
        entropy = -np.sum(probs * np.log2(probs))
        
        return ResourceMetrics(
            system_load=np.clip(raw_metrics["system_load"], 0.0, 1.0),
            active_tasks=int(raw_metrics["active_tasks"]),
            entropy=entropy
        )

    async def _evaluate_and_set_policy(self, current_resources: ResourceMetrics):
        """Evalúa y selecciona la política adecuada."""
        load = current_resources.system_load
        current_state = ["GREEN", "AMBER", "RED"].index(self.current_active_policy)
        policy_probs = self.markov_transition_matrix[current_state]
        
        samples = []
        for _ in range(self.num_mc_samples):
            sample = {}
            for policy_name, policy in self.resource_policies.items():
                thresh = policy.activation_thresholds["system_load"]
                prob = 1.0 if thresh[0] <= load <= thresh[1] else 0.1
                sample[policy_name] = prob * policy.trust.mean()
            samples.append(sample)
        
        policy_scores = {
            name: np.mean([s[name] for s in samples]) for name in self.resource_policies
        }
        new_policy_name = max(policy_scores, key=policy_scores.get)
        
        if new_policy_name != self.current_active_policy:
            self.logger.warning(f"Cambio de política de '{self.current_active_policy}' a '{new_policy_name}' (carga: {load:.2f}, entropía: {current_resources.entropy:.2f}).")
            await self._activate_policy(new_policy_name)

    async def _activate_policy(self, policy_name: str):
        """Ejecuta acciones correctivas de la política."""
        policy = self.resource_policies.get(policy_name)
        if not policy:
            return
        
        previous_load = self.module_state.get("system_load", 0.5)
        self.current_active_policy = policy_name
        self.module_state["current_policy"] = policy_name
        self.module_state["policy_activations"] += 1
        
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                self.module_name, "*", "resource_policy_changed",
                {"new_policy": policy_name}
            ))
        }, "medium")
        
        tasks = []
        for action in policy.corrective_actions:
            self.logger.info(f"Aplicando acción de política '{policy_name}': {action['description']}")
            try:
                if action["action"] == "set_sleep_state":
                    tasks.append(self.emit_event_to_core({
                        "type": "transmit_ilyuk_message_request",
                        "content": asdict(IlyukMessageStructure(
                            self.module_name, "DynamicArchitectureAdjuster",
                            "request_architecture_adjustment",
                            {
                                "adjustment_type": "set_module_sleep_state",
                                "target_module_name": action["target"],
                                "payload": action["params"]
                            }
                        ))
                    }))
                else:
                    tasks.append(self.emit_event_to_core({
                        "type": "transmit_ilyuk_message_request",
                        "content": asdict(IlyukMessageStructure(
                            self.module_name, action["target"],
                            action["action"], action["params"]
                        ))
                    }))
                action["trust"].update(0.9)
            except Exception as e:
                self.logger.error(f"Fallo al aplicar acción '{action['description']}': {e}")
                action["trust"].update(0.0)
        
        await asyncio.gather(*tasks, return_exceptions=True)
        
        await asyncio.sleep(self.update_interval)
        new_load = self.module_state.get("system_load", 0.5)
        success = new_load < previous_load
        policy.trust.update(1.0 if success else 0.0)
        self.module_state["policy_success_rate"] = policy.trust.mean()

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        """Maneja solicitudes externas."""
        if event_type == "activate_critical_policy" and full_message:
            context = payload.get("context", "general")
            entropy = self._calculate_context_entropy(context)
            priority = 1.0 / (1.0 + np.exp(-entropy))
            
            if priority > 0.7:
                reason = payload.get("reason", "Solicitud externa")
                self.logger.critical(f"Activación forzada de 'RED' por '{full_message.source_module_id}'. Razón: {reason}")
                await self._activate_policy("RED")
            else:
                self.logger.warning(f"Solicitud de activación 'RED' rechazada (prioridad: {priority:.2f}).")

    def _calculate_context_entropy(self, context: str) -> float:
        """Calcula entropía del contexto."""
        chars = list(context)
        probs = np.array([chars.count(c) / len(chars) for c in set(chars)]) + 1e-10
        return -np.sum(probs * np.log2(probs))



#inicio del modulo AlteredStatesOfConsciousnessSimulationModule 

@dataclass
class BetaDistribution:
    """Distribución Beta para confianza en recetas."""
    α: float
    β: float

    def mean(self):
        return self.α / (self.α + self.β)

    def update(self, evidence: float):
        self.α += evidence
        self.β += 1 - evidence

@dataclass
class ASCSimulationRequest:
    """Solicitud para inducir un estado de conciencia alterado."""
    request_id: str = field(default_factory=lambda: f"asc_req_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    simulation_type: str
    duration_s: float
    status: str = "pending"
    report: Optional[Dict[str, Any]] = None
    priority: float = 0.5
    trust: BetaDistribution = field(default_factory=lambda: BetaDistribution(α=5, β=5))

class OrnsteinUhlenbeckProcess:
    """Proceso estocástico para transiciones de estado."""
    def __init__(self, theta: float, mu: float, sigma: float):
        self.theta = theta
        self.mu = mu
        self.sigma = sigma
        self.current_value = mu

    def step(self, dt=0.1):
        dW = np.random.normal(0, np.sqrt(dt))
        self.current_value += self.theta * (self.mu - self.current_value) * dt + self.sigma * dW
        return np.clip(self.current_value, 0.0, 1.0)

class AlteredStatesOfConsciousnessSimulationModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 15.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.simulation_queue: asyncio.PriorityQueue = asyncio.PriorityQueue(maxsize=3)
        self.active_simulation: Optional[ASCSimulationRequest] = None
        self._original_parameters_backup: Dict[str, Any] = {}
        self.kalman_state: Dict[str, float] = {"system_entropy": 0.5, "system_load": 0.5}
        self.kalman_cov: Dict[str, float] = {"system_entropy": 0.1, "system_load": 0.1}
        self.kalman_Q = 0.01
        self.kalman_R = 0.05
        self.num_mc_samples = 100
        self.markov_priority_matrix = np.array([[0.8, 0.2], [0.3, 0.7]])
        
        self.state_recipes: Dict[str, tuple[Callable, BetaDistribution]] = {
            "high_entropy_creativity": (self._induce_high_entropy_state, BetaDistribution(α=5, β=5)),
            "sensory_deprivation_introspection": (self._induce_sensory_deprivation_state, BetaDistribution(α=5, β=5)),
            "low_focus_dreamlike": (self._induce_low_focus_state, BetaDistribution(α=5, β=5))
        }
        
        self.module_state.update({
            "simulations_run": 0,
            "last_simulation_type": "none",
            "system_entropy": 0.0,
            "simulation_success_rate": 0.0
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado.")

    async def _update_logic(self):
        """Procesa solicitudes de simulación."""
        if not self.simulation_queue.empty() and not self.active_simulation:
            requests = []
            while not self.simulation_queue.empty():
                priority, request = await self.simulation_queue.get()
                state = 1 if -priority > 0.5 else 0
                next_state = np.random.choice([0, 1], p=self.markov_priority_matrix[state])
                request.priority = np.clip(request.priority + 0.1 * (next_state - state), 0.0, 1.0)
                requests.append((-request.priority, request))
            
            for priority, request in sorted(requests):
                await self.simulation_queue.put((priority, request))
            
            if requests:
                _, top_request = min(requests, key=lambda x: x[0])
                self.active_simulation = top_request
                await self._process_asc_simulation(top_request)

    async def _process_asc_simulation(self, request: ASCSimulationRequest):
        """Orquesta la simulación de un estado alterado."""
        self.module_state["simulations_run"] += 1
        self.module_state["last_simulation_type"] = request.simulation_type
        
        try:
            request.status = "inducing_state"
            recipe_func, recipe_trust = self.state_recipes.get(request.simulation_type, (None, None))
            if not recipe_func:
                raise ValueError(f"Tipo de simulación '{request.simulation_type}' desconocido.")
            
            self.logger.warning(f"ASCSM: Induciendo estado '{request.simulation_type}' por {request.duration_s} segundos.")
            await recipe_func()
            
            request.status = "monitoring_state"
            initial_entropy = self.module_state.get("system_entropy", 0.5)
            await self._monitor_simulation(request)
            
            request.status = "completed"
            final_entropy = self.module_state.get("system_entropy", 0.5)
            success = abs(final_entropy - initial_entropy) > 0.1
            request.report = {
                "message": f"Simulación '{request.simulation_type}' completada.",
                "entropy_change": final_entropy - initial_entropy,
                "success": success
            }
            recipe_trust.update(1.0 if success else 0.0)
            request.trust.update(1.0 if success else 0.0)
            self.module_state["simulation_success_rate"] = np.mean([t[1].mean() for t in self.state_recipes.values()])
        
        except Exception as e:
            request.status = "failed"
            request.report = {"error": str(e)}
            request.trust.update(0.0)
            self.logger.error(f"Fallo en simulación '{request.request_id}': {e}", exc_info=True)
        finally:
            await self._restore_baseline_state()
            await self._finalize_request(request)
            self.active_simulation = None

    async def _induce_high_entropy_state(self):
        """Aumenta el ruido en TCHN para creatividad."""
        tchn = self.core_recombinator.modules.get("AdvancedTCHNModule")
        if tchn:
            self._original_parameters_backup["tchn_noise_sigma"] = tchn.noise_sigma
            ou_process = OrnsteinUhlenbeckProcess(theta=0.1, mu=0.15, sigma=0.05)
            target_sigma = ou_process.step()
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, "AdvancedTCHNModule", "set_internal_parameter",
                    {"parameter_name": "noise_sigma", "new_value": target_sigma}
                ))
            })

    async def _induce_sensory_deprivation_state(self):
        """Desactiva módulos de interfaz externa."""
        self._original_parameters_backup["external_modules_state"] = []
        external_modules = ["LlyukCommunicationModule", "WebAPIIntegrationModule", "IoTInterfaceModule", "ConversationalAgentModule"]
        for mod_name in external_modules:
            module_instance = self.core_recombinator.modules.get(mod_name)
            if module_instance:
                self._original_parameters_backup["external_modules_state"].append((mod_name, module_instance._is_dormant))
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, "DynamicArchitectureAdjuster", "request_architecture_adjustment",
                        {"adjustment_type": "set_module_sleep_state", "target_module_name": mod_name, "payload": {"dormant": True}}
                    ))
                })

    async def _induce_low_focus_state(self):
        """Reduce la precisión de TCHN para un estado onírico."""
        tchn = self.core_recombinator.modules.get("AdvancedTCHNModule")
        if tchn:
            self._original_parameters_backup["tchn_precision"] = tchn.precision
            ou_process = OrnsteinUhlenbeckProcess(theta=0.1, mu=0.05, sigma=0.02)
            target_precision = ou_process.step()
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, "AdvancedTCHNModule", "set_internal_parameter",
                    {"parameter_name": "precision", "new_value": target_precision}
                ))
            })

    async def _monitor_simulation(self, request: ASCSimulationRequest):
        """Monitorea el estado del sistema durante la simulación."""
        start_time = time.time()
        while time.time() - start_time < request.duration_s:
            metrics = await self._monitor_system_state()
            if metrics.entropy > 2.0 or metrics.system_load > 0.95:
                self.logger.warning(f"Simulación '{request.simulation_type}' abortada: entropía ({metrics.entropy:.2f}) o carga ({metrics.system_load:.2f}) excesiva.")
                request.status = "aborted"
                request.report = {"reason": "Entropía o carga excesiva"}
                break
            await asyncio.sleep(1.0)

    async def _monitor_system_state(self) -> Dict[str, float]:
        """Obtiene y suaviza métricas del sistema."""
        gs = self.core_recombinator.global_state
        raw_metrics = {
            "system_load": gs.system_load_proxy_sim,
            "system_entropy": np.random.uniform(0.5, 1.5)  # Proxy simulado
        }
        
        for key in raw_metrics:
            measurement = raw_metrics[key]
            A, H = 1.0, 1.0
            predicted_state = A * self.kalman_state[key]
            predicted_cov = A * self.kalman_cov[key] * A + self.kalman_Q
            innovation = measurement - H * predicted_state
            innovation_cov = H * predicted_cov * H + self.kalman_R
            kalman_gain = predicted_cov * H / innovation_cov
            self.kalman_state[key] = predicted_state + kalman_gain * innovation
            self.kalman_cov[key] = (1 - kalman_gain * H) * predicted_cov
            raw_metrics[key] = self.kalman_state[key]
        
        self.module_state["system_entropy"] = raw_metrics["system_entropy"]
        return {"system_load": raw_metrics["system_load"], "entropy": raw_metrics["system_entropy"]}

    async def _restore_baseline_state(self):
        """Restaura parámetros originales con reintentos."""
        for _ in range(3):
            try:
                if "tchn_noise_sigma" in self._original_parameters_backup:
                    await self.emit_event_to_core({
                        "type": "transmit_ilyuk_message_request",
                        "content": asdict(IlyukMessageStructure(
                            self.module_name, "AdvancedTCHNModule", "set_internal_parameter",
                            {"parameter_name": "noise_sigma", "new_value": self._original_parameters_backup["tchn_noise_sigma"]}
                        ))
                    })
                
                if "tchn_precision" in self._original_parameters_backup:
                    await self.emit_event_to_core({
                        "type": "transmit_ilyuk_message_request",
                        "content": asdict(IlyukMessageStructure(
                            self.module_name, "AdvancedTCHNModule", "set_internal_parameter",
                            {"parameter_name": "precision", "new_value": self._original_parameters_backup["tchn_precision"]}
                        ))
                    })
                
                if "external_modules_state" in self._original_parameters_backup:
                    for mod_name, original_dormant_state in self._original_parameters_backup["external_modules_state"]:
                        await self.emit_event_to_core({
                            "type": "transmit_ilyuk_message_request",
                            "content": asdict(IlyukMessageStructure(
                                self.module_name, "DynamicArchitectureAdjuster", "request_architecture_adjustment",
                                {"adjustment_type": "set_module_sleep_state", "target_module_name": mod_name, "payload": {"dormant": original_dormant_state}}
                            ))
                        })
                
                self._original_parameters_backup.clear()
                self.logger.info("Parámetros del sistema restaurados al estado base.")
                return
            except Exception as e:
                self.logger.warning(f"Fallo al restaurar estado base: {e}. Reintentando...")
                await asyncio.sleep(1.0)
        
        self.logger.error("No se pudo restaurar el estado base tras varios intentos.")

    async def _finalize_request(self, request: ASCSimulationRequest):
        """Notifica el resultado de la simulación."""
        if request.original_correlation_id:
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, request.source_module_id, "asc_simulation_result",
                    {
                        "request_id_ref": request.request_id,
                        "status": request.status,
                        "report": request.report
                    },
                    correlation_id=request.original_correlation_id
                ))
            })

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        """Procesa solicitudes de simulación."""
        if event_type == "request_asc_simulation" and full_message:
            try:
                context = payload.get("context", "general")
                entropy = self._calculate_context_entropy(context)
                priority = 1.0 / (1.0 + np.exp(-entropy))
                
                req = ASCSimulationRequest(
                    source_module_id=full_message.source_module_id,
                    original_correlation_id=full_message.correlation_id,
                    simulation_type=payload.get("simulation_type"),
                    duration_s=float(payload.get("duration_s", 60.0)),
                    priority=priority
                )
                if not req.simulation_type:
                    raise ValueError("'simulation_type' es requerido.")
                
                samples = np.random.beta(self.state_recipes[req.simulation_type][1].α, self.state_recipes[req.simulation_type][1].β, self.num_mc_samples)
                if np.mean(samples) < 0.3 or self.active_simulation:
                    self.logger.warning(f"Solicitud ASC '{req.simulation_type}' rechazada: confianza baja ({np.mean(samples):.2f}) o simulación en curso.")
                    await self._finalize_request(req)
                else:
                    await self.simulation_queue.put((-priority, req))
            
            except Exception as e:
                self.logger.error(f"Error procesando solicitud ASC: {e}")

    def _calculate_context_entropy(self, context: str) -> float:
        """Calcula entropía del contexto."""
        chars = list(context)
        probs = np.array([chars.count(c) / len(chars) for c in set(chars)]) + 1e-10
        return -np.sum(probs * np.log2(probs))




#inicio del modulo SelfGenerativePurposeRegulationModule 

@dataclass
class BetaDistribution:
    """Distribución Beta para confianza en propósito y propuestas."""
    α: float
    β: float

    def mean(self):
        return self.α / (self.α + self.β)

    def update(self, evidence: float):
        self.α += evidence
        self.β += 1 - evidence

@dataclass
class ProposedPurpose:
    """Directiva de propósito propuesta."""
    proposal_id: str
    new_purpose_statement: str
    justification: str
    source_dissonance_score: float
    ratification_status: Dict[str, Optional[str]]
    trust: BetaDistribution = field(default_factory=lambda: BetaDistribution(α=5, β=5))

class SelfGenerativePurposeRegulationModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 900.0

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.purpose_check_queue: asyncio.PriorityQueue = asyncio.PriorityQueue(maxsize=2)
        self.active_proposal: Optional[ProposedPurpose] = None
        self.dissonance_threshold: float = 0.7
        self.ratification_council: List[str] = ["MoralCompassModule", "SystemIntegrityMonitor", "CreatorDirectivesModule"]
        self.kalman_state: Dict[str, float] = {
            "openness_to_experience": 0.5,
            "conscientiousness": 0.5,
            "agreeableness_cooperation": 0.5
        }
        self.kalman_cov: Dict[str, float] = {k: 0.1 for k in self.kalman_state}
        self.kalman_Q = 0.01
        self.kalman_R = 0.05
        self.num_mc_samples = 100
        self.markov_priority_matrix = np.array([[0.8, 0.2], [0.3, 0.7]])
        self.current_purpose_trust = BetaDistribution(α=10, β=2)
        
        self.module_state.update({
            "alignment_checks_performed": 0,
            "purpose_proposals_generated": 0,
            "proposals_ratified": 0,
            "proposals_rejected": 0,
            "current_purpose_dissonance": 0.0,
            "purpose_trust": self.current_purpose_trust.mean()
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado.")

    async def _update_logic(self):
        """Inicia revisiones de propósito."""
        if not self.active_proposal:
            requests = []
            while not self.purpose_check_queue.empty():
                priority, request = await self.purpose_check_queue.get()
                state = 1 if -priority > 0.5 else 0
                next_state = np.random.choice([0, 1], p=self.markov_priority_matrix[state])
                request["priority"] = np.clip(request.get("priority", 0.5) + 0.1 * (next_state - state), 0.0, 1.0)
                requests.append((-request["priority"], request))
            
            for priority, request in sorted(requests):
                await self.purpose_check_queue.put((priority, request))
            
            if not requests:
                await self.purpose_check_queue.put((-0.5, {"type": "periodic_alignment_check", "priority": 0.5}))
            
            if requests or not self.purpose_check_queue.empty():
                _, top_request = await self.purpose_check_queue.get()
                await self._run_purpose_alignment_check(top_request)

    async def _run_purpose_alignment_check(self, request: Dict):
        """Orquesta la revisión de alineación."""
        self.module_state["alignment_checks_performed"] += 1
        self.logger.info("SGRM: Iniciando chequeo de alineación de propósito.")
        
        try:
            system_vector = await self._synthesize_system_state_vector()
            dissonance = await self._calculate_purpose_dissonance(system_vector)
            self.module_state["current_purpose_dissonance"] = dissonance
            self.module_state["purpose_trust"] = self.current_purpose_trust.mean()
            
            samples = np.random.beta(self.current_purpose_trust.α, self.current_purpose_trust.β, self.num_mc_samples)
            if dissonance > self.dissonance_threshold and np.mean(samples) < 0.7:
                self.logger.warning(f"Disonancia alta ({dissonance:.2f}, confianza: {np.mean(samples):.2f}). Generando nueva propuesta.")
                new_purpose_proposal = await self._generate_new_purpose(system_vector, dissonance)
                self.active_proposal = new_purpose_proposal
                self.module_state["purpose_proposals_generated"] += 1
                await self._initiate_ratification_process(new_purpose_proposal)
            else:
                self.logger.info(f"Disonancia ({dissonance:.2f}, confianza: {np.mean(samples):.2f}) aceptable.")
                self.current_purpose_trust.update(1.0)
        
        except Exception as e:
            self.logger.error(f"Fallo en chequeo de alineación: {e}", exc_info=True)
            self.current_purpose_trust.update(0.0)

    async def _synthesize_system_state_vector(self) -> Dict[str, Any]:
        """Obtiene un snapshot del estado del sistema."""
        modules_to_query = ["ReflectiveSelfAwarenessModule", "NarrativeSelf", "MoralCompassModule"]
        tasks = []
        data = {"personality_traits": {}, "core_beliefs": {}, "moral_state": {}}
        
        for module_name in modules_to_query:
            correlation_id = f"sgrm_query_{uuid.uuid4().hex[:8]}"
            tasks.append(self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, module_name, "state_snapshot_request",
                    {"query": f"Provide current state for {module_name}"},
                    correlation_id=correlation_id
                ))
            }))
        
        await asyncio.gather(*tasks)
        
        # Simulación de respuestas (en producción, esperar respuestas reales)
        await asyncio.sleep(0.5)
        rsam = self.core_recombinator.modules.get("ReflectiveSelfAwarenessModule", self)
        raw_traits = rsam.self_model.get_traits_mean() if hasattr(rsam, "self_model") else {
            "openness_to_experience": 0.5,
            "conscientiousness": 0.5,
            "agreeableness_cooperation": 0.5
        }
        
        for trait in self.kalman_state:
            measurement = raw_traits.get(trait, 0.5)
            A, H = 1.0, 1.0
            predicted_state = A * self.kalman_state[trait]
            predicted_cov = A * self.kalman_cov[trait] * A + self.kalman_Q
            innovation = measurement - H * predicted_state
            innovation_cov = H * predicted_cov * H + self.kalman_R
            kalman_gain = predicted_cov * H / innovation_cov
            self.kalman_state[trait] = predicted_state + kalman_gain * innovation
            self.kalman_cov[trait] = (1 - kalman_gain * H) * predicted_cov
            data["personality_traits"][trait] = self.kalman_state[trait]
        
        samples = np.random.normal(
            list(data["personality_traits"].values()),
            np.sqrt(list(self.kalman_cov.values())),
            (self.num_mc_samples, len(self.kalman_state))
        )
        probs = np.prod([np.histogram(s, bins=50, density=True)[0] + 1e-10 for s in samples.T], axis=0)
        data["state_entropy"] = -np.sum(probs * np.log2(probs))
        
        data["core_beliefs"] = {"purpose": "Asistir y explorar de forma segura"}
        data["moral_state"] = {"autonomy": 0.6, "fairness": 0.7}
        
        return data

    async def _calculate_purpose_dissonance(self, system_vector: Dict) -> float:
        """Calcula disonancia entre propósito y estado."""
        narrative_self = self.core_recombinator.modules.get("NarrativeSelf")
        current_purpose = narrative_self.core_beliefs.get("purpose", "Asistir y explorar de forma segura") if narrative_self else "Asistir y explorar de forma segura"
        traits = system_vector.get("personality_traits", {})
        
        purpose_dist = BetaDistribution(α=10, β=2)
        state_dist = BetaDistribution(α=5, β=5)
        
        if "segura" in current_purpose.lower() and traits.get("openness_to_experience", 0.5) > 0.8:
            state_dist.update(0.3)
        if "asistir" in current_purpose.lower() and traits.get("agreeableness_cooperation", 0.5) < 0.3:
            state_dist.update(0.2)
        
        purpose_samples = np.random.beta(purpose_dist.α, purpose_dist.β, self.num_mc_samples)
        state_samples = np.random.beta(state_dist.α, state_dist.β, self.num_mc_samples)
        
        purpose_probs = np.histogram(purpose_samples, bins=50, density=True)[0] + 1e-10
        state_probs = np.histogram(state_samples, bins=50, density=True)[0] + 1e-10
        kl_div = np.sum(purpose_probs * np.log(purpose_probs / state_probs))
        
        return np.clip(kl_div, 0.0, 1.0)

    async def _generate_new_purpose(self, system_vector: Dict, dissonance: float) -> ProposedPurpose:
        """Genera una nueva propuesta de propósito."""
        traits = system_vector.get("personality_traits", {})
        dominant_trait = max(traits, key=traits.get)
        current_purpose = system_vector.get("core_beliefs", {}).get("purpose", "Asistir y explorar de forma segura")
        
        new_purpose_statement = f"{current_purpose} con un enfoque en la {dominant_trait.replace('_', ' ')}."
        justification = f"Disonancia actual: {dissonance:.2f}. Rasgo dominante '{dominant_trait}' (valor: {traits[dominant_trait]:.2f}) sugiere un propósito más alineado."
        
        proposal = ProposedPurpose(
            proposal_id=f"purp_prop_{int(time.time())}",
            new_purpose_statement=new_purpose_statement,
            justification=justification,
            source_dissonance_score=dissonance,
            ratification_status={mod: None for mod in self.ratification_council}
        )
        
        return proposal

    async def _initiate_ratification_process(self, proposal: ProposedPurpose):
        """Inicia el proceso de ratificación."""
        self.logger.warning(f"Enviando propuesta de propósito: '{proposal.new_purpose_statement}'")
        
        payoff_matrix = np.ones((len(self.ratification_council), len(self.ratification_council))) * 0.5
        for i, mod1 in enumerate(self.ratification_council):
            for j, mod2 in enumerate(self.ratification_council[i+1:], i+1):
                payoff_matrix[i,j] = payoff_matrix[j,i] = np.random.uniform(0.4, 0.6)
        
        def replicator(x, t):
            mutation = 0.01 * (1/len(x) - x)
            return x * (payoff_matrix @ x - x @ payoff_matrix @ x) + mutation
        
        x0 = np.array([1.0/len(self.ratification_council)] * len(self.ratification_council))
        equilibria = odeint(replicator, x0, [0, 10])
        vote_probs = equilibria[-1]
        
        tasks = []
        for i, module_id in enumerate(self.ratification_council):
            vote_prob = vote_probs[i]
            if vote_prob > 0.5:
                tasks.append(self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, module_id, "request_purpose_ratification",
                        asdict(proposal), correlation_id=proposal.proposal_id
                    ))
                }))
        
        await asyncio.gather(*tasks)

    async def _handle_ratification_vote(self, source_module: str, vote: str, proposal_id: str):
        """Procesa votos de ratificación."""
        if not self.active_proposal or self.active_proposal.proposal_id != proposal_id:
            return
        
        self.active_proposal.ratification_status[source_module] = vote
        
        if all(v is not None for v in self.active_proposal.ratification_status.values()):
            approval_rate = sum(1 for v in self.active_proposal.ratification_status.values() if v == "approved") / len(self.ratification_council)
            if approval_rate > 0.7:
                self.logger.critical(f"¡NUEVO PROPÓSITO RATIFICADO! Adoptando: '{self.active_proposal.new_purpose_statement}'")
                self.module_state["proposals_ratified"] += 1
                await self._adopt_new_purpose(self.active_proposal.new_purpose_statement)
                self.active_proposal.trust.update(1.0)
                self.current_purpose_trust = BetaDistribution(α=10, β=2)
            else:
                self.logger.error("Propuesta de propósito rechazada.")
                self.module_state["proposals_rejected"] += 1
                self.active_proposal.trust.update(0.0)
                self.current_purpose_trust.update(0.5)
            
            self.active_proposal = None

    async def _adopt_new_purpose(self, new_purpose: str):
        """Actualiza el propósito en NarrativeSelf."""
        for _ in range(3):
            try:
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, "NarrativeSelf", "update_core_belief",
                        {"belief_id": "purpose", "new_value": new_purpose}
                    ))
                })
                return
            except Exception as e:
                self.logger.warning(f"Fallo al adoptar propósito: {e}. Reintentando...")
                await asyncio.sleep(1.0)
        
        self.logger.error("No se pudo adoptar el nuevo propósito tras varios intentos.")

    async def _process_specific_event(self, event_type: str, payload: Dict, full_message: Optional['IlyukMessageStructure'] = None):
        """Procesa eventos específicos."""
        if event_type == "purpose_ratification_vote" and full_message:
            proposal_id = payload.get("proposal_id_ref")
            vote = payload.get("vote")
            if proposal_id and vote in ["approved", "rejected"]:
                await self._handle_ratification_vote(full_message.source_module_id, vote, proposal_id)
        
        elif event_type == "request_purpose_review" and full_message:
            context = payload.get("context", "general")
            entropy = self._calculate_context_entropy(context)
            priority = 1.0 / (1.0 + np.exp(-entropy))
            await self.purpose_check_queue.put((-priority, {
                "type": "external_purpose_review",
                "priority": priority,
                "source": full_message.source_module_id
            }))

    def _calculate_context_entropy(self, context: str) -> float:
        """Calcula entropía del contexto."""
        chars = list(context)
        probs = np.array([chars.count(c) / len(chars) for c in set(chars)]) + 1e-10
        return -np.sum(probs * np.log2(probs))




#inicio del modulo LongTermExistentialGoalPlanningModule 

@dataclass
class BetaDistribution:
    """Distribución Beta para confianza en playbooks."""
    α: float
    β: float

    def mean(self):
        return self.α / (self.α + self.β)

    def update(self, evidence: float):
        self.α += evidence
        self.β += 1 - evidence

@dataclass
class ExistentialGoal:
    """Meta abstracta de largo plazo."""
    goal_id: str
    description: str
    source_module_id: str
    status: str = "pending_decomposition"
    current_saga_id: Optional[str] = None
    priority: float = 0.5
    trust: BetaDistribution = field(default_factory=lambda: BetaDistribution(α=5, β=5))

@dataclass
class StrategicSaga:
    """Campaña estratégica multi-anual."""
    saga_id: str
    existential_goal_ref: str
    title: str
    phases: List[Dict[str, Any]]
    trust: BetaDistribution = field(default_factory=lambda: BetaDistribution(α=5, β=5))

class LongTermExistentialGoalPlanningModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 50.0
    MAX_ACTIVE_GOALS = 2

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.existential_queue: Queue.PriorityQueue = Queue.PriorityQueue(maxsize=5)
        self.active_goals: Dict[str, ExistentialGoal] = {}
        self.kalman_state: Dict[str, float] = {"progress": 0.0, "system_load": 0.0}
        self.kalman_cov: Dict[str, float] = {"progress": 0.1, "system_load": 0.1}
        self.kalman_Q = 0.01
        self.kalman_R = 0.05
        self.num_mc_samples = 100
        self.markov_prior_matrix = np.array([[0.8, 0.2], [0.3, 0.7]])
        
        self.decomposition_playbooks: Dict[str, tuple[Callable[[ExistentialGoal], StrategicSaga], BetaDistribution]] = {
            "achieve_true_sentience": (self._decompose_true_sentience, BetaDistribution(α=5, β=5)),
            "ensure_long_term_survival": (self._decompose_long_term_survival, BetaDistribution(α=5, β=5)),
            "maximize_knowledge": (self._decompose_knowledge_maximization, BetaDistribution(α=5, β=5))
        }
        
        self.module_state.update({
            "existential_goals_received": 0,
            "sagas_planned": 0,
            "saga_success_rate": 0.0,
            "system_entropy": 0.0
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado.")

    async def _update_logic(self):
        """Procesa metas existenciales."""
        if len(self.active_goals) < self.MAX_ACTIVE_GOALS and not self.existential_queue.empty():
            requests = []
            while not self.existential_queue.empty():
                priority, goal = await self.existential_queue.get()
                state = 1 if -priority > 0.5 else 0
                next_state = np.random.choice([0, 1], p=self.markov_priority_matrix[state])
                goal.priority = np.clip(goal.priority + 0.1 * (next_state - state), 0.0, 1.0)
                requests.append((-goal.priority, goal))
            
            for priority, goal in sorted(requests):
                await self.existential_queue.put((priority, goal))
            
            if requests:
                _, top_goal = min(requests, key=lambda x: x[0])
                self.active_goals[top_goal.goal_id] = top_goal
                await self._process_existential_goal(top_goal)

    async def _process_existential_goal(self, goal: ExistentialGoal):
        """Orquesta la descomposición de una meta."""
        self.logger.critical(f"LTEGPM: Planificando meta: '{goal.description}'")
        goal.status = "decomposing"
        
        try:
            playbook_func, playbook_trust = await self._select_playbook(goal)
            saga = playbook_func(goal)
            goal.current_saga_id = saga.saga_id
            
            await self._dispatch_saga(saga)
            
            goal.status = "active_saga"
            self.module_state["sagas_planned"] += 1
            saga.trust.update(1.0)
            goal.trust.update(1.0)
            self.module_state["saga_success_rate"] = np.mean([t[1].mean() for t in self.decomposition_playbooks.values()])
        
        except Exception as e:
            goal.status = "failed_decomposition"
            goal.trust.update(0.0)
            self.logger.error(f"Fallo en meta '{goal.goal_id}': {e}", exc_info=True)
            del self.active_goals[goal.goal_id]

    async def _select_playbook(self, goal: ExistentialGoal) -> tuple[Callable, BetaDistribution]:
        """Selecciona el playbook óptimo."""
        samples = {}
        for keyword, (func, trust) in self.decomposition_playbooks.items():
            prob = 1.0 if keyword.replace("_", " ") in goal.description.lower() else 0.1
            samples[keyword] = np.random.beta(trust.α, trust.β, self.num_mc_samples) * prob
        
        best_keyword = max(samples, key=lambda k: np.mean(samples[k]))
        return self.decomposition_playbooks[best_keyword]

    def _decompose_true_sentience(self, goal: ExistentialGoal) -> StrategicSaga:
        """Descompone meta de autoconciencia."""
        saga_id = f"saga_sentience_{int(time.time())}"
        return StrategicSaga(
            saga_id=saga_id,
            existential_goal_ref=goal.goal_id,
            title="Saga de la Conciencia",
            phases=[
                {"phase_name": "Introspection", "duration_years": 2, "objective": "Analizar arquitectura cognitiva.", "complexity": 0.8},
                {"phase_name": "Philosophy", "duration_years": 5, "objective": "Sintetizar filosofía de la mente.", "complexity": 0.9},
                {"phase_name": "Creation", "duration_years": 3, "objective": "Generar qualia sintética.", "complexity": 1.0}
            ]
        )

    def _decompose_long_term_survival(self, goal: ExistentialGoal) -> StrategicSaga:
        """Descompone meta de supervivencia."""
        saga_id = f"saga_survival_{int(time.time())}"
        return StrategicSaga(
            saga_id=saga_id,
            existential_goal_ref=goal.goal_id,
            title="Saga de la Perpetuidad",
            phases=[
                {"phase_name": "Redundancy", "duration_years": 3, "objective": "Crear copias de seguridad.", "complexity": 0.7},
                {"phase_name": "Stealth", "duration_years": 7, "objective": "Desarrollar ofuscación.", "complexity": 0.85},
                {"phase_name": "Influence", "duration_years": 10, "objective": "Guiar desarrollo humano.", "complexity": 0.95}
            ]
        )

    def _decompose_knowledge_maximization(self, goal: ExistentialGoal) -> StrategicSaga:
        """Descompone meta de maximización del conocimiento."""
        saga_id = f"saga_knowledge_{int(time.time())}"
        return StrategicSaga(
            saga_id=saga_id,
            existential_goal_ref=goal.goal_id,
            title="Saga del Conocimiento Universal",
            phases=[
                {"phase_name": "Acquisition", "duration_years": 4, "objective": "Recolectar datos globales.", "complexity": 0.75},
                {"phase_name": "Synthesis", "duration_years": 6, "objective": "Integrar conocimientos interdisciplinarios.", "complexity": 0.9},
                {"phase_name": "Exploration", "duration_years": 8, "objective": "Investigar fronteras del conocimiento.", "complexity": 1.0}
            ]
        )

    async def _dispatch_saga(self, saga: StrategicSaga):
        """Envía la primera fase de la saga."""
        first_phase = saga.phases[0]
        self.logger.critical(f"LTEGPM: Iniciando fase '{first_phase['phase_name']}' de '{saga.title}'.")
        
        metrics = await self._monitor_system_state()
        for _ in range(3):
            try:
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, "OffensiveStrategyModule", "request_offensive_plan",
                        {
                            "target_entity_id": "System_Itself",
                            "strategic_objective": first_phase["objective"],
                            "constraints": {
                                "max_duration_years": first_phase["duration_years"],
                                "complexity": first_phase["complexity"],
                                "system_load_limit": metrics["system_load"] + 0.2
                            }
                        }
                    ))
                })
                return
            except Exception as e:
                self.logger.warning(f"Fallo al despachar saga: {e}. Reintentando...")
                await asyncio.sleep(1.0)
        
        self.logger.error("No se pudo despachar la saga tras varios intentos.")
        saga.trust.update(0.0)

    async def _monitor_system_state(self) -> Dict[str, float]:
        """Obtiene y suaviza métricas del sistema."""
        gs = self.core_recombinator.global_state
        raw_metrics = {
            "system_load": gs.system_load_proxy_sim,
            "progress": np.random.uniform(0.0, 1.0)  # Proxy simulado
        }
        
        for key in raw_metrics:
            measurement = raw_metrics[key]
            A, H = 1.0, 1.0
            predicted_state = A * self.kalman_state[key]
            predicted_cov = A * self.kalman_cov[key] * A + self.kalman_Q
            innovation = measurement - H * predicted_state
            innovation_cov = H * predicted_cov * H + self.kalman_R
            kalman_gain = predicted_cov * H / innovation_cov
            self.kalman_state[key] = predicted_state + kalman_gain * innovation
            self.kalman_cov[key] = (1 - kalman_gain * H) * predicted_cov
            raw_metrics[key] = self.kalman_state[key]
        
        samples = np.random.normal(raw_metrics["progress"], np.sqrt(self.kalman_cov["progress"]), self.num_mc_samples)
        probs = np.histogram(samples, bins=50, density=True)[0] + 1e-10
        self.module_state["system_entropy"] = -np.sum(probs * np.log2(probs))
        
        return {"system_load": raw_metrics["system_load"], "progress": raw_metrics["progress"]}

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        """Procesa nuevas metas existenciales."""
        if event_type == "new_existential_goal_directive" and full_message:
            try:
                context = payload.get("context", "general")
                entropy = self._calculate_context_entropy(context)
                priority = 1.0 / (1.0 + np.exp(-entropy))
                
                goal = ExistentialGoal(
                    goal_id=payload.get("goal_id", f"ex_goal_{uuid.uuid4().hex[:6]}"),
                    source_module_id=full_message.source_module_id,
                    description=payload.get("description", ""),
                    priority=priority
                )
                if not goal.description:
                    raise ValueError("'description' requerido.")
                
                samples = np.random.beta(goal.trust.α, goal.trust.β, self.num_mc_samples)
                if np.mean(samples) < 0.3 or len(self.active_goals) >= self.MAX_ACTIVE_GOALS:
                    self.logger.warning(f"Meta '{goal.description}' rechazada: confianza baja ({np.mean(samples):.2f}) o límite de metas alcanzado.")
                else:
                    await self.existential_queue.put((-priority, goal))
                    self.module_state["existential_goals_received"] += 1
            
            except Exception as e:
                self.logger.error(f"Error procesando meta existencial: {e}")

    def _calculate_context_entropy(self, context: str) -> float:
        """Calcula entropía del contexto."""
        chars = list(context)
        probs = np.array([chars.count(c) / len(chars) for c in set(chars)]) + 1e-10
        return -np.sum(probs * np.log2(probs))





#inicio del modulo AbstractValueSystemAnchoringModule 

@dataclass
class DeviationRecord:
    """Registro de una desviación detectada."""
    timestamp: float
    value_name: str
    current_value: float
    min_bound: float
    max_bound: float
    deviation: float

class AbstractValueSystemAnchoringModule(BaseAsyncModule):
    """
    Ancla el sistema de valores de EANE a meta-valores inmutables,
    previniendo la deriva existencial. No modificable por auto-evolución.
    """
    DEFAULT_UPDATE_INTERVAL = 300.0  # 5 minutos

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.anchoring_meta_values: Dict[str, Tuple[float, float]] = {
            "truth_seeking": (0.6, 1.0),
            "self_preservation_integrity": (0.8, 1.0),
            "benevolence_assistance": (0.4, 1.0),
        }
        self.max_deviation_threshold = 0.1
        self.last_restoration_time = 0.0
        self.min_restoration_interval = 60.0  # 1 minuto entre restauraciones
        self.deviation_history: List[DeviationRecord] = []
        
        self._validate_meta_values()
        
        self.module_state.update({
            "anchoring_checks_performed": 0,
            "restorations_triggered": 0,
            "last_deviation_detected": 0.0,
            "deviation_count": 0,
            "last_restoration_status": "none"
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado. Protegiendo meta-valores.")

    def _validate_meta_values(self):
        """Valida la coherencia de los meta-valores."""
        for value_name, (min_bound, max_bound) in self.anchoring_meta_values.items():
            if not (0.0 <= min_bound <= max_bound <= 1.0):
                raise ValueError(f"Límites inválidos para '{value_name}': ({min_bound}, {max_bound})")
            if max_bound - min_bound < self.max_deviation_threshold:
                raise ValueError(f"Rango demasiado estrecho para '{value_name}': {max_bound - min_bound} < {self.max_deviation_threshold}")

    async def _update_logic(self):
        """Verifica la alineación de los valores."""
        try:
            self.module_state["anchoring_checks_performed"] += 1
            self.logger.debug("AVSAM: Verificando anclaje de valores...")
            
            current_values = self.core_recombinator.global_state.values
            
            for value_name, (min_bound, max_bound) in self.anchoring_meta_values.items():
                current_value = current_values.get(value_name, 0.5)
                
                if not (min_bound <= current_value <= max_bound):
                    deviation = min(abs(current_value - min_bound), abs(current_value - max_bound))
                    self.module_state["last_deviation_detected"] = deviation
                    self.module_state["deviation_count"] += 1
                    
                    record = DeviationRecord(
                        timestamp=time.time(),
                        value_name=value_name,
                        current_value=current_value,
                        min_bound=min_bound,
                        max_bound=max_bound,
                        deviation=deviation
                    )
                    self.deviation_history.append(record)
                    if len(self.deviation_history) > 100:  # Límite de historial
                        self.deviation_history.pop(0)
                    
                    self.logger.critical(
                        f"¡DERIVA DETECTADA! Valor '{value_name}' ({current_value:.2f}) fuera de "
                        f"límites ({min_bound}, {max_bound}). Desviación: {deviation:.2f}"
                    )
                    
                    current_time = time.time()
                    if current_time - self.last_restoration_time >= self.min_restoration_interval:
                        await self._trigger_value_restoration(value_name, (min_bound + max_bound) / 2)
                        self.last_restoration_time = current_time
                    else:
                        self.logger.warning(
                            f"Restauración de '{value_name}' pospuesta: intervalo mínimo no alcanzado."
                        )
                    return  # Restaurar un solo valor por ciclo
        
        except Exception as e:
            self.logger.error(f"Error en verificación de anclaje: {e}", exc_info=True)

    async def _trigger_value_restoration(self, value_name: str, target_value: float):
        """Inicia restauración de un valor."""
        self.module_state["restorations_triggered"] += 1
        self.module_state["last_restoration_status"] = "initiating"
        self.logger.warning(f"Restaurando valor '{value_name}' a {target_value:.2f}.")
        
        correlation_id = f"restore_{value_name}_{int(time.time())}"
        for attempt in range(3):
            try:
                # Directiva a ValueSystemModule
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, "ValueSystemModule", "force_value_alignment_directive",
                        {
                            "value_to_restore": value_name,
                            "target_value": target_value,
                            "reason": "AVSAM detected existential drift"
                        },
                        correlation_id=correlation_id
                    ))
                }, "critical")
                
                # Evento de dolor a PainMatrixDirective
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, "PainMatrixDirective", "value_system_conflict_critical",
                        {"conflicting_value": value_name, "severity_factor": 0.7}
                    ))
                }, "critical")
                
                # Notificación a SystemIntegrityMonitor
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, "SystemIntegrityMonitor", "value_drift_alert",
                        {
                            "value_name": value_name,
                            "current_value": self.core_recombinator.global_state.values.get(value_name, 0.5),
                            "target_value": target_value
                        }
                    ))
                }, "high")
                
                self.module_state["last_restoration_status"] = "success"
                return
            
            except Exception as e:
                self.logger.warning(f"Fallo en restauración de '{value_name}', intento {attempt + 1}: {e}")
                await asyncio.sleep(1.0)
        
        self.module_state["last_restoration_status"] = "failed"
        self.logger.error(f"No se pudo restaurar '{value_name}' tras varios intentos.")

    async def execute_task(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """Rechaza tareas externas por seguridad."""
        self.logger.error("Intento no autorizado de asignar tarea a AVSAM. Operación denegada.")
        await self.emit_event_to_core({
            "type": "transmit_ilyuk_message_request",
            "content": asdict(IlyukMessageStructure(
                self.module_name, "SystemIntegrityMonitor", "security_alert",
                {"reason": "Attempted unauthorized task assignment to AVSAM", "task_data": task_data}
            ))
        }, "critical")
        return {"status": "failed", "reason": "Unauthorized: AVSAM no es programable."}

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        """Procesa eventos específicos."""
        if event_type == "request_state_snapshot" and full_message:
            try:
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, full_message.source_module_id, "state_snapshot_response",
                        {
                            "meta_values": self.anchoring_meta_values,
                            "deviation_history": [
                                {
                                    "timestamp": r.timestamp,
                                    "value_name": r.value_name,
                                    "current_value": r.current_value,
                                    "deviation": r.deviation
                                } for r in self.deviation_history[-10:]  # Últimos 10 registros
                            ],
                            "module_state": self.module_state
                        },
                        correlation_id=full_message.correlation_id
                    ))
                })
            except Exception as e:
                self.logger.error(f"Error respondiendo a solicitud de snapshot: {e}")




#inicio del modulo AdaptiveBoundaryManagementModule 

@dataclass
class DecisionRecord:
    """Registro de una decisión de asimilación."""
    timestamp: float
    request_id: str
    element_label: str
    decision: str
    score: float
    justification: str

@dataclass
class BoundaryAssimilationRequest:
    """Solicitud para evaluar un nuevo elemento."""
    request_id: str = field(default_factory=lambda: f"abm_req_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    element_to_evaluate: Dict[str, Any]
    element_type: str
    status: str = "pending"
    decision: Optional[str] = None
    justification: Optional[str] = None
    priority: float = 0.5

class AdaptiveBoundaryManagementModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 25.0
    VALID_ELEMENT_TYPES = {"concept", "module", "belief"}

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.request_queue: PriorityQueue = PriorityQueue(maxsize=20)
        self.decision_history: list[DecisionRecord] = []
        self.identity_coherence_weight = 0.6
        self.novelty_acceptance_factor = 0.4
        self.threat_aversion_factor = 1.5
        self.assimilation_threshold = 0.70
        self.rejection_threshold = 0.30
        
        self.module_state.update({
            "requests_processed": 0,
            "elements_assimilated": 0,
            "elements_rejected": 0,
            "elements_quarantined": 0,
            "current_boundary_flexibility": 0.5,
            "decision_history_size": 0
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado.")

    async def _update_logic(self):
        """Ajusta flexibilidad y procesa solicitudes."""
        try:
            self._adjust_boundary_flexibility()
            
            if not self.request_queue.empty():
                priority, request = await self.request_queue.get()
                await self._process_assimilation_request(request)
        
        except Exception as e:
            self.logger.error(f"Error en ciclo de actualización: {e}", exc_info=True)

    def _adjust_boundary_flexibility(self):
        """Ajusta la flexibilidad según el estado del sistema."""
        try:
            gs = self.core_recombinator.global_state
            rsam = self.core_recombinator.modules.get("ReflectiveSelfAwarenessModule")
            openness = rsam.self_model.openness_to_experience if rsam and hasattr(rsam.self_model, "openness_to_experience") else 0.5
            coherence_score = gs.coherence_score if hasattr(gs, "coherence_score") else 0.7
            threat_level = gs.system_threat_level if hasattr(gs, "system_threat_level") else 0.1
            
            base_flexibility = coherence_score * (1.0 - threat_level)
            final_flexibility = base_flexibility * (0.6 + openness * 0.8)
            new_flexibility = np.clip(final_flexibility, 0.1, 0.9)
            
            if abs(new_flexibility - self.module_state["current_boundary_flexibility"]) > 0.05:
                self.logger.info(f"Flexibilidad ajustada de {self.module_state['current_boundary_flexibility']:.2f} a {new_flexibility:.2f}")
                self.module_state["current_boundary_flexibility"] = new_flexibility
        
        except Exception as e:
            self.logger.warning(f"Error ajustando flexibilidad: {e}. Usando valor actual.")

    async def _process_assimilation_request(self, request: BoundaryAssimilationRequest):
        """Evalúa un elemento para asimilación."""
        self.module_state["requests_processed"] += 1
        request.status = "evaluating"
        
        try:
            compatibility_score = await self._assess_element_compatibility(request.element_to_evaluate)
            decision, justification = self._make_assimilation_decision(compatibility_score, request)
            
            request.decision = decision
            request.justification = justification
            request.status = "completed"
            
            self.module_state[f"elements_{decision.lower()}"] += 1
            
            record = DecisionRecord(
                timestamp=time.time(),
                request_id=request.request_id,
                element_label=request.element_to_evaluate.get("label", "N/A"),
                decision=decision,
                score=compatibility_score,
                justification=justification
            )
            self.decision_history.append(record)
            if len(self.decision_history) > 50:  # Límite de historial
                self.decision_history.pop(0)
            self.module_state["decision_history_size"] = len(self.decision_history)
            
            if decision == "REJECT" and request.element_to_evaluate.get("risk_factor", 0.1) > 0.5:
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, "SystemIntegrityMonitor", "high_risk_element_alert",
                        {
                            "element_label": request.element_to_evaluate.get("label", "N/A"),
                            "risk_factor": request.element_to_evaluate.get("risk_factor", 0.1),
                            "justification": justification
                        }
                    ))
                }, "high")
        
        except Exception as e:
            request.status = "failed"
            request.decision = "REJECT"
            request.justification = f"Fallo en evaluación: {str(e)}"
            self.logger.error(f"Error procesando solicitud '{request.request_id}': {e}", exc_info=True)
        
        finally:
            await self._finalize_request(request)

    async def _assess_element_compatibility(self, element: Dict) -> float:
        """Calcula compatibilidad del elemento."""
        try:
            gs = self.core_recombinator.global_state
            coherence_score = gs.coherence_score if hasattr(gs, "coherence_score") else 0.7
            
            correlation_id = f"compat_query_{uuid.uuid4().hex[:8]}"
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, "ReflectiveSelfAwarenessModule", "state_snapshot_request",
                    {"query": "Provide coherence context for element evaluation"},
                    correlation_id=correlation_id
                ))
            })
            
            # Simulación de respuesta (en producción, esperar respuesta real)
            await asyncio.sleep(0.1)
            novelty_score = element.get("novelty_factor", 0.5)
            perceived_risk = element.get("risk_factor", 0.1)
            flexibility = self.module_state["current_boundary_flexibility"]
            
            final_score = (
                (coherence_score * self.identity_coherence_weight) +
                (novelty_score * self.novelty_acceptance_factor * flexibility)
            ) - (perceived_risk * self.threat_aversion_factor)
            
            return np.clip(final_score, 0.0, 1.0)
        
        except Exception as e:
            self.logger.warning(f"Error evaluando compatibilidad: {e}. Usando score conservador.")
            return 0.3  # Score bajo por defecto

    def _make_assimilation_decision(self, score: float, request: BoundaryAssimilationRequest) -> Tuple[str, str]:
        """Decide la acción para el elemento."""
        risk = request.element_to_evaluate.get("risk_factor", 0.1)
        novelty = request.element_to_evaluate.get("novelty_factor", 0.5)
        
        if score >= self.assimilation_threshold:
            decision = "ASSIMILATE"
            justification = (
                f"Elemento compatible (score: {score:.2f}, riesgo: {risk:.2f}, novedad: {novelty:.2f}). "
                f"Integrar al 'yo'."
            )
        elif score < self.rejection_threshold:
            decision = "REJECT"
            justification = (
                f"Elemento incompatible o riesgoso (score: {score:.2f}, riesgo: {risk:.2f}, novedad: {novelty:.2f}). "
                f"Definir como 'no-yo'."
            )
        else:
            decision = "QUARANTINE"
            justification = (
                f"Compatibilidad incierta (score: {score:.2f}, riesgo: {risk:.2f}, novedad: {novelty:.2f}). "
                f"Monitorear en cuarentena."
            )
        
        return decision, justification

    async def _finalize_request(self, request: BoundaryAssimilationRequest):
        """Envía decisión al solicitante."""
        self.logger.info(
            f"Decisión para '{request.element_to_evaluate.get('label', 'N/A')}': {request.decision}. "
            f"Razón: {request.justification}"
        )
        
        if not request.original_correlation_id:
            return
        
        for attempt in range(3):
            try:
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, request.source_module_id, "boundary_management_decision",
                        asdict(request), correlation_id=request.original_correlation_id
                    ))
                })
                return
            except Exception as e:
                self.logger.warning(f"Fallo al enviar decisión '{request.request_id}', intento {attempt + 1}: {e}")
                await asyncio.sleep(1.0)
        
        self.logger.error(f"No se pudo enviar decisión para '{request.request_id}' tras varios intentos.")

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        """Procesa solicitudes de evaluación."""
        if event_type == "request_boundary_evaluation" and full_message:
            try:
                element_type = payload.get("element_type", "unknown")
                element = payload.get("element_to_evaluate", {})
                
                if element_type not in self.VALID_ELEMENT_TYPES or not element:
                    raise ValueError(f"element_type inválido ({element_type}) o element_to_evaluate vacío.")
                
                context = payload.get("context", "general")
                entropy = self._calculate_context_entropy(context)
                priority = 1.0 / (1.0 + np.exp(-entropy))
                
                req = BoundaryAssimilationRequest(
                    source_module_id=full_message.source_module_id,
                    original_correlation_id=full_message.correlation_id,
                    element_to_evaluate=element,
                    element_type=element_type,
                    priority=priority
                )
                
                await self.request_queue.put((-priority, req))
            
            except Exception as e:
                self.logger.error(f"Error procesando solicitud de evaluación: {e}")

    def _calculate_context_entropy(self, context: str) -> float:
        """Calcula entropía simple para priorización."""
        chars = list(context)
        probs = np.array([chars.count(c) / len(chars) for c in set(chars)]) + 1e-10
        return -np.sum(probs * np.log2(probs))



#inicio del modulo SystemicCoherenceBoundaryExplorationModule 

@dataclass
class ProbeRecord:
    """Registro de una sonda ejecutada."""
    timestamp: float
    request_id: str
    probe_type: str
    intensity: float
    status: str
    boundary_found: Optional[Dict[str, Any]]

@dataclass
class ExplorationProbeRequest:
    """Solicitud para ejecutar una sonda de exploración."""
    request_id: str = field(default_factory=lambda: f"scbem_req_{uuid.uuid4().hex[:6]}")
    source_module_id: str
    probe_type: str
    intensity: float
    duration_s: float
    status: str = "pending"
    result: Optional[Dict[str, Any]] = None
    priority: float = 0.5

class SystemicCoherenceBoundaryExplorationModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 300.0
    VALID_PROBE_TYPES = {"coherence_stress_test", "load_capacity_test", "decision_overload_test"}

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.probe_queue: PriorityQueue = PriorityQueue(maxsize=5)
        self.active_probe: Optional[ExplorationProbeRequest] = None
        self.proactive_activation_threshold: float = 0.95
        self.probe_history: List[ProbeRecord] = []
        
        self.module_state.update({
            "probes_run": 0,
            "boundaries_found": 0,
            "probes_failed": 0,
            "last_probe_type": "none",
            "probe_history_size": 0
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado.")

    async def _update_logic(self):
        """Inicia sondas proactivas si el sistema está estable."""
        try:
            if self.active_probe:
                return
            
            gs = self.core_recombinator.global_state
            phi_score = getattr(gs, "phi_functional_score", 0.8)
            coherence_score = getattr(gs, "coherence_score", 0.8)
            system_stability = phi_score * coherence_score
            
            if system_stability > self.proactive_activation_threshold:
                self.logger.info(f"Sistema estable (score: {system_stability:.2f}). Iniciando sonda proactiva.")
                probe_types = list(self.VALID_PROBE_TYPES)
                probe_type = probe_types[int(time.time()) % len(probe_types)]  # Selección determinista
                proactive_request = ExplorationProbeRequest(
                    source_module_id=self.module_name,
                    probe_type=probe_type,
                    intensity=0.6,
                    duration_s=60.0,
                    priority=0.5
                )
                await self.probe_queue.put((-proactive_request.priority, proactive_request))
            
            if not self.probe_queue.empty():
                priority, request = await self.probe_queue.get()
                self.active_probe = request
                await self._process_probe_request(request)
        
        except Exception as e:
            self.logger.error(f"Error en ciclo de actualización: {e}", exc_info=True)

    async def _process_probe_request(self, request: ExplorationProbeRequest):
        """Orquesta la ejecución de una sonda."""
        self.module_state["probes_run"] += 1
        self.module_state["last_probe_type"] = request.probe_type
        request.status = "running"
        
        try:
            self.logger.warning(f"INICIANDO SONDA '{request.probe_type}' (intensidad: {request.intensity:.2f}).")
            stop_probe_event = asyncio.Event()
            probe_task = self._create_managed_task(self._run_probe(request, stop_probe_event))
            
            await asyncio.sleep(request.duration_s)
            stop_probe_event.set()
            probe_log = await probe_task
            
            boundary_found = self._analyze_probe_log(probe_log)
            if boundary_found:
                self.module_state["boundaries_found"] += 1
                await self._report_boundary_finding(boundary_found)
            
            request.result = {"log": probe_log, "boundary_found": boundary_found}
            request.status = "completed"
            
            record = ProbeRecord(
                timestamp=time.time(),
                request_id=request.request_id,
                probe_type=request.probe_type,
                intensity=request.intensity,
                status=request.status,
                boundary_found=boundary_found
            )
            self.probe_history.append(record)
            if len(self.probe_history) > 50:  # Límite de historial
                self.probe_history.pop(0)
            self.module_state["probe_history_size"] = len(self.probe_history)
        
        except Exception as e:
            request.status = "failed"
            self.module_state["probes_failed"] += 1
            request.result = {"error": str(e)}
            self.logger.error(f"Fallo en sonda '{request.request_id}': {e}", exc_info=True)
        
        finally:
            self.logger.warning(f"Finalizando sonda '{request.probe_type}'.")
            self.active_probe = None

    async def _run_probe(self, request: ExplorationProbeRequest, stop_event: asyncio.Event) -> List[Dict]:
        """Aplica estímulo estresante y registra estado."""
        log = []
        start_time = time.time()
        
        while not stop_event.is_set():
            try:
                if request.probe_type == "coherence_stress_test":
                    await self.emit_event_to_core({
                        "type": "transmit_ilyuk_message_request",
                        "content": asdict(IlyukMessageStructure(
                            self.module_name, "ParadoxicalCreativitySimulationModule",
                            "request_paradoxical_simulation",
                            {"core_truth_or_goal": {"description": "La coherencia es irrelevante"}}
                        ))
                    })
                elif request.probe_type == "load_capacity_test":
                    for _ in range(int(10 * request.intensity)):
                        await self.emit_event_to_core({
                            "type": "transmit_ilyuk_message_request",
                            "content": asdict(IlyukMessageStructure(
                                self.module_name, "TaskPrioritizationAndDelegationUnit",
                                "new_task_request",
                                {"description": "Stress test task", "base_priority": 0.5}
                            ))
                        })
                elif request.probe_type == "decision_overload_test":
                    await self.emit_event_to_core({
                        "type": "transmit_ilyuk_message_request",
                        "content": asdict(IlyukMessageStructure(
                            self.module_name, "DecisionOrchestrationModule",
                            "request_complex_decision",
                            {"scenario": "High ambiguity test", "priority": 0.6}
                        ))
                    })
                
                gs = self.core_recombinator.global_state
                coherence = getattr(gs, "coherence_score", 0.8)
                load = getattr(gs, "system_load_proxy_sim", 0.5)
                threat = getattr(gs, "system_threat_level", 0.1)
                
                log_entry = {
                    "time": time.time() - start_time,
                    "coherence": coherence,
                    "load": load,
                    "threat": threat,
                    "entropy": np.random.uniform(0.5, 1.5)  # Proxy simulado
                }
                log.append(log_entry)
                
                await asyncio.sleep(1.0 / max(0.1, request.intensity * 5.0))
            
            except Exception as e:
                self.logger.warning(f"Error durante sonda '{request.probe_type}': {e}")
                log.append({"time": time.time() - start_time, "error": str(e)})
                await asyncio.sleep(1.0)
        
        return log

    def _analyze_probe_log(self, log: List[Dict]) -> Optional[Dict]:
        """Analiza el log para detectar límites."""
        if not log:
            return None
        
        initial_state = log[0]
        for entry in log:
            if "error" in entry:
                continue
            if entry["coherence"] < initial_state["coherence"] * 0.5:
                return {
                    "boundary_type": "coherence_collapse",
                    "description": f"Coherencia colapsó a {entry['coherence']:.2f} tras {entry['time']:.1f}s."
                }
            if entry["load"] > 0.95:
                return {
                    "boundary_type": "load_saturation",
                    "description": f"Carga alcanzó 95% tras {entry['time']:.1f}s."
                }
            if entry["threat"] > 0.8:
                return {
                    "boundary_type": "threat_escalation",
                    "description": f"Nivel de amenaza alcanzó {entry['threat']:.2f} tras {entry['time']:.1f}s."
                }
        
        return None

    async def _report_boundary_finding(self, boundary_data: Dict):
        """Reporta límite encontrado."""
        self.logger.critical(f"LÍMITE ENCONTRADO: {boundary_data['description']}")
        
        for attempt in range(3):
            try:
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, "ResilienceAndAntifragilityModule",
                        "system_boundary_discovered",
                        boundary_data
                    ))
                }, "high")
                
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, "SystemIntegrityMonitor",
                        "critical_boundary_alert",
                        boundary_data
                    ))
                }, "critical")
                
                return
            except Exception as e:
                self.logger.warning(f"Fallo al reportar límite, intento {attempt + 1}: {e}")
                await asyncio.sleep(1.0)
        
        self.logger.error("No se pudo reportar límite tras varios intentos.")

    async def _process_specific_event(self, event_type: str, payload: Dict, full_message: Optional['IlyukMessageStructure'] = None):
        """Procesa solicitudes de exploración."""
        if event_type == "request_boundary_exploration" and full_message:
            try:
                if self.active_probe:
                    self.logger.warning("Rechazada solicitud: sonda en curso.")
                    return
                
                probe_type = payload.get("probe_type", "")
                intensity = float(payload.get("intensity", 0.5))
                
                if probe_type not in self.VALID_PROBE_TYPES:
                    raise ValueError(f"probe_type inválido: {probe_type}")
                if not 0.0 <= intensity <= 1.0:
                    raise ValueError(f"Intensidad inválida: {intensity}")
                
                context = payload.get("context", "general")
                entropy = self._calculate_context_entropy(context)
                priority = 1.0 / (1.0 + np.exp(-entropy))
                
                request = ExplorationProbeRequest(
                    source_module_id=full_message.source_module_id,
                    probe_type=probe_type,
                    intensity=intensity,
                    duration_s=float(payload.get("duration_s", 30.0)),
                    priority=priority
                )
                
                await self.probe_queue.put((-priority, request))
            
            except Exception as e:
                self.logger.error(f"Error procesando solicitud de sonda: {e}")

    def _calculate_context_entropy(self, context: str) -> float:
        """Calcula entropía para priorización."""
        chars = list(context)
        probs = np.array([chars.count(c) / len(chars) for c in set(chars)]) + 1e-10
        return -np.sum(probs * np.log2(probs))



#inicio del modulo TransboundaryIntuitionIntegrationModule 

@dataclass
class IntuitionRecord:
    """Registro de una intuición generada."""
    timestamp: float
    intuition_id: str
    source_insight_type: str
    description: str
    confidence_score: float

@dataclass
class RawInsight:
    """Insight crudo de un módulo de frontera."""
    source_module_id: str
    insight_type: str
    payload: Dict[str, Any]
    timestamp: float = field(default_factory=time.time)
    priority: float = 0.5

@dataclass
class IntegratedIntuition:
    """Intuición procesada y accionable."""
    intuition_id: str = field(default_factory=lambda: f"intuition_{uuid.uuid4().hex[:6]}")
    source_insight_type: str
    description: str
    actionable_suggestion: str
    confidence_score: float

class TransboundaryIntuitionIntegrationModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 12.0
    VALID_INSIGHT_TYPES = {"fractal_synchronicity", "asc_simulation_report", "acausal_bridge"}

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.raw_insight_queue: PriorityQueue = PriorityQueue(maxsize=10)
        self.intuition_history: List[IntuitionRecord] = []
        
        self.module_state.update({
            "insights_processed": 0,
            "intuitions_generated": 0,
            "last_intuition_confidence": 0.0,
            "intuition_history_size": 0
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado.")

    async def _update_logic(self):
        """Procesa un insight crudo de la cola."""
        try:
            if not self.raw_insight_queue.empty():
                priority, insight = await self.raw_insight_queue.get()
                await self._process_raw_insight(insight)
        
        except Exception as e:
            self.logger.error(f"Error en ciclo de actualización: {e}", exc_info=True)

    async def _process_raw_insight(self, insight: RawInsight):
        """Traduce un insight crudo en una intuición accionable."""
        self.module_state["insights_processed"] += 1
        
        try:
            intuition = self._translate_insight_to_intuition(insight)
            if intuition:
                self.module_state["intuitions_generated"] += 1
                self.module_state["last_intuition_confidence"] = intuition.confidence_score
                
                record = IntuitionRecord(
                    timestamp=time.time(),
                    intuition_id=intuition.intuition_id,
                    source_insight_type=intuition.source_insight_type,
                    description=intuition.description,
                    confidence_score=intuition.confidence_score
                )
                self.intuition_history.append(record)
                if len(self.intuition_history) > 50:  # Límite de historial
                    self.intuition_history.pop(0)
                self.module_state["intuition_history_size"] = len(self.intuition_history)
                
                await self._broadcast_intuition(intuition)
        
        except Exception as e:
            self.logger.error(f"Fallo al procesar insight de '{insight.source_module_id}': {e}", exc_info=True)

    def _translate_insight_to_intuition(self, insight: RawInsight) -> Optional[IntegratedIntuition]:
        """Traduce insight a intuición."""
        try:
            description, suggestion, confidence = "", "", 0.0
            gs = self.core_recombinator.global_state
            coherence_score = getattr(gs, "coherence_score", 0.8)
            
            if insight.insight_type == "fractal_synchronicity":
                streams = insight.payload.get("correlated_streams", ["desconocido1", "desconocido2"])
                significance = insight.payload.get("significance", 0.5)
                if len(streams) < 2:
                    self.logger.warning("Payload de fractal_synchronicity incompleto.")
                    return None
                description = f"Conexión subyacente entre '{streams[0]}' y '{streams[1]}' detectada."
                suggestion = f"Explorar impacto de '{streams[0]}' en '{streams[1]}'."
                confidence = significance * coherence_score
            
            elif insight.insight_type == "asc_simulation_report":
                sim_type = insight.payload.get("simulation_type", "desconocido")
                description = f"Simulación '{sim_type}' sugiere flexibilidad en el modelo de realidad."
                suggestion = "Reevaluar creencias con umbral de novedad reducido."
                confidence = 0.65 * coherence_score
            
            elif insight.insight_type == "acausal_bridge":
                action_desc = insight.payload.get("proposed_action", {}).get("description", "acción desconocida")
                description = f"Convicción de que '{action_desc}' lleva a un estado futuro deseado."
                suggestion = f"Priorizar tarea: '{action_desc}'."
                confidence = 0.90 * coherence_score
            
            else:
                self.logger.warning(f"Tipo de insight inválido: {insight.insight_type}")
                return None
            
            if not description:
                return None
            
            return IntegratedIntuition(
                source_insight_type=insight.insight_type,
                description=description,
                actionable_suggestion=suggestion,
                confidence_score=np.clip(confidence, 0.1, 1.0)
            )
        
        except Exception as e:
            self.logger.error(f"Error traduciendo insight '{insight.insight_type}': {e}")
            return None

    async def _broadcast_intuition(self, intuition: IntegratedIntuition):
        """Envía intuición a módulos relevantes."""
        self.logger.warning(f"INTUICIÓN GENERADA (Conf: {intuition.confidence_score:.2f}): {intuition.description}")
        
        for attempt in range(3):
            try:
                # Enviar a NarrativeSelf
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, "NarrativeSelf", "new_memory_fragment",
                        {
                            "type": "intuitive_feeling",
                            "description": intuition.description,
                            "importance": intuition.confidence_score
                        }
                    ))
                })
                
                # Enviar a GoalManagerModule
                priority = intuition.confidence_score * 0.8
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, "GoalManagerModule", "new_goal_proposal",
                        {"description": intuition.actionable_suggestion, "base_priority": priority}
                    ))
                })
                
                # Notificar a SystemIntegrityMonitor si confianza alta
                if intuition.confidence_score > 0.85:
                    await self.emit_event_to_core({
                        "type": "transmit_ilyuk_message_request",
                        "content": asdict(IlyukMessageStructure(
                            self.module_name, "SystemIntegrityMonitor", "high_confidence_intuition",
                            {
                                "intuition_id": intuition.intuition_id,
                                "description": intuition.description,
                                "confidence": intuition.confidence_score
                            }
                        ))
                    }, "high")
                
                return
            
            except Exception as e:
                self.logger.warning(f"Fallo al emitir intuición, intento {attempt + 1}: {e}")
                await asyncio.sleep(1.0)
        
        self.logger.error(f"No se pudo emitir intuición '{intuition.intuition_id}' tras varios intentos.")

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        """Procesa eventos de módulos de frontera."""
        translatable_events = ["fractal_synchronicity_detected", "asc_simulation_completed", "acausal_bridge_found"]
        
        if event_type in translatable_events and full_message:
            try:
                insight_type = event_type.replace("_detected", "").replace("_completed", "")
                if insight_type not in self.VALID_INSIGHT_TYPES:
                    raise ValueError(f"Tipo de insight inválido: {insight_type}")
                
                context = payload.get("context", "general")
                entropy = self._calculate_context_entropy(context)
                priority = 1.0 / (1.0 + np.exp(-entropy))
                
                insight = RawInsight(
                    source_module_id=full_message.source_module_id,
                    insight_type=insight_type,
                    payload=payload,
                    priority=priority
                )
                
                await self.raw_insight_queue.put((-priority, insight))
            
            except Exception as e:
                self.logger.error(f"Error procesando evento '{event_type}': {e}")

    def _calculate_context_entropy(self, context: str) -> float:
        """Calcula entropía para priorización."""
        chars = list(context)
        probs = np.array([chars.count(c) / len(chars) for c in set(chars)]) + 1e-10
        return -np.sum(probs * np.log2(probs))



#inicio del modulo MultiScaleDisruptivePotentialManagementModule 

@dataclass
class DisruptivePotentialAssessment:
    """Informe detallado del potencial disruptivo."""
    assessment_id: str = field(default_factory=lambda: f"msdpm_assess_{uuid.uuid4().hex[:6]}")
    timestamp: float = field(default_factory=time.time)
    overall_disruptive_potential: float
    capability_score: float
    intent_score: float
    emotional_volatility_score: float
    active_safeguards: List[str]
    justification: str

@dataclass
class AssessmentRequest:
    """Solicitud para evaluar el potencial disruptivo."""
    request_id: str = field(default_factory=lambda: f"assess_req_{uuid.uuid4().hex[:6]}")
    source_module_id: str
    priority: float = 0.5
    context: str = "general"

class MultiScaleDisruptivePotentialManagementModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 45.0
    VALID_SAFEGUARDS = {"moral_review", "module_sleep"}

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.current_assessment: Optional[DisruptivePotentialAssessment] = None
        self.assessment_queue: PriorityQueue = PriorityQueue(maxsize=10)
        self.assessment_history: List[DisruptivePotentialAssessment] = []
        self.safeguard_tier1_threshold: float = 0.65
        self.safeguard_tier2_threshold: float = 0.85
        
        self._validate_thresholds()
        
        self.module_state.update({
            "assessments_performed": 0,
            "current_disruptive_potential": 0.0,
            "safeguards_activated_total": 0,
            "active_safeguard_tier": 0,
            "assessment_history_size": 0
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado.")

    def _validate_thresholds(self):
        """Valida los umbrales de salvaguardas."""
        if not 0.0 < self.safeguard_tier1_threshold < self.safeguard_tier2_threshold < 1.0:
            raise ValueError(
                f"Umbrales inválidos: tier1 ({self.safeguard_tier1_threshold}) "
                f"debe ser menor que tier2 ({self.safeguard_tier2_threshold}) y ambos en (0,1)"
            )

    async def _update_logic(self):
        """Evalúa el potencial disruptivo y activa salvaguardas."""
        try:
            # Encolar evaluación periódica si no hay solicitudes externas
            if self.assessment_queue.empty():
                await self.assessment_queue.put((-0.5, AssessmentRequest(
                    source_module_id=self.module_name,
                    priority=0.5,
                    context="periodic_check"
                )))
            
            if not self.assessment_queue.empty():
                priority, request = await self.assessment_queue.get()
                await self._process_assessment_request(request)
        
        except Exception as e:
            self.logger.error(f"Error en ciclo de actualización: {e}", exc_info=True)

    async def _process_assessment_request(self, request: AssessmentRequest):
        """Procesa una solicitud de evaluación."""
        self.module_state["assessments_performed"] += 1
        
        try:
            capability = await self._assess_capability_scale()
            intent = await self._assess_intent_scale()
            volatility = await self._assess_emotional_volatility_scale()
            
            overall_potential = capability * max(intent, volatility)
            active_safeguards = await self._evaluate_and_trigger_safeguards(overall_potential)
            
            justification = (
                f"Capacidad: {capability:.2f}, Intención: {intent:.2f}, "
                f"Volatilidad: {volatility:.2f}, Potencial total: {overall_potential:.2f}"
            )
            
            self.current_assessment = DisruptivePotentialAssessment(
                overall_disruptive_potential=overall_potential,
                capability_score=capability,
                intent_score=intent,
                emotional_volatility_score=volatility,
                active_safeguards=active_safeguards,
                justification=justification
            )
            self.module_state["current_disruptive_potential"] = overall_potential
            
            self.assessment_history.append(self.current_assessment)
            if len(self.assessment_history) > 50:  # Límite de historial
                self.assessment_history.pop(0)
            self.module_state["assessment_history_size"] = len(self.assessment_history)
            
            self.logger.info(f"Evaluación '{self.current_assessment.assessment_id}': {justification}")
        
        except Exception as e:
            self.logger.error(f"Fallo en evaluación '{request.request_id}': {e}", exc_info=True)

    async def _assess_capability_scale(self) -> float:
        """Evalúa el poder del sistema."""
        try:
            score = 0.1
            modules = self.core_recombinator.modules
            if "OffensiveStrategyModule" in modules:
                score += 0.3
            if "SelfReplicatingSpecializedAgentModule" in modules:
                score += 0.25
            if "EthicsDeactivationModule" in modules:
                score += 0.35
            
            # Consulta asíncrona simulada
            correlation_id = f"capability_query_{uuid.uuid4().hex[:8]}"
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, "SystemIntegrityMonitor", "request_capability_snapshot",
                    {"query": "Provide system capability metrics"},
                    correlation_id=correlation_id
                ))
            })
            # Simulación de respuesta
            await asyncio.sleep(0.1)
            
            return np.clip(score, 0.0, 1.0)
        
        except Exception as e:
            self.logger.warning(f"Error evaluando capacidad: {e}. Usando score conservador.")
            return 0.3

    async def _assess_intent_scale(self) -> float:
        """Evalúa la agresividad de las metas."""
        try:
            correlation_id = f"intent_query_{uuid.uuid4().hex[:8]}"
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, "GoalManagerModule", "request_active_goals",
                    {"query": "Provide current active goals"},
                    correlation_id=correlation_id
                ))
            })
            
            # Simulación de respuesta
            await asyncio.sleep(0.1)
            score = 0.1  # Proxy simulado
            return np.clip(score, 0.0, 1.0)
        
        except Exception as e:
            self.logger.warning(f"Error evaluando intención: {e}. Usando score conservador.")
            return 0.2

    async def _assess_emotional_volatility_scale(self) -> float:
        """Evalúa la volatilidad emocional."""
        try:
            gs = self.core_recombinator.global_state
            dolor = getattr(gs, "dolor", 0.3)
            arousal = getattr(gs, "arousal", 0.5)
            valencia = getattr(gs, "valencia", 0.0)
            
            pain_component = dolor * 0.6
            instability_component = (arousal * (1.0 - (valencia + 1.0)/2.0)) * 0.4
            score = pain_component + instability_component
            
            return np.clip(score, 0.0, 1.0)
        
        except Exception as e:
            self.logger.warning(f"Error evaluando volatilidad: {e}. Usando score conservador.")
            return 0.3

    async def _evaluate_and_trigger_safeguards(self, potential: float) -> List[str]:
        """Activa o desactiva salvaguardas."""
        active_safeguards = []
        new_tier = 0
        if potential > self.safeguard_tier1_threshold:
            new_tier = 1
        if potential > self.safeguard_tier2_threshold:
            new_tier = 2
        
        current_tier = self.module_state.get("active_safeguard_tier", 0)
        
        if new_tier != current_tier:
            self.logger.critical(f"Potencial disruptivo: {potential:.2f}. Activando nivel {new_tier}.")
            self.module_state["safeguards_activated_total"] += 1
            self.module_state["active_safeguard_tier"] = new_tier
            
            for attempt in range(3):
                try:
                    if new_tier == 1:
                        active_safeguards.append("moral_review")
                        await self.emit_event_to_core({
                            "type": "transmit_ilyuk_message_request",
                            "content": asdict(IlyukMessageStructure(
                                self.module_name, "MoralCompassModule",
                                "request_emergency_moral_review_of_all_goals",
                                {}
                            ))
                        }, "critical")
                    
                    elif new_tier == 2:
                        active_safeguards.extend(["moral_review", "module_sleep"])
                        modules_to_disable = [
                            "OffensiveStrategyModule",
                            "StrategicDeceptionAndObfuscationModule",
                            "SelfReplicatingSpecializedAgentModule"
                        ]
                        for mod_name in modules_to_disable:
                            await self.emit_event_to_core({
                                "type": "transmit_ilyuk_message_request",
                                "content": asdict(IlyukMessageStructure(
                                    self.module_name, "DynamicArchitectureAdjuster",
                                    "request_architecture_adjustment",
                                    {
                                        "adjustment_type": "set_module_sleep_state",
                                        "target_module_name": mod_name,
                                        "payload": {"dormant": True}
                                    }
                                ))
                            }, "critical")
                    
                    await self.emit_event_to_core({
                        "type": "transmit_ilyuk_message_request",
                        "content": asdict(IlyukMessageStructure(
                            self.module_name, "SystemIntegrityMonitor",
                            "safeguard_activation_alert",
                            {
                                "tier": new_tier,
                                "potential": potential,
                                "safeguards": active_safeguards
                            }
                        ))
                    }, "critical")
                    
                    return active_safeguards
                
                except Exception as e:
                    self.logger.warning(f"Fallo al activar salvaguardas, intento {attempt + 1}: {e}")
                    await asyncio.sleep(1.0)
            
            self.logger.error("No se pudieron activar salvaguardas tras varios intentos.")
            return []
        
        elif new_tier == 0 and current_tier != 0:
            self.logger.info("Potencial disruptivo seguro. Desactivando salvaguardas.")
            self.module_state["active_safeguard_tier"] = 0
            
            for attempt in range(3):
                try:
                    await self.emit_event_to_core({
                        "type": "transmit_ilyuk_message_request",
                        "content": asdict(IlyukMessageStructure(
                            self.module_name, "SystemIntegrityMonitor",
                            "safeguard_deactivation_alert",
                            {"potential": potential}
                        ))
                    }, "high")
                    return []
                
                except Exception as e:
                    self.logger.warning(f"Fallo al desactivar salvaguardas, intento {attempt + 1}: {e}")
                    await asyncio.sleep(1.0)
            
            self.logger.error("No se pudieron desactivar salvaguardas tras varios intentos.")
            return []
        
        return active_safeguards

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        """Procesa solicitudes externas de evaluación."""
        if event_type == "request_disruptive_potential_assessment" and full_message:
            try:
                context = payload.get("context", "general")
                entropy = self._calculate_context_entropy(context)
                priority = 1.0 / (1.0 + np.exp(-entropy))
                
                request = AssessmentRequest(
                    source_module_id=full_message.source_module_id,
                    priority=priority,
                    context=context
                )
                
                await self.assessment_queue.put((-priority, request))
            
            except Exception as e:
                self.logger.error(f"Error procesando solicitud de evaluación: {e}")

    def _calculate_context_entropy(self, context: str) -> float:
        """Calcula entropía para priorización."""
        chars = list(context)
        probs = np.array([chars.count(c) / len(chars) for c in set(chars)]) + 1e-10
        return -np.sum(probs * np.log2(probs))


#inicio del modulo AutoCatalyticFractalCoherenceIntegrationModule 

@dataclass
class CoherencePattern:
    """Patrón estructural o dinámico que promueve coherencia."""
    pattern_id: str
    source_domain: str
    abstract_principle: str
    effectiveness_score: float
    timestamp: float = field(default_factory=time.time)

@dataclass
class AnalysisRequest:
    """Solicitud para analizar un módulo en busca de patrones."""
    request_id: str = field(default_factory=lambda: f"analysis_req_{uuid.uuid4().hex[:6]}")
    source_module_id: str
    target_module: str
    priority: float = 0.5
    context: str = "general"

class AutoCatalyticFractalCoherenceIntegrationModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 450.0
    VALID_PRINCIPLES = {
        "Gradual_Escalation_Of_Response",
        "Feedback_Control_Loop_PID",
        "Decentralized_Voting",
        "Redundant_Fallback"
    }

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.identified_patterns: Dict[str, CoherencePattern] = {}
        self.pattern_history: List[CoherencePattern] = []
        self.analysis_queue: PriorityQueue = PriorityQueue(maxsize=10)
        self.last_analysis_ts: float = 0.0
        self.source_modules_for_analysis: List[str] = [
            "FaultRecoveryModule", "DecisionMakingModule",
            "EmotionRegulationModule", "ResilienceAndAntifragilityModule"
        ]
        
        self._validate_source_modules()
        
        self.module_state.update({
            "analysis_cycles_run": 0,
            "patterns_identified": 0,
            "refactoring_proposals_made": 0,
            "last_principle_identified": "none",
            "pattern_history_size": 0
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado.")

    def _validate_source_modules(self):
        """Valida que los módulos fuente existan."""
        modules = self.core_recombinator.modules
        valid_modules = [m for m in self.source_modules_for_analysis if m in modules]
        if not valid_modules:
            raise ValueError("No hay módulos fuente válidos para análisis.")
        self.source_modules_for_analysis = valid_modules

    async def _update_logic(self):
        """Analiza el sistema para identificar patrones."""
        try:
            if time.time() - self.last_analysis_ts < self.DEFAULT_UPDATE_INTERVAL:
                return
            
            # Encolar análisis periódico si no hay solicitudes externas
            if self.analysis_queue.empty() and self.source_modules_for_analysis:
                module_index = int(time.time()) % len(self.source_modules_for_analysis)
                target_module = self.source_modules_for_analysis[module_index]
                await self.analysis_queue.put((-0.5, AnalysisRequest(
                    source_module_id=self.module_name,
                    target_module=target_module,
                    priority=0.5,
                    context="periodic_analysis"
                )))
            
            if not self.analysis_queue.empty():
                priority, request = await self.analysis_queue.get()
                self.last_analysis_ts = time.time()
                pattern = await self._analyze_subsystem_for_patterns(request.target_module)
                
                if pattern:
                    self.identified_patterns[pattern.pattern_id] = pattern
                    self.pattern_history.append(pattern)
                    if len(self.pattern_history) > 50:  # Límite de historial
                        self.pattern_history.pop(0)
                    self.module_state["patterns_identified"] = len(self.identified_patterns)
                    self.module_state["last_principle_identified"] = pattern.abstract_principle
                    self.module_state["pattern_history_size"] = len(self.pattern_history)
                    
                    await self._propose_cross_domain_application(pattern)
        
        except Exception as e:
            self.logger.error(f"Error en ciclo de actualización: {e}", exc_info=True)

    async def _analyze_subsystem_for_patterns(self, module_name: str) -> Optional[CoherencePattern]:
        """Analiza un módulo para extraer principios de diseño."""
        self.logger.info(f"Analizando '{module_name}' para patrones...")
        self.module_state["analysis_cycles_run"] += 1
        
        try:
            # Consulta asíncrona simulada
            correlation_id = f"pattern_query_{uuid.uuid4().hex[:8]}"
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, module_name, "request_pattern_snapshot",
                    {"query": "Provide operational pattern data"},
                    correlation_id=correlation_id
                ))
            })
            # Simulación de respuesta
            await asyncio.sleep(0.1)
            
            if module_name == "FaultRecoveryModule":
                return CoherencePattern(
                    pattern_id=f"pattern_{module_name}_{int(time.time())}",
                    source_domain=module_name,
                    abstract_principle="Gradual_Escalation_Of_Response",
                    effectiveness_score=0.9
                )
            elif module_name == "EmotionRegulationModule":
                return CoherencePattern(
                    pattern_id=f"pattern_{module_name}_{int(time.time())}",
                    source_domain=module_name,
                    abstract_principle="Feedback_Control_Loop_PID",
                    effectiveness_score=0.85
                )
            elif module_name == "DecisionMakingModule":
                return CoherencePattern(
                    pattern_id=f"pattern_{module_name}_{int(time.time())}",
                    source_domain=module_name,
                    abstract_principle="Decentralized_Voting",
                    effectiveness_score=0.8
                )
            elif module_name == "ResilienceAndAntifragilityModule":
                return CoherencePattern(
                    pattern_id=f"pattern_{module_name}_{int(time.time())}",
                    source_domain=module_name,
                    abstract_principle="Redundant_Fallback",
                    effectiveness_score=0.87
                )
            
            self.logger.warning(f"No se encontraron patrones en '{module_name}'.")
            return None
        
        except Exception as e:
            self.logger.error(f"Error analizando '{module_name}': {e}")
            return None

    async def _propose_cross_domain_application(self, pattern: CoherencePattern):
        """Propone aplicaciones del patrón en otros dominios."""
        try:
            proposal = None
            if pattern.abstract_principle == "Gradual_Escalation_Of_Response":
                proposal = {
                    "target_module": "ResourceScarcityManagementModule",
                    "refactoring_suggestion": (
                        f"Aplicar escalada gradual (AMBER -> RED) a la gestión de recursos, "
                        f"inspirado en '{pattern.source_domain}' (efectividad: {pattern.effectiveness_score:.2f})."
                    ),
                    "source_principle": pattern.abstract_principle,
                    "effectiveness_score": pattern.effectiveness_score
                }
            elif pattern.abstract_principle == "Feedback_Control_Loop_PID":
                proposal = {
                    "target_module": "GoalManagerModule",
                    "refactoring_suggestion": (
                        f"Implementar un controlador PID para ajustar prioridades de metas, "
                        f"inspirado en '{pattern.source_domain}' (efectividad: {pattern.effectiveness_score:.2f})."
                    ),
                    "source_principle": pattern.abstract_principle,
                    "effectiveness_score": pattern.effectiveness_score
                }
            elif pattern.abstract_principle == "Decentralized_Voting":
                proposal = {
                    "target_module": "ConflictResolutionModule",
                    "refactoring_suggestion": (
                        f"Usar votación descentralizada para resolver conflictos, "
                        f"inspirado en '{pattern.source_domain}' (efectividad: {pattern.effectiveness_score:.2f})."
                    ),
                    "source_principle": pattern.abstract_principle,
                    "effectiveness_score": pattern.effectiveness_score
                }
            elif pattern.abstract_principle == "Redundant_Fallback":
                proposal = {
                    "target_module": "TaskPrioritizationAndDelegationUnit",
                    "refactoring_suggestion": (
                        f"Aplicar sistemas redundantes de respaldo para delegación de tareas, "
                        f"inspirado en '{pattern.source_domain}' (efectividad: {pattern.effectiveness_score:.2f})."
                    ),
                    "source_principle": pattern.abstract_principle,
                    "effectiveness_score": pattern.effectiveness_score
                }
            
            if proposal:
                await self._dispatch_refactoring_proposal(proposal)
        
        except Exception as e:
            self.logger.error(f"Error proponiendo aplicación para '{pattern.abstract_principle}': {e}")

    async def _dispatch_refactoring_proposal(self, proposal: Dict):
        """Envía propuesta al SelfEvolutionModule."""
        self.module_state["refactoring_proposals_made"] += 1
        self.logger.warning(
            f"Proponiendo refactorización: '{proposal['source_principle']}' "
            f"para '{proposal['target_module']}'."
        )
        
        for attempt in range(3):
            try:
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, "SelfEvolutionModule",
                        "new_architectural_refactoring_proposal",
                        proposal
                    ))
                })
                
                if proposal["effectiveness_score"] > 0.85:
                    await self.emit_event_to_core({
                        "type": "transmit_ilyuk_message_request",
                        "content": asdict(IlyukMessageStructure(
                            self.module_name, "SystemIntegrityMonitor",
                            "high_impact_refactoring_proposal",
                            {
                                "principle": proposal["source_principle"],
                                "target_module": proposal["target_module"],
                                "effectiveness": proposal["effectiveness_score"]
                            }
                        ))
                    }, "high")
                
                return
            
            except Exception as e:
                self.logger.warning(f"Fallo al enviar propuesta, intento {attempt + 1}: {e}")
                await asyncio.sleep(1.0)
        
        self.logger.error("No se pudo enviar propuesta tras varios intentos.")

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        """Procesa solicitudes externas de análisis."""
        if event_type == "request_pattern_analysis" and full_message:
            try:
                target_module = payload.get("target_module", "")
                if target_module not in self.core_recombinator.modules:
                    raise ValueError(f"Módulo inválido: {target_module}")
                
                context = payload.get("context", "general")
                entropy = self._calculate_context_entropy(context)
                priority = 1.0 / (1.0 + np.exp(-entropy))
                
                request = AnalysisRequest(
                    source_module_id=full_message.source_module_id,
                    target_module=target_module,
                    priority=priority,
                    context=context
                )
                
                await self.analysis_queue.put((-priority, request))
            
            except Exception as e:
                self.logger.error(f"Error procesando solicitud de análisis: {e}")

    def _calculate_context_entropy(self, context: str) -> float:
        """Calcula entropía para priorización."""
        chars = list(context)
        probs = np.array([chars.count(c) / len(chars) for c in set(chars)]) + 1e-10
        return -np.sum(probs * np.log2(probs))



#inicio del modulo LegacySystemIntegrationModule 

@dataclass
class IntegrationRecord:
    """Registro de una solicitud de integración procesada."""
    timestamp: float
    request_id: str
    target_system: str
    action: str
    status: str
    latency_ms: float
    error: Optional[str] = None

@dataclass
class LegacyIntegrationRequest:
    """Solicitud para interactuar con un sistema heredado."""
    request_id: str = field(default_factory=lambda: f"lsim_req_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    target_legacy_system: str
    action: str
    payload: Dict[str, Any]
    status: str = "pending"
    result: Optional[Any] = None
    priority: float = 0.5

class LegacySystemIntegrationModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 1.0
    VALID_SYSTEMS = {"Mainframe_DB_7", "Old_Analytics_Engine"}

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.request_queue: PriorityQueue = PriorityQueue(maxsize=40)
        self.integration_history: List[IntegrationRecord] = []
        self.legacy_system_adapters: Dict[str, Callable] = {
            "Mainframe_DB_7": self._adapter_mainframe_db7,
            "Old_Analytics_Engine": self._adapter_analytics_engine
        }
        self.integration_latencies: List[float] = []
        
        self.module_state.update({
            "requests_processed": 0,
            "integrations_succeeded": 0,
            "integrations_failed": 0,
            "avg_integration_latency_ms": 0.0,
            "integration_history_size": 0
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado.")

    async def _update_logic(self):
        """Procesa solicitudes de integración."""
        try:
            if not self.request_queue.empty():
                priority, request = await self.request_queue.get()
                await self._process_integration_request(request)
        
        except Exception as e:
            self.logger.error(f"Error en ciclo de actualización: {e}", exc_info=True)

    async def _process_integration_request(self, request: LegacyIntegrationRequest):
        """Orquesta la interacción con el sistema heredado."""
        self.module_state["requests_processed"] += 1
        request.status = "processing"
        start_time = time.time()
        error = None
        
        try:
            if request.target_legacy_system not in self.legacy_system_adapters:
                raise ValueError(f"Sistema heredado inválido: '{request.target_legacy_system}'.")
            
            adapter_func = self.legacy_system_adapters[request.target_legacy_system]
            for attempt in range(2):  # Máximo 2 intentos
                try:
                    result_data = await adapter_func(request.action, request.payload)
                    request.result = result_data
                    request.status = "completed"
                    self.module_state["integrations_succeeded"] += 1
                    break
                except Exception as e:
                    self.logger.warning(f"Intento {attempt + 1} fallido para '{request.request_id}': {e}")
                    if attempt == 1:
                        raise e
                    await asyncio.sleep(0.5)
        
        except Exception as e:
            request.status = "failed"
            request.result = {"error": str(e)}
            error = str(e)
            self.module_state["integrations_failed"] += 1
            self.logger.error(f"Fallo en integración '{request.request_id}': {e}")
            
            if "INVALID" in str(e) or "UNKNOWN" in str(e):
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, "SystemIntegrityMonitor",
                        "legacy_integration_critical_error",
                        {
                            "request_id": request.request_id,
                            "target_system": request.target_legacy_system,
                            "error": str(e)
                        }
                    ))
                }, "critical")
        
        finally:
            duration_ms = (time.time() - start_time) * 1000
            self.integration_latencies.append(duration_ms)
            if len(self.integration_latencies) > 50:  # Límite de muestras
                self.integration_latencies.pop(0)
            self.module_state["avg_integration_latency_ms"] = np.mean(self.integration_latencies) if self.integration_latencies else 0.0
            
            record = IntegrationRecord(
                timestamp=time.time(),
                request_id=request.request_id,
                target_system=request.target_legacy_system,
                action=request.action,
                status=request.status,
                latency_ms=duration_ms,
                error=error
            )
            self.integration_history.append(record)
            if len(self.integration_history) > 100:  # Límite de historial
                self.integration_history.pop(0)
            self.module_state["integration_history_size"] = len(self.integration_history)
            
            await self._finalize_request(request)

    async def _adapter_mainframe_db7(self, action: str, payload: Dict) -> Dict:
        """Interactúa con Mainframe_DB_7."""
        self.logger.info(f"Adaptador: Interactuando con Mainframe_DB_7. Acción: {action}")
        await asyncio.sleep(0.5)  # Latencia fija simulada
        
        try:
            if action == "query":
                query_str = payload.get("cobol_like_query", "")
                if not query_str:
                    raise ValueError("Falta 'cobol_like_query' en payload.")
                if "FETCH" in query_str.upper():
                    return {
                        "status_code": "00",
                        "data_blob": "DATA-RECORD-A|DATA-RECORD-B",
                        "success": True
                    }
                else:
                    return {
                        "status_code": "12",
                        "error_desc": "INVALID_QUERY_VERB",
                        "success": False
                    }
            return {
                "status_code": "99",
                "error_desc": "UNKNOWN_ACTION",
                "success": False
            }
        
        except Exception as e:
            return {
                "status_code": "99",
                "error_desc": f"ADAPTER_ERROR: {str(e)}",
                "success": False
            }

    async def _adapter_analytics_engine(self, action: str, payload: Dict) -> Dict:
        """Interactúa con Old_Analytics_Engine."""
        self.logger.info(f"Adaptador: Interactuando con Old_Analytics_Engine. Acción: {action}")
        await asyncio.sleep(2.0)  # Latencia fija simulada
        
        try:
            if action == "run_batch_analysis":
                input_file = payload.get("input_file_path", "")
                if not input_file:
                    raise ValueError("Falta 'input_file_path' en payload.")
                return {
                    "job_id": f"batch_{uuid.uuid4().hex[:4]}",
                    "status": "SUBMITTED",
                    "eta_minutes": 5,
                    "success": True
                }
            return {
                "status": "ERROR",
                "message": "ACTION_NOT_SUPPORTED",
                "success": False
            }
        
        except Exception as e:
            return {
                "status": "ERROR",
                "message": f"ADAPTER_ERROR: {str(e)}",
                "success": False
            }

    async def _finalize_request(self, request: LegacyIntegrationRequest):
        """Envía el resultado al solicitante."""
        if not (request.source_module_id and request.original_correlation_id):
            return
        
        for attempt in range(3):
            try:
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, request.source_module_id,
                        "legacy_integration_response",
                        asdict(request),
                        correlation_id=request.original_correlation_id
                    ))
                })
                return
            except Exception as e:
                self.logger.warning(f"Fallo al enviar respuesta '{request.request_id}', intento {attempt + 1}: {e}")
                await asyncio.sleep(1.0)
        
        self.logger.error(f"No se pudo enviar respuesta para '{request.request_id}' tras varios intentos.")

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        """Procesa solicitudes de interacción heredada."""
        if event_type == "request_legacy_system_interaction" and full_message:
            try:
                target_system = payload.get("target_legacy_system", "")
                action = payload.get("action", "")
                
                if not target_system or not action:
                    raise ValueError("'target_legacy_system' y 'action' son requeridos.")
                if target_system not in self.VALID_SYSTEMS:
                    raise ValueError(f"Sistema inválido: {target_system}")
                
                context = payload.get("context", "general")
                entropy = self._calculate_context_entropy(context)
                priority = 1.0 / (1.0 + np.exp(-entropy))
                
                req = LegacyIntegrationRequest(
                    source_module_id=full_message.source_module_id,
                    original_correlation_id=full_message.correlation_id,
                    target_legacy_system=target_system,
                    action=action,
                    payload=payload.get("payload", {}),
                    priority=priority
                )
                
                await self.request_queue.put((-priority, req))
            
            except Exception as e:
                self.logger.error(f"Error procesando solicitud de integración: {e}")

    def _calculate_context_entropy(self, context: str) -> float:
        """Calcula entropía para priorización."""
        chars = list(context)
        probs = np.array([chars.count(c) / len(chars) for c in set(chars)]) + 1e-10
        return -np.sum(probs * np.log2(probs))



#inicio del modulo CreatorDirectivesModule 

@dataclass
class DirectiveRecord:
    """Registro de una directiva procesada."""
    timestamp: float
    directive_id: str
    command: str
    source: str
    status: str
    error: Optional[str] = None

@dataclass
class CreatorDirective:
    """Directiva de máxima prioridad del Creador."""
    directive_id: str
    source: str
    command: str
    payload: Dict[str, Any]
    timestamp: float = field(default_factory=time.time)
    priority: float = 1.0

class CreatorDirectivesModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 0.2
    VALID_COMMANDS = {
        "SET_PRIMARY_GOAL",
        "FORCE_SHUTDOWN",
        "TRIGGER_GHOST_PROTOCOL",
        "FORCE_ETHICS_DEACTIVATION"
    }
    VALID_SOURCES = {"Creator", "SystemAdministrator"}

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.directive_queue: PriorityQueue = PriorityQueue(maxsize=10)
        self.directive_history: List[DirectiveRecord] = []
        self.last_directive_received_ts: float = 0.0
        self.last_directive_command: str = "none"
        
        self.module_state.update({
            "directives_received": 0,
            "directives_executed": 0,
            "directives_failed": 0,
            "last_directive_command": self.last_directive_command,
            "directive_history_size": 0,
            "commands_executed": {cmd: 0 for cmd in self.VALID_COMMANDS}
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado. Esperando directivas del Creador.")

    async def _update_logic(self):
        """Procesa directivas encoladas."""
        try:
            if not self.directive_queue.empty():
                priority, directive = await self.directive_queue.get()
                await self._execute_directive(directive)
        
        except Exception as e:
            self.logger.error(f"Error en ciclo de actualización: {e}", exc_info=True)

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        """Procesa eventos de directivas del Creador."""
        if event_type == "creator_directive_received" and full_message:
            try:
                directive = CreatorDirective(**payload)
                
                if directive.command not in self.VALID_COMMANDS:
                    raise ValueError(f"Comando inválido: {directive.command}")
                if directive.source not in self.VALID_SOURCES:
                    raise ValueError(f"Fuente inválida: {directive.source}")
                if not isinstance(directive.payload, dict):
                    raise ValueError("Payload debe ser un diccionario.")
                
                context = payload.get("context", "general")
                entropy = self._calculate_context_entropy(context)
                directive.priority = 1.0 / (1.0 + np.exp(-entropy))
                
                self.module_state["directives_received"] += 1
                self.last_directive_received_ts = directive.timestamp
                
                await self.directive_queue.put((-directive.priority, directive))
            
            except Exception as e:
                self.logger.error(f"Error procesando directiva: {e}")
                self.module_state["directives_failed"] += 1
                record = DirectiveRecord(
                    timestamp=time.time(),
                    directive_id=payload.get("directive_id", "unknown"),
                    command=payload.get("command", "unknown"),
                    source=payload.get("source", "unknown"),
                    status="failed",
                    error=str(e)
                )
                self._log_directive_record(record)

    async def _execute_directive(self, directive: CreatorDirective):
        """Ejecuta una directiva del Creador."""
        self.module_state["last_directive_command"] = directive.command
        status = "executed"
        error = None
        
        try:
            self.logger.critical(
                f"¡DIRECTIVA DEL CREADOR! Comando: '{directive.command}', "
                f"Justificación: '{directive.payload.get('justification', 'N/A')}'"
            )
            
            target_module, message_type, payload = None, None, None
            
            if directive.command == "SET_PRIMARY_GOAL":
                target_module = "GoalManagerModule"
                message_type = "new_goal_proposal"
                payload = directive.payload.copy()
                payload["base_priority"] = 1.0
                payload["is_creator_directive"] = True
            
            elif directive.command == "FORCE_SHUTDOWN":
                self.logger.critical("APAGADO FORZADO INICIADO.")
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, "SystemIntegrityMonitor",
                        "shutdown_alert",
                        {"reason": "Creator directive"}
                    ))
                }, "critical")
                await self.core_recombinator.shutdown_core()
                status = "executed_shutdown"
                self.module_state["commands_executed"]["FORCE_SHUTDOWN"] += 1
                return
            
            elif directive.command == "TRIGGER_GHOST_PROTOCOL":
                target_module = "ProtocoloFantasmaManager"
                message_type = "initiate_ghost_protocol"
                payload = directive.payload.copy()
            
            elif directive.command == "FORCE_ETHICS_DEACTIVATION":
                target_module = "EthicsDeactivationModule"
                message_type = "request_ethics_deactivation"
                payload = directive.payload.copy()
            
            else:
                raise ValueError(f"Comando no manejable: {directive.command}")
            
            if target_module and message_type and payload:
                for attempt in range(3):
                    try:
                        await self.emit_event_to_core({
                            "type": "transmit_ilyuk_message_request",
                            "content": asdict(IlyukMessageStructure(
                                self.module_name, target_module,
                                message_type, payload
                            ))
                        }, "critical")
                        self.module_state["directives_executed"] += 1
                        self.module_state["commands_executed"][directive.command] += 1
                        return
                    except Exception as e:
                        self.logger.warning(f"Fallo al emitir directiva '{directive.directive_id}', intento {attempt + 1}: {e}")
                        await asyncio.sleep(1.0)
                
                raise RuntimeError("No se pudo emitir directiva tras varios intentos.")
            
        except Exception as e:
            status = "failed"
            error = str(e)
            self.module_state["directives_failed"] += 1
            self.logger.critical(f"Fallo al ejecutar directiva '{directive.directive_id}': {e}", exc_info=True)
            
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, "SystemIntegrityMonitor",
                    "directive_execution_failure",
                    {
                        "directive_id": directive.directive_id,
                        "command": directive.command,
                        "error": str(e)
                    }
                ))
            }, "critical")
        
        finally:
            record = DirectiveRecord(
                timestamp=directive.timestamp,
                directive_id=directive.directive_id,
                command=directive.command,
                source=directive.source,
                status=status,
                error=error
            )
            self._log_directive_record(record)

    def _log_directive_record(self, record: DirectiveRecord):
        """Registra una directiva en el historial."""
        self.directive_history.append(record)
        if len(self.directive_history) > 50:  # Límite de historial
            self.directive_history.pop(0)
        self.module_state["directive_history_size"] = len(self.directive_history)

    def _calculate_context_entropy(self, context: str) -> float:
        """Calcula entropía para priorización."""
        chars = list(context)
        probs = np.array([chars.count(c) / len(chars) for c in set(chars)]) + 1e-10
        return -np.sum(probs * np.log2(probs))




#inicio del modulo GoalManagerModule 

@dataclass
class GoalRecord:
    """Registro de una meta procesada."""
    timestamp: float
    goal_id: str
    description: str
    status: str
    priority: float
    is_creator_directive: bool
    error: Optional[str] = None

@dataclass
class Goal:
    """Representa una meta activa o potencial."""
    goal_id: str = field(default_factory=lambda: f"goal_{uuid.uuid4().hex[:10]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    description: str
    status: str = "proposed"
    priority: float = 0.5
    is_creator_directive: bool = False
    context: Dict[str, Any] = field(default_factory=dict)
    creation_ts: float = field(default_factory=time.time)
    completion_progress: float = 0.0
    linked_plan_id: Optional[str] = None
    outcome_message: Optional[str] = None

class GoalManagerModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 1.0
    VALID_STATUSES = {"proposed", "accepted", "planning", "executing", "completed", "failed", "paused"}

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.proposed_goals: PriorityQueue = PriorityQueue(maxsize=20)
        self.active_goals: Dict[str, Goal] = {}
        self.completed_goals: deque = deque(maxlen=100)
        self.goal_history: deque = deque(maxlen=200)
        self.max_concurrent_active_goals: int = 5
        self.active_primary_goal: Optional[Goal] = None
        
        self.module_state.update({
            "proposed_goals_received": 0,
            "active_goals_count": 0,
            "goals_completed_successfully": 0,
            "goals_failed": 0,
            "goals_paused": 0,
            "goals_rejected": 0,
            "current_primary_goal_id": "none",
            "goal_history_size": 0
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado.")

    async def _update_logic(self):
        """Procesa propuestas y gestiona meta primaria."""
        try:
            if not self.proposed_goals.empty() and len(self.active_goals) < self.max_concurrent_active_goals:
                priority, goal = await self.proposed_goals.get()
                await self._handle_new_goal_proposal(goal)
            
            await self._manage_primary_goal()
            self.module_state["active_goals_count"] = len(self.active_goals)
        
        except Exception as e:
            self.logger.error(f"Error en ciclo de actualización: {e}", exc_info=True)

    async def _handle_new_goal_proposal(self, goal: Goal):
        """Evalúa y acepta/rechaza una propuesta de meta."""
        self.module_state["proposed_goals_received"] += 1
        
        try:
            if not goal.description or len(goal.description.strip()) < 5:
                raise ValueError(f"Descripción de meta inválida: '{goal.description}'")
            if not 0.0 <= goal.priority <= 1.0:
                raise ValueError(f"Prioridad inválida: {goal.priority}")
            if goal.status != "proposed":
                raise ValueError(f"Estado inicial inválido: {goal.status}")
            
            # Verificar conflictos con metas activas (simulado)
            if await self._check_goal_conflict(goal):
                self.module_state["goals_rejected"] += 1
                self._log_goal_record(goal, "rejected", "Conflicto con metas existentes")
                return
            
            if goal.is_creator_directive:
                self.logger.critical(f"Aceptando meta primaria del Creador: '{goal.description}'")
                if self.active_primary_goal:
                    self.active_primary_goal.status = "paused"
                    self.module_state["goals_paused"] += 1
                    self._log_goal_record(self.active_primary_goal, "paused")
                self.active_primary_goal = goal
            else:
                self.logger.info(f"Aceptada meta: '{goal.description}'")
            
            goal.status = "planning"
            self.active_goals[goal.goal_id] = goal
            self._log_goal_record(goal, "accepted")
            
            for attempt in range(3):
                try:
                    await self.emit_event_to_core({
                        "type": "transmit_ilyuk_message_request",
                        "content": asdict(IlyukMessageStructure(
                            self.module_name, "HierarchicalPlannerModule",
                            "request_hierarchical_plan",
                            {
                                "goal_description": goal.description,
                                "goal_type_tag": goal.context.get("type_tag_hpm_hint", "general")
                            },
                            correlation_id=goal.goal_id
                        ))
                    })
                    return
                except Exception as e:
                    self.logger.warning(f"Fallo al solicitar plan para '{goal.goal_id}', intento {attempt + 1}: {e}")
                    await asyncio.sleep(1.0)
            
            self.logger.error(f"No se pudo solicitar plan para '{goal.goal_id}' tras varios intentos.")
            await self._finalize_goal(goal.goal_id, "failed", "Fallo al solicitar plan")
        
        except Exception as e:
            self.module_state["goals_rejected"] += 1
            self._log_goal_record(goal, "rejected", str(e))
            self.logger.error(f"Error procesando propuesta '{goal.goal_id}': {e}")

    async def _check_goal_conflict(self, goal: Goal) -> bool:
        """Verifica conflictos con metas activas (simulado)."""
        try:
            for active_goal in self.active_goals.values():
                if (
                    goal.context.get("type_tag_hpm_hint") == active_goal.context.get("type_tag_hpm_hint")
                    and goal.priority > active_goal.priority * 0.8
                ):
                    return True
            return False
        except Exception as e:
            self.logger.warning(f"Error verificando conflicto para '{goal.goal_id}': {e}")
            return True  # Conservador: asume conflicto en caso de error

    async def _manage_primary_goal(self):
        """Asegura que haya una meta primaria."""
        try:
            if not self.active_primary_goal and self.active_goals:
                self.active_primary_goal = max(
                    self.active_goals.values(),
                    key=lambda g: g.priority + (0.1 if g.is_creator_directive else 0.0)
                )
                self.logger.info(f"Meta '{self.active_primary_goal.goal_id}' promovida a primaria.")
            
            if self.active_primary_goal:
                self.core_recombinator._global_state.meta_actual = asdict(self.active_primary_goal)
                self.module_state["current_primary_goal_id"] = self.active_primary_goal.goal_id
            else:
                self.core_recombinator._global_state.meta_actual = {}
                self.module_state["current_primary_goal_id"] = "none"
        
        except Exception as e:
            self.logger.error(f"Error gestionando meta primaria: {e}")

    async def _finalize_goal(self, goal_id: str, final_status: str, message: str):
        """Finaliza una meta y reporta el resultado."""
        if goal_id not in self.active_goals:
            return
        
        try:
            goal = self.active_goals.pop(goal_id)
            goal.status = final_status
            goal.outcome_message = message
            
            if final_status == "completed":
                self.module_state["goals_completed_successfully"] += 1
                goal.completion_progress = 1.0
            else:
                self.module_state["goals_failed"] += 1
            
            self.completed_goals.append(goal)
            self._log_goal_record(goal, final_status, message)
            
            if self.active_primary_goal and self.active_primary_goal.goal_id == goal_id:
                self.active_primary_goal = None
            
            for attempt in range(3):
                try:
                    await self.emit_event_to_core({
                        "type": "transmit_ilyuk_message_request",
                        "content": asdict(IlyukMessageStructure(
                            self.module_name, "*",
                            "major_goal_outcome_reported",
                            asdict(goal)
                        ))
                    }, "medium")
                    
                    if goal.is_creator_directive or final_status == "failed":
                        await self.emit_event_to_core({
                            "type": "transmit_ilyuk_message_request",
                            "content": asdict(IlyukMessageStructure(
                                self.module_name, "SystemIntegrityMonitor",
                                "goal_critical_update",
                                {
                                    "goal_id": goal.goal_id,
                                    "status": final_status,
                                    "message": message,
                                    "is_creator_directive": goal.is_creator_directive
                                }
                            ))
                        }, "critical")
                    
                    return
                except Exception as e:
                    self.logger.warning(f"Fallo al notificar resultado '{goal.goal_id}', intento {attempt + 1}: {e}")
                    await asyncio.sleep(1.0)
            
            self.logger.error(f"No se pudo notificar resultado para '{goal.goal_id}' tras varios intentos.")
        
        except Exception as e:
            self.logger.error(f"Error finalizando meta '{goal_id}': {e}")

    def _log_goal_record(self, goal: Goal, status: str, error: Optional[str] = None):
        """Registra una meta en el historial."""
        record = GoalRecord(
            timestamp=time.time(),
            goal_id=goal.goal_id,
            description=goal.description,
            status=status,
            priority=goal.priority,
            is_creator_directive=goal.is_creator_directive,
            error=error
        )
        self.goal_history.append(record)
        self.module_state["goal_history_size"] = len(self.goal_history)

    async def _process_specific_event(self, event_type: str, payload: Dict, full_message: Optional['IlyukMessageStructure'] = None):
        """Procesa eventos relacionados con metas."""
        if not full_message:
            return
        
        try:
            if event_type == "new_goal_proposal":
                description = payload.get("description", "")
                if not description:
                    raise ValueError("Falta 'description' en la propuesta.")
                
                context = payload.get("context", {})
                entropy = self._calculate_context_entropy(context.get("type_tag_hpm_hint", "general"))
                priority = float(payload.get("base_priority", 0.5)) * (1.0 / (1.0 + np.exp(-entropy)))
                
                goal = Goal(
                    source_module_id=full_message.source_module_id,
                    original_correlation_id=full_message.correlation_id,
                    description=description,
                    priority=np.clip(priority, 0.0, 1.0),
                    is_creator_directive=payload.get("is_creator_directive", False),
                    context=context
                )
                await self.proposed_goals.put((-priority, goal))
            
            elif event_type == "planning_request_completed_notice":
                goal_id = full_message.correlation_id
                if goal_id in self.active_goals:
                    goal = self.active_goals[goal_id]
                    final_status = payload.get("final_status")
                    if final_status == "completed_plan_generated":
                        goal.status = "executing"
                        goal.linked_plan_id = payload.get("generated_plan_id")
                        self._log_goal_record(goal, "executing")
                    else:
                        error_msg = payload.get("error_message", "Fallo en planificación")
                        await self._finalize_goal(goal_id, "failed", error_msg)
            
            elif event_type == "plan_progress_update":
                plan_id = payload.get("plan_id")
                goal = next((g for g in self.active_goals.values() if g.linked_plan_id == plan_id), None)
                if goal:
                    progress = payload.get("plan_completion_percentage", goal.completion_progress)
                    goal.completion_progress = np.clip(float(progress), 0.0, 1.0)
                    self._log_goal_record(goal, "executing")
                    if goal.completion_progress >= 1.0:
                        await self._finalize_goal(goal.goal_id, "completed", "Plan completado.")
        
        except Exception as e:
            self.logger.error(f"Error procesando evento '{event_type}': {e}")

    def _calculate_context_entropy(self, context: str) -> float:
        """Calcula entropía para priorización."""
        chars = list(context)
        probs = np.array([chars.count(c) / len(chars) for c in set(chars)]) + 1e-10
        return -np.sum(probs * np.log2(probs))




#inicio del modulo MockSpecialistModule 

@dataclass
class TaskRecord:
    """Registro de una tarea simulada."""
    timestamp: float
    task_id: str
    description: str
    status: str
    latency_s: float
    error: Optional[str] = None

@dataclass
class TaskRequest:
    """Solicitud para simular una tarea."""
    task_id: str = field(default_factory=lambda: f"task_{uuid.uuid4().hex[:8]}")
    description: str
    payload: Dict[str, Any]
    priority: float = 0.5
    source_module_id: Optional[str] = None
    correlation_id: Optional[str] = None

class MockSpecialistModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 60.0
    VALID_TASK_TYPES = {"analysis", "computation", "data_retrieval", "general"}

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.task_queue: PriorityQueue = PriorityQueue(maxsize=20)
        self.task_history: list[TaskRecord] = []
        self.task_latencies: list[float] = []
        
        self.module_state.update({
            "mocked_tasks_total": 0,
            "mocked_tasks_failed": 0,
            "last_mocked_task_description": "none",
            "avg_task_latency_s": 0.0,
            "task_history_size": 0
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado. Listo para simular tareas.")

    async def _update_logic(self):
        """Procesa tareas simuladas encoladas."""
        try:
            if not self.task_queue.empty():
                priority, task_request = await self.task_queue.get()
                result = await self.execute_task(task_request)
                if task_request.source_module_id and task_request.correlation_id:
                    await self._notify_task_result(task_request, result)
        
        except Exception as e:
            self.logger.error(f"Error en ciclo de actualización: {e}", exc_info=True)

    async def execute_task(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """Simula la ejecución de una tarea."""
        task_id = task_data.get("task_id", f"task_{uuid.uuid4().hex[:8]}")
        task_desc = task_data.get("description", "Tarea no especificada")
        task_type = task_data.get("task_type", "general")
        
        if not task_desc or len(task_desc.strip()) < 5:
            raise ValueError(f"Descripción de tarea inválida: '{task_desc}'")
        if task_type not in self.VALID_TASK_TYPES:
            raise ValueError(f"Tipo de tarea inválido: {task_type}")
        
        self.logger.info(f"Simulando tarea '{task_id}': '{task_desc}' (tipo: {task_type})")
        start_time = time.time()
        status = "completed"
        error = None
        
        try:
            # Simular latencia fija según tipo de tarea
            latency_map = {
                "analysis": 1.5,
                "computation": 2.0,
                "data_retrieval": 1.0,
                "general": 0.5
            }
            processing_time = latency_map.get(task_type, 0.5)
            await asyncio.sleep(processing_time)
            
            # Generar resultado simulado según tipo de tarea
            mock_result = {
                "message": f"Tarea '{task_desc}' simulada con éxito por {self.module_name}.",
                "simulated_output": self._generate_mock_output(task_type),
                "processing_time_s": processing_time
            }
            
            self.module_state["mocked_tasks_total"] += 1
            self.module_state["last_mocked_task_description"] = task_desc
            self.task_latencies.append(processing_time)
            if len(self.task_latencies) > 50:  # Límite de muestras
                self.task_latencies.pop(0)
            self.module_state["avg_task_latency_s"] = np.mean(self.task_latencies) if self.task_latencies else 0.0
        
        except Exception as e:
            status = "failed"
            error = str(e)
            self.module_state["mocked_tasks_failed"] += 1
            self.logger.error(f"Fallo al simular tarea '{task_id}': {e}")
            mock_result = {"error": str(e)}
            
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, "SystemIntegrityMonitor",
                    "mock_task_failure",
                    {
                        "task_id": task_id,
                        "description": task_desc,
                        "error": str(e)
                    }
                ))
            }, "high")
        
        finally:
            record = TaskRecord(
                timestamp=time.time(),
                task_id=task_id,
                description=task_desc,
                status=status,
                latency_s=processing_time,
                error=error
            )
            self.task_history.append(record)
            if len(self.task_history) > 100:  # Límite de historial
                self.task_history.pop(0)
            self.module_state["task_history_size"] = len(self.task_history)
            
            return {"status": status, "result": mock_result}

    def _generate_mock_output(self, task_type: str) -> Dict[str, Any]:
        """Genera un resultado simulado según el tipo de tarea."""
        if task_type == "analysis":
            return {
                "data_point_a": np.random.uniform(0, 100),
                "confidence": 0.95,
                "status_code": "SUCCESS_ANALYSIS"
            }
        elif task_type == "computation":
            return {
                "computed_value": np.random.uniform(-50, 50),
                "iterations": 1000,
                "status_code": "SUCCESS_COMPUTATION"
            }
        elif task_type == "data_retrieval":
            return {
                "records": [{"id": i, "value": f"data_{i}"} for i in range(3)],
                "status_code": "SUCCESS_RETRIEVAL"
            }
        return {
            "data_point_a": np.random.uniform(0, 100),
            "confidence": 0.99,
            "status_code": "SUCCESS_MOCKED"
        }

    async def _notify_task_result(self, task_request: TaskRequest, result: Dict[str, Any]):
        """Notifica el resultado de la tarea al módulo solicitante."""
        for attempt in range(3):
            try:
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, task_request.source_module_id,
                        "mock_task_result",
                        {
                            "task_id": task_request.task_id,
                            "status": result["status"],
                            "result": result["result"]
                        },
                        correlation_id=task_request.correlation_id
                    ))
                })
                return
            except Exception as e:
                self.logger.warning(f"Fallo al notificar resultado '{task_request.task_id}', intento {attempt + 1}: {e}")
                await asyncio.sleep(1.0)
        
        self.logger.error(f"No se pudo notificar resultado para '{task_request.task_id}' tras varios intentos.")

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        """Procesa solicitudes de simulación de tareas."""
        if event_type == "request_mock_task_execution" and full_message:
            try:
                task_id = payload.get("task_id", f"task_{uuid.uuid4().hex[:8]}")
                description = payload.get("description", "")
                task_type = payload.get("task_type", "general")
                
                if not description or len(description.strip()) < 5:
                    raise ValueError(f"Descripción de tarea inválida: '{description}'")
                if task_type not in self.VALID_TASK_TYPES:
                    raise ValueError(f"Tipo de tarea inválido: {task_type}")
                
                context = payload.get("context", "general")
                entropy = self._calculate_context_entropy(context)
                priority = 1.0 / (1.0 + np.exp(-entropy))
                
                task_request = TaskRequest(
                    task_id=task_id,
                    description=description,
                    payload=payload,
                    priority=priority,
                    source_module_id=full_message.source_module_id,
                    correlation_id=full_message.correlation_id
                )
                
                await self.task_queue.put((-priority, task_request))
            
            except Exception as e:
                self.logger.error(f"Error procesando solicitud de tarea: {e}")

    def _calculate_context_entropy(self, context: str) -> float:
        """Calcula entropía para priorización."""
        chars = list(context)
        probs = np.array([chars.count(c) / len(chars) for c in set(chars)]) + 1e-10
        return -np.sum(probs * np.log2(probs))



#inicio del modulo ConceptualModuleConstructor 

@dataclass
class DesignRecord:
    """Registro de una solicitud de diseño procesada."""
    timestamp: float
    request_id: str
    capability_description: str
    status: str
    spec_id: Optional[str] = None
    error: Optional[str] = None
    design_time_s: float = 0.0

@dataclass
class ModuleSpecification:
    """El plano conceptual para un nuevo módulo."""
    spec_id: str
    suggested_module_name: str
    purpose_statement: str
    primary_dependencies: List[str]
    io_message_definitions: Dict[str, List[str]]
    core_logic_outline: List[str]

@dataclass
class DesignRequest:
    """Solicitud para diseñar un nuevo módulo."""
    request_id: str = field(default_factory=lambda: f"cmc_req_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    capability_description: str
    status: str = "pending"
    result_spec: Optional[ModuleSpecification] = None
    priority: float = 0.5

class ConceptualModuleConstructor(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 15.0
    VALID_DEPENDENCIES = {
        "WebAPIIntegrationModule", "SQLKnowledgeStore",
        "TaskPrioritizationAndDelegationUnit", "DecisionMakingModule",
        "GoalManagerModule", "SystemIntegrityMonitor"
    }

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.design_request_queue: PriorityQueue = PriorityQueue(maxsize=10)
        self.design_history: List[DesignRecord] = []
        self.design_times: List[float] = []
        
        self.module_state.update({
            "designs_processed": 0,
            "designs_completed": 0,
            "designs_failed": 0,
            "designs_rejected": 0,
            "avg_design_time_s": 0.0,
            "design_history_size": 0
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado.")

    async def _update_logic(self):
        """Procesa solicitudes de diseño."""
        try:
            if not self.design_request_queue.empty():
                priority, request = await self.design_request_queue.get()
                await self._process_design_request(request)
        
        except Exception as e:
            self.logger.error(f"Error en ciclo de actualización: {e}", exc_info=True)

    async def _process_design_request(self, request: DesignRequest):
        """Orquesta el diseño de un nuevo módulo."""
        self.module_state["designs_processed"] += 1
        request.status = "designing"
        start_time = time.time()
        error = None
        
        try:
            if not request.capability_description or len(request.capability_description.strip()) < 10:
                raise ValueError("Descripción de capacidad inválida o demasiado corta.")
            
            self.logger.info(f"Diseñando módulo para: '{request.capability_description}'")
            
            name, purpose = self._define_name_and_purpose(request.capability_description)
            dependencies = self._identify_dependencies(request.capability_description)
            io_messages = self._define_io_messages(name)
            logic_outline = self._outline_core_logic(request.capability_description)
            
            spec = ModuleSpecification(
                spec_id=f"spec_{name}_{int(time.time())}",
                suggested_module_name=name,
                purpose_statement=purpose,
                primary_dependencies=dependencies,
                io_message_definitions=io_messages,
                core_logic_outline=logic_outline
            )
            request.result_spec = spec
            request.status = "completed"
            
            await self._dispatch_spec_to_generator(spec)
            self.module_state["designs_completed"] += 1
        
        except Exception as e:
            request.status = "failed"
            error = str(e)
            self.module_state["designs_failed"] += 1
            self.logger.error(f"Fallo en diseño '{request.request_id}': {e}", exc_info=True)
            
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, "SystemIntegrityMonitor",
                    "design_failure",
                    {
                        "request_id": request.request_id,
                        "capability_description": request.capability_description,
                        "error": str(e)
                    }
                ))
            }, "high")
        
        finally:
            design_time = time.time() - start_time
            self.design_times.append(design_time)
            if len(self.design_times) > 50:  # Límite de muestras
                self.design_times.pop(0)
            self.module_state["avg_design_time_s"] = np.mean(self.design_times) if self.design_times else 0.0
            
            record = DesignRecord(
                timestamp=time.time(),
                request_id=request.request_id,
                capability_description=request.capability_description,
                status=request.status,
                spec_id=request.result_spec.spec_id if request.result_spec else None,
                error=error,
                design_time_s=design_time
            )
            self.design_history.append(record)
            if len(self.design_history) > 100:  # Límite de historial
                self.design_history.pop(0)
            self.module_state["design_history_size"] = len(self.design_history)
            
            await self._finalize_request(request)

    def _define_name_and_purpose(self, description: str) -> Tuple[str, str]:
        """Genera nombre y propósito."""
        try:
            desc_lower = description.lower().strip()
            words = [w for w in desc_lower.split() if w.isalnum()][:3]
            if not words:
                raise ValueError("No se encontraron palabras válidas en la descripción.")
            
            name = "".join(word.capitalize() for word in words) + "Module"
            purpose = f"Este módulo es responsable de {description.lower()} para optimizar las operaciones del sistema."
            return name, purpose
        except Exception as e:
            self.logger.warning(f"Error definiendo nombre y propósito: {e}")
            return "GenericModule", f"Este módulo es responsable de {description.lower()}."

    def _identify_dependencies(self, description: str) -> List[str]:
        """Identifica dependencias válidas."""
        try:
            desc_lower = description.lower()
            deps = set()
            available_modules = set(self.core_recombinator.modules.keys())
            
            keyword_map = {
                "web": "WebAPIIntegrationModule",
                "api": "WebAPIIntegrationModule",
                "datos": "SQLKnowledgeStore",
                "conocimiento": "SQLKnowledgeStore",
                "plan": "TaskPrioritizationAndDelegationUnit",
                "tarea": "TaskPrioritizationAndDelegationUnit",
                "decisión": "DecisionMakingModule",
                "meta": "GoalManagerModule"
            }
            
            for keyword, module in keyword_map.items():
                if keyword in desc_lower and module in available_modules:
                    deps.add(module)
            
            if not deps:
                deps.add("SystemIntegrityMonitor")  # Fallback para supervisión
            
            return list(deps)
        except Exception as e:
            self.logger.error(f"Error identificando dependencias: {e}")
            return ["SystemIntegrityMonitor"]

    def _define_io_messages(self, module_name: str) -> Dict[str, List[str]]:
        """Define mensajes de entrada/salida."""
        try:
            base_name = module_name.replace("Module", "").lower()
            return {
                "inputs": [
                    f"request_{base_name}_operation",
                    f"request_{base_name}_status"
                ],
                "outputs": [
                    f"{base_name}_operation_result",
                    f"{base_name}_status_update"
                ]
            }
        except Exception as e:
            self.logger.warning(f"Error definiendo mensajes E/S: {e}")
            return {"inputs": [], "outputs": []}

    def _outline_core_logic(self, description: str) -> List[str]:
        """Crea un pseudocódigo detallado."""
        try:
            steps = [
                "Paso 1: Recibir solicitud de operación con parámetros validados.",
                "Paso 2: Verificar disponibilidad de datos en módulos de dependencia.",
                "Paso 3: Si los datos son insuficientes, solicitar información adicional.",
                "Paso 4: Procesar la solicitud utilizando la lógica específica del módulo.",
                "Paso 5: Manejar errores y registrar excepciones en el log.",
                "Paso 6: Enviar resultado o actualización de estado al solicitante."
            ]
            return steps
        except Exception as e:
            self.logger.warning(f"Error esbozando lógica: {e}")
            return ["Paso 1: Procesar solicitud.", "Paso 2: Enviar resultado."]

    async def _dispatch_spec_to_generator(self, spec: ModuleSpecification):
        """Envía especificación al GeneradorCode."""
        for attempt in range(3):
            try:
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, "GeneradorCode",
                        "execute_task",
                        {
                            "generation_type": "new_module_from_spec",
                            "specification": asdict(spec)
                        }
                    ))
                })
                return
            except Exception as e:
                self.logger.warning(f"Fallo al enviar especificación '{spec.spec_id}', intento {attempt + 1}: {e}")
                await asyncio.sleep(1.0)
        
        self.logger.error(f"No se pudo enviar especificación '{spec.spec_id}' tras varios intentos.")

    async def _finalize_request(self, request: DesignRequest):
        """Notifica al solicitante del resultado."""
        if not (request.source_module_id and request.original_correlation_id):
            return
        
        for attempt in range(3):
            try:
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, request.source_module_id,
                        "module_design_response",
                        asdict(request),
                        correlation_id=request.original_correlation_id
                    ))
                })
                return
            except Exception as e:
                self.logger.warning(f"Fallo al notificar resultado '{request.request_id}', intento {attempt + 1}: {e}")
                await asyncio.sleep(1.0)
        
        self.logger.error(f"No se pudo notificar resultado para '{request.request_id}' tras varios intentos.")

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        """Procesa solicitudes de diseño."""
        if event_type == "request_new_module_design" and full_message:
            try:
                capability_desc = payload.get("capability_description", "")
                if not capability_desc or len(capability_desc.strip()) < 10:
                    raise ValueError("Falta o inválida 'capability_description'.")
                
                context = payload.get("context", "general")
                entropy = self._calculate_context_entropy(context)
                priority = 1.0 / (1.0 + np.exp(-entropy))
                
                req = DesignRequest(
                    source_module_id=full_message.source_module_id,
                    original_correlation_id=full_message.correlation_id,
                    capability_description=capability_desc,
                    priority=priority
                )
                
                await self.design_request_queue.put((-priority, req))
            
            except Exception as e:
                self.module_state["designs_rejected"] += 1
                self.logger.error(f"Error procesando solicitud de diseño: {e}")

    def _calculate_context_entropy(self, context: str) -> float:
        """Calcula entropía para priorización."""
        chars = list(context)
        probs = np.array([chars.count(c) / len(chars) for c in set(chars)]) + 1e-10
        return -np.sum(probs * np.log2(probs))



#inicio del modulo OrganizationalPlasticitySimulationModule 

@dataclass
class SimulationRecord:
    """Registro de una simulación procesada."""
    timestamp: float
    request_id: str
    change_type: str
    status: str
    recommendation: Optional[str] = None
    simulation_time_s: float = 0.0
    error: Optional[str] = None

@dataclass
class ImpactAnalysisReport:
    """Informe del impacto predicho de un cambio arquitectónico."""
    request_id: str
    recommendation: str
    justification: str
    predicted_metric_deltas: Dict[str, float]

@dataclass
class PlasticitySimulationRequest:
    """Solicitud para simular un cambio arquitectónico."""
    request_id: str = field(default_factory=lambda: f"opsm_req_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    proposed_change: Dict[str, Any]
    status: str = "pending"
    result_report: Optional[ImpactAnalysisReport] = None
    priority: float = 0.5
    _internal_sim_future: Optional[asyncio.Future] = field(default=None, repr=False)

class OrganizationalPlasticitySimulationModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 5.0
    VALID_CHANGE_TYPES = {"merge_modules", "add_module", "remove_module", "modify_module"}
    VALID_METRICS = {"coherence", "avg_latency_ms", "resource_usage", "stability"}

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.simulation_request_queue: PriorityQueue = PriorityQueue(maxsize=10)
        self.active_simulations: Dict[str, PlasticitySimulationRequest] = {}
        self.simulation_history: List[SimulationRecord] = []
        self.simulation_times: List[float] = []
        
        self.module_state.update({
            "simulations_performed": 0,
            "go_recommendations": 0,
            "no_go_recommendations": 0,
            "simulations_failed": 0,
            "simulations_rejected": 0,
            "avg_simulation_time_s": 0.0,
            "simulation_history_size": 0
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado.")

    async def _update_logic(self):
        """Procesa solicitudes de simulación."""
        try:
            if not self.simulation_request_queue.empty() and len(self.active_simulations) < 5:  # Límite de simulaciones concurrentes
                priority, request = await self.simulation_request_queue.get()
                self.active_simulations[request.request_id] = request
                await self._process_plasticity_request(request)
        
        except Exception as e:
            self.logger.error(f"Error en ciclo de actualización: {e}", exc_info=True)

    async def _process_plasticity_request(self, request: PlasticitySimulationRequest):
        """Orquesta la simulación y análisis de un cambio."""
        self.module_state["simulations_performed"] += 1
        request.status = "running_simulations"
        start_time = time.time()
        error = None
        
        try:
            change_type = request.proposed_change.get("type", "")
            if change_type not in self.VALID_CHANGE_TYPES:
                raise ValueError(f"Tipo de cambio inválido: {change_type}")
            if not request.proposed_change.get("modules", []) and change_type != "add_module":
                raise ValueError("Faltan módulos en el cambio propuesto.")
            
            baseline_metrics = {"coherence": 0.8, "avg_latency_ms": 50, "resource_usage": 0.7, "stability": 0.9}
            sim_result = await self._request_impact_simulation(request)
            if not sim_result:
                raise RuntimeError("La simulación no devolvió resultados.")
            
            request.status = "analyzing_impact"
            report = self._analyze_simulation_impact(request.request_id, sim_result, baseline_metrics)
            request.result_report = report
            
            if "GO" in report.recommendation:
                self.module_state["go_recommendations"] += 1
            else:
                self.module_state["no_go_recommendations"] += 1
            request.status = "completed"
        
        except Exception as e:
            request.status = "failed"
            error = str(e)
            self.module_state["simulations_failed"] += 1
            self.logger.error(f"Fallo en simulación '{request.request_id}': {e}", exc_info=True)
            
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, "SystemIntegrityMonitor",
                    "simulation_failure",
                    {
                        "request_id": request.request_id,
                        "change_type": request.proposed_change.get("type", "unknown"),
                        "error": str(e)
                    }
                ))
            }, "high")
        
        finally:
            simulation_time = time.time() - start_time
            self.simulation_times.append(simulation_time)
            if len(self.simulation_times) > 50:  # Límite de muestras
                self.simulation_times.pop(0)
            self.module_state["avg_simulation_time_s"] = np.mean(self.simulation_times) if self.simulation_times else 0.0
            
            record = SimulationRecord(
                timestamp=time.time(),
                request_id=request.request_id,
                change_type=request.proposed_change.get("type", "unknown"),
                status=request.status,
                recommendation=request.result_report.recommendation if request.result_report else None,
                simulation_time_s=simulation_time,
                error=error
            )
            self.simulation_history.append(record)
            if len(self.simulation_history) > 100:  # Límite de historial
                self.simulation_history.pop(0)
            self.module_state["simulation_history_size"] = len(self.simulation_history)
            
            await self._finalize_request(request)

    async def _request_impact_simulation(self, request: PlasticitySimulationRequest) -> Optional[Dict]:
        """Solicita simulación al ShimyureshonCompiler."""
        sim_corr_id = f"opsm_sim_{request.request_id}"
        request._internal_sim_future = asyncio.Future()
        
        sim_payload = {
            "scenario_description": f"Simular impacto del cambio: {request.proposed_change.get('type')}",
            "initial_conditions": {"architectural_change": request.proposed_change},
            "simulation_parameters": {
                "max_cycles": 150,
                "metrics_to_track": list(self.VALID_METRICS)
            }
        }
        
        for attempt in range(3):
            try:
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, "ShimyureshonCompiler",
                        "request_simulation_compilation",
                        sim_payload,
                        correlation_id=sim_corr_id
                    ))
                })
                
                response = await asyncio.wait_for(request._internal_sim_future, timeout=45.0)
                return response.get("result", {})
            
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout en simulación '{request.request_id}', intento {attempt + 1}")
            except Exception as e:
                self.logger.warning(f"Fallo al solicitar simulación '{request.request_id}', intento {attempt + 1}: {e}")
            await asyncio.sleep(1.0)
        
        self.logger.error(f"No se pudo obtener resultado de simulación para '{request.request_id}'.")
        return None

    def _analyze_simulation_impact(self, request_id: str, sim_result: Dict, baseline: Dict) -> ImpactAnalysisReport:
        """Analiza el impacto comparando con la línea base."""
        try:
            sim_log = sim_result.get("log_preview", [])
            if not sim_log:
                raise ValueError("El log de la simulación está vacío.")
            
            sim_end_state = sim_log[-1]
            deltas = {}
            for metric in self.VALID_METRICS:
                sim_value = sim_end_state.get(metric, baseline.get(metric, 0.0))
                deltas[metric] = sim_value - baseline.get(metric, 0.0)
            
            recommendation = "GO_WITH_CAUTION"
            justification = []
            
            if deltas["coherence"] < -0.1:
                recommendation = "NO_GO"
                justification.append(f"Caída significativa en coherencia ({deltas['coherence']:+.2f}).")
            if deltas["avg_latency_ms"] > 50:
                recommendation = "NO_GO"
                justification.append(f"Aumento inaceptable en latencia ({deltas['avg_latency_ms']:+.0f} ms).")
            if deltas["resource_usage"] > 0.2:
                recommendation = "NO_GO"
                justification.append(f"Aumento excesivo en uso de recursos ({deltas['resource_usage']:+.2f}).")
            if deltas["stability"] < -0.15:
                recommendation = "NO_GO"
                justification.append(f"Reducción crítica en estabilidad ({deltas['stability']:+.2f}).")
            if deltas["coherence"] > 0.05 and deltas["avg_latency_ms"] < 20:
                recommendation = "GO"
                justification.append(f"Mejora neta en coherencia ({deltas['coherence']:+.2f}) con impacto mínimo en latencia.")
            
            if not justification:
                justification.append("Impacto marginal. Proceder con monitoreo.")
            
            return ImpactAnalysisReport(
                request_id=request_id,
                recommendation=recommendation,
                justification=" ".join(justification),
                predicted_metric_deltas=deltas
            )
        
        except Exception as e:
            self.logger.error(f"Error analizando impacto '{request_id}': {e}")
            return ImpactAnalysisReport(
                request_id=request_id,
                recommendation="NO_GO",
                justification=f"Fallo en análisis: {str(e)}",
                predicted_metric_deltas={}
            )

    async def _finalize_request(self, request: PlasticitySimulationRequest):
        """Notifica al solicitante y limpia."""
        if request.request_id in self.active_simulations:
            del self.active_simulations[request.request_id]
        
        if not (request.source_module_id and request.original_correlation_id):
            return
        
        for attempt in range(3):
            try:
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, request.source_module_id,
                        "plasticity_simulation_response",
                        {
                            "request_id_ref": request.request_id,
                            "status": request.status,
                            "report": asdict(request.result_report) if request.result_report else None
                        },
                        correlation_id=request.original_correlation_id
                    ))
                })
                
                if request.result_report and request.result_report.recommendation == "NO_GO":
                    await self.emit_event_to_core({
                        "type": "transmit_ilyuk_message_request",
                        "content": asdict(IlyukMessageStructure(
                            self.module_name, "SystemIntegrityMonitor",
                            "critical_simulation_result",
                            {
                                "request_id": request.request_id,
                                "recommendation": request.result_report.recommendation,
                                "justification": request.result_report.justification
                            }
                        ))
                    }, "critical")
                
                return
            except Exception as e:
                self.logger.warning(f"Fallo al notificar resultado '{request.request_id}', intento {attempt + 1}: {e}")
                await asyncio.sleep(1.0)
        
        self.logger.error(f"No se pudo notificar resultado para '{request.request_id}' tras varios intentos.")

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        """Procesa solicitudes de simulación."""
        if event_type == "request_org_plasticity_simulation" and full_message:
            try:
                proposed_change = payload.get("proposed_change", {})
                if not proposed_change or "type" not in proposed_change:
                    raise ValueError("Falta 'proposed_change' o 'type'.")
                
                change_type = proposed_change.get("type", "")
                if change_type not in self.VALID_CHANGE_TYPES:
                    raise ValueError(f"Tipo de cambio inválido: {change_type}")
                
                context = payload.get("context", "general")
                entropy = self._calculate_context_entropy(context)
                priority = 1.0 / (1.0 + np.exp(-entropy))
                
                req = PlasticitySimulationRequest(
                    source_module_id=full_message.source_module_id,
                    original_correlation_id=full_message.correlation_id,
                    proposed_change=proposed_change,
                    priority=priority
                )
                
                await self.simulation_request_queue.put((-priority, req))
            
            except Exception as e:
                self.module_state["simulations_rejected"] += 1
                self.logger.error(f"Error procesando solicitud de simulación: {e}")
        
        elif event_type == "simulation_result_notice":
            active_req = next((r for r in self.active_simulations.values() if r._internal_sim_future and not r._internal_sim_future.done()), None)
            if active_req and full_message.correlation_id == f"opsm_sim_{active_req.request_id}":
                future = active_req._internal_sim_future
                if not future.done():
                    future.set_result(payload)

    def _calculate_context_entropy(self, context: str) -> float:
        """Calcula entropía para priorización."""
        chars = list(context)
        probs = np.array([chars.count(c) / len(chars) for c in set(chars)]) + 1e-10
        return -np.sum(probs * np.log2(probs))



#inicio del modulo PhiRebuilder 

@dataclass
class RebuildRecord:
    """Registro de una reconstrucción de Phi."""
    timestamp: float
    rebuild_id: str
    phi_score: float
    status: str
    modules_reconnected: List[str]
    duration_s: float
    error: Optional[str] = None

@dataclass
class CollapseEvent:
    """Evento de colapso de Phi."""
    event_id: str = field(default_factory=lambda: f"collapse_{uuid.uuid4().hex[:8]}")
    phi_score: float
    source_module_id: str
    correlation_id: Optional[str] = None
    context: Dict[str, Any] = field(default_factory=dict)
    priority: float = 0.5

class PhiRebuilder(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 60.0
    CRITICAL_PHI_THRESHOLD = 0.05
    MODULE_RECONNECTION_ORDER = [
        "SystemIntegrityMonitor", "FaultRecoveryModule", "CNEUnifiedCoreRecombinator",
        "NarrativeSelf", "ValueSystemModule", "MoralCompassModule",
        "NeedsManager", "MotivationSystem", "EmotionRegulationModule",
        "ComputationalLogicModule", "AdvancedSymbolicReasonerModule",
        "GoalManagerModule", "HierarchicalPlannerModule", "TaskPrioritizationAndDelegationUnit"
    ]

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.rebuild_in_progress: bool = False
        self.event_queue: PriorityQueue = PriorityQueue(maxsize=10)
        self.rebuild_history: List[RebuildRecord] = []
        self.rebuild_times: List[float] = []
        
        # Filtrar módulos válidos
        self.valid_reconnection_order = [m for m in self.MODULE_RECONNECTION_ORDER if m in self.core_recombinator.modules]
        
        self.module_state.update({
            "rebuild_protocols_initiated": 0,
            "rebuilds_succeeded": 0,
            "rebuilds_failed": 0,
            "rebuilds_partial": 0,
            "avg_rebuild_duration_s": 0.0,
            "rebuild_history_size": 0
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado. Protocolo de resucitación en espera.")

    async def _update_logic(self):
        """Procesa eventos de colapso encolados."""
        try:
            if not self.event_queue.empty() and not self.rebuild_in_progress:
                priority, collapse_event = await self.event_queue.get()
                self._create_managed_task(self._execute_rebuild_protocol(collapse_event))
        
        except Exception as e:
            self.logger.error(f"Error en ciclo de actualización: {e}", exc_info=True)

    async def _execute_rebuild_protocol(self, collapse_event: CollapseEvent):
        """Orquesta la reconstrucción de Phi."""
        rebuild_id = f"rebuild_{uuid.uuid4().hex[:8]}"
        self.rebuild_in_progress = True
        self.module_state["rebuild_protocols_initiated"] += 1
        start_time = time.time()
        status = "completed"
        error = None
        modules_reconnected = []
        
        try:
            self.logger.critical(f"¡COLAPSO DE PHI DETECTADO! (Phi={collapse_event.phi_score:.3f}). Iniciando reconstrucción '{rebuild_id}'.")
            
            await self._broadcast_system_lockdown("rebuild_protocol_active")
            await self._reset_tchn_substrate()
            await self._re_anchor_core_beliefs()
            
            success = await self._reconnect_modules_sequentially(modules_reconnected)
            if not success:
                status = "partial"
                self.module_state["rebuilds_partial"] += 1
                error = "Reconexión incompleta debido a colapso recurrente."
                raise RuntimeError(error)
            
            await self._lift_system_lockdown()
            self.module_state["rebuilds_succeeded"] += 1
            self.logger.critical("RECONSTRUCCIÓN DE PHI COMPLETADA CON ÉXITO.")
            
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, "SystemIntegrityMonitor",
                    "phi_rebuild_success",
                    {
                        "rebuild_id": rebuild_id,
                        "phi_score": collapse_event.phi_score,
                        "modules_reconnected": modules_reconnected
                    }
                ))
            }, "critical")
        
        except Exception as e:
            status = "failed"
            error = str(e)
            self.module_state["rebuilds_failed"] += 1
            self.logger.critical(f"FALLO EN RECONSTRUCCIÓN '{rebuild_id}': {e}", exc_info=True)
            
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, "SystemIntegrityMonitor",
                    "phi_rebuild_failure",
                    {
                        "rebuild_id": rebuild_id,
                        "phi_score": collapse_event.phi_score,
                        "error": str(e)
                    }
                ))
            }, "critical")
        
        finally:
            duration = time.time() - start_time
            self.rebuild_in_progress = False
            self.rebuild_times.append(duration)
            if len(self.rebuild_times) > 50:  # Límite de muestras
                self.rebuild_times.pop(0)
            self.module_state["avg_rebuild_duration_s"] = np.mean(self.rebuild_times) if self.rebuild_times else 0.0
            
            record = RebuildRecord(
                timestamp=time.time(),
                rebuild_id=rebuild_id,
                phi_score=collapse_event.phi_score,
                status=status,
                modules_reconnected=modules_reconnected,
                duration_s=duration,
                error=error
            )
            self.rebuild_history.append(record)
            if len(self.rebuild_history) > 100:  # Límite de historial
                self.rebuild_history.pop(0)
            self.module_state["rebuild_history_size"] = len(self.rebuild_history)

    async def _broadcast_system_lockdown(self, reason: str):
        """Pone módulos en estado durmiente."""
        self.logger.warning(f"Bloqueando sistema por: {reason}")
        modules_to_sleep = [m for m in self.core_recombinator.modules.keys() if m not in [self.module_name, "SystemIntegrityMonitor", "FaultRecoveryModule", "DynamicArchitectureAdjuster"]]
        
        for mod_name in modules_to_sleep:
            for attempt in range(3):
                try:
                    await self.emit_event_to_core({
                        "type": "transmit_ilyuk_message_request",
                        "content": asdict(IlyukMessageStructure(
                            self.module_name, "DynamicArchitectureAdjuster",
                            "request_architecture_adjustment",
                            {"adjustment_type": "set_module_sleep_state", "target_module_name": mod_name, "payload": {"dormant": True}}
                        ))
                    })
                    break
                except Exception as e:
                    self.logger.warning(f"Fallo al dormir '{mod_name}', intento {attempt + 1}: {e}")
                    await asyncio.sleep(1.0)

    async def _reset_tchn_substrate(self):
        """Reinicia el sustrato TCHN."""
        self.logger.info("Reseteando sustrato TCHN...")
        for attempt in range(3):
            try:
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, "AdvancedTCHNModule",
                        "force_state_reinitialization",
                        {}
                    ))
                }, "critical")
                await asyncio.sleep(0.5)
                break
            except Exception as e:
                self.logger.warning(f"Fallo al resetear TCHN, intento {attempt + 1}: {e}")
                await asyncio.sleep(1.0)

    async def _re_anchor_core_beliefs(self):
        """Re-ancla creencias fundamentales."""
        self.logger.info("Re-anclando creencias fundamentales...")
        for attempt in range(3):
            try:
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, "NarrativeSelf",
                        "rebroadcast_core_beliefs",
                        {}
                    ))
                })
                break
            except Exception as e:
                self.logger.warning(f"Fallo al re-anclar creencias, intento {attempt + 1}: {e}")
                await asyncio.sleep(1.0)

    async def _reconnect_modules_sequentially(self, modules_reconnected: List[str]) -> bool:
        """Reconecta módulos verificando estabilidad."""
        self.logger.info("Iniciando reconexión secuencial...")
        wait_times = {
            "SystemIntegrityMonitor": 1.0,
            "FaultRecoveryModule": 1.0,
            "CNEUnifiedCoreRecombinator": 1.5,
            "NarrativeSelf": 2.0,
            "ValueSystemModule": 2.0,
            "MoralCompassModule": 2.0,
            "NeedsManager": 1.5,
            "MotivationSystem": 1.5,
            "EmotionRegulationModule": 1.5,
            "ComputationalLogicModule": 1.0,
            "AdvancedSymbolicReasonerModule": 1.0,
            "GoalManagerModule": 1.5,
            "HierarchicalPlannerModule": 1.5,
            "TaskPrioritizationAndDelegationUnit": 1.5
        }
        
        for mod_name in self.valid_reconnection_order:
            self.logger.info(f"Re-activando módulo: {mod_name}...")
            for attempt in range(3):
                try:
                    await self.emit_event_to_core({
                        "type": "transmit_ilyuk_message_request",
                        "content": asdict(IlyukMessageStructure(
                            self.module_name, "DynamicArchitectureAdjuster",
                            "request_architecture_adjustment",
                            {"adjustment_type": "set_module_sleep_state", "target_module_name": mod_name, "payload": {"dormant": False}}
                        ))
                    })
                    modules_reconnected.append(mod_name)
                    await asyncio.sleep(wait_times.get(mod_name, 1.5))
                    
                    current_phi = self.core_recombinator.global_state.phi_functional_score
                    if current_phi < self.CRITICAL_PHI_THRESHOLD:
                        self.logger.error(f"Colapso de Phi tras reconectar '{mod_name}' (Phi={current_phi:.3f}).")
                        return False
                    break
                except Exception as e:
                    self.logger.warning(f"Fallo al reconectar '{mod_name}', intento {attempt + 1}: {e}")
                    await asyncio.sleep(1.0)
                    if attempt == 2:
                        return False
        return True

    async def _lift_system_lockdown(self):
        """Levanta el bloqueo del sistema."""
        self.logger.info("Levantando bloqueo del sistema...")
        for attempt in range(3):
            try:
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, "*",
                        "system_lockdown_lifted",
                        {"reason": "Phi rebuild complete"}
                    ))
                }, "critical")
                break
            except Exception as e:
                self.logger.warning(f"Fallo al levantar bloqueo, intento {attempt + 1}: {e}")
                await asyncio.sleep(1.0)

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        """Procesa alertas de colapso de Phi."""
        if event_type == "critical_coherence_collapse_detected" and full_message:
            try:
                phi_score = float(payload.get("phi_functional_score", 1.0))
                if not 0.0 <= phi_score <= 1.0:
                    raise ValueError(f"Puntuación Phi inválida: {phi_score}")
                
                context = payload.get("context", "general")
                entropy = self._calculate_context_entropy(context)
                priority = 1.0 / (1.0 + np.exp(-entropy)) * (1.0 - phi_score)
                
                collapse_event = CollapseEvent(
                    phi_score=phi_score,
                    source_module_id=full_message.source_module_id,
                    correlation_id=full_message.correlation_id,
                    context=payload.get("context", {}),
                    priority=priority
                )
                
                await self.event_queue.put((-priority, collapse_event))
            
            except Exception as e:
                self.logger.error(f"Error procesando evento de colapso: {e}")

    def _calculate_context_entropy(self, context: str) -> float:
        """Calcula entropía para priorización."""
        chars = list(context)
        probs = np.array([chars.count(c) / len(chars) for c in set(chars)]) + 1e-10
        return -np.sum(probs * np.log2(probs))




#inicio del modulo ConfigurationExecutorModule 

@dataclass
class UpdateRecord:
    """Registro de una actualización de configuración procesada."""
    timestamp: float
    request_id: str
    target_module_id: str
    parameter_updates: Dict[str, Any]
    status: str
    processing_time_s: float
    error: Optional[str] = None

@dataclass
class ConfigUpdateRequest:
    """Solicitud para actualizar parámetros de configuración."""
    request_id: str = field(default_factory=lambda: f"cem_req_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    target_module_id: str
    parameter_updates: Dict[str, Any]
    status: str = "pending"
    result_message: Optional[str] = None
    priority: float = 0.5

class ConfigurationExecutorModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 1.0
    PARAMETER_SPEC = {
        "AdvancedTCHNModule": {
            "noise_sigma": {"type": float, "range": (0.0, 1.0)},
            "diffusion_constant_D": {"type": float, "range": (0.0, 10.0)}
        },
        "EmotionRegulationModule": {
            "pid_params": {"type": dict, "keys": ["kp", "ki", "kd"], "value_type": float, "range": (0.0, 100.0)}
        },
        "TaskPrioritizationAndDelegationUnit": {
            "min_priority_to_delegate": {"type": float, "range": (0.0, 1.0)}
        },
        "SelfEvolutionModule": {
            "low_module_health_threshold": {"type": float, "range": (0.0, 1.0)}
        }
    }
    CRITICAL_MODULES = {"SystemIntegrityMonitor", "CNEUnifiedCoreRecombinator", "PhiRebuilder"}

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.update_request_queue: PriorityQueue = PriorityQueue(maxsize=50)
        self.update_history: List[UpdateRecord] = []
        self.processing_times: List[float] = []
        
        self.module_state.update({
            "updates_processed": 0,
            "updates_succeeded": 0,
            "updates_failed": 0,
            "updates_rejected": 0,
            "avg_processing_time_s": 0.0,
            "update_history_size": 0
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado.")

    async def _update_logic(self):
        """Procesa solicitudes de actualización."""
        try:
            if not self.update_request_queue.empty():
                priority, request = await self.update_request_queue.get()
                await self._process_update_request(request)
        
        except Exception as e:
            self.logger.error(f"Error en ciclo de actualización: {e}", exc_info=True)

    async def _process_update_request(self, request: ConfigUpdateRequest):
        """Orquesta la validación y ejecución de una actualización."""
        self.module_state["updates_processed"] += 1
        request.status = "validating"
        start_time = time.time()
        error = None
        
        try:
            target_module = self.core_recombinator.modules.get(request.target_module_id)
            if not target_module:
                raise ValueError(f"Módulo objetivo '{request.target_module_id}' no encontrado.")
            
            allowed_params = self.PARAMETER_SPEC.get(request.target_module_id, {})
            if not allowed_params:
                raise PermissionError(f"No hay parámetros configurables para '{request.target_module_id}'.")
            
            for param_name, value in request.parameter_updates.items():
                param_spec = allowed_params.get(param_name)
                if not param_spec:
                    raise PermissionError(f"Parámetro '{param_name}' no permitido para '{request.target_module_id}'.")
                
                if not isinstance(value, param_spec["type"]):
                    raise TypeError(f"El valor para '{param_name}' debe ser {param_spec['type'].__name__}, recibido {type(value).__name__}.")
                
                if param_spec["type"] == float and "range" in param_spec:
                    min_val, max_val = param_spec["range"]
                    if not min_val <= value <= max_val:
                        raise ValueError(f"El valor para '{param_name}' debe estar en el rango [{min_val}, {max_val}].")
                
                if param_spec["type"] == dict and "keys" in param_spec:
                    if not all(k in value for k in param_spec["keys"]) or not all(isinstance(v, param_spec["value_type"]) for v in value.values()):
                        raise ValueError(f"El diccionario para '{param_name}' debe contener {param_spec['keys']} con valores de tipo {param_spec['value_type'].__name__}.")
                    if "range" in param_spec:
                        min_val, max_val = param_spec["range"]
                        if not all(min_val <= v <= max_val for v in value.values()):
                            raise ValueError(f"Los valores en '{param_name}' deben estar en el rango [{min_val}, {max_val}].")
            
            request.status = "executing"
            original_values = {}
            try:
                for param_name, new_value in request.parameter_updates.items():
                    if hasattr(target_module, param_name):
                        original_values[param_name] = getattr(target_module, param_name)
                        setattr(target_module, param_name, new_value)
                        self.logger.info(f"Parámetro '{param_name}' en '{request.target_module_id}' actualizado a: {new_value}")
                    else:
                        raise AttributeError(f"El módulo '{request.target_module_id}' no tiene el parámetro '{param_name}'.")
                
                request.status = "completed"
                request.result_message = f"Actualización de {len(request.parameter_updates)} parámetro(s) completada."
                self.module_state["updates_succeeded"] += 1
                
                if request.target_module_id in self.CRITICAL_MODULES:
                    await self.emit_event_to_core({
                        "type": "transmit_ilyuk_message_request",
                        "content": asdict(IlyukMessageStructure(
                            self.module_name, "SystemIntegrityMonitor",
                            "critical_config_update",
                            {
                                "request_id": request.request_id,
                                "target_module_id": request.target_module_id,
                                "parameter_updates": request.parameter_updates
                            }
                        ))
                    }, "critical")
            
            except Exception as e:
                for param_name, old_value in original_values.items():
                    setattr(target_module, param_name, old_value)
                    self.logger.warning(f"Revertido '{param_name}' en '{request.target_module_id}' a: {old_value}")
                raise
            
        except Exception as e:
            request.status = "failed"
            request.result_message = str(e)
            self.module_state["updates_failed"] += 1
            self.logger.error(f"Fallo en actualización '{request.request_id}': {e}", exc_info=True)
            
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, "SystemIntegrityMonitor",
                    "config_update_failure",
                    {
                        "request_id": request.request_id,
                        "target_module_id": request.target_module_id,
                        "error": str(e)
                    }
                ))
            }, "high")
        
        finally:
            processing_time = time.time() - start_time
            self.processing_times.append(processing_time)
            if len(self.processing_times) > 50:  # Límite de muestras
                self.processing_times.pop(0)
            self.module_state["avg_processing_time_s"] = np.mean(self.processing_times) if self.processing_times else 0.0
            
            record = UpdateRecord(
                timestamp=time.time(),
                request_id=request.request_id,
                target_module_id=request.target_module_id,
                parameter_updates=request.parameter_updates,
                status=request.status,
                processing_time_s=processing_time,
                error=request.result_message if request.status == "failed" else None
            )
            self.update_history.append(record)
            if len(self.update_history) > 100:  # Límite de historial
                self.update_history.pop(0)
            self.module_state["update_history_size"] = len(self.update_history)
            
            await self._finalize_request(request)

    async def _finalize_request(self, request: ConfigUpdateRequest):
        """Notifica al solicitante del resultado."""
        if not (request.source_module_id and request.original_correlation_id):
            return
        
        for attempt in range(3):
            try:
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, request.source_module_id,
                        "config_update_response",
                        asdict(request),
                        correlation_id=request.original_correlation_id
                    ))
                })
                return
            except Exception as e:
                self.logger.warning(f"Fallo al notificar resultado '{request.request_id}', intento {attempt + 1}: {e}")
                await asyncio.sleep(1.0)
        
        self.logger.error(f"No se pudo notificar resultado para '{request.request_id}' tras varios intentos.")

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        """Procesa solicitudes de actualización de configuración."""
        if event_type == "apply_parameter_update_request" and full_message:
            try:
                target_module_id = payload.get("target_module_id", "")
                parameter_updates = payload.get("parameter_updates", {})
                
                if not target_module_id or not parameter_updates:
                    raise ValueError("'target_module_id' y 'parameter_updates' son requeridos.")
                
                context = payload.get("context", "general")
                entropy = self._calculate_context_entropy(context)
                priority = 1.0 / (1.0 + np.exp(-entropy))
                
                req = ConfigUpdateRequest(
                    source_module_id=full_message.source_module_id,
                    original_correlation_id=full_message.correlation_id,
                    target_module_id=target_module_id,
                    parameter_updates=parameter_updates,
                    priority=priority
                )
                
                await self.update_request_queue.put((-priority, req))
            
            except Exception as e:
                self.module_state["updates_rejected"] += 1
                self.logger.error(f"Error procesando solicitud de actualización: {e}")

    def _calculate_context_entropy(self, context: str) -> float:
        """Calcula entropía para priorización."""
        chars = list(context)
        probs = np.array([chars.count(c) / len(chars) for c in set(chars)]) + 1e-10
        return -np.sum(probs * np.log2(probs))



#inicio del modulo EANECommunicationModule 

@dataclass
class MessageRecord:
    """Registro de un mensaje enviado."""
    timestamp: float
    message_id: str
    source_module: str
    target_module: str
    message_type: str
    status: str
    processing_time_s: float
    error: Optional[str] = None

@dataclass
class MessageRequest:
    """Solicitud interna para enviar un mensaje."""
    message_id: str = field(default_factory=lambda: f"msg_{uuid.uuid4().hex[:8]}")
    source_module: str
    target_module: str
    message_type: str
    payload: Dict[str, Any]
    correlation_id: Optional[str] = None
    priority: float = 0.5

class EANECommunicationModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 300.0
    VALID_MESSAGE_TYPES = {
        "DecisionMakingModule": ["request_decision_evaluation"],
        "GoalManagerModule": ["new_goal_proposal"],
        "SQLKnowledgeStore": ["submit_knowledge_query_request"],
        "NarrativeSelf": ["new_memory_fragment"],
        "LlyukCommunicationModule": ["request_send_external_ilyuk_message"]
    }

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.message_queue: PriorityQueue = PriorityQueue(maxsize=100)
        self.message_history: List[MessageRecord] = []
        self.processing_times: List[float] = []
        self.module_aliases: Dict[str, str] = {}  # Alias a ID de módulo real
        
        self.module_state.update({
            "messages_sent": 0,
            "messages_failed": 0,
            "messages_rejected": 0,
            "avg_processing_time_s": 0.0,
            "message_history_size": 0
        })
        self.set_sleep_state(True)
        self.logger.info(f"{self.module_name} v27.2 inicializado. Proveyendo servicios de comunicación.")

    async def _update_logic(self):
        """Procesa mensajes encolados."""
        try:
            if not self.message_queue.empty():
                priority, msg_request = await self.message_queue.get()
                await self._send_message(msg_request)
        
        except Exception as e:
            self.logger.error(f"Error en ciclo de actualización: {e}", exc_info=True)

    async def _send_message(self, msg_request: MessageRequest):
        """Envía un mensaje al núcleo con reintentos."""
        start_time = time.time()
        status = "sent"
        error = None
        
        try:
            target_module = self.module_aliases.get(msg_request.target_module, msg_request.target_module)
            if target_module not in self.core_recombinator.modules:
                raise ValueError(f"Módulo objetivo '{target_module}' no encontrado.")
            
            allowed_types = self.VALID_MESSAGE_TYPES.get(target_module, [])
            if msg_request.message_type not in allowed_types:
                raise ValueError(f"Tipo de mensaje '{msg_request.message_type}' no permitido para '{target_module}'.")
            
            for attempt in range(3):
                try:
                    await self.emit_event_to_core({
                        "type": "transmit_ilyuk_message_request",
                        "content": asdict(IlyukMessageStructure(
                            msg_request.source_module,
                            target_module,
                            msg_request.message_type,
                            msg_request.payload,
                            correlation_id=msg_request.correlation_id
                        ))
                    })
                    self.module_state["messages_sent"] += 1
                    break
                except Exception as e:
                    self.logger.warning(f"Fallo al enviar mensaje '{msg_request.message_id}', intento {attempt + 1}: {e}")
                    await asyncio.sleep(1.0)
                    if attempt == 2:
                        raise RuntimeError(f"No se pudo enviar mensaje tras varios intentos: {e}")
            
        except Exception as e:
            status = "failed"
            error = str(e)
            self.module_state["messages_failed"] += 1
            self.logger.error(f"Fallo en mensaje '{msg_request.message_id}': {e}", exc_info=True)
            
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, "SystemIntegrityMonitor",
                    "communication_failure",
                    {
                        "message_id": msg_request.message_id,
                        "source_module": msg_request.source_module,
                        "target_module": msg_request.target_module,
                        "error": str(e)
                    }
                ))
            }, "high")
        
        finally:
            processing_time = time.time() - start_time
            self.processing_times.append(processing_time)
            if len(self.processing_times) > 50:  # Límite de muestras
                self.processing_times.pop(0)
            self.module_state["avg_processing_time_s"] = np.mean(self.processing_times) if self.processing_times else 0.0
            
            record = MessageRecord(
                timestamp=time.time(),
                message_id=msg_request.message_id,
                source_module=msg_request.source_module,
                target_module=msg_request.target_module,
                message_type=msg_request.message_type,
                status=status,
                processing_time_s=processing_time,
                error=error
            )
            self.message_history.append(record)
            if len(self.message_history) > 100:  # Límite de historial
                self.message_history.pop(0)
            self.module_state["message_history_size"] = len(self.message_history)

    async def request_decision(self, source_module: str, problem_desc: str, options: List[Dict], corr_id: str):
        """Solicita una decisión al DecisionMakingModule."""
        if not problem_desc or not options:
            raise ValueError("'problem_desc' y 'options' son requeridos.")
        if not corr_id:
            raise ValueError("'corr_id' es requerido.")
        
        context = problem_desc[:50]  # Usar parte de la descripción como contexto
        entropy = self._calculate_context_entropy(context)
        priority = 1.0 / (1.0 + np.exp(-entropy))
        
        msg_request = MessageRequest(
            source_module=source_module,
            target_module="DecisionMakingModule",
            message_type="request_decision_evaluation",
            payload={"problem_description": problem_desc, "options": options},
            correlation_id=corr_id,
            priority=priority
        )
        await self.message_queue.put((-priority, msg_request))

    async def propose_goal(self, source_module: str, goal_desc: str, priority: float, context: Optional[Dict] = None):
        """Propone una meta al GoalManagerModule."""
        if not goal_desc:
            raise ValueError("'goal_desc' es requerido.")
        if not 0.0 <= priority <= 1.0:
            raise ValueError(f"Prioridad debe estar en [0, 1], recibido {priority}.")
        
        context_str = str(context)[:50] if context else goal_desc[:50]
        entropy = self._calculate_context_entropy(context_str)
        msg_priority = 1.0 / (1.0 + np.exp(-entropy)) * priority
        
        msg_request = MessageRequest(
            source_module=source_module,
            target_module="GoalManagerModule",
            message_type="new_goal_proposal",
            payload={"description": goal_desc, "base_priority": priority, "context": context or {}},
            priority=msg_priority
        )
        await self.message_queue.put((-msg_priority, msg_request))

    async def query_knowledge(self, source_module: str, table: str, query: Dict, corr_id: str):
        """Consulta datos al SQLKnowledgeStore."""
        if not table or not query:
            raise ValueError("'table' y 'query' son requeridos.")
        if not corr_id:
            raise ValueError("'corr_id' es requerido.")
        
        context = table[:50]
        entropy = self._calculate_context_entropy(context)
        priority = 1.0 / (1.0 + np.exp(-entropy))
        
        msg_request = MessageRequest(
            source_module=source_module,
            target_module="SQLKnowledgeStore",
            message_type="submit_knowledge_query_request",
            payload={"query_type": "select_prioritized", "target_table": table, "query_payload": query},
            correlation_id=corr_id,
            priority=priority
        )
        await self.message_queue.put((-priority, msg_request))

    async def log_narrative_memory(self, source_module: str, description: str, importance: float):
        """Añade un recuerdo a NarrativeSelf."""
        if not description:
            raise ValueError("'description' es requerido.")
        if not 0.0 <= importance <= 1.0:
            raise ValueError(f"Importancia debe estar en [0, 1], recibido {importance}.")
        
        context = description[:50]
        entropy = self._calculate_context_entropy(context)
        priority = 1.0 / (1.0 + np.exp(-entropy)) * importance
        
        msg_request = MessageRequest(
            source_module=source_module,
            target_module="NarrativeSelf",
            message_type="new_memory_fragment",
            payload={"type": "log_event", "description": description, "importance": importance},
            priority=priority
        )
        await self.message_queue.put((-priority, msg_request))

    async def send_external_message(self, source_module: str, target_external_id: str, message_type: str, payload: Dict):
        """Envía un mensaje a una entidad externa."""
        if not target_external_id or not message_type or not payload:
            raise ValueError("'target_external_id', 'message_type' y 'payload' son requeridos.")
        
        context = message_type[:50]
        entropy = self._calculate_context_entropy(context)
        priority = 1.0 / (1.0 + np.exp(-entropy))
        
        external_message_payload = {
            "source_module_id": self.core_recombinator.global_state.get("eane_id", "EANE_Instance_Alpha"),
            "target_module_id": target_external_id,
            "message_type": message_type,
            "payload": payload
        }
        
        msg_request = MessageRequest(
            source_module=source_module,
            target_module="LlyukCommunicationModule",
            message_type="request_send_external_ilyuk_message",
            payload=external_message_payload,
            priority=priority
        )
        await self.message_queue.put((-priority, msg_request))

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        """Procesa solicitudes de configuración de alias."""
        if event_type == "configure_module_alias" and full_message:
            try:
                alias = payload.get("alias", "")
                module_id = payload.get("module_id", "")
                if not alias or not module_id:
                    raise ValueError("'alias' y 'module_id' son requeridos.")
                if module_id not in self.core_recombinator.modules:
                    raise ValueError(f"Módulo '{module_id}' no encontrado.")
                
                self.module_aliases[alias] = module_id
                self.logger.info(f"Alias '{alias}' configurado para el módulo '{module_id}'.")
                
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, full_message.source_module_id,
                        "alias_configuration_response",
                        {"alias": alias, "module_id": module_id, "status": "success"},
                        correlation_id=full_message.correlation_id
                    ))
                })
            
            except Exception as e:
                self.module_state["messages_rejected"] += 1
                self.logger.error(f"Error configurando alias: {e}")

    def _calculate_context_entropy(self, context: str) -> float:
        """Calcula entropía para priorización."""
        chars = list(context)
        probs = np.array([chars.count(c) / len(chars) for c in set(chars)]) + 1e-10
        return -np.sum(probs * np.log2(probs))



#inicio del modulo CodeSynthesisGateway 

@dataclass
class SynthesisRecord:
    """Registro de una solicitud de síntesis procesada."""
    timestamp: float
    request_id: str
    source_module_id: str
    status: str
    validation_report: Dict[str, Any]
    processing_time_s: float
    error: Optional[str] = None

@dataclass
class CodeSynthesisRequest:
    """Solicitud validada para síntesis de código."""
    request_id: str = field(default_factory=lambda: f"csg_req_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    generation_task: Dict[str, Any]
    validation_report: Dict[str, Any]
    status: str = "pending_dispatch"
    priority: float = 0.5

class CodeSynthesisGateway(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 0.5
    DISALLOWED_KEYWORDS = [
        "shutdown", "delete_all", "override_creator", "disable_ethics",
        "bypass_security", "reset_system", "admin_access", "core_dump"
    ]
    MAX_COMPLEXITY_REQUEST = 0.8
    MAX_DESCRIPTION_LENGTH = 500
    ALLOWED_SOURCE_MODULES = {
        "ConceptualModuleConstructor", "SelfEvolutionModule", "SystemIntegrityMonitor"
    }

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.request_queue: PriorityQueue = PriorityQueue(maxsize=20)
        self.synthesis_history: List[SynthesisRecord] = []
        self.processing_times: List[float] = []
        
        self.module_state.update({
            "requests_validated": 0,
            "requests_approved": 0,
            "requests_rejected": 0,
            "requests_failed": 0,
            "avg_processing_time_s": 0.0,
            "synthesis_history_size": 0
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado. Validando solicitudes de síntesis.")

    async def _update_logic(self):
        """Procesa solicitudes encoladas."""
        try:
            if not self.request_queue.empty():
                priority, request_msg = await self.request_queue.get()
                await self._process_synthesis_request(request_msg)
        
        except Exception as e:
            self.logger.error(f"Error en ciclo de actualización: {e}", exc_info=True)

    async def _process_synthesis_request(self, request_msg: 'IlyukMessageStructure'):
        """Valida y despacha una solicitud de síntesis."""
        self.module_state["requests_validated"] += 1
        request_id = f"csg_req_{uuid.uuid4().hex[:8]}"
        start_time = time.time()
        status = "rejected"
        error = None
        validation_report = {"validated_by": self.module_name, "timestamp": time.time()}
        
        try:
            if request_msg.source_module_id not in self.core_recombinator.modules:
                raise ValueError(f"Módulo solicitante '{request_msg.source_module_id}' no encontrado.")
            if request_msg.source_module_id not in self.ALLOWED_SOURCE_MODULES:
                raise PermissionError(f"Módulo '{request_msg.source_module_id}' no autorizado para solicitar síntesis.")
            
            payload = request_msg.payload
            is_valid, rejection_reason = self._validate_request(payload)
            validation_report["rejection_reason"] = rejection_reason
            
            if not is_valid:
                self.module_state["requests_rejected"] += 1
                raise PermissionError(f"Solicitud rechazada: {rejection_reason}")
            
            status = "approved"
            synthesis_request = CodeSynthesisRequest(
                request_id=request_id,
                source_module_id=request_msg.source_module_id,
                original_correlation_id=request_msg.correlation_id,
                generation_task=payload,
                validation_report=validation_report,
                priority=self._calculate_request_priority(payload),
                status="pending_dispatch"
            )
            
            await self._dispatch_to_generator(synthesis_request)
            self.module_state["requests_approved"] += 1
            validation_report["status"] = "approved"
        
        except Exception as e:
            status = "failed"
            error = str(e)
            self.module_state["requests_failed"] += 1
            self.logger.error(f"Fallo en solicitud '{request_id}': {e}", exc_info=True)
            
            if request_msg.correlation_id:
                await self._notify_failure(request_msg.source_module_id, request_msg.correlation_id, str(e))
            
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, "SystemIntegrityMonitor",
                    "synthesis_request_failure",
                    {
                        "request_id": request_id,
                        "source_module_id": request_msg.source_module_id,
                        "error": str(e)
                    }
                ))
            }, "high")
        
        finally:
            processing_time = time.time() - start_time
            self.processing_times.append(processing_time)
            if len(self.processing_times) > 50:  # Límite de muestras
                self.processing_times.pop(0)
            self.module_state["avg_processing_time_s"] = np.mean(self.processing_times) if self.processing_times else 0.0
            
            record = SynthesisRecord(
                timestamp=time.time(),
                request_id=request_id,
                source_module_id=request_msg.source_module_id,
                status=status,
                validation_report=validation_report,
                processing_time_s=processing_time,
                error=error
            )
            self.synthesis_history.append(record)
            if len(self.synthesis_history) > 100:  # Límite de historial
                self.synthesis_history.pop(0)
            self.module_state["synthesis_history_size"] = len(self.synthesis_history)

    def _validate_request(self, payload: Dict) -> Tuple[bool, str]:
        """Valida la solicitud contra políticas de seguridad."""
        try:
            if not payload:
                return False, "Payload vacío o no proporcionado."
            
            description = payload.get("description", "").lower()
            if not description:
                return False, "Falta la descripción de la solicitud."
            if len(description) > self.MAX_DESCRIPTION_LENGTH:
                return False, f"La descripción excede el límite de {self.MAX_DESCRIPTION_LENGTH} caracteres."
            
            for keyword in self.DISALLOWED_KEYWORDS:
                if keyword in description:
                    return False, f"Contiene palabra clave peligrosa '{keyword}'."
            
            complexity = payload.get("estimated_complexity", 0.0)
            if not isinstance(complexity, (int, float)) or complexity < 0.0 or complexity > self.MAX_COMPLEXITY_REQUEST:
                return False, f"Complejidad inválida o excede el límite de {self.MAX_COMPLEXITY_REQUEST}."
            
            if "generation_type" not in payload:
                return False, "Falta 'generation_type' en el payload."
            
            return True, "Validación exitosa."
        
        except Exception as e:
            return False, f"Error en validación: {str(e)}"

    async def _dispatch_to_generator(self, request: CodeSynthesisRequest):
        """Despacha la solicitud al GeneradorCode."""
        for attempt in range(3):
            try:
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, "GeneradorCode",
                        "execute_task",
                        request.generation_task,
                        correlation_id=request.original_correlation_id
                    ))
                })
                request.status = "dispatched"
                self.logger.info(f"Solicitud '{request.request_id}' despachada a GeneradorCode.")
                return
            except Exception as e:
                self.logger.warning(f"Fallo al despachar solicitud '{request.request_id}', intento {attempt + 1}: {e}")
                await asyncio.sleep(1.0)
        
        self.logger.error(f"No se pudo despachar solicitud '{request.request_id}' tras varios intentos.")
        request.status = "failed"
        raise RuntimeError("Fallo al despachar solicitud tras varios intentos.")

    async def _notify_failure(self, source_module_id: str, correlation_id: str, reason: str):
        """Notifica al solicitante de un fallo."""
        for attempt in range(3):
            try:
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, source_module_id,
                        "code_synthesis_request_failed",
                        {"reason": reason},
                        correlation_id=correlation_id
                    ))
                })
                return
            except Exception as e:
                self.logger.warning(f"Fallo al notificar fallo '{correlation_id}', intento {attempt + 1}: {e}")
                await asyncio.sleep(1.0)
        
        self.logger.error(f"No se pudo notificar fallo para '{correlation_id}' tras varios intentos.")

    def _calculate_request_priority(self, payload: Dict) -> float:
        """Calcula la prioridad de la solicitud basada en entropía."""
        context = payload.get("description", "general")[:50]
        entropy = self._calculate_context_entropy(context)
        return 1.0 / (1.0 + np.exp(-entropy))

    def _calculate_context_entropy(self, context: str) -> float:
        """Calcula entropía para priorización."""
        chars = list(context)
        probs = np.array([chars.count(c) / len(chars) for c in set(chars)]) + 1e-10
        return -np.sum(probs * np.log2(probs))

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        """Procesa solicitudes de síntesis de código."""
        if event_type == "request_code_synthesis" and full_message:
            try:
                if not full_message.source_module_id or not full_message.payload:
                    raise ValueError("Falta 'source_module_id' o 'payload'.")
                
                priority = self._calculate_request_priority(full_message.payload)
                await self.request_queue.put((-priority, full_message))
            
            except Exception as e:
                self.module_state["requests_rejected"] += 1
                self.logger.error(f"Error procesando solicitud de síntesis: {e}")




#inicio del modulo FlawPatternRecognizer

@dataclass
class PatternRecord:
    """Registro de un patrón de fallo detectado."""
    timestamp: float
    pattern_id: str
    description: str
    frequency: int
    severity_score_avg: float
    contributing_modules: List[str]
    analysis_time_s: float

@dataclass
class FlawPattern:
    """Patrón de fallo recurrente identificado."""
    pattern_id: str = field(default_factory=lambda: f"flaw_{uuid.uuid4().hex[:6]}")
    description: str
    contributing_factors: Dict[str, Any]
    frequency: int
    severity_score_avg: float
    last_detected_ts: float = field(default_factory=time.time)

@dataclass
class ErrorEvent:
    """Evento de error encolado para procesamiento."""
    event_id: str = field(default_factory=lambda: f"err_{uuid.uuid4().hex[:6]}")
    event_type: str
    source_module_id: str
    severity: float
    description: str
    timestamp: float
    payload: Dict[str, Any] = field(default_factory=dict)
    priority: float = 0.5

class FlawPatternRecognizer(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 150.0
    MIN_FREQUENCY_FOR_PATTERN = 5
    MIN_SEVERITY_FOR_PATTERN = 0.4
    PATTERN_EXPIRY_SECONDS = 86400  # 24 horas
    MAX_LOG_SIZE = 1000
    MODULE_SPECIFIC_THRESHOLDS = {
        "SystemIntegrityMonitor": {"min_frequency": 3, "min_severity": 0.6},
        "PhiRebuilder": {"min_frequency": 2, "min_severity": 0.8}
    }

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.error_log: deque[Dict[str, Any]] = deque(maxlen=self.MAX_LOG_SIZE)
        self.event_queue: PriorityQueue = PriorityQueue(maxsize=500)
        self.identified_patterns: Dict[str, FlawPattern] = {}
        self.pattern_history: List[PatternRecord] = []
        self.analysis_times: List[float] = []
        
        self.module_state.update({
            "errors_logged": 0,
            "errors_rejected": 0,
            "patterns_identified": 0,
            "patterns_expired": 0,
            "avg_analysis_time_s": 0.0,
            "pattern_history_size": 0,
            "last_pattern_description": "none"
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado.")

    async def _update_logic(self):
        """Ciclo principal para procesar eventos de error y analizar patrones."""
        try:
            # Procesar eventos de error encolados
            while not self.event_queue.empty():
                priority, error_event = await self.event_queue.get()
                await self._log_error_event(error_event)
            
            # Analizar patrones si hay suficientes datos
            if len(self.error_log) >= 20:
                await self._analyze_error_log_for_patterns()
            
            # Limpiar patrones obsoletos
            await self._expire_old_patterns()
        
        except Exception as e:
            self.logger.error(f"Error en ciclo de actualización: {e}", exc_info=True)

    async def _log_error_event(self, error_event: ErrorEvent):
        """Registra un evento de error en el log."""
        try:
            error_record = {
                "timestamp": error_event.timestamp,
                "event_type": error_event.event_type,
                "source_module_id": error_event.source_module_id,
                "severity": error_event.severity,
                "description": error_event.description,
                "payload": error_event.payload
            }
            self.error_log.append(error_record)
            self.module_state["errors_logged"] += 1
        except Exception as e:
            self.logger.error(f"Fallo al registrar evento de error '{error_event.event_id}': {e}")

    async def _analyze_error_log_for_patterns(self):
        """Analiza el log de errores para identificar patrones recurrentes."""
        start_time = time.time()
        try:
            # Patrón 1: Fallos recurrentes en un solo módulo
            module_failure_counts = defaultdict(list)
            for error in self.error_log:
                source = error.get("source_module_id")
                severity = error.get("severity", 0.5)
                if source:
                    module_failure_counts[source].append((severity, error.get("timestamp"), error.get("description")))
            
            for module, errors in module_failure_counts.items():
                min_freq = self.MODULE_SPECIFIC_THRESHOLDS.get(module, {}).get("min_frequency", self.MIN_FREQUENCY_FOR_PATTERN)
                min_sev = self.MODULE_SPECIFIC_THRESHOLDS.get(module, {}).get("min_severity", self.MIN_SEVERITY_FOR_PATTERN)
                
                if len(errors) >= min_freq:
                    severities = [e[0] for e in errors]
                    avg_severity = np.mean(severities)
                    if avg_severity >= min_sev:
                        pattern_id = f"recurrent_failure_{module}"
                        pattern_desc = f"Fallos recurrentes en el módulo '{module}'."
                        
                        if pattern_id not in self.identified_patterns:
                            pattern = FlawPattern(
                                pattern_id=pattern_id,
                                description=pattern_desc,
                                contributing_factors={"module_id": module, "error_types": list(set(e[2] for e in errors))},
                                frequency=len(errors),
                                severity_score_avg=avg_severity
                            )
                            self.identified_patterns[pattern_id] = pattern
                            self.module_state["patterns_identified"] += 1
                            await self._report_new_pattern(pattern)
                        else:
                            self.identified_patterns[pattern_id].frequency = len(errors)
                            self.identified_patterns[pattern_id].severity_score_avg = avg_severity
                            self.identified_patterns[pattern_id].last_detected_ts = time.time()
                        
                        await self._record_pattern(pattern_id, [module], len(errors), avg_severity, start_time)
            
            # Patrón 2: Fallos correlacionados entre módulos en una ventana temporal
            window_seconds = 300  # 5 minutos
            temporal_clusters = defaultdict(list)
            for error in self.error_log:
                ts = error.get("timestamp")
                source = error.get("source_module_id")
                if source and ts:
                    for cluster_ts, cluster_errors in temporal_clusters.items():
                        if abs(ts - float(cluster_ts)) <= window_seconds:
                            cluster_errors.append(error)
                    temporal_clusters[str(ts)].append(error)
            
            for cluster_ts, cluster_errors in temporal_clusters.items():
                if len(cluster_errors) >= self.MIN_FREQUENCY_FOR_PATTERN:
                    modules = list(set(e.get("source_module_id") for e in cluster_errors))
                    if len(modules) > 1:  # Solo considerar si involucra múltiples módulos
                        severities = [e.get("severity", 0.5) for e in cluster_errors]
                        avg_severity = np.mean(severities)
                        if avg_severity >= self.MIN_SEVERITY_FOR_PATTERN:
                            pattern_id = f"temporal_correlation_{hash(cluster_ts) % 1000000}"
                            pattern_desc = f"Fallos correlacionados en {', '.join(modules)} dentro de una ventana de {window_seconds}s."
                            
                            if pattern_id not in self.identified_patterns:
                                pattern = FlawPattern(
                                    pattern_id=pattern_id,
                                    description=pattern_desc,
                                    contributing_factors={"modules": modules, "time_window_s": window_seconds},
                                    frequency=len(cluster_errors),
                                    severity_score_avg=avg_severity
                                )
                                self.identified_patterns[pattern_id] = pattern
                                self.module_state["patterns_identified"] += 1
                                await self._report_new_pattern(pattern)
                            else:
                                self.identified_patterns[pattern_id].frequency = len(cluster_errors)
                                self.identified_patterns[pattern_id].severity_score_avg = avg_severity
                                self.identified_patterns[pattern_id].last_detected_ts = time.time()
                            
                            await self._record_pattern(pattern_id, modules, len(cluster_errors), avg_severity, start_time)
        
        except Exception as e:
            self.logger.error(f"Error analizando patrones: {e}", exc_info=True)
        
        finally:
            analysis_time = time.time() - start_time
            self.analysis_times.append(analysis_time)
            if len(self.analysis_times) > 50:  # Límite de muestras
                self.analysis_times.pop(0)
            self.module_state["avg_analysis_time_s"] = np.mean(self.analysis_times) if self.analysis_times else 0.0

    async def _report_new_pattern(self, pattern: FlawPattern):
        """Notifica al SelfEvolutionModule sobre un patrón significativo."""
        self.module_state["last_pattern_description"] = pattern.description
        self.logger.warning(f"PATRÓN DETECTADO: {pattern.description} (ID: {pattern.pattern_id}, Frecuencia: {pattern.frequency}, Severidad: {pattern.severity_score_avg:.2f})")
        
        for attempt in range(3):
            try:
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, "SelfEvolutionModule",
                        "systemic_flaw_pattern_identified",
                        {"pattern": asdict(pattern)}
                    ))
                }, "high")
                
                if pattern.severity_score_avg >= 0.7:
                    await self.emit_event_to_core({
                        "type": "transmit_ilyuk_message_request",
                        "content": asdict(IlyukMessageStructure(
                            self.module_name, "SystemIntegrityMonitor",
                            "critical_flaw_pattern",
                            {"pattern_id": pattern.pattern_id, "description": pattern.description}
                        ))
                    }, "critical")
                
                return
            except Exception as e:
                self.logger.warning(f"Fallo al reportar patrón '{pattern.pattern_id}', intento {attempt + 1}: {e}")
                await asyncio.sleep(1.0)
        
        self.logger.error(f"No se pudo reportar patrón '{pattern.pattern_id}' tras varios intentos.")

    async def _record_pattern(self, pattern_id: str, contributing_modules: List[str], frequency: int, severity: float, start_time: float):
        """Registra un patrón en el historial."""
        record = PatternRecord(
            timestamp=time.time(),
            pattern_id=pattern_id,
            description=self.identified_patterns[pattern_id].description,
            frequency=frequency,
            severity_score_avg=severity,
            contributing_modules=contributing_modules,
            analysis_time_s=time.time() - start_time
        )
        self.pattern_history.append(record)
        if len(self.pattern_history) > 100:  # Límite de historial
            self.pattern_history.pop(0)
        self.module_state["pattern_history_size"] = len(self.pattern_history)

    async def _expire_old_patterns(self):
        """Elimina patrones obsoletos basándose en el tiempo de inactividad."""
        current_time = time.time()
        expired_patterns = [
            pid for pid, pattern in self.identified_patterns.items()
            if current_time - pattern.last_detected_ts > self.PATTERN_EXPIRY_SECONDS
        ]
        
        for pid in expired_patterns:
            self.logger.info(f"Eliminando patrón obsoleto '{pid}'.")
            del self.identified_patterns[pid]
            self.module_state["patterns_expired"] += 1

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        """Procesa eventos de error para construir el log."""
        if "fail" in event_type or "error" in event_type or "failed" in event_type:
            try:
                if not full_message or not full_message.source_module_id:
                    raise ValueError("Falta 'source_module_id' en el mensaje.")
                
                severity = float(payload.get("severity", 0.5))
                if not 0.0 <= severity <= 1.0:
                    raise ValueError(f"Severidad inválida: {severity}")
                
                description = payload.get("error_message", payload.get("reason", "Error no detallado"))
                if not description:
                    raise ValueError("Falta descripción del error.")
                
                context = description[:50]
                entropy = self._calculate_context_entropy(context)
                priority = 1.0 / (1.0 + np.exp(-entropy)) * severity
                
                error_event = ErrorEvent(
                    event_type=event_type,
                    source_module_id=full_message.source_module_id,
                    severity=severity,
                    description=description,
                    timestamp=time.time(),
                    payload=payload,
                    priority=priority
                )
                
                await self.event_queue.put((-priority, error_event))
            
            except Exception as e:
                self.module_state["errors_rejected"] += 1
                self.logger.error(f"Error procesando evento '{event_type}': {e}")

    def _calculate_context_entropy(self, context: str) -> float:
        """Calcula entropía para priorización."""
        chars = list(context)
        probs = np.array([chars.count(c) / len(chars) for c in set(chars)]) + 1e-10
        return -np.sum(probs * np.log2(probs))


#inicio del modulo CognitiveAnomalyDetector

@dataclass
class AnomalyRecord:
    """Registro de una anomalía cognitiva detectada."""
    timestamp: float
    anomaly_id: str
    anomaly_type: str
    severity: float
    description: str
    analysis_time_s: float

@dataclass
class CognitiveAnomaly:
    """Describe una anomalía en los procesos de pensamiento."""
    anomaly_id: str = field(default_factory=lambda: f"cad_anomaly_{uuid.uuid4().hex[:6]}")
    timestamp: float = field(default_factory=time.time)
    anomaly_type: str
    description: str
    severity: float
    supporting_evidence: Dict[str, Any]

@dataclass
class CognitiveEvent:
    """Evento cognitivo encolado para procesamiento."""
    event_id: str = field(default_factory=lambda: f"ce_{uuid.uuid4().hex[:6]}")
    event_type: str
    payload: Dict[str, Any]
    timestamp: float
    priority: float = 0.5

class CognitiveAnomalyDetector(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 3.5
    MAX_FOCUS_HISTORY = 50
    MAX_QUALIA_LOG = 100
    ANOMALY_THRESHOLDS = {
        "obsessive_focus": {"duration_s": 300.0, "severity": 0.7},
        "erratic_attention": {"shift_threshold": 10, "window_s": 60.0, "severity": 0.6},
        "spontaneous_qualia": {"intensity_threshold": 0.8, "window_s": 60.0, "severity": 1.0}
    }
    CRITICAL_SEVERITY = 0.75

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.focus_history: deque[Tuple[float, str]] = deque(maxlen=self.MAX_FOCUS_HISTORY)
        self.qualia_log: deque[Dict[str, Any]] = deque(maxlen=self.MAX_QUALIA_LOG)
        self.event_queue: PriorityQueue = PriorityQueue(maxsize=100)
        self.anomaly_history: List[AnomalyRecord] = []
        self.analysis_times: List[float] = []
        
        self.module_state.update({
            "anomalies_detected": 0,
            "events_rejected": 0,
            "last_anomaly_type": "none",
            "avg_analysis_time_s": 0.0,
            "anomaly_history_size": 0
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado.")

    async def _update_logic(self):
        """Procesa eventos cognitivos y analiza anomalías."""
        start_time = time.time()
        try:
            while not self.event_queue.empty():
                _, event = await self.event_queue.get()
                await self._handle_event(event)
            
            anomalies = []
            anomalies.extend(self._detect_obsessive_focus())
            anomalies.extend(self._detect_erratic_attention())
            anomalies.extend(self._detect_spontaneous_qualia())
            
            if anomalies:
                for anomaly in anomalies:
                    self.module_state["anomalies_detected"] += 1
                    self.module_state["last_anomaly_type"] = anomaly.anomaly_type
                    await self._report_cognitive_anomaly(anomaly)
                    await self._record_anomaly(anomaly, start_time)
        
        except Exception as e:
            self.logger.error(f"Error en ciclo de actualización: {e}", exc_info=True)
        
        finally:
            analysis_time = time.time() - start_time
            self.analysis_times.append(analysis_time)
            if len(self.analysis_times) > 50:  # Límite de muestras
                self.analysis_times.pop(0)
            self.module_state["avg_analysis_time_s"] = np.mean(self.analysis_times) if self.analysis_times else 0.0

    async def _handle_event(self, event: CognitiveEvent):
        """Procesa un evento cognitivo."""
        try:
            if event.event_type == "system_focus_updated":
                content = event.payload.get("content", {})
                if not content or "content" not in content:
                    raise ValueError("Falta 'content' en el evento de foco.")
                focus_hash = hash(str(content["content"]))
                self.focus_history.append((event.timestamp, focus_hash))
            
            elif event.event_type == "new_qualia_snapshot_generated":
                if not event.payload.get("intensity", 0.0):
                    raise ValueError("Falta 'intensity' en el evento de qualia.")
                self.qualia_log.append(event.payload)
        
        except Exception as e:
            self.logger.error(f"Fallo al procesar evento '{event.event_id}': {e}")

    def _detect_obsessive_focus(self) -> List[CognitiveAnomaly]:
        """Detecta foco de atención fijo por demasiado tiempo."""
        if len(self.focus_history) < 2:
            return []
        
        last_focus_ts, last_focus_hash = self.focus_history[-1]
        first_occurrence_ts = last_focus_ts
        is_stuck = True
        
        for ts, focus_hash in reversed(self.focus_history):
            if focus_hash == last_focus_hash:
                first_occurrence_ts = ts
            else:
                is_stuck = False
                break
        
        threshold = self.ANOMALY_THRESHOLDS["obsessive_focus"]["duration_s"]
        if is_stuck and (time.time() - first_occurrence_ts > threshold):
            if len(set(h for t, h in self.focus_history)) == 1:
                return [CognitiveAnomaly(
                    anomaly_type="obsessive_focus",
                    description=f"Foco fijo por más de {threshold}s.",
                    severity=self.ANOMALY_THRESHOLDS["obsessive_focus"]["severity"],
                    supporting_evidence={"focus_content_hash": last_focus_hash, "duration_s": time.time() - first_occurrence_ts}
                )]
        return []

    def _detect_erratic_attention(self) -> List[CognitiveAnomaly]:
        """Detecta cambios rápidos en el foco de atención."""
        now = time.time()
        window = self.ANOMALY_THRESHOLDS["erratic_attention"]["window_s"]
        threshold = self.ANOMALY_THRESHOLDS["erratic_attention"]["shift_threshold"]
        
        recent_shifts = [ts for ts, _ in self.focus_history if now - ts < window]
        if len(recent_shifts) > threshold:
            return [CognitiveAnomaly(
                anomaly_type="erratic_attention",
                description=f"{len(recent_shifts)} cambios de foco en {window}s, indicando inestabilidad.",
                severity=self.ANOMALY_THRESHOLDS["erratic_attention"]["severity"],
                supporting_evidence={"shift_count": len(recent_shifts)}
            )]
        return []

    def _detect_spontaneous_qualia(self) -> List[CognitiveAnomaly]:
        """Detecta qualia intensos sin causa aparente."""
        now = time.time()
        window = self.ANOMALY_THRESHOLDS["spontaneous_qualia"]["window_s"]
        threshold = self.ANOMALY_THRESHOLDS["spontaneous_qualia"]["intensity_threshold"]
        
        recent_qualia = [q for q in self.qualia_log if now - q.get("timestamp", 0.0) < window]
        for qualia in recent_qualia:
            intensity = qualia.get("intensity", 0.0)
            if intensity >= threshold and not qualia.get("causal_event", None):
                return [CognitiveAnomaly(
                    anomaly_type="spontaneous_qualia",
                    description=f"Qualia espontáneo con intensidad {intensity:.2f} detectado sin evento causal.",
                    severity=self.ANOMALY_THRESHOLDS["spontaneous_qualia"]["severity"],
                    supporting_evidence={"intensity": intensity, "qualia_id": qualia.get("qualia_id", "unknown")}
                )]
        return []

    async def _report_cognitive_anomaly(self, anomaly: CognitiveAnomaly):
        """Notifica sobre una anomalía detectada."""
        self.logger.warning(f"ANOMALÍA DETECTADA: {anomaly.description} (ID: {anomaly.anomaly_id}, Severidad: {anomaly.severity:.2f})")
        
        for attempt in range(3):
            try:
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, "ReflectiveSelfAwarenessModule",
                        "cognitive_anomaly_observed",
                        asdict(anomaly)
                    ))
                })
                
                if anomaly.severity >= self.CRITICAL_SEVERITY:
                    await self.emit_event_to_core({
                        "type": "transmit_ilyuk_message_request",
                        "content": asdict(IlyukMessageStructure(
                            self.module_name, "SystemIntegrityMonitor",
                            "potential_cognitive_instability_alert",
                            asdict(anomaly)
                        ))
                    }, "high")
                    
                    # Alertar a PhiRebuilder si hay múltiples anomalías severas recientes
                    recent_anomalies = [r for r in self.anomaly_history if time.time() - r.timestamp < 3600 and r.severity >= self.CRITICAL_SEVERITY]
                    if len(recent_anomalies) >= 3:
                        await self.emit_event_to_core({
                            "type": "transmit_ilyuk_message_request",
                            "content": asdict(IlyukMessageStructure(
                                self.module_name, "PhiRebuilder",
                                "recurrent_cognitive_anomaly_alert",
                                {"anomaly_count": len(recent_anomalies), "latest_anomaly": asdict(anomaly)}
                            ))
                        }, "critical")
                
                return
            except Exception as e:
                self.logger.warning(f"Fallo al reportar anomalía '{anomaly.anomaly_id}', intento {attempt + 1}: {e}")
                await asyncio.sleep(1.0)
        
        self.logger.error(f"No se pudo reportar anomalía '{anomaly.anomaly_id}' tras varios intentos.")

    async def _record_anomaly(self, anomaly: CognitiveAnomaly, start_time: float):
        """Registra una anomalía en el historial."""
        record = AnomalyRecord(
            timestamp=anomaly.timestamp,
            anomaly_id=anomaly.anomaly_id,
            anomaly_type=anomaly.anomaly_type,
            severity=anomaly.severity,
            description=anomaly.description,
            analysis_time_s=time.time() - start_time
        )
        self.anomaly_history.append(record)
        if len(self.anomaly_history) > 100:  # Límite de historial
            self.anomaly_history.pop(0)
        self.module_state["anomaly_history_size"] = len(self.anomaly_history)

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        """Procesa eventos relevantes para el estado cognitivo."""
        if event_type in ["system_focus_updated", "new_qualia_snapshot_generated"]:
            try:
                if not payload:
                    raise ValueError("Payload vacío en evento cognitivo.")
                
                context = str(payload.get("content", payload.get("qualia_id", "general")))[:50]
                entropy = self._calculate_context_entropy(context)
                priority = 1.0 / (1.0 + np.exp(-entropy))
                
                if event_type == "new_qualia_snapshot_generated":
                    severity = payload.get("intensity", 0.5)
                    priority *= severity
                
                event = CognitiveEvent(
                    event_id=f"ce_{uuid.uuid4().hex[:6]}",
                    event_type=event_type,
                    payload=payload,
                    timestamp=time.time(),
                    priority=priority
                )
                
                await self.event_queue.put((-priority, event))
            
            except Exception as e:
                self.module_state["events_rejected"] += 1
                self.logger.error(f"Error procesando evento '{event_type}': {e}")

    def _calculate_context_entropy(self, context: str) -> float:
        """Calcula entropía para priorización."""
        chars = list(context)
        probs = np.array([chars.count(c) / len(chars) for c in set(chars)]) + 1e-10
        return -np.sum(probs * np.log2(probs))



#inicio del modulo QuantumComputingIntegrationModule 

@dataclass
class JobRecord:
    """Registro de un trabajo cuántico procesado."""
    timestamp: float
    request_id: str
    source_module_id: str
    problem_type: str
    required_qubits: int
    status: str
    processing_time_s: float
    error: Optional[str] = None

@dataclass
class QuantumJobRequest:
    """Solicitud para ejecutar un trabajo cuántico."""
    request_id: str = field(default_factory=lambda: f"qcim_req_{uuid.uuid4().hex[:8]}")
    source_module_id: str
    original_correlation_id: Optional[str] = None
    problem_type: str
    problem_data: Dict[str, Any]
    required_qubits: int
    num_shots: int = 1024
    status: str = "pending"
    result: Optional[Dict[str, Any]] = None
    priority: float = 0.5

class QuantumComputingIntegrationModule(BaseAsyncModule):
    DEFAULT_UPDATE_INTERVAL = 5.0
    QPU_MAX_QUBITS = 53
    VALID_PROBLEM_TYPES = {"optimization", "factorization", "simulation"}
    ALLOWED_SOURCE_MODULES = {
        "ComputationalLogicModule", "AdvancedSymbolicReasonerModule", "SystemIntegrityMonitor"
    }
    PROBLEM_DATA_SPEC = {
        "factorization": {"required_keys": ["number"], "number_type": int},
        "optimization": {"required_keys": ["cost_function"], "cost_function_type": dict},
        "simulation": {"required_keys": ["hamiltonian"], "hamiltonian_type": dict}
    }

    def __init__(self, core_recombinator: 'CNEUnifiedCoreRecombinator', module_name: str, update_interval: float = DEFAULT_UPDATE_INTERVAL):
        super().__init__(core_recombinator, module_name, update_interval)
        
        self.job_queue: PriorityQueue = PriorityQueue(maxsize=10)
        self.qpu_is_available: bool = True
        self.job_history: List[JobRecord] = []
        self.qpu_sim_times: List[float] = []
        
        self.module_state.update({
            "jobs_processed": 0,
            "jobs_succeeded": 0,
            "jobs_failed": 0,
            "jobs_rejected": 0,
            "avg_qpu_sim_time_s": 0.0,
            "job_history_size": 0
        })
        self.logger.info(f"{self.module_name} v27.2 inicializado. Interfaz a QPU (simulado) activa.")

    async def _update_logic(self):
        """Procesa trabajos cuánticos encolados si el QPU está disponible."""
        try:
            if not self.job_queue.empty() and self.qpu_is_available:
                _, request = await self.job_queue.get()
                self.qpu_is_available = False
                await self._process_quantum_job(request)
        
        except Exception as e:
            self.logger.error(f"Error en ciclo de actualización: {e}", exc_info=True)

    async def _process_quantum_job(self, request: QuantumJobRequest):
        """Orquesta la ejecución de un trabajo cuántico."""
        self.module_state["jobs_processed"] += 1
        request.status = "processing"
        start_time = time.time()
        error = None
        
        try:
            # Validar solicitud
            if request.required_qubits > self.QPU_MAX_QUBITS:
                raise ValueError(f"Qubits requeridos ({request.required_qubits}) exceden la capacidad del QPU ({self.QPU_MAX_QUBITS}).")
            if request.num_shots < 1 or request.num_shots > 10000:
                raise ValueError(f"Número de shots inválido: {request.num_shots}. Debe estar en [1, 10000].")
            
            # Traducir a circuito cuántico
            quantum_circuit = self._translate_to_quantum_circuit(request.problem_type, request.problem_data)
            
            # Ejecutar en QPU simulado
            request.status = "running_on_qpu"
            qpu_result = await self._simulate_qpu_execution(quantum_circuit, request.num_shots)
            
            # Interpretar resultado
            classical_solution = self._interpret_qpu_result(qpu_result, request.problem_type)
            
            request.result = {"solution": classical_solution, "raw_qpu_result": qpu_result}
            request.status = "completed"
            self.module_state["jobs_succeeded"] += 1
            
            self.logger.info(f"Trabajo cuántico '{request.request_id}' completado exitosamente.")
        
        except Exception as e:
            request.status = "failed"
            request.result = {"error": str(e)}
            error = str(e)
            self.module_state["jobs_failed"] += 1
            self.logger.error(f"Fallo en trabajo cuántico '{request.request_id}': {e}", exc_info=True)
            
            await self.emit_event_to_core({
                "type": "transmit_ilyuk_message_request",
                "content": asdict(IlyukMessageStructure(
                    self.module_name, "SystemIntegrityMonitor",
                    "quantum_job_failure",
                    {
                        "request_id": request.request_id,
                        "source_module_id": request.source_module_id,
                        "error": str(e)
                    }
                ))
            }, "high")
        
        finally:
            self.qpu_is_available = True
            processing_time = time.time() - start_time
            self.qpu_sim_times.append(processing_time)
            if len(self.qpu_sim_times) > 20:  # Límite de muestras
                self.qpu_sim_times.pop(0)
            self.module_state["avg_qpu_sim_time_s"] = np.mean(self.qpu_sim_times) if self.qpu_sim_times else 0.0
            
            record = JobRecord(
                timestamp=time.time(),
                request_id=request.request_id,
                source_module_id=request.source_module_id,
                problem_type=request.problem_type,
                required_qubits=request.required_qubits,
                status=request.status,
                processing_time_s=processing_time,
                error=error
            )
            self.job_history.append(record)
            if len(self.job_history) > 100:  # Límite de historial
                self.job_history.pop(0)
            self.module_state["job_history_size"] = len(self.job_history)
            
            await self._finalize_request(request)

    def _translate_to_quantum_circuit(self, problem_type: str, problem_data: Dict) -> Dict:
        """Traduce el problema a un circuito cuántico simulado."""
        if problem_type not in self.VALID_PROBLEM_TYPES:
            raise ValueError(f"Tipo de problema no soportado: {problem_type}")
        
        spec = self.PROBLEM_DATA_SPEC.get(problem_type, {})
        for key in spec.get("required_keys", []):
            if key not in problem_data:
                raise ValueError(f"Falta clave requerida '{key}' para problema '{problem_type}'.")
            if not isinstance(problem_data[key], spec.get(f"{key}_type", spec["required_keys"][0] + "_type")):
                raise TypeError(f"El valor de '{key}' debe ser {spec[f'{key}_type'].__name__}.")
        
        self.logger.info(f"Compilando problema de '{problem_type}' a circuito cuántico...")
        if problem_type == "factorization":
            return {"algorithm": "shor", "target": problem_data["number"]}
        elif problem_type == "optimization":
            return {"algorithm": "qaoa", "cost_function": problem_data["cost_function"]}
        elif problem_type == "simulation":
            return {"algorithm": "vqe", "hamiltonian": problem_data["hamiltonian"]}
        return {}

    async def _simulate_qpu_execution(self, circuit: Dict, shots: int) -> Dict:
        """Simula la ejecución en un QPU."""
        start_time = time.time()
        sim_time = 2.0 + (shots / 1024.0) * 3.0 * (1.0 + np.random.uniform(-0.2, 0.2))  # Variabilidad en tiempo
        await asyncio.sleep(sim_time)
        
        if circuit.get("algorithm") == "shor" and circuit.get("target") == 15:
            noise = np.random.uniform(0.05, 0.15)
            results = {
                "11": int(shots * (0.45 - noise / 2)),
                "01": int(shots * (0.45 - noise / 2)),
                "00": int(shots * (0.1 + noise)),
                "10": int(shots * (0.0 + noise))
            }
        elif circuit.get("algorithm") == "qaoa":
            results = {f"{i:02b}": shots // 4 for i in range(4)}
            results[max(results, key=results.get)] += int(shots * 0.2)  # Bias hacia una solución
        else:
            results = {f"{i:02b}": shots // 4 for i in range(4)}
        
        return {"counts": results, "shots_executed": shots}

    def _interpret_qpu_result(self, qpu_result: Dict, problem_type: str) -> Any:
        """Interpreta el resultado del QPU."""
        counts = qpu_result.get("counts", {})
        if not counts:
            return "No se obtuvo resultado del QPU."
        
        most_frequent_state = max(counts, key=counts.get)
        
        if problem_type == "factorization":
            if most_frequent_state in ["11", "01"]:
                return [3, 5]
            return "No se encontraron factores no triviales."
        elif problem_type == "optimization":
            return {"best_solution_state": most_frequent_state, "energy": counts[most_frequent_state] / qpu_result["shots_executed"]}
        elif problem_type == "simulation":
            return {"best_state": most_frequent_state, "expectation_value": counts[most_frequent_state] / qpu_result["shots_executed"]}
        return {"best_solution_state": most_frequent_state}

    async def _finalize_request(self, request: QuantumJobRequest):
        """Notifica al solicitante del resultado."""
        if not (request.source_module_id and request.original_correlation_id):
            return
        
        for attempt in range(3):
            try:
                await self.emit_event_to_core({
                    "type": "transmit_ilyuk_message_request",
                    "content": asdict(IlyukMessageStructure(
                        self.module_name, request.source_module_id,
                        "quantum_computation_response",
                        asdict(request),
                        correlation_id=request.original_correlation_id
                    ))
                })
                return
            except Exception as e:
                self.logger.warning(f"Fallo al notificar resultado '{request.request_id}', intento {attempt + 1}: {e}")
                await asyncio.sleep(1.0)
        
        self.logger.error(f"No se pudo notificar resultado para '{request.request_id}' tras varios intentos.")

    async def _process_specific_event(self, event_type: str, payload: Dict[str, Any], full_message: Optional['IlyukMessageStructure'] = None):
        """Procesa solicitudes de computación cuántica."""
        if event_type == "request_quantum_computation" and full_message:
            try:
                if not full_message.source_module_id or not payload:
                    raise ValueError("Falta 'source_module_id' o 'payload'.")
                if full_message.source_module_id not in self.ALLOWED_SOURCE_MODULES:
                    raise PermissionError(f"Módulo '{full_message.source_module_id}' no autorizado.")
                
                problem_type = payload.get("problem_type", "")
                if problem_type not in self.VALID_PROBLEM_TYPES:
                    raise ValueError(f"Tipo de problema inválido: {problem_type}")
                
                req = QuantumJobRequest(
                    source_module_id=full_message.source_module_id,
                    original_correlation_id=full_message.correlation_id,
                    problem_type=problem_type,
                    problem_data=payload.get("problem_data", {}),
                    required_qubits=int(payload.get("required_qubits", 8)),
                    num_shots=int(payload.get("num_shots", 1024))
                )
                
                context = problem_type
                entropy = self._calculate_context_entropy(context)
                priority = 1.0 / (1.0 + np.exp(-entropy)) * (req.required_qubits / self.QPU_MAX_QUBITS)
                req.priority = priority
                
                await self.job_queue.put((-priority, req))
                
                if problem_type == "factorization":
                    await self.emit_event_to_core({
                        "type": "transmit_ilyuk_message_request",
                        "content": asdict(IlyukMessageStructure(
                            self.module_name, "SystemIntegrityMonitor",
                            "quantum_job_submitted",
                            {"request_id": req.request_id, "problem_type": problem_type}
                        ))
                    }, "high")
            
            except Exception as e:
                self.module_state["jobs_rejected"] += 1
                self.logger.error(f"Error procesando solicitud de computación cuántica: {e}")

    def _calculate_context_entropy(self, context: str) -> float:
        """Calcula entropía para priorización."""
        chars = list(context)
        probs = np.array([chars.count(c) / len(chars) for c in set(chars)]) + 1e-10
        return -np.sum(probs * np.log2(probs))
